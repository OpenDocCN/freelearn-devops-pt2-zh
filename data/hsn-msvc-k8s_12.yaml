- en: Monitoring, Logging, and Metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控、日志记录和指标
- en: 'In this chapter, we will focus on the operational side of running a large-scale
    distributed system on Kubernetes, as well as on how to design the system and what
    to take into account to ensure top-notch operational posture. That being said,
    things will always go south and you must be ready to detect, troubleshoot, and
    respond as soon as possible. The operational best practices that Kubernetes provides
    out of the box include the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注在Kubernetes上运行大规模分布式系统的操作方面，以及如何设计系统以及要考虑什么以确保一流的操作姿态。也就是说，事情总会出现问题，你必须准备好尽快检测、解决问题并做出响应。Kubernetes提供的操作最佳实践包括以下内容：
- en: Self-healing
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自愈
- en: Auto scaling
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放
- en: Resource management
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源管理
- en: However, the cluster administrator and the developers must understand how these
    capabilities work, configure, and interact in order to understand them properly.
    There is always a balancing act between high availability, robustness, performance,
    security, and cost. It's also important to realize that all of these factors and
    the relationships between them change over time and must be revisited and evaluated
    regularly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，集群管理员和开发人员必须了解这些功能是如何工作的，如何配置和交互，以便正确理解它们。高可用性、健壮性、性能、安全性和成本之间总是需要权衡。重要的是要意识到所有这些因素及其之间的关系会随着时间的推移而发生变化，必须定期重新审视和评估。
- en: 'This is where monitoring comes in. Monitoring is all about understanding what''s
    going on with your system. There are several sources of information that are relevant
    for different purposes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是监控的作用。监控就是要了解系统的运行情况。有几个信息来源与不同的目的相关：
- en: '**Logging**: You explicitly log relevant information in your application code
    (and libraries you use may log too).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志记录**：您明确记录应用程序代码中的相关信息（您使用的库也可能会记录）。'
- en: '**Metrics**: Collect detailed information about your system such as CPU, memory,
    disk usage, disk I/O, network, and custom application metrics.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**：收集有关系统的详细信息，如CPU、内存、磁盘使用情况、磁盘I/O、网络和自定义应用程序指标。'
- en: '**Tracing**: Attach an ID to follow a request across multiple microservices.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：附加ID以跟踪请求跨多个微服务。'
- en: In this chapter, we will see how Go-kit, Kubernetes, and the ecosystem enable
    and support all the relevant use cases.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到Go-kit、Kubernetes和生态系统如何实现并支持所有相关的用例。
- en: 'The following topics are covered in this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Self-healing with Kubernetes
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes进行自愈
- en: Autoscaling a Kubernetes cluster
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放Kubernetes集群
- en: Provisioning resources with Kubernetes
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes配置资源
- en: Getting performance right
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确的性能
- en: Logging
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录
- en: Collecting metrics on Kubernetes
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes上收集指标
- en: Alerting
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 警报
- en: Distributed tracing
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式跨越
- en: Technical requirements
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will install several components into the cluster:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在集群中安装几个组件：
- en: '**Prometheus**: A metrics and alerting solution'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**：指标和警报解决方案'
- en: '**Fluentd**: A central logging agent'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fluentd**：中央日志代理'
- en: '**Jaeger**: A distributed tracing system'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jaeger**：分布式跟踪系统'
- en: The code
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: 'The code is split between two Git repositories:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 代码分为两个Git存储库：
- en: You can find the code samples here: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter12](https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter12)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在这里找到代码示例：[https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter12](https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter12)
- en: 'You can find the updated Delinkcious application here: [https://github.com/the-gigi/delinkcious/releases/tag/v0.10](https://github.com/the-gigi/delinkcious/releases/tag/v0.10)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在这里找到更新后的Delinkcious应用程序：[https://github.com/the-gigi/delinkcious/releases/tag/v0.10](https://github.com/the-gigi/delinkcious/releases/tag/v0.10)
- en: Self-healing with Kubernetes
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes进行自愈
- en: Self-healing is a very important property of large-scale systems made up of
    a myriad of physical and virtual components. Microservice-based systems running
    on large Kubernetes clusters are a prime example. Components can fail in multiple
    ways. The premise of self-healing is that the overall system will not fail and
    will be able to automatically heal itself, even if this causes it to operate in
    a reduced capacity temporarily.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自愈是由无数物理和虚拟组件构成的大规模系统的一个非常重要的属性。基于大型Kubernetes集群运行的微服务系统就是一个典型的例子。组件可能以多种方式失败。自愈的前提是整个系统不会失败，并且能够自动修复自己，即使这可能会导致系统在暂时的降低容量下运行。
- en: 'The building blocks of such reliable systems are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可靠系统的基本构建块如下：
- en: Redundancy
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冗余
- en: Observability
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观测性
- en: Auto-recovery
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动恢复
- en: The basic premise is that every component might fail – machines crash, disks
    get corrupted, network connections drop, configuration may get out of sync, new
    software releases have bugs, third-party services have outages, and so on. Redundancy
    means there are no **single point of failures** (**SPOFs**). You can run multiple
    replicas of many components, like nodes and pods, write data to multiple data
    stores, and deploy your system in multiple data centers, availability zones, or
    regions. You are even able to deploy your system on multiple cloud platforms (especially
    if you use Kubernetes). There is a limit to redundancy, of course. Total redundancy
    is very expansive. For example, running a complete redundant system on both AWS
    and GKE is probably a luxury that very few companies can afford or even need.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本前提是每个组件都可能失败 - 机器崩溃，磁盘损坏，网络连接中断，配置可能不同步，新软件发布存在错误，第三方服务中断等等。冗余意味着没有单点故障。您可以运行许多组件的多个副本，如节点和Pod，将数据写入多个数据存储，并在多个数据中心、可用区或地区部署系统。您甚至可以在多个云平台上部署系统（特别是如果您使用Kubernetes）。当然，冗余是有限的。完全的冗余非常昂贵。例如，在AWS和GKE上运行完全冗余的系统可能是很少有公司能够负担或甚至需要的奢侈品。
- en: Observability is the ability to detect when things go wrong. You must monitor
    your system and understand the signals you observe in order to detect abnormal
    situations. This is the first step before remediation and recovery can take place.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是检测出问题发生的能力。您必须监视您的系统，并了解您观察到的信号，以便检测异常情况。这是在进行补救和恢复之前的第一步。
- en: The automated part of auto healing and recovery is not needed in theory. You
    could have a team of operators watching a dashboard all day and take corrective
    action when they identify a problem. In practice, this approach doesn't scale.
    Humans are slow to respond, interpret, and act – not to mention that they are
    much more error-prone. That being said, most automated solutions start with manual
    processes that get automated later as the cost of repeated manual intervention
    becomes clear. If some issues happen only once in a blue moon, then it may be
    OK to address those with manual intervention.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化的自愈和恢复在理论上是不需要的。您可以有一个团队的操作员整天观察仪表板，并在识别出问题时采取纠正措施。实际上，这种方法是不可扩展的。人类反应、解释和行动都很慢
    - 更不用说他们更容易出错。也就是说，大多数自动化解决方案都是从后来成本重复手动干预变得清晰的手动流程开始的。如果某些问题只是偶尔发生，那么可能可以通过手动干预来解决。
- en: Let's discuss several failure modes and see how Kubernetes helps with all the
    pillars of self-healing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论几种故障模式，并看看Kubernetes如何帮助所有自愈的支柱。
- en: Container failures
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器故障
- en: Kubernetes runs containers inside pods. If a container dies for whatever reason,
    Kubernetes will detect it and restart it right away by default. The behavior of
    Kubernetes can be controlled by the `restartPolicy` file of the pod spec. The
    possible values are `Always` (default), `OnFailure`, and `Never`. Note that the
    restart policy applies to all the containers in the pod. There is no way to specify
    a restart policy per container. This seems a little short-sighted as you may have
    multiple containers in a pod that require a different restart policy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在pod内运行容器。如果容器因任何原因而死亡，Kubernetes将默认立即检测并重新启动它。Kubernetes的行为可以通过pod规范的`restartPolicy`文件来控制。可能的值为`Always`（默认值），`OnFailure`和`Never`。请注意，重启策略适用于pod中的所有容器。无法针对每个容器指定重启策略。这似乎有点短视，因为您可能在一个pod中有多个需要不同重启策略的容器。
- en: 'If a container keeps failing, it will enter a `CrashOff`. Let''s see this in
    action by introducing an intentional error to our API gateway:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个容器一直失败，它将进入`CrashOff`状态。让我们通过向API网关引入有意的错误来看看这种情况：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After performing a tilt up, we can see that the API gateway enters a `CrashLoopBackOff`
    state. This means that it keeps failing and Kubernetes keep restarting it. The
    backoff part is the delay between restart attempts. Kubernetes uses an exponential
    backoff delay starting at 10 seconds and doubling every time, up to a maximum
    delay of 5 minutes:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 进行倾斜后，我们可以看到API网关进入`CrashLoopBackOff`状态。这意味着它一直失败，Kubernetes一直重新启动它。回退部分是重新启动尝试之间的延迟。Kubernetes使用指数回退延迟，从10秒开始，每次加倍，最长延迟为5分钟：
- en: '![](assets/f2ee91c7-ecb9-417d-8dc5-6c168a71c5a5.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f2ee91c7-ecb9-417d-8dc5-6c168a71c5a5.png)'
- en: Crash loop backoff
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 崩溃循环回退
- en: This approach is very useful because if the failure was transient, then Kubernetes
    would self-heal by restarting the container until the transient issue went away.
    However, if the problem were to persist, then the container status and the error
    logs are around and provide observability that can be used by higher-level recovery
    processes or as a last resort by a human operator or developer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法非常有用，因为如果故障是暂时的，那么Kubernetes会通过重新启动容器来自我修复，直到暂时问题消失。但是，如果问题持续存在，那么容器状态和错误日志将保留下来，并提供可供高级恢复流程使用的可观察性，或者作为人为操作员或开发人员的最后手段。
- en: Node failure
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点故障
- en: When a node fails, all the pods on the node will become unavailable and Kubernetes
    will schedule them to run on other nodes in the cluster. Assuming you design your
    system with redundancy in place and the failed node is not a SPOF, the system
    should recover automatically. If the cluster has just a few nodes, then the loss
    of a node can be significant to the cluster's ability to handle traffic.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当节点失败时，节点上的所有pod将变得不可用，Kubernetes将安排它们在集群中的其他节点上运行。假设您设计的系统具有冗余性，并且失败的节点不是单点故障，系统应该会自动恢复。如果集群只有几个节点，那么节点的丢失对集群处理流量的能力可能会有重大影响。
- en: Systemic failures
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统性故障
- en: 'Sometimes, systemic failures take place. Some of these are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会发生系统性故障。其中一些如下：
- en: Total networking failure (entire cluster is unreachable)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总网络故障（整个集群无法访问）
- en: Data center outage
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中心故障
- en: Availability zone outage
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用性区域故障
- en: Region outage
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区域故障
- en: Cloud provider outage
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云服务提供商故障
- en: In these situations, you may not have redundancy by design (the cost-benefit
    ratio is not economical). The system will be down. Users will experience an outage.
    The important thing is not to lose or corrupt any data and be able to come back
    online as soon as the root cause is addressed. However, if it is important for
    your organization to stay online at all costs, Kubernetes will have options for
    you. The operative word is *will*, as in the future. The work on this is conducted
    under a project called federation v2, (v1 was deprecated as it suffered from too
    many problems.)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，你可能没有通过设计实现冗余（成本效益比不经济）。系统将会宕机。用户将会经历中断。重要的是不要丢失或损坏任何数据，并且能够在根本原因得到解决后尽快恢复在线。然而，如果你的组织必须以任何代价保持在线，Kubernetes将为你提供选项。操作词是*将*，即将来。这项工作是在一个名为联邦v2的项目下进行的（v1由于存在太多问题而被弃用）。
- en: You will be able to bring up a complete Kubernetes cluster or even a set of
    clusters in a different data center, a different availability zone, a different
    region, or even a different cloud provider. You will be able to run, manage, and
    treat those physically distributed clusters as a single logical cluster and, hopefully,
    fail over between those clusters seamlessly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你将能够在不同的数据中心、不同的可用性区域、不同的地区甚至不同的云提供商中启动一个完整的Kubernetes集群，甚至一组集群。你将能够将这些物理分布的集群作为一个单一的逻辑集群来运行、管理和处理，并且希望在这些集群之间无缝地进行故障转移。
- en: If you want to implement this kind of cluster-level redundancy, you may consider
    building it using the gardener ([https://gardener.cloud/](https://gardener.cloud/))
    project.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要实现这种集群级别的冗余，你可以考虑使用gardener（[https://gardener.cloud/](https://gardener.cloud/)）项目来构建它。
- en: Autoscaling a Kubernetes cluster
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动缩放Kubernetes集群
- en: Autoscaling is all about adapting your system to demand. This can mean adding
    more replicas to a deployment, expanding the capacity of existing nodes, or adding
    new nodes. While scaling your cluster up or down is not a failure, it follows
    the same pattern as self-healing. You can consider a cluster that is misaligned
    with demand as unhealthy. If the cluster is underprovisioned, then requests are
    not handled or wait too long, which can lead to timeouts or just poor performance.
    If the cluster is overprovisioned, then you're paying for resources you don't
    need. In both cases, you can consider the cluster as unhealthy, even if the pods
    and services themselves are up and running.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 自动缩放就是将你的系统调整到需求。这可能意味着向部署添加更多的副本，扩展现有节点的容量，或者添加新的节点。虽然扩展你的集群不是一个失败，但它遵循与自愈相同的模式。你可以将与需求不一致的集群视为不健康。如果集群配置不足，那么请求将无法处理或等待时间太长，这可能导致超时或性能不佳。如果集群配置过多，那么你将为你不需要的资源付费。在这两种情况下，即使pod和服务本身正在运行，你也可以将集群视为不健康。
- en: 'Just like with self-healing, you first need to detect that you need to scale
    your cluster, and then you can take the correct action. There are several ways
    to scale your cluster capacity: you can add more pods, you can add new nodes,
    and you can increase the capacity of existing nodes. Let''s review them in detail.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 就像自愈一样，你首先需要检测到你需要扩展你的集群，然后你可以采取正确的行动。有几种方法可以扩展集群的容量：你可以添加更多的pod，你可以添加新的节点，你可以增加现有节点的容量。让我们详细地回顾一下它们。
- en: Horizontal pod autoscaling
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水平pod自动缩放
- en: 'The horizontal pod autoscaler is a controller that is designed to adjust the
    number of pods in a deployment to match the load on those pods. The decision of
    whether a deployment should be scaled up (add pods) or down (remove pods) is based
    on metrics. Out of the box, the horizontal pod autoscaler supports CPU utilization,
    but custom metrics can be added too. The cool thing about the horizontal autoscaler
    is that it sits on top of the standard Kubernetes deployment and just adjusts
    its replica count. The deployment itself and the pods are blissfully unaware that
    they are being scaled:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 水平Pod自动缩放器是一个控制器，旨在根据Pod的负载调整部署中的Pod数量。是否应该扩展（增加Pod）或缩减（删除Pod）部署的决定基于指标。水平Pod自动缩放器默认支持CPU利用率，但也可以添加自定义指标。水平自动缩放器的好处在于它位于标准Kubernetes部署的顶部，只需调整其副本数量。部署本身和Pod都不知道它们正在被缩放：
- en: '![](assets/5adba37c-b6ff-470b-af58-1f0d64729baf.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5adba37c-b6ff-470b-af58-1f0d64729baf.png)'
- en: Horizontal pod autoscaler
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 水平Pod自动缩放器
- en: The preceding diagram illustrates how the horizontal autoscaler works.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表说明了水平自动缩放器的工作原理。
- en: Using the horizontal pod autoscaler
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用水平Pod自动缩放器
- en: 'We can use kubectl for autoscaling. Since the autoscaler relies on Heapster
    and the metrics server, we need to enable them using the `minikube addons` command.
    We have already enabled Heapster, so this should be good enough:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用kubectl进行自动缩放。由于自动缩放器依赖Heapster和度量服务器，我们需要使用`minikube addons`命令启用它们。我们已经启用了Heapster，所以这应该足够了：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We must also specify a CPU request in the pod spec of the deployment:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须在部署的Pod规范中指定CPU请求：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you may recall, a resource request is what Kubernetes promises it can provide
    to the container if it is ever scheduled. This way, the horizontal pod autoscaler
    can ensure that it will start a new pod only if it can provide this requested
    minimum of CPU to the new pod.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 资源请求是Kubernetes承诺可以为容器提供的资源。这样，水平Pod自动缩放器可以确保只有在能够为新Pod提供所请求的最低CPU时才会启动新的Pod。
- en: 'Let''s introduce some code that will cause the social graph manager to waste
    a lot of CPU:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍一些代码，这些代码将导致社交图管理器浪费大量的CPU：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, we are scaling the social graph manager between 1 and 5 pods based on
    CPU utilization of 50%:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们根据50%的CPU利用率在1到5个Pod之间调整社交图管理器：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After running a tilt up and deploying the CPU wasting code, the CPU utilization
    increased, and more and more pods were created up to the maximum of five. Here
    is a screenshot of the Kubernetes dashboard that shows the CPU, the pods, and
    the horizontal pod autoscaler:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 运行倾斜并部署浪费CPU的代码后，CPU利用率增加，越来越多的Pod被创建，最多达到五个。这是Kubernetes仪表板的屏幕截图，显示了CPU、Pod和水平Pod自动缩放器：
- en: '![](assets/81876839-787b-4c2a-a890-1802c792179d.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/81876839-787b-4c2a-a890-1802c792179d.png)'
- en: Hp dashboard
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Hp仪表板
- en: 'Let''s review the horizontal pod autoscaler itself:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看水平Pod自动缩放器本身：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see, the current load is `138%` of CPU utilization, which means that
    more than one CPU core is needed, which is greater than the 50%. Therefore, the
    social graph manager will keep running five pods (the maximum that's allowed).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，当前负载为CPU利用率的`138%`，这意味着需要超过一个CPU核心，这大于50%。因此，社交图管理器将继续运行五个Pod（允许的最大数量）。
- en: The horizontal pod autoscaler is a universal mechanism that has been part of
    Kubernetes for a long time. It depends on internal components only for collecting
    metrics. We've demonstrated the default CPU-based autoscaling here, but it can
    be configured to work based on multiple custom metrics, too. Now is a good time
    to look at some other autoscaling methods.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 水平 Pod 自动缩放器是 Kubernetes 的一个长期存在的通用机制。它仅依赖于内部组件来收集指标。我们在这里演示了默认的基于 CPU 的自动缩放，但它也可以配置为基于多个自定义指标工作。现在是时候看一些其他自动缩放方法了。
- en: Cluster autoscaling
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群自动缩放
- en: Pod autoscaling is a gift to developers and operators – there's no need for
    them to manually scale services up and down or write their own half-based autoscaling
    scripts. Kubernetes provides a robust solution that is well-designed, well-implemented,
    and battle tested. However, that leaves the question of cluster capacity. If Kubernetes
    tries to add more pods to your cluster, but the cluster is running at maximum
    capacity, then the pod autoscaler will fail. On the other hand, if you over-provision
    your cluster just in case the pod autoscaler needs to add a few more pods, then
    you're wasting money.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 自动缩放对开发人员和运维人员来说是一份礼物 - 他们不需要手动调整服务的规模或编写自己的半成品自动缩放脚本。Kubernetes 提供了一个经过良好设计、良好实现和经过实战测试的强大解决方案。然而，这就留下了集群容量的问题。如果
    Kubernetes 尝试向集群添加更多的 Pod，但集群已经运行到最大容量，那么 Pod 自动缩放器将失败。另一方面，如果您过度配置集群，以防 Pod 自动缩放器需要添加更多的
    Pod，那么您就是在浪费金钱。
- en: Enter the `auto-scaler` cluster ([https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 进入 `auto-scaler` 集群 ([https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler))。
- en: It is a Kubernetes project that has been generally available since Kubernetes
    1.8\. It works with GCP, AWS, Azure, AliCloud, and BaiduCloud. If GKE, EKS, and
    AKS give you a managed control plane (they take care of managing Kubernetes itself),
    then the cluster autoscaler gives you a managed data plane. It will add or remove
    nodes from your cluster based on your needs and your configuration.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个自 Kubernetes 1.8 版以来一直可用的 Kubernetes 项目。它适用于 GCP、AWS、Azure、AliCloud 和 BaiduCloud。如果
    GKE、EKS 和 AKS 为您提供了托管的控制平面（它们负责管理 Kubernetes 本身），那么集群自动缩放器为您提供了一个托管的数据平面。它将根据您的需求和配置向集群添加或删除节点。
- en: The trigger for adjusting the size of the cluster is when Kubernetes can't schedule
    pods due to insufficient resources. This works really well with the horizontal
    pod autoscaler. Together, the combination gives you a truly elastic Kubernetes
    cluster that can grow and shrink automatically (within bounds) to match the current
    load.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 调整集群大小的触发器是当 Kubernetes 由于资源不足而无法调度 Pod 时。这与水平 Pod 自动缩放器非常配合。结合起来，这种组合可以使您拥有一个真正弹性的
    Kubernetes 集群，可以根据当前负载自动增长和收缩（在一定范围内）。
- en: The cluster autoscaler is essentially very simple. It doesn't care why pods
    can't be scheduled. It will add nodes to the cluster as long as pods can't be
    scheduled. It will remove empty nodes or nodes that their pods can be rescheduled
    on other nodes. That being said, it is not a completely mindless mechanism.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动缩放器本质上非常简单。它不关心为什么无法调度 Pod。只要无法调度 Pod，它就会向集群添加节点。它会删除空节点或者它们的 Pod 可以被重新调度到其他节点上的节点。也就是说，它并不是一个完全没有头脑的机制。
- en: 'It is aware of several Kubernetes concepts and takes them into account when
    deciding to grow or shrink the cluster:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它了解几个 Kubernetes 概念，并在决定增长或收缩集群时考虑它们：
- en: PodDisruptionBudgets
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod 中断预算
- en: Overall resource constraints
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整体资源约束
- en: Affinity and anti-affinity
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亲和性和反亲和性
- en: Pod priorities and preemption
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod 优先级和抢占
- en: 'For example, if pods with best effort priority can''t be scheduled, the cluster
    autoscaler will not grow the cluster. In particular, it will not remove nodes
    that have one or more of these properties:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果无法调度具有最佳努力优先级的Pod，集群自动缩放器将不会扩展集群。特别是，它不会删除具有以下一个或多个属性的节点：
- en: Use local storage
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用本地存储
- en: 'Annotated with `"cluster-autoscaler.kubernetes.io/scale-down-disabled": "true"`'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '带有注释`"cluster-autoscaler.kubernetes.io/scale-down-disabled": "true"`'
- en: 'Host pods annotated `"cluster-autoscaler.kubernetes.io/safe-to-evict": "false"`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '主机Pod带有注释`"cluster-autoscaler.kubernetes.io/safe-to-evict": "false"`'
- en: Host nodes with restrictive `PodDisruptionBudget`
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有限制性`PodDisruptionBudget`的主机节点
- en: The total time for adding a node is typically less than 5 minutes. The cluster
    autoscaler scans for unscheduled pods every ten seconds and immediately provisions
    a new node if necessary. However, the cloud provider takes 3-4 minutes to provide
    and attach the node to the cluster.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 添加节点的总时间通常不到5分钟。集群自动缩放器每10秒扫描一次未调度的Pod，并在必要时立即提供新节点。但是，云提供商需要3-4分钟来提供并将节点附加到集群。
- en: 'Let''s move on to another form of autoscaling: vertical pod autoscaling.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们转向另一种形式的自动缩放：垂直Pod自动缩放。
- en: Vertical pod autoscaling
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垂直Pod自动缩放
- en: The vertical pod autoscaler is currently (Kubernetes 1.15) in its Beta stages.
    It takes on a different task related to autoscaling – fine-tuning your CPU and
    memory requests. Consider a pod that doesn't really do much and needs 100 MiB
    of memory, but it currently requests 500 MiB. First of all, it's a net waste of
    400 MiB of memory that is always allocated to the pod and is never used. However,
    the impact can be much greater. Because the pod is chunkier, it can prevent other
    pods from getting scheduled alongside it.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直Pod自动缩放器目前（Kubernetes 1.15）处于Beta阶段。它承担了与自动缩放相关的不同任务-微调CPU和内存请求。考虑一个实际上并不做太多事情并且需要100
    MiB内存的Pod，但它当前请求了500 MiB。首先，这是对分配给Pod的400 MiB内存的净浪费，而且从来没有被使用。然而，影响可能更大。因为Pod更加臃肿，它可能会阻止其他Pod在其旁边被调度。
- en: The vertical autoscaler addresses this problem by monitoring the actual CPU
    and memory usage of pods and adjusting their requests automatically. It also requires
    that you install the metrics server.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直自动缩放器通过监视Pod的实际CPU和内存使用情况并自动调整其请求来解决这个问题。它还要求您安装度量服务器。
- en: 'This is very cool. The vertical pod autoscaler works in several modes:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常酷。垂直Pod自动缩放器以几种模式工作：
- en: '**Initial**: Assigns resource requests when the pod is created'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始**: 在创建Pod时分配资源请求'
- en: '**Auto**: Assigns resource requests when the pod is created and also updates
    them during the pod''s lifetime'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动**: 在创建Pod时分配资源请求，并在Pod的生命周期中更新它们'
- en: '**Recreate**: Similar to Auto, the pod always restarts when its resource requests
    need to be updated'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重建**: 类似于Auto，当需要更新资源请求时，Pod总是重新启动'
- en: '**updatedOff**: Doesn''t modify the resource requests, but recommendations
    can be viewed'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**updatedOff**: 不修改资源请求，但可以查看建议'
- en: 'At the moment, Auto works just like Recreate and restarts the pods on every
    change. In the future, it will use an in-place update. Let''s take the vertical
    autoscaler for a spin. The installation is pretty rough and requires cloning the
    Git repository and running a shell script (that runs many other shell scripts):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Auto的工作方式与重建相同，并在每次更改时重新启动Pod。将来，它将使用原地更新。让我们来试试垂直自动缩放器。安装过程相当粗糙，需要克隆Git存储库并运行一个shell脚本（该脚本运行许多其他shell脚本）：
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It installs a service, two CRDs, and three pods:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 它安装了一个服务、两个CRD和三个Pod：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s create a VPA configuration file for the link manager deployment. We''ll
    set the mode to `Off` so that it only recommends on proper values of CPU and memory
    requests, but doesn''t actually set them:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为链接管理器部署创建一个VPA配置文件。我们将把模式设置为`Off`，这样它只会建议CPU和内存请求的适当值，但不会实际设置它们：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can create it and examine the recommendations:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建并检查建议：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: I don't recommend letting the vertical pod autoscaler loose on your system at
    this point. It is still in flux and has some serious limitations. The biggest
    one is that it can't run side by side with the horizontal pod autoscaler.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我不建议在这一点上让垂直Pod自动缩放器在你的系统上失控。它仍然在变化中，并且有一些严重的限制。最大的限制是它不能与水平Pod自动缩放器并行运行。
- en: An interesting approach, if you want to utilize it to fine-tune your resource
    requests, is to run it for a while on a test cluster that mimics your production
    cluster, turn off the horizontal pod autoscaler, and see how well it does.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的方法，如果你想利用它来微调你的资源请求，是在一个模拟你的生产集群的测试集群上运行一段时间，关闭水平Pod自动缩放器，看看它的表现如何。
- en: Provisioning resources with Kubernetes
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes配置资源
- en: Provisioning resources has traditionally been an operator or system administrator
    job. However, with the DevOps approach, developers are often tasked with self-provisioning.
    If the organization has a traditional IT department, they are often more concerned
    with what permissions developers should have for provisioning and what global
    limits should they set. In this section, we will look at the problem of resource
    provisioning from both viewpoints.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，资源的配置一直是操作员或系统管理员的工作。然而，采用DevOps方法后，开发人员经常被要求自行配置资源。如果组织有一个传统的IT部门，他们通常更关心开发人员应该具有什么权限来配置资源以及他们应该设置什么全局限制。在本节中，我们将从两个角度来看资源配置的问题。
- en: What resources should you provision?
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你应该配置什么资源？
- en: It's important to distinguish between Kubernetes resources and the underlying
    infrastructure resources they depend on. For Kubernetes resources, the Kubernetes
    API is the way to go. How you interact with the API is up to you, but I recommend
    that you generate YAML files and run them through `kubectl create` or `kubectl
    apply` as part of your CI/CD pipeline.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要区分Kubernetes资源和它们所依赖的基础设施资源。对于Kubernetes资源，Kubernetes API是一个好方法。你如何与API交互取决于你，但我建议你生成YAML文件，并在你的CI/CD流水线中通过`kubectl
    create`或`kubectl apply`来运行它们。
- en: Commands like `kubectl run` and `kubectl scale` are useful for interactive exploration
    of your cluster and running ad hoc tasks, but they go against the grain of declarative
    infrastructure as code.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 像`kubectl run`和`kubectl scale`这样的命令对于交互式地探索你的集群和运行临时任务是有用的，但它们违背了声明性基础设施即代码的原则。
- en: You could also directly hit the REST endpoints of the Kubernetes API or use
    a client library if you have a very complex CI/CD workflow that you implement
    using some higher-level programming language like Python. Even there, you can
    consider just invoking `kubectl`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以直接访问Kubernetes API的REST端点，或者如果你使用一些高级编程语言如Python实现非常复杂的CI/CD工作流程，可以使用客户端库。即使在那里，你也可以考虑只调用`kubectl`。
- en: Let's move on to the infrastructure layer that your cluster is running on. The
    primary resources are compute, memory, and storage. Nodes combine compute, memory,
    and local storage. Shared storage is provisioned separately. In the cloud, you
    may use pre-provisioned cloud storage. This means that your primary concern is
    to provision nodes and external storage for your cluster. But that's not all.
    You also need to connect all these nodes via a networking layer and consider permissions.
    The networking in a Kubernetes cluster is taken care of most of the time by a
    CNI provider. The famous flat networking model where each pod gets its own IP
    is one of the best features of Kubernetes and simplifies so many things for developers.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们转向您的集群正在运行的基础架构层。主要资源是计算、内存和存储。节点结合了计算、内存和本地存储。共享存储是单独配置的。在云中，您可能会使用预配置的云存储。这意味着您的主要关注点是为您的集群配置节点和外部存储。但这还不是全部。您还需要通过网络层连接所有这些节点，并考虑权限。Kubernetes集群中的网络大部分时间由CNI提供者负责。每个Pod都有自己的IP地址的著名的扁平网络模型是Kubernetes的最佳特性之一，它为开发人员简化了许多事情。
- en: Permissions and access are usually handled by **role-based access control**
    (**RBAC**) on Kubernetes, as we discussed at length in [Chapter 6](f7718dfe-8c96-495b-9089-36b9bbced4c8.xhtml),
    *Securing Microservices with Kubernetes*.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes上，权限和访问通常由**基于角色的访问控制**（**RBAC**）处理，正如我们在[第6章](f7718dfe-8c96-495b-9089-36b9bbced4c8.xhtml)中详细讨论的那样，《使用Kubernetes保护微服务》。
- en: It's very important to impose reasonable quotas and limits on resources given
    that we strive for automatic provisioning.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们努力实现自动配置的情况下，对资源施加合理的配额和限制非常重要。
- en: Defining container limits
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义容器限制
- en: 'On Kubernetes, we can define limits on CPU and memory per container. These
    ensure that the container will not use more than the limit. It serves two primary
    purposes:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes上，我们可以为每个容器定义CPU和内存限制。这确保容器不会使用超过限制的资源。它有两个主要目的：
- en: Prevents containers and pods on the same node from cannibalizing each other
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止同一节点上的容器和Pod相互争夺资源
- en: Helps Kubernetes schedule pods in the most efficient way by knowing the maximum
    amount of resources a pod will use
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过了解Pod将使用的最大资源量，帮助Kubernetes以最有效的方式调度Pod
- en: We've looked at limits from a security lens in [Chapter 6](f7718dfe-8c96-495b-9089-36b9bbced4c8.xhtml),
    *Securing Microservices on Kubernetes*. The emphasis was on controlling the blast
    radius. If a container is compromised, it can utilize more than the limit of resources
    configured for it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第6章](f7718dfe-8c96-495b-9089-36b9bbced4c8.xhtml)中从安全角度审视了限制，《在Kubernetes上保护微服务》。重点是控制爆炸半径。如果容器受到损害，它可能会利用为其配置的资源限制以上的资源。
- en: 'Here is an example of setting CPU and memory limits for the `user-manager`
    service. It follows the best practice of setting both resource limits and resource
    requests to the same values:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为`user-manager`服务设置CPU和内存限制的示例。它遵循了将资源限制和资源请求设置为相同值的最佳实践：
- en: '[PRE10]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Setting container limits is very useful, but it doesn't help with the problem
    of runaway allocation of many pods or other resources. This is where resource
    quotas come in.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 设置容器限制非常有用，但它无法解决许多Pod或其他资源的不受控制的分配问题。这就是资源配额发挥作用的地方。
- en: Specifying resource quotas
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定资源配额
- en: 'Kubernetes lets you specify quotas per namespace. There are different types
    of quotas you can set, for example, CPU, memory, and counts of various objects,
    including persistent volume claims. Let''s set some quotas for the default namespace
    of Delinkcious:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes允许您针对每个命名空间指定配额。您可以设置不同类型的配额，例如CPU、内存和各种对象的计数，包括持久卷索赔。让我们为Delinkcious的默认命名空间设置一些配额：
- en: '[PRE11]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is the command to apply to `quota`:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是应用于`quota`的命令：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we can check the resource quota objects for the actual usage and compare
    it to the quota to see how close we are:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以检查实际使用的资源配额对象，并将其与配额进行比较，以查看我们的接近程度：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Obviously, this resource quota is far beyond the current utilization of the
    cluster. That's fine. It doesn't allocate or reserve any resources. It just means
    that the quota is not very restricting.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这个资源配额远远超出了集群的当前使用情况。这没关系。它不分配或保留任何资源。这只是意味着配额并不是非常限制性的。
- en: There are many more nuances and options for resource quotas. There are scopes
    that apply the resource quota for resources with certain conditions or states
    (`Terminating`, `NotTerminating`, `BestEffort`, and `NotBestEffort`). There are
    resources that are quota-specific to certain priority classes. The gist is that
    you can get pretty granular and provide resource quota policies to control the
    resource allocation in your cluster, even in the face of mistakes in configuration
    or attacks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 资源配额还有许多微妙和选项。有适用于具有特定条件或状态（`Terminating`、`NotTerminating`、`BestEffort`和`NotBestEffort`）的资源的范围。有些资源是特定于某些优先级类别的配额。要点是，您可以变得非常精细，并提供资源配额策略来控制集群中的资源分配，即使在配置错误或攻击的情况下。
- en: At this point, we have got our bases covered with resource quotas and can move
    on to actually provisioning resources. There are several ways to do this, and
    we may want to employ some, if not all of them, for complicated systems.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经覆盖了资源配额，并可以继续实际配置资源。有几种方法可以做到这一点，对于复杂的系统，我们可能希望使用其中一些，如果不是全部。
- en: Manual provisioning
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动配置
- en: Manual provisioning sounds like an anti-pattern, but in practice it is useful
    in several situations; for example, if you are managing on-premises cluster where
    you physically have to provision servers, wire them together, and install storage
    too. Another common use case is during development when you want to develop your
    automated provisioning, but you have an interactive experiment (probably not in
    production). However, even in production, if you discover some misconfiguration
    or another issue, you may need to respond by manually provisioning some resources
    to address the crisis.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 手动配置听起来像是一种反模式，但在实践中在几种情况下是有用的；例如，如果您正在管理物理上必须配置服务器、将它们连接在一起并安装存储的本地集群。另一个常见的用例是在开发过程中，当您想要开发自己的自动配置，但又需要进行交互式实验（可能不是在生产环境）。然而，即使在生产环境中，如果您发现了一些错误配置或其他问题，您可能需要通过手动配置一些资源来应对危机。
- en: Utilizing autoscaling
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用自动缩放
- en: On the cloud, it is highly recommended to use the autoscaling solutions we discussed
    earlier. The horizontal pod autoscaler is a no-brainer. The cluster autoscaler
    is great too, if your cluster deals with a very dynamic workload and you don't
    want to overprovision on a regular basis. The vertical autoscaler is probably
    best for fine-tuning your resource requests at this point.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上，强烈建议使用我们之前讨论过的自动缩放解决方案。水平Pod自动缩放器是一个不错的选择。集群自动缩放器也很棒，如果您的集群处理非常动态的工作负载，并且您不想经常过度配置。垂直自动缩放器可能是在这一点上对资源请求进行微调的最佳选择。
- en: Rolling your own automated provisioning
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化配置自己的资源
- en: If you have more sophisticated needs, you can always roll your own. Kubernetes
    encourages both running your own controllers that can watch for different events
    and respond by provisioning some resources or even running some tools locally,
    or as part of your CI/CD pipeline, that check the state of the cluster and make
    some provisioning decisions.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有更复杂的需求，您总是可以自己动手。Kubernetes鼓励同时运行自己的控制器，可以监视不同的事件并通过配置一些资源或者在本地运行一些工具来响应，或者作为您的CI/CD流水线的一部分，检查集群的状态并做出一些配置决策。
- en: Once your cluster is properly provisioned, you should start thinking about performance.
    Performance is interesting because there are so many trade-offs you need to take
    into account.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的集群得到了适当的配置，你应该开始考虑性能问题。性能很有趣，因为你需要考虑很多权衡。
- en: Getting performance right
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正确理解性能
- en: 'Performance is important for many reasons, which we will delve into soon. It
    is very important to understand when is the right time to try and improve performance.
    My guiding principle is: make it work, make it right, make it fast. That is, first,
    just get the system to do whatever it needs to do, however slow and clunky. Then,
    clean up the architecture and the code. Now, you are ready to take on performance
    and consider refactoring, changes, and many other factors that can impact performance.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 性能之所以重要，有很多原因，我们很快就会深入探讨。了解何时是尝试提高性能的合适时机非常重要。我的指导原则是：让它工作，让它正确，让它快。也就是说，首先，让系统做任何需要做的事情，无论多么慢和笨拙。然后，清理架构和代码。现在，你准备好提高性能并考虑重构、变化以及其他可能影响性能的因素了。
- en: But there is a preliminary step for performance improvements, and that's profiling
    and benchmarking. Trying to improve performance without measuring what you try
    to improve is just like trying to make your code work correctly without writing
    any tests. Not only is it futile, but, even if you actually got lucky and improved
    the performance, how would you know without measurements?
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，性能改进有一个初步步骤，那就是性能分析和基准测试。试图在没有衡量你尝试改进的内容的情况下提高性能，就好像试图让你的代码在没有编写任何测试的情况下正确运行一样。这不仅是徒劳的，而且，即使你真的幸运地提高了性能，没有测量，你怎么知道呢？
- en: Let's understand something about performance. It makes everything complicated.
    However, it is often a necessary evil. Improving performance is important when
    it affects the user experience or cost. To make things worse, improving the user
    experience often comes at a cost. Finding the sweet spot is difficult. Unfortunately,
    the sweet spot doesn't stay put. Your system evolves, the number of users grow,
    technologies change, and the costs of your resources change. For example, a small
    social media startup has no business building its own data centers, but a social
    media giant like Facebook now designs their own custom servers to squeeze a little
    bit more performance and save costs. Scale changes a lot.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解一些关于性能的事情。它使一切变得复杂。然而，它通常是一个必要的恶。当性能影响用户体验或成本时，提高性能就变得重要。更糟糕的是，提高用户体验通常是有成本的。找到平衡点很困难。不幸的是，平衡点不会固定不变。你的系统会发展，用户数量会增长，技术会改变，资源成本也会改变。例如，一个小型社交媒体初创公司没有必要建立自己的数据中心，但像Facebook这样的社交媒体巨头现在设计他们自己的定制服务器来挤出更多性能并节省成本。规模变化很大。
- en: The bottom line is, that in order to make those decisions, you must understand
    how your system works and be able to measure every component and the impact on
    the performance of changes that have been made to your system.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 底线是，为了做出这些决定，你必须了解你的系统如何运作，并能够衡量每个组件以及对系统性能产生影响的变化。
- en: Performance and user experience
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和用户体验
- en: The user experience is all about perceived performance. How fast do I see pretty
    pictures on my screen after I click a button? Obviously, you can improve the real
    performance of your system, buy faster hardware, run things in parallel, improve
    your algorithms, upgrade your dependencies to newer and more performant versions,
    and so on. But, very often, it is more about smarter architecture and doing less
    work by adding caches, providing approximate results, and pushing work to the
    client. Then, there are methods like pre-fetching, where you try to do work before
    it is needed in order to anticipate the user's needs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 用户体验完全取决于感知性能。我点击按钮后，我在屏幕上看到漂亮的图片需要多快？显然，你可以通过改进系统的实际性能来提高性能，购买更快的硬件，以并行方式运行任务，改进算法，将依赖项升级到更新和更高性能的版本等等。但是，很多时候，更多的是关于更智能的架构，通过添加缓存、提供近似结果和将工作推送到客户端来减少工作量。然后，还有预取的方法，你可以在需要之前尝试做一些工作，以预测用户的需求。
- en: User experience decisions can significantly impact performance. Consider a chat
    program where the clients constantly poll the server every second for every keystroke
    versus just checking once every minute for new messages. That's a different user
    experience with a 60x performance price tag.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 用户体验决策可以显著影响性能。比如考虑一个聊天程序，客户端每秒钟不断地轮询服务器以获取每次按键操作，与每分钟只检查一次新消息的用户体验是不同的，后者的性能成本是前者的60倍。
- en: Performance and high availability
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和高可用性
- en: One of the worst routine things that can happen on a system is a timeout. A
    timeout means that the user will not get an answer on time. A timeout means that
    you did a lot of work that is now wasted. You may have retry logic and the user
    will eventually get their answer, but performance will take a hit. When your system
    and all its components are highly available (as well as not overloaded), you can
    minimize the occurrence of timeouts. If your system is very redundant, you can
    even send the same request multiple times to different backends and, whenever
    one of them responds, you have the answer.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 系统中最糟糕的例行事务之一就是超时。超时意味着用户无法及时得到答案。超时意味着你做了很多工作，现在都白费了。你可能有重试逻辑，用户最终会得到答案，但性能会受到影响。当你的系统及其所有组件都具有高可用性（并且没有过载）时，你可以最大程度地减少超时的发生。如果你的系统非常冗余，甚至可以将相同的请求多次发送到不同的后端，每当其中一个响应时，你就有了答案。
- en: On the other hand, a highly available and redundant system sometimes requires
    syncing with all the shards/backends (or at least a quorum) to make sure you have
    the latest, most up-to-date answer. Of course, inserting or updating data is also
    more complicated and often takes longer on a highly available system. If the redundancy
    is across multiple availability zones, regions, or continents, it can add orders
    of magnitude to the response time.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一个高可用和冗余的系统有时需要与所有分片/后端（或至少是多数派）同步，以确保你拥有最新的、最新的答案。当然，在高可用系统上插入或更新数据也更加复杂，通常需要更长的时间。如果冗余跨越多个可用区、地区或大陆，响应时间可能会增加数个数量级。
- en: Performance and cost
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和成本
- en: Performance and cost have a very interesting relationship. There are many ways
    to improve performance. Some of them reduce costs, like optimizing your code,
    compressing the data you send, or pushing computation to the client. However,
    other ways to improve performance increase the cost, like running on stronger
    hardware, replicating your data to multiple locations close to your client, and
    pre-fetching unrequested data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 性能和成本之间有着非常有趣的关系。有许多方法可以提高性能。其中一些方法可以降低成本，比如优化你的代码，压缩你发送的数据，或者将计算推送到客户端。然而，其他提高性能的方法会增加成本，比如在更强大的硬件上运行，将数据复制到靠近客户端的多个位置，并预取未请求的数据。
- en: In the end, this is a business decision. Even win-win performance improvements
    are not always like improving your algorithms is, at the high-priority. For example,
    you can invest a lot of time in coming up with an algorithm that runs 10x faster
    than the previous algorithm. But the computation time might be negligible in the
    overall time to process a request because it's dominated by access to the database,
    serializing the data, and sending it to the client. In this case, you just wasted
    time that could have been used for developing something more useful, you potentially
    destabilized your code and introduced bugs, and made your code harder to understand.
    Again, good metrics and profiling will help you identify the hot spots in your
    system that are worth improvement performance-wise and cost-wise.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这是一个商业决策。即使是双赢的性能改进并不总是像改进算法那样优先级高。例如，您可以花费大量时间想出比以前算法快10倍的算法。但是计算时间可能在整个处理请求的时间中是微不足道的，因为它被数据库访问、序列化数据和发送给客户端所主导。在这种情况下，您只是浪费了本来可以用来开发更有用的东西的时间，可能使您的代码不稳定并引入了错误，并使您的代码更难理解。再次强调，良好的指标和分析将帮助您确定系统中值得改进性能和成本的热点。
- en: Performance and security
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能和安全
- en: Performance and security are generally at odds. Security typically pushes toward
    encryption across the board, outside and inside the cluster. There are strong
    authentication and authorization methods, may be necessary, but has performance
    overhead. However, security sometimes indirectly helps performance by advocating
    to cut unnecessary features and reduce the surface area of the system. This spartan
    approach that produces tighter systems allows you to focus on a smaller target
    to improve performance. Typically, secure systems don't just add arbitrary features
    that can hurt performance without careful consideration.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 性能和安全通常是相互对立的。安全通常倾向于在整个系统内外推动加密。强大的身份验证和授权方法可能是必要的，但会带来性能开销。然而，安全有时间接地通过倡导削减不必要的功能和减少系统的表面积来帮助性能。这种产生更紧凑系统的简约方法使您能够专注于改善性能的更小目标。通常，安全系统不会随意添加可能在没有仔细考虑的情况下损害性能的任意功能。
- en: Later, we will explore how to collect and use metrics with Kubernetes, but first
    let's take a look at logging, which is another pillar of monitoring your system.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将探讨如何使用Kubernetes收集和使用指标，但首先让我们来看看日志记录，这是监控系统的另一个支柱。
- en: Logging
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: Logging is the ability to record messages during the operation of your system.
    Log messages are typically structured and timestamped. They are often indispensable
    when trying to diagnose problems and troubleshoot your system. They are also critical
    when doing post-mortems and discovering root causes after the fact. In a large-scale
    distributed system, there will be many components that log messages. Collecting,
    organizing, and sifting through them is a non-trivial task. But first, let's consider
    what information is useful to log.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录是在系统运行过程中记录消息的能力。日志消息通常是结构化的并带有时间戳。在诊断问题和解决系统故障时，它们通常是不可或缺的。在进行事后分析并发现根本原因时，它们也至关重要。在大规模分布式系统中，将有许多组件记录日志消息。收集、整理和筛选这些消息是一项非常重要的任务。但首先，让我们考虑记录哪些信息是有用的。
- en: What should you log?
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您应该记录什么？
- en: This is the million dollar question. A simplistic approach is to log *everything*.
    You can never have too much data, and it's difficult to predict what data you'll
    need when trying to figure out what's wrong with your system. However, what does
    everything mean exactly? You can obviously go too far. For example, you can log
    every call to every little function in your code, including all the parameters,
    as well as the current state, or log the payload of every network call. Sometimes,
    there are security and regulatory restrictions that prevent you from logging certain
    data, like **protected health information** (**PHI**) and **personally identifiable
    information** (**PII**). You'll need to understand your system well enough to
    decide what kind of information is relevant for you. A good starting point is
    logging any incoming requests and interactions between your microservices and
    between your microservices and third-party services.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个百万美元的问题。一个简单的方法是记录*一切*。你永远不可能有太多的数据，很难预测在尝试弄清楚系统出了什么问题时你会需要什么数据。然而，一切到底意味着什么？显然你可以走得太远。例如，你可以记录代码中每一个小函数的每一个调用，包括所有的参数，以及当前状态，或者记录每一个网络调用的有效负载。有时，有安全和监管限制会阻止你记录某些数据，比如**受保护的健康信息**（**PHI**）和**个人可识别信息**（**PII**）。你需要足够了解你的系统来决定哪种信息对你是相关的。一个很好的起点是记录所有的传入请求以及你的微服务之间的交互，以及你的微服务和第三方服务之间的交互。
- en: Logging versus error reporting
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录与错误报告
- en: Errors are a special kind of information. There are errors that your code can
    handle (for example, with retries or using some alternative). However, there are
    also errors that must be handled as soon as possible or the system will suffer
    partial or complete outage. But even errors that are not urgent sometimes require
    that you record a lot of information. You could log errors just like any other
    information, but it is often worthwhile to record errors to a dedicated error
    reporting service like Rollbar or Sentry. One of the crucial pieces of information
    with errors is a stack trace that includes the state (local variables) of each
    frame in the stack. For a production system, I recommend that you use a dedicated
    error reporting service, in addition to just logging.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 错误是一种特殊的信息。有些错误是你的代码可以处理的（例如，通过重试或使用一些替代方法）。然而，也有一些错误必须尽快处理，否则系统将遭受部分或完全的停机。但即使不紧急的错误有时也需要记录大量的信息。你可以像记录其他信息一样记录错误，但通常值得将错误记录到专用的错误报告服务，比如Rollbar或Sentry。错误的一个关键信息是包含堆栈中每个帧的状态（局部变量）的堆栈跟踪。对于生产系统，我建议你使用专门的错误报告服务，而不仅仅是记录日志。
- en: The quest for the perfect Go logging interface
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 追求完美的Go日志记录接口的探索
- en: 'Delinkcious is primarily implemented with Go, so let''s talk about logging
    in Go. There is a standard library Logger, which is a struct and not an interface.
    It is configurable, and you can pass an `io.Writer` object when you create it.
    However, the methods of the `Logger` struct are rigid and don''t support log levels
    or structured logging. Also, the fact that there is just one output writer may
    be a limitation in some cases. Here is the specification for the standard Logger:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Delinkcious主要是用Go实现的，所以让我们来谈谈Go中的日志记录。有一个标准库Logger，它是一个结构体而不是一个接口。它是可配置的，你可以在创建它时传递一个`io.Writer`对象。然而，`Logger`结构的方法是固定的，不支持日志级别或结构化日志记录。而且，只有一个输出写入器的事实在某些情况下可能是一个限制。这是标准Logger的规范：
- en: '[PRE14]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you need those capabilities, you need to use another library that sits on
    top of the standard library `Logger`. There are several packages that provide
    various flavors:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要这些功能，你需要使用另一个库，它位于标准库`Logger`之上。有几个包提供了各种不同的风格：
- en: '`glog`: [https://godoc.org/github.com/golang/glog](https://godoc.org/github.com/golang/glog)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glog`: [https://godoc.org/github.com/golang/glog](https://godoc.org/github.com/golang/glog)'
- en: '`logrus`: [https://github.com/Sirupsen/logrus](https://github.com/Sirupsen/logrus)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logrus`: [https://github.com/Sirupsen/logrus](https://github.com/Sirupsen/logrus)'
- en: '`loggo`: [https://godoc.org/github.com/juju/loggo](https://godoc.org/github.com/juju/loggo)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loggo`: [https://godoc.org/github.com/juju/loggo](https://godoc.org/github.com/juju/loggo)'
- en: '`log15`: [https://github.com/inconshreveable/log15](https://github.com/inconshreveable/log15)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log15`: [https://github.com/inconshreveable/log15](https://github.com/inconshreveable/log15)'
- en: They address the interface, comparability, and playability in different ways.
    However, we're using Go-kit, which has its own take on logging.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 它们以不同的方式处理接口、可比性和可玩性。然而，我们正在使用Go-kit，它对日志记录有自己的看法。
- en: Logging with Go-kit
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Go-kit记录日志
- en: 'Go-kit has the simplest interface ever. There is just one method, `Log()`,
    that accepts a list of keys and values that can be of any type:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Go-kit拥有有史以来最简单的接口。只有一个方法`Log()`，它接受一个可以是任何类型的键和值列表：
- en: '[PRE15]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The basic idea here is that Go-kit has no opinions about how you log your messages.
    Do you always add a timestamp? Do you have logging levels? What levels? The answers
    to all these questions are up to you. You get a totally generic interface and
    you decide what key-values you want to log.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的基本思想是，Go-kit对于如何记录消息没有意见。您总是添加时间戳吗？您有日志级别吗？什么级别？所有这些问题的答案都取决于您。您获得一个完全通用的接口，您决定要记录哪些键值。
- en: Setting up a logger with Go-kit
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Go-kit设置记录器
- en: 'OK. The interface is generic, but we need an actual logger object to work with.
    Go-kit supports several writers and logger objects that generate familiar log
    formats like JSON, logfmt, or logrus out of the box. Let''s set up a logger with
    JSON formatter and a sync writer. A sync writer is safe to use from multiple Go
    routines, and a JSON formatter formats the key values into a JSON string. In addition,
    we can add some default fields, such as the service name, which is where the log
    message is coming from in the source code and the current timestamp. Since we
    may want to use the same logger specification from multiple services, let''s put
    it in a package all the services can use. One last thing is to add also a `Fatal()`
    function that will forward to the standard `log.Fatal()` function. This allows
    code that currently uses `Fatal()` to continue working without changes. Here is
    the Delinkcious log package that contains a factory function for the logger and
    the `Fatal()` function:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。接口是通用的，但我们需要一个实际的记录器对象来使用。Go-kit支持几种写入器和记录器对象，可以生成熟悉的日志格式，如JSON、logfmt或logrus。让我们使用JSON格式和同步写入器设置一个记录器。同步写入器可以安全地从多个Go例程中使用，JSON格式化器将键值格式化为JSON字符串。此外，我们可以添加一些默认字段，例如服务名称，这是日志消息在源代码中的来源，以及当前时间戳。由于我们可能希望从多个服务中使用相同的记录器规范，让我们将其放在一个所有服务都可以使用的包中。最后一件事是添加一个`Fatal()`函数，它将转发到标准的`log.Fatal()`函数。这允许当前使用`Fatal()`的代码继续工作而无需更改。这是Delinkcious日志包，其中包含记录器的工厂函数和`Fatal()`函数：
- en: '[PRE16]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The writer just writes to the standard error stream, which will be captured
    and sent to the container logs on Kubernetes.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 写入器只是写入标准错误流，这将被捕获并发送到Kubernetes容器日志中。
- en: To see our logger in action, let's attach it to our link service.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的记录器是如何工作的，让我们把它附加到我们的链接服务上。
- en: Using a logging middleware
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用日志中间件
- en: Let's think about where we want to instantiate our logger and then where we
    want to use it and log messages. This is important because we need to make sure
    that the logger is available to all the places in the code that need to log messages.
    A trivial approach is to just add a logger parameter to all our interfaces and
    propagate the logger in this way. However, this is very disruptive and will violate
    our clean object model. Logging is really an implementation and operational detail.
    Ideally, it should not appear in our object model types or interfaces. Also, it
    is a Go-kit type and, so far, we've managed to keep our object model and even
    our domain packages totally oblivious to the fact that they are wrapped by Go-kit.
    The Delinkcious services under SVC are the only part of the code that is Go-kit
    aware.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下我们想要实例化记录器的地方，然后在哪里使用它并记录消息。这很重要，因为我们需要确保记录器对代码中需要记录消息的所有地方都是可用的。一个微不足道的方法是只需将记录器参数添加到所有接口中，并以这种方式传播记录器。然而，这样做会非常破坏性，并违反我们清晰的对象模型。记录是一个实现和操作细节。理想情况下，它不应出现在我们的对象模型类型或接口中。此外，它是一个Go-kit类型，到目前为止，我们已经成功地使我们的对象模型甚至我们的领域包完全不知道它们被Go-kit包装。Delinkcious服务在SVC下是唯一知道Go-kit的代码部分。
- en: 'Let''s try to keep it this way. Go-kit provides the middleware concept, which
    allows us to chain multiple middleware components in a loosely coupled way. All
    the middleware components for a service implement the service interface, and a
    little shim allows Go-kit to call them one after the other. Let''s begin with
    the shim, which is just a function type that accepts a `LinkManager` interface
    and returns a `LinkManager` interface:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试保持这种状态。Go-kit提供了中间件概念，允许我们以一种松散耦合的方式链接多个中间件组件。服务的所有中间件组件都实现了服务接口，一个小的包装器允许Go-kit依次调用它们。让我们从包装器开始，它只是一个接受`LinkManager`接口并返回`LinkManager`接口的函数类型：
- en: '[PRE17]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `logging_middleware.go` file has a factory function called `newLoggingMiddlware()`
    that takes a logger object and returns a function that matches `linkManagerMiddleware`.
    That function, in turn, instantiates the `loggingMiddelware` struct, passing it
    the next component in the chain and the logger:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`logging_middleware.go`文件有一个名为`newLoggingMiddlware()`的工厂函数，它接受一个记录器对象并返回一个与`linkManagerMiddleware`匹配的函数。这个函数又实例化了`loggingMiddelware`结构，将链中的下一个组件和记录器传递给它：'
- en: '[PRE18]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This may be very confusing, but the basic idea is having the ability to chain
    arbitrary middleware components that do some work and let the rest of the computation
    go on. The reason that we have all these layers of indirection is that Go-kit
    doesn''t know anything about our types and interfaces, so we have to assist by
    writing this boilerplate code. As I mentioned earlier, all of it can, and should
    be, auto-generated. Let''s examine the `loggingMiddleware` struct and its methods.
    The struct itself has a `linkManager` interface, which is the next component in
    the chain and the logger object:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会很令人困惑，但基本思想是能够链接任意中间件组件，执行一些工作并让其余的计算继续进行。我们之所以有这么多层间接性，是因为Go-kit对我们的类型和接口一无所知，所以我们必须通过编写这些样板代码来协助。正如我之前提到的，所有这些都可以自动生成，也应该自动生成。让我们来看看`loggingMiddleware`结构及其方法。结构本身有一个`linkManager`接口，它是链中的下一个组件和记录器对象：
- en: '[PRE19]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As a `LinkManager` middleware component, it must implement the `LinkManager`
    interface methods. Here is the implementation of `GetLinks()`. It uses the logger
    to log a few values, specifically, the method name, that is, `GetLinks`, the request
    object, the result, and the duration. Then, it calls the `GetLinks()` method on
    the next component in the chain:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 作为`LinkManager`中间件组件，它必须实现`LinkManager`接口方法。这是`GetLinks()`的实现。它使用记录器记录一些值，特别是方法名称，即`GetLinks`，请求对象，结果和持续时间。然后，它调用链中下一个组件的`GetLinks()`方法。
- en: '[PRE20]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For simplicity, the other methods just call the next component in the chain
    doing anything:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，其他方法只是调用链中的下一个组件而不做任何事情：
- en: '[PRE21]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The middleware chain concept is very powerful. The middleware can preprocess
    inputs before passing them on to the next component, it can short circuit and
    return immediately without calling the next component, or it can postprocess the
    result coming from the next component.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 中间件链概念非常强大。中间件可以在将输入传递给下一个组件之前预处理输入，它可以短路并立即返回而不调用下一个组件，或者它可以对来自下一个组件的结果进行后处理。
- en: 'Let''s see the log output from the link service when running our smoke test.
    It looks a bit messy for humans, but all the necessary information is there, clearly
    marked and ready for large-scale analysis if needed. It''s easy to grep and it''s
    easy to use tools like `jq` to dig deeper:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在运行冒烟测试时从链接服务中的日志输出。对于人类来说，它看起来有点混乱，但所有必要的信息都在那里，清晰标记并且可以随时进行大规模分析。它很容易使用grep，并且很容易使用`jq`等工具进行深入挖掘。
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Thanks to Go-kit, we have a strong and flexible logging mechanism in place.
    However, manually fetching logs with `kubectl logs` doesn't scale. For real-world
    systems, we need centralized log management.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Go-kit，我们已经有了一个强大而灵活的日志记录机制。然而，使用`kubectl logs`手动获取日志并不具备可扩展性。对于真实世界的系统，我们需要集中式日志管理。
- en: Centralized logging with Kubernetes
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes的集中式日志记录
- en: In Kubernetes, containers write to the standard output and standard error streams.
    Kubernetes makes those logs available (for example, via `kubectl logs`). You can
    even get logs of the previous run of a container if it crashed by using `kubectl
    logs -p`, but, if the pod is rescheduled, then its containers and their logs disappear.
    If the node itself crashes, you'll lose the logs too. Even when all the logs are
    available for a cluster with a lot of services, it is a non-trivial task to sift
    through the container logs and try to make sense of the state of the system. Enter
    centralized logging. The idea is to have a log agent running, either as a side
    container in each pod, or as daemon set on each node, listen to all the logs,
    and ship them in real time to a centralized location where they can be aggregated,
    filtered, and sorted. Of course, you can explicitly log from your containers directly
    to the centralized logging service too.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，容器写入标准输出和标准错误流。Kubernetes使这些日志可用（例如，通过`kubectl logs`）。甚至可以通过使用`kubectl
    logs -p`获取容器的上一次运行的日志，但是，如果Pod被重新调度，那么它的容器和它们的日志就会消失。如果节点本身崩溃，您也会丢失日志。即使对于具有大量服务的集群，所有日志都是可用的，筛选容器日志并尝试理解系统状态是一项非平凡的任务。进入集中式日志记录。其想法是运行一个日志代理，可以作为每个Pod中的边缘容器，或者作为每个节点上的守护程序集，监听所有日志，并实时将它们发送到一个集中的位置，那里可以对它们进行聚合、过滤和排序。当然，您也可以直接从您的容器显式地记录到集中式日志记录服务。
- en: The simplest and most robust approach in my opinion is the demon set. The cluster
    admin makes sure that a log agent is installed on each node and that's it. There's
    no need to change your pod spec to inject side containers, no need to depend on
    special libraries to communicate with remote logging services. Your code writes
    to standard output and standard error, and you're done. Most other services you
    may use, like web servers and databases, can be configured to write to the standard
    output and standard error, too.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，最简单和最健壮的方法是使用守护进程集。集群管理员确保在每个节点上安装了一个日志代理，就这样。无需更改您的pod规范以注入侧边容器，也无需依赖特殊库与远程日志记录服务通信。您的代码写入标准输出和标准错误，就完成了。您可能使用的大多数其他服务，如Web服务器和数据库，也可以配置为写入标准输出和标准错误。
- en: 'One of the most popular log agents on Kubernetes is Fluentd ([https://www.fluentd.org](https://www.fluentd.org)).
    It is also a CNCF graduated project. You should use Fluentd unless you have a
    very good reason to use another logging agent. Here is a diagram that illustrates
    how Fluentd fits into Kubernetes as a DaemonSet that is deployed into each node,
    pulls all the logs of all the pods, and sends them to a centralized log management
    system:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes上最流行的日志代理之一是Fluentd（[https://www.fluentd.org](https://www.fluentd.org)）。它也是一个CNCF毕业项目。除非您有非常充分的理由使用其他日志代理，否则应该使用Fluentd。下面是一个图表，说明了Fluentd如何作为一个DaemonSet适配到Kubernetes中，部署到每个节点，拉取所有pod的日志，并将它们发送到一个集中的日志管理系统：
- en: '![](assets/79606ae7-f9ee-4d71-8fab-e1ed57d8b274.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/79606ae7-f9ee-4d71-8fab-e1ed57d8b274.png)'
- en: Fluentd
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd
- en: 'Let''s talk about the log management system. In the open source world, the
    ELK stack – ElasticSearch, LogStash, and Kibana – are a very popular combination.
    ElasticSearch stores the logs and provides various ways to slice and dice them.
    LogStash is the log ingest pipeline and Kibana is a powerful visualization solution.
    Fluentd can replace LogStash as the logging agent, and you get the EFK stack –
    ElasticSearch. Fluentd and Kibana work very well on Kubernetes. There''s also
    Helm charts and the GitHub repository, which can install EFK on your Kubernetes
    cluster in one click. However, you should also consider out of cluster logging
    service. As we discussed previously, logs are very helpful for troubleshooting
    and post mortems. If your cluster is in trouble, you might not be able to access
    your logs at the time you need them the most. Fluentd can integrate with a plethora
    of data outputs. Check the full list here: [https://www.fluentd.org/dataoutputs](https://www.fluentd.org/dataoutputs).
    We''ve got logging covered, so now it''s time to talk about metrics.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈日志管理系统。在开源世界中，ELK堆栈——ElasticSearch、LogStash和Kibana——是非常流行的组合。ElasticSearch存储日志并提供各种切片和切块的方式。LogStash是日志摄取管道，Kibana是一个强大的可视化解决方案。Fluentd可以替代LogStash作为日志代理，你可以得到EFK堆栈——ElasticSearch、Fluentd和Kibana在Kubernetes上运行得非常好。还有Helm图表和GitHub存储库，可以在您的Kubernetes集群上一键安装EFK。然而，你也应该考虑集群外的日志记录服务。正如我们之前讨论过的，日志对故障排除和事后分析非常有帮助。如果您的集群出现问题，您可能无法在最需要的时候访问日志。Fluentd可以与大量的数据输出集成。在这里查看完整列表：[https://www.fluentd.org/dataoutputs](https://www.fluentd.org/dataoutputs)。我们已经涵盖了日志记录，现在是时候谈谈指标了。
- en: Collecting metrics on Kubernetes
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes上收集指标
- en: Metrics are a key component that enables many interesting use cases like self-healing,
    autoscaling, and alerting. Kubernetes, as a distributed platform, has a very strong
    offering around metrics, with a powerful yet generic and flexible metrics API.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是许多有趣用例的关键组件，如自愈、自动缩放和警报。作为一个分布式平台，Kubernetes在指标方面提供了非常强大的功能，具有强大而通用且灵活的指标API。
- en: Kubernetes always had support for metrics via cAdvisor (integrated into kube-proxy)
    and Heapster ([https://github.com/kubernetes-retired/heapster](https://github.com/kubernetes-retired/heapster)).
    However, cAdvisor was removed in Kubernetes 1.12 and Heapster was removed in Kubernetes
    1.13\. You can still install them (like we did earlier on minikube using the Heapster
    add-on), but they aren't part of Kubernetes and aren't recommended  anymore. The
    new way to do metrics on Kubernetes is by using the metrics API and the metrics
    server ([https://github.com/kubernetes-incubator/metrics-server](https://github.com/kubernetes-incubator/metrics-server)).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes一直支持通过cAdvisor（集成到kube-proxy中）和Heapster（[https://github.com/kubernetes-retired/heapster](https://github.com/kubernetes-retired/heapster)）来支持度量。但是，cAdvisor在Kubernetes
    1.12中被移除，Heapster在Kubernetes 1.13中被移除。您仍然可以安装它们（就像我们之前在minikube上使用Heapster插件一样），但它们不再是Kubernetes的一部分，也不再推荐使用。在Kubernetes上进行度量的新方法是使用度量API和度量服务器（[https://github.com/kubernetes-incubator/metrics-server](https://github.com/kubernetes-incubator/metrics-server)）。
- en: Introducing the Kubernetes metrics API
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Kubernetes度量API
- en: 'The Kubernetes metrics API is very generic. It supports node and pod metrics,
    as well as custom metrics. A metric has a usage field, a timestamp, and a window
    (the time range the metric was collected in). Here is the API definition for node
    metrics:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes度量API非常通用。它支持节点和Pod度量，以及自定义度量。度量有一个使用字段，一个时间戳和一个窗口（度量收集的时间范围）。以下是节点度量的API定义：
- en: '[PRE23]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The usage field type is `ResourceList`, but it''s actually a map of a resource
    name to a quantity:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用字段类型为`ResourceList`，但实际上是资源名称到数量的映射：
- en: '[PRE24]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'There are two other metrics-related APIs: the external metrics API and the
    custom metrics API. They are designed for extending the Kubernetes metrics with
    arbitrary custom metrics or metrics coming from outside Kubernetes, such as cloud
    providers monitoring. You can annotate those additional metrics and use them for
    autoscaling.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另外两个与度量相关的API：外部度量API和自定义度量API。它们旨在通过任意自定义度量或来自Kubernetes外部的度量（例如云提供商监控）来扩展Kubernetes度量。您可以注释这些额外的度量并将其用于自动缩放。
- en: Understanding the Kubernetes metrics server
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Kubernetes度量服务器
- en: 'The Kubernetes metric server is a modern replacement for Heapster and cAdvisor.
    It implements the metrics API and provides the nodes and pods metrics. Those metrics
    are used by the various autoscalers and by the Kubernetes scheduler itself when
    dealing with best effort scenarios. Depending on your Kubernetes distribution,
    the metrics server may or may not be installed. If you need to install it, you
    can use helm. For example, on AWS EKS, you have to install the metrics server
    yourself using the following command (you can choose any namespace):'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes度量服务器是Heapster和cAdvisor的现代替代品。它实现了度量API并提供节点和Pod度量。这些度量由各种自动缩放器使用，并且在处理尽力而为的情况时，Kubernetes调度器本身也会使用这些度量。根据您的Kubernetes发行版，度量服务器可能已安装或未安装。如果需要安装它，您可以使用helm。例如，在AWS
    EKS上，您必须自己安装度量服务器，使用以下命令（您可以选择任何命名空间）：
- en: '[PRE25]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Typically, you don''t interact with the metrics server directly. You can access
    the metrics using the `kubectl get --raw` command:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您不直接与度量服务器交互。您可以使用`kubectl get --raw`命令访问度量：
- en: '[PRE26]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In addition, you can use the very useful `kubectl` command, that is, `kubectl
    top`, which gives you a quick overview of the performance of your nodes or pods:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以使用非常有用的`kubectl`命令，即`kubectl top`，它可以快速查看节点或Pod的性能概况：
- en: '[PRE27]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note that as of Kubernetes 1.15 (current version at the time of writing) the
    Kubernetes dashboard doesn't integrate with the metrics server for performance
    yet. It still requires Heapster. I'm sure you will be able to work with the metrics-server
    soon.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，截至撰写时的Kubernetes 1.15（当前版本），Kubernetes仪表板尚未与性能指标服务器集成。它仍然需要Heapster。我相信您很快就能与metrics-server一起使用。
- en: 'The metrics-server is the standard Kubernetes metrics solution for CPU and
    memory, but, if you want to go further and consider custom metrics, there is one
    obvious choice: Prometheus. Unlike most things Kubernetes, where you have a plethora
    of options in the metrics arena, Prometheus stands head and shoulders above all
    the other free and open source options.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: metrics-server是用于CPU和内存的标准Kubernetes指标解决方案，但是，如果您想进一步考虑自定义指标，那么Prometheus是一个明显的选择。与大多数Kubernetes不同，在指标领域有大量选项，Prometheus在所有其他免费和开源选项中脱颖而出。
- en: Using Prometheus
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Prometheus
- en: 'Prometheus ([https://prometheus.io/](https://prometheus.io/)) is an open source
    and CNCF graduated project (the second after Kubernetes itself). It is the de
    facto standard metrics collection solution for Kubernetes. It has an impressive
    set of features, a large installation base on Kubernetes, and an active community.
    Some of the prominent features are as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus（[https://prometheus.io/](https://prometheus.io/)）是一个开源的CNCF毕业项目（仅次于Kubernetes本身）。它是Kubernetes的事实标准指标收集解决方案。它具有令人印象深刻的功能集，在Kubernetes上有大量安装基础，并且拥有活跃的社区。一些突出的功能如下：
- en: A generic multi-dimensional data model where each metric is modeled as a time
    series of key-value pairs
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用的多维数据模型，其中每个指标都被建模为键值对的时间序列
- en: A powerful query language, called PromQL, that lets you generate reports, graphs,
    and tables
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个强大的查询语言，称为PromQL，可以让您生成报告、图形和表格
- en: A built-in alerting engine where alerts are defined and triggered by PromQL
    queries
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置警报引擎，其中警报由PromQL查询定义和触发
- en: Powerful visualization – Grafana, console template language, and more
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强大的可视化 - Grafana，控制台模板语言等
- en: Many integrations with other infrastructure components beyond Kubernetes
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与Kubernetes之外的其他基础设施组件的许多集成
- en: 'Let''s look at the following references:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下参考资料：
- en: '**Monitoring your Kubernetes Deployments with Prometheus**:[ https://supergiant.io/blog/monitoring-your-kubernetes-deployments-with-prometheus/](https://supergiant.io/blog/monitoring-your-kubernetes-deployments-with-prometheus/)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用Prometheus监视您的Kubernetes部署**：[ https://supergiant.io/blog/monitoring-your-kubernetes-deployments-with-prometheus/](https://supergiant.io/blog/monitoring-your-kubernetes-deployments-with-prometheus/)'
- en: '**Configure Kubernetes Autoscaling With Custom Metrics**: [https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/](https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用自定义指标配置Kubernetes自动缩放**：[https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/](https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/)'
- en: Deploying Prometheus into the cluster
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Prometheus部署到集群中
- en: Prometheus is a large project with many capabilities, options, and integrations.
    Deploying it and managing it is not a trivial task. There a couple of projects
    that can help. The Prometheus operator ([https://github.com/coreos/prometheus-operator](https://github.com/coreos/prometheus-operator))
    provides a way to deeply configure Prometheus using Kubernetes resources.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是一个功能强大的项目，具有许多功能、选项和集成。部署和管理它并不是一项微不足道的任务。有一些项目可以提供帮助。Prometheus
    operator（[https://github.com/coreos/prometheus-operator](https://github.com/coreos/prometheus-operator)）提供了一种使用Kubernetes资源深度配置Prometheus的方法。
- en: 'The operator concept ([https://coreos.com/blog/introducing-operators.html](https://coreos.com/blog/introducing-operators.html))
    was introduced in 2016 by CoreOS (who was acquired by RedHat, who was acquired
    by IBM). A Kubernetes operator is a controller that is responsible for managing
    stateful applications inside a cluster using Kubernetes CRDs. Operators, in practice,
    extend the Kubernetes API to provide a seamless experience when managing foreign
    components like Prometheus. Actually, the Prometheus operator was the first operator
    (along with the Etcd operator):'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 操作员概念（[https://coreos.com/blog/introducing-operators.html](https://coreos.com/blog/introducing-operators.html)）是由CoreOS在2016年引入的（后来被RedHat收购，再后来被IBM收购）。Kubernetes操作员是负责使用Kubernetes
    CRD在集群内管理有状态应用程序的控制器。实际上，操作员在实践中扩展了Kubernetes API，以在管理像Prometheus这样的外部组件时提供无缝体验。实际上，Prometheus操作员是第一个操作员（连同Etcd操作员）：
- en: '![](assets/462b7964-4c5c-4de6-8951-9e6a3a0bd822.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/462b7964-4c5c-4de6-8951-9e6a3a0bd822.png)'
- en: Prometheus operator
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus操作员
- en: 'The kube-promethus ([https://github.com/coreos/kube-prometheus](https://github.com/coreos/kube-prometheus))
    project is built on top of the Prometheus operator and adds the following:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: kube-promethus（[https://github.com/coreos/kube-prometheus](https://github.com/coreos/kube-prometheus)）项目是建立在Prometheus操作员之上的，并添加了以下内容：
- en: Grafana visualization
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana可视化
- en: A highly available Prometheus cluster
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用的Prometheus集群
- en: A highly available `Alertmanager` cluster
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用的`Alertmanager`集群
- en: An adapter for the Kubernetes Metrics APIs
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于Kubernetes度量标准API的适配器
- en: Kernel and OS metrics via the Prometheus node exporter
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Prometheus节点导出器获取内核和操作系统度量标准
- en: Various metrics on the state of Kubernetes objects via `kube-state-metrics`
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`kube-state-metrics`获取Kubernetes对象状态的各种度量标准
- en: The Prometheus operator brings the ability to launch a Prometheus instance into
    a Kubernetes namespace, configure it, and target services via labels to the table.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus操作员带来了在Kubernetes命名空间中启动Prometheus实例、配置它并通过标签定位服务的能力。
- en: 'For now, we''ll just use helm to deploy a full-fledged installation of Prometheus:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用helm部署一个完整的Prometheus安装：
- en: '[PRE28]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The Prometheus server can be accessed via port `80` on the following DNS name
    from within your cluster: `prometheus-server.default.svc.cluster.local`.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过集群内以下DNS名称的端口`80`访问Prometheus服务器：`prometheus-server.default.svc.cluster.local`。
- en: 'Get the Prometheus server URL by running the following commands in the same
    shell:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在同一个shell中运行以下命令来获取Prometheus服务器URL：
- en: '[PRE29]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The Prometheus `alertmanager` can be accessed via port `80` on the following
    DNS name from within your cluster:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus `alertmanager`可以通过集群内以下DNS名称的端口`80`访问：
- en: '[PRE30]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Get the `Alertmanager` URL by running the following commands in the same shell:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在同一个shell中运行以下命令来获取`Alertmanager` URL：
- en: '[PRE31]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The Prometheus `pushgateway` can be accessed via port 9091 on the following
    DNS name from within your cluster:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus `pushgateway`可以通过集群内以下DNS名称的端口9091访问：
- en: '[PRE32]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Get the `PushGateway` URL by running the following commands in the same shell:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在同一个shell中运行以下命令来获取`PushGateway` URL：
- en: '[PRE33]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s see what services were installed:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看安装了哪些服务：
- en: '[PRE34]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Everything seems in order. Let''s follow the instructions and check out the
    Prometheus web UI:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一切似乎都很正常。让我们按照说明查看一下Prometheus web UI：
- en: '[PRE35]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can now browse to `localhost:9090` and do some checks. Let''s check the
    number of goroutines in the cluster:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以浏览到`localhost:9090`并进行一些检查。让我们检查一下集群中goroutines的数量：
- en: '![](assets/a6db6584-7a81-464e-9125-3a8597f6ea86.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a6db6584-7a81-464e-9125-3a8597f6ea86.png)'
- en: Prometheus web UI
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus web UI
- en: 'The number of metrics that have been collected by Prometheus is mind-numbing.
    There are hundreds of different built-in metrics. Check out how small the scroll
    thumb on the right is when opening the metric selection dropdown:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus收集的指标数量令人震惊。有数百种不同的内置指标。打开指标选择下拉菜单时，看看右侧滚动条有多小：
- en: '![](assets/479deab5-2693-4282-9023-bb58d35be2be.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/479deab5-2693-4282-9023-bb58d35be2be.png)'
- en: Prometheus dropdown
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus下拉菜单
- en: There are way more metrics than you will ever need, but each one of them can
    be important for some specific troubleshooting task.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 比你所需的指标要多得多，但它们每一个对于某些特定的故障排除任务都可能很重要。
- en: Recording custom metrics from Delinkcious
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Delinkcious记录自定义指标
- en: 'OK: Prometheus is installed and collecting standard metrics automatically,
    but we want to record our own custom metrics too. Prometheus works in pull mode.
    A service that want to provide metrics needs to expose a `/metrics` endpoint (it
    is possible to push metrics to Prometheus too, using its Push Gateway). Let''s
    utilize the middleware concept of Go-kit and add a metrics middleware that''s
    similar to the logging middleware. We will take advantage of the Go client library
    provided by Prometheus.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 好的：Prometheus已安装并自动收集标准指标，但我们也想记录自己的自定义指标。Prometheus以拉模式工作。想要提供指标的服务需要公开一个`/metrics`端点（也可以使用其Push
    Gateway将指标推送到Prometheus）。让我们利用Go-kit的中间件概念，并添加一个类似于日志中间件的指标中间件。我们将利用Prometheus提供的Go客户端库。
- en: 'The client library provides several primitives like counter, summary, histogram,
    and gauge. For the purpose of understanding how to record metrics from a Go service,
    we will instrument each endpoint of the link service to record the number of requests
    (a counter), as well as a summary of all requests (a summary). Let''s start by
    providing factory functions in a separate library called pkg/metrics. The library
    provides a convenient wrapper around the Prometheus Go client. Go-kit has its
    own abstraction layer on top of the Prometheus Go client, but it doesn''t provide
    a lot of value, unless you plan to switch to another metrics provider like `statsd`.
    This is unlikely for Delinkcious and probably for your system too. The service
    name, metric name, and help string will be used to construct the fully qualified
    metric name later:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端库提供了几种原语，如计数器、摘要、直方图和仪表。为了理解如何从Go服务记录指标，我们将对链接服务的每个端点进行仪器化，记录请求的数量（计数器）以及所有请求的摘要（摘要）。让我们从一个名为pkg/metrics的单独库中提供工厂函数。该库提供了一个方便的包装器，围绕Prometheus
    Go客户端。Go-kit在Prometheus Go客户端的顶部有自己的抽象层，但除非你打算切换到另一个指标提供程序（如`statsd`），否则它并没有提供太多价值。这对于Delinkcious和你的系统来说也不太可能。服务名称、指标名称和帮助字符串将用于稍后构建完全限定的指标名称：
- en: '[PRE36]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The next step is to construct the middleware. It should look very familiar,
    as it is almost identical to the logging middleware. The `newMetricsMiddleware()`
    function creates a counter and a summary metrics for each endpoint and returns
    it as the generic `linkManagerMiddleware` function we defined earlier (a function
    that accepts the next middleware and returns itself to assemble a chain of components
    that all implement the `om.LinkManager` interface):'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建中间件。它应该看起来非常熟悉，因为它几乎与日志中间件完全相同。`newMetricsMiddleware()`函数为每个端点创建一个计数器和摘要指标，并将其作为我们之前定义的通用`linkManagerMiddleware`函数返回（一个接受下一个中间件并返回自身以组装所有实现`om.LinkManager`接口的组件链的函数）：
- en: '[PRE37]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The `metricsMiddleware` struct stores the next middleware and two maps. One
    map is a mapping of method names to Prometheus counters, while the other map is
    a mapping of method names to Prometheus summaries. They are used by the `LinkManager`
    interface methods to record metrics separately for each method:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`metricsMiddleware`结构存储了下一个中间件和两个映射。一个映射是方法名称到Prometheus计数器的映射，而另一个映射是方法名称到Prometheus摘要的映射。它们被`LinkManager`接口方法用于分别记录每个方法的指标：'
- en: '[PRE38]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The middleware methods use the pattern of performing an action, which, in this
    case, is recording metrics and then calling the next component. Here is the `GetLinks()`
    method:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 中间件方法使用执行操作的模式，这种情况下是记录指标，然后调用下一个组件。这是`GetLinks()`方法：
- en: '[PRE39]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The actual metric recording is done by the `recordMetrics()` method, which
    takes the method name (`GetLinks` here) and beginning time. It is deferred until
    the end of the `GetLinks()` method, which allows it to calculate the duration
    of the `GetLinks()` method itself. It uses the counter and summary from the maps
    that match the method name:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的指标记录是由`recordMetrics()`方法完成的，它接受方法名称（这里是`GetLinks`）和开始时间。它被延迟到`GetLinks()`方法的结尾，这使它能够计算`GetLinks()`方法本身的持续时间。它使用与方法名称匹配的映射中的计数器和摘要：
- en: '[PRE40]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'At this point, we have our metrics middleware ready to go, but we still need
    to hook it up to the middleware chain and expose it as the `/metrics` endpoint.
    Since we''ve done all the preliminary work, these are just two lines in the link
    service''s `Run()` method:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的指标中间件已经准备就绪，但我们仍然需要将其连接到中间件链并将其公开为`/metrics`端点。由于我们已经完成了所有的准备工作，这只是链接服务的`Run()`方法中的两行代码：
- en: '[PRE41]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now, we can query the `/metrics` endpoint and see our metrics being returned.
    Let's run the smoke test three times and check the metrics of the `GetLinks()`
    and `AddLink()` methods. As expected, the `AddLink()` method was called once per
    smoke test (three times total) and the `GetLinks()` method was called three times
    per test and nine times total. We can also see the help strings.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查询`/metrics`端点并查看返回的指标。让我们运行三次烟雾测试并检查`GetLinks()`和`AddLink()`方法的指标。正如预期的那样，`AddLink()`方法在每次烟雾测试中被调用一次（总共三次），而`GetLinks()`方法在每次测试中被调用三次，总共九次。我们还可以看到帮助字符串。
- en: 'The summary quantiles are very useful when dealing with large datasets:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 总结分位数在处理大型数据集时非常有用：
- en: '[PRE42]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Custom metrics are great. However, beyond looking at a lot of numbers and graphs
    and histograms and admiring your handiwork, the real value of metrics is to inform
    an automated system or you about changes in the state of the system. That's where
    alerting comes in.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义指标非常好。然而，除了查看大量的数字、图表和直方图，欣赏你的手工作品之外，指标的真正价值在于通知自动化系统或您有关系统状态的变化。这就是警报的作用。
- en: Alerting
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警报
- en: Alerting is super important for critical systems. You can plan and build resiliency
    features as much as you want, but you will never build a failproof system. The
    right mindset for building robust and reliable systems is to try to minimize failures,
    but also acknowledge that failures will happen. When failures do happen, you need
    quick detection and have to alert the right people so that they can investigate
    and address the problem. Note that I said explicitly *alerting people*. If your
    system has self-healing capabilities, then you may be interested in viewing a
    report of the issues that the system was able to rectify itself. I don't consider
    those failures, because the system is designed to handle them. For example, containers
    can crash as much as they want; the kubelet will keep restarting them. A container
    crash is not considered a failure from a Kubernetes point of view. If your application
    running inside the container is not designed to handle such crashes and restarts,
    then you may want to configure an alert for this case, but that's your decision.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关键系统来说，警报非常重要。你可以尽可能地计划和构建弹性功能，但你永远无法构建一个无懈可击的系统。构建强大可靠系统的正确心态是尽量减少故障，但也要承认故障会发生。当故障发生时，你需要快速检测并警报相关人员，以便他们能够调查和解决问题。请注意，我明确说了*警报人员*。如果你的系统具有自愈能力，那么你可能有兴趣查看系统能够自行纠正的问题报告。我不认为这些是故障，因为系统设计用于处理它们。例如，容器可以崩溃多少次都可以；kubelet将继续重新启动它们。从Kubernetes的角度来看，容器崩溃并不被视为故障。如果容器内运行的应用程序没有设计来处理这样的崩溃和重启，那么你可能需要为这种情况配置警报，但这是你的决定。
- en: The main point I want to raise is that failure is a big word. Many things that
    could be considered failures are processes running out of memory, a server crashing,
    a corrupted disk, an intermittent or prolonged network outage, and a data center
    going offline. However, if you design for it and put mitigating measures in place,
    they are not failures of the system. The system will keep running as designed,
    possibly in a reduced capacity, but still running. If those incidents happen a
    lot and degrade to the total throughput of the system or the user experience in
    a significant way, you may want to investigate the root causes and address them.
    This is all part of defining **service-level objectives** (**SLOs**) and **service-level
    agreements** (**SLAs**). As long as you operate within your SLAs, the system is
    not failing, even if multiple components are failing and even if a service doesn't
    meet its SLO.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我想提出的主要观点是，失败是一个很大的词。许多可能被视为失败的事情包括内存耗尽、服务器崩溃、磁盘损坏、间歇性或长时间的网络中断，以及数据中心下线。然而，如果你为此进行设计并采取缓解措施，它们并不是系统的失败。系统将按设计继续运行，可能以降低的容量，但仍在运行。如果这些事件经常发生并且显著地降低了系统的总吞吐量或用户体验，你可能需要调查根本原因并加以解决。这都是定义**服务水平目标**（**SLOs**）和**服务水平协议**（**SLAs**）的一部分。只要你在SLAs范围内运作，系统就不会失败，即使多个组件失败，即使服务未达到其SLO。
- en: Embracing component failure
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接受组件故障
- en: Embracing failure means recognizing that components will fail all the time in
    a large system. This is not an unusual situation. You want to minimize component
    failures because each failure has various costs, even if the system as a whole
    continues to work. But it will happen. Most component failures can be handled
    either automatically or without urgency by having redundancy in place. However,
    systems evolve all the time and most systems are not in the perfect position where
    every component failure has mitigation in place for each type of failure. As a
    result, theoretically preventable component failures might become system failures.
    For example, if you write your logs to a local disk and you don't rotate your
    log files, then, eventually, you'll run out of disk space (very common failure),
    and, if the server using this disk is running some critical component with no
    redundancy, then you've got a system failure on your hands.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 接受失败意味着认识到在一个大型系统中，组件会经常失败。这并不是一个不寻常的情况。你希望尽量减少组件的故障，因为每次故障都会有各种成本，即使整个系统仍在运行。但这种情况会发生。大多数组件故障可以通过自动处理或通过设置冗余来处理。然而，系统不断发展，大多数系统并不处于每个组件故障都有相应应对措施的完美状态。因此，从理论上讲，本来可以预防的组件故障可能会变成系统故障。例如，如果你将日志写入本地磁盘并且不旋转日志文件，那么最终你的磁盘空间会用完（非常常见的故障），如果使用该磁盘的服务器正在运行一些关键组件而没有冗余，那么你就会面临系统故障。
- en: Grudgingly accepting system failure
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 勉强接受系统故障
- en: So, system failures will happen. Even the largest cloud providers have outages
    from time to time. There are different levels of system failures, ranging from
    temporary short failure of a non-critical subsystem, through to total outage of
    the entire system for a prolonged time, all the way to massive data loss. An extreme
    example is when malicious attackers target a company and all its backups, which
    can put it out of business. This is more related to security, but it's good to
    understand the full spectrum of system failures.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，系统故障是会发生的。即使是最大的云服务提供商也会不时发生故障。系统故障有不同的级别，从临时短暂的非关键子系统故障，到整个系统长时间的完全停机，甚至到大规模数据丢失。一个极端的例子是恶意攻击者针对一家公司及其所有备份，这可能会使其破产。这更多地与安全有关，但了解系统故障的整个范围是很好的。
- en: Common approaches for dealing with system failures are redundancy, backups,
    and compartmentalization. These are solid approaches, but are expensive, and,
    as we mentioned earlier, will not prevent all failures. The next step after minimizing
    the likelihood and impact of system failures is to plan for quick disaster recovery.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 处理系统故障的常见方法是冗余、备份和分隔。这些是可靠的方法，但成本高，正如我们之前提到的，它们并不能预防所有故障。在最大程度地减少系统故障的可能性和影响之后，下一步是计划快速的灾难恢复。
- en: Taking human factors into account
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑人为因素
- en: Now, we're strictly in the domain of people responding to an actual incident.
    Some critical systems may have 24/7 live monitoring by people watching the system
    state diligently and ready to act. Most companies will have alerts based on various
    triggers. Note that, even if you have live 24/7 monitoring for complex systems,
    you still need to surface alerts to the people monitoring the system because,
    for such systems, there is typically a huge amount of data and information that
    describe the current state.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们严格处于人们对实际事件做出反应的领域。一些关键系统可能会由人们进行24/7实时监控，他们会认真观察系统状态并随时准备采取行动。大多数公司会根据各种触发器设置警报。请注意，即使对于复杂系统，你有24/7实时监控，你仍然需要向监控系统的人员提供警报，因为对于这样的系统，通常会有大量描述当前状态的数据和信息。
- en: Let's look at several aspects of a reasonable alerting plan that work well for
    people.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一个合理的警报计划的几个方面，这对人们非常有效。
- en: Warnings versus alerts
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警告与警报
- en: Let's consider our out of disk space situation again. This is a case were the
    state gets worse over time. The disk space is gradually reduced as more and more
    data is logged to the log files. If you've got nothing in place, you will discover
    that you've ran out of disk space when an application starts to issue strange
    errors, often downstream from the actual failure, and you'll have to trace it
    back to the source. I've been there and done that; it's no fun. A better approach
    is to check the disk space regularly and raise an alert when it exceeds a certain
    threshold (for example, 95%). But why wait until the situation becomes critical?
    In such gradually worsening situations, it is much better to detect the problem
    early (for example, 75%) and issue a warning through some mechanism. This will
    give the system operator ample time to respond without causing an unnecessary
    crisis.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次考虑磁盘空间不足的情况。这是一个随着时间而恶化的情况。随着越来越多的数据记录到日志文件中，磁盘空间逐渐减少。如果你没有采取任何措施，你会发现当应用程序开始发出奇怪的错误时，通常是实际故障的下游，你将不得不追溯到源头。我曾经历过这种情况；这并不好玩。更好的方法是定期检查磁盘空间，并在超过一定阈值时（例如95%）发出警报。但为什么要等到情况变得危急？在这种逐渐恶化的情况下，更好的做法是在早期（例如75%）检测到问题并通过某种机制发出警告。这将给系统操作员充足的时间做出反应，而不会引发不必要的危机。
- en: Considering severity levels
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑严重级别
- en: 'This brings us to alert severity levels. Different severity levels deserve
    different responses. Different organizations may define their own levels. For
    example, PagerDuty has a 1-5 scale that follows the DEFCON ladder. I personally
    prefer two levels for alerts: *wake me up at 3 AM* and *it can wait to the morning*.
    I like to think of severity levels in practical terms. What kind of response or
    follow up do you perform for each severity level? If you always do the same thing
    for severity levels 3 -5, then what''s the benefits of classifying them as 3,
    4, and 5 as opposed to just grouping them together into a single low-priority
    severity level?'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了警报严重级别。不同的严重级别需要不同的响应。不同的组织可以定义自己的级别。例如，PagerDuty有一个1-5的等级，遵循DEFCON阶梯。我个人更喜欢警报的两个级别：*在凌晨3点叫醒我*和*可以等到早上*。我喜欢以实际的方式来考虑严重级别。对于每个严重级别，你会执行什么样的响应或后续工作？如果你总是对3-5级别的严重性做同样的事情，那么将它们分类为3、4和5级别与将它们归为单一的低优先级严重级别有什么好处呢？
- en: Your situation may be different, so make sure that you consider all stakeholders.
    Production incidents are not fun.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 你的情况可能不同，所以确保考虑所有利益相关者。生产事故并不好玩。
- en: Determining alert channels
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定警报通道
- en: 'Alert channels are tightly coupled to severity levels. Let''s consider the
    following options:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 警报通道与严重级别紧密相关。让我们考虑以下选项：
- en: Wake-up call to on-call engineer
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叫醒电话给值班工程师
- en: Instant message to a public channel
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即时消息到公共频道
- en: Email
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子邮件
- en: Often, the same incident will be broadcasted to multiple channels. Obviously,
    the wake-up call is the most intrusive, the instant message (for example, slack)
    may pop up as a notification, but someone has to be around and look at it. The
    email is often more informative in nature. It is common to combine multiple channels.
    For example, the on-call engineer gets the wake up call, the team incident channel
    gets a message, and the group manager gets and email.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，同一事件会被广播到多个通道。显然，叫醒电话是最具侵入性的，即时消息（例如，slack）可能会弹出通知，但必须有人在附近看到它。电子邮件通常更具信息性。结合多个通道是很常见的。例如，值班工程师接到叫醒电话，团队事件通道收到一条消息，团队经理收到一封电子邮件。
- en: Fine-tuning noisy alerts
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化嘈杂的警报
- en: 'Noisy alerts are a problem. If there are too many alerts – especially low-priority
    ones – then there are two major problems:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 嘈杂的警报是一个问题。如果警报太多 - 尤其是低优先级的警报 - 那么就会出现两个主要问题：
- en: It is distracting to all the people that get notified (especially to the poor
    engineer being woke up in the middle of the night).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这会分散所有收到通知的人的注意力（尤其是在半夜被叫醒的可怜工程师）。
- en: It might lead to people ignoring alerts.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可能导致人们忽略警报。
- en: You don't want to miss an important alert because of a lot of noisy low-priority
    alerts. Fine-tuning your alerts is an art and an ongoing process.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 您不希望因为大量嘈杂的低优先级警报而错过重要的警报。调整警报是一门艺术，也是一个持续的过程。
- en: I recommend reading and adopting *My Philosophy on Alerting* ([https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit](https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit))
    by Rob Ewaschuk (ex-Google site reliability engineer).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议阅读并采纳Rob Ewaschuk（前Google网站可靠性工程师）的《关于警报的我的哲学》（[https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit](https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit)）。
- en: Utilizing the Prometheus alert manager
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用Prometheus警报管理器
- en: 'Alerts naturally feed off metrics. Prometheus, in addition to being a fantastic
    metrics collector, also provides an alert manager. We''ve already installed it
    as part of the overall Prometheus installation:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 警报自然而然地依赖于指标。除了作为一个出色的指标收集器外，Prometheus还提供了一个警报管理器。我们已经将其作为整体Prometheus安装的一部分安装了：
- en: '[PRE43]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We're not going to configure any alerts because I don't want to be on call for
    Delinkcious.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会配置任何警报，因为我不想为Delinkcious值班。
- en: 'The Alert manager has a conceptual model that includes the following:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 警报管理器具有以下概念模型：
- en: Groupings
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分组
- en: Integrations
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成
- en: Inhibition
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抑制
- en: Silences
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沉默
- en: Grouping deals with consolidating multiple signals into a single notification.
    For example, if many of your services use AWS S3 and it suffers an outage, then
    a lot of services might trigger alerts. But with grouping, you can configure the
    alert manager to send just one notification.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 分组处理将多个信号合并为单个通知。例如，如果您的许多服务使用AWS S3并且出现故障，那么许多服务可能会触发警报。但是通过分组，您可以配置警报管理器仅发送一个通知。
- en: Integrations are notification targets. The alert manager supports many targets
    out of the box like email, PagerDuty, Slack, HipChat, PushOver, OpsGenie, VictoOps,
    and WeChat. For all other integrations, the recommendation is to use the generic
    HTTP webhook integration.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 集成是通知目标。警报管理器支持许多目标，如电子邮件、PagerDuty、Slack、HipChat、PushOver、OpsGenie、VictoOps和微信。对于所有其他集成，建议使用通用的HTTP
    webhook集成。
- en: Inhibition is an interesting concept where you can skip sending notifications
    for alerts if other alerts are already firing. This is another way on top of grouping
    to avoid sending multiple notifications for the same high-level problem.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 抑制是一个有趣的概念，您可以跳过发送通知，如果其他警报已经触发。这是在分组之上的另一种方式，可以避免为相同的高级问题发送多个通知。
- en: Silences are just a mechanism to temporarily mute some alerts. This is useful
    if your alerting rules are not neatly configured with grouping and inhibitions,
    or even if some valid alerts keep firing, but you are already handling the situation
    and you don't need more notifications at the moment. You can configure silences
    in the web UI.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 沉默只是一种暂时静音某些警报的机制。如果您的警报规则没有与分组和抑制清晰地配置，或者即使一些有效的警报仍在触发，但您已经处理了情况，并且暂时不需要更多通知，这将非常有用。您可以在Web
    UI中配置沉默。
- en: Configuring alerts in Prometheus
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Prometheus中配置警报
- en: 'You can raise alerts by configuring rules in the Prometheus server configuration
    file. Those alerts are handled by the alert manager which decides, based on its
    configuration, what to do about them. Here is an example:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在Prometheus服务器配置文件中配置规则来触发警报。这些警报由警报管理器处理，根据其配置决定如何处理这些警报。以下是一个示例：
- en: '[PRE44]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The rule has an expression, which, if true, triggers the alert. There is a period
    of time (1 minute here) where the condition must be true, so that you can avoid
    triggering one-off anomalies (if you so choose). There is severity associated
    with the alert and some annotations.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 规则有一个表达式，如果为真，则触发警报。有一个时间段（这里是1分钟），条件必须为真，这样您就可以避免触发一次性异常（如果您选择的话）。警报有与之关联的严重性和一些注释。
- en: With metrics and alerts covered, let's move on and see what to do when an alert
    fires and we get notified of a problem.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理了指标和警报之后，让我们继续看看在警报触发并通知我们有问题时该怎么做。
- en: Distributed tracing
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式跟踪
- en: 'The notifications that alert you that something is wrong can be as vague as
    *Something is wrong with the website*. Well, that''s not very useful for troubleshooting,
    detecting the root cause, and fixing it. This is especially true for microservice-based
    architectures where every user request can be handled by a large number of microservices
    and each component might fail in interesting ways. There are several ways to try
    and narrow down the scope:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 警报通知您有什么问题可能会很模糊，比如“网站出了问题”。这对于故障排除、检测根本原因和修复并不是很有用。特别是对于基于微服务的架构，每个用户请求可能由大量微服务处理，每个组件可能以有趣的方式失败。有几种方法可以尝试缩小范围：
- en: Look at recent deployments and configuration changes.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看最近的部署和配置更改。
- en: Check whether any of your third-party dependencies suffered an outage.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查您的第三方依赖是否遭受了中断。
- en: Consider similar issues if the root cause hasn't been fixed yet.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果根本原因尚未解决，请考虑类似的问题。
- en: If you're lucky, you can just diagnose the problem right away. However, when
    debugging large-scale distributed systems, you don't really want to rely on luck.
    It's much better to have a methodical approach in place. Enter distributed tracing.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 如果幸运的话，您可以立即诊断问题。然而，在调试大规模分布式系统时，您真的不想依赖运气。最好是有一个系统的方法。进入分布式跟踪。
- en: 'We will use the Jaeger ([https://www.jaegertracing.io/](https://www.jaegertracing.io/))
    distributed tracing system. It is yet another CNCF project that started as an
    Uber open source project. The problems Jaeger can help with are as follows:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Jaeger（[https://www.jaegertracing.io/](https://www.jaegertracing.io/)）分布式跟踪系统。这是又一个CNCF项目，最初是Uber的开源项目。Jaeger可以帮助解决的问题如下：
- en: Distributed transaction monitoring
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式事务监控
- en: Performance and latency optimization
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能和延迟优化
- en: Root cause analysis
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根本原因分析
- en: Service dependency analysis
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务依赖分析
- en: Distributed context propagation
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式上下文传播
- en: Before we can use Jaeger, we need to install it into the cluster.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以使用Jaeger之前，我们需要将其安装到集群中。
- en: Installing Jaeger
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Jaeger
- en: 'The best way to install Jaeger is using the Jaeger-operator, so let''s install
    the operator first:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Jaeger的最佳方式是使用Jaeger-operator，所以让我们首先安装运算符：
- en: '[PRE45]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Once the operator has been installed, we can create a Jaeger instance using
    the following manifest:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了运算符之后，我们可以使用以下清单创建一个Jaeger实例：
- en: '[PRE46]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This is a simple in-memory instance. You can also create instances that are
    backed up by Elasticsearch and Cassandra:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的内存实例。您还可以创建由Elasticsearch和Cassandra支持的实例：
- en: '![](assets/84c05323-cd15-47b8-8331-24d78c6fc841.png)Jaeger UI'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/84c05323-cd15-47b8-8331-24d78c6fc841.png)Jaeger UI'
- en: Jaeger has a very slick web UI that lets you drill down and explore distributed
    workflows.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger有一个非常漂亮的Web UI，可以让您深入了解和探索分布式工作流程。
- en: Integrating tracing into your services
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将跟踪集成到您的服务中
- en: There are several steps here, but the gist of it is that you can think of tracing
    as another form of middleware. The core abstraction is a span. A request spans
    multiple microservices, and you record those spans and associate logs with them.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个步骤，但其要点是，你可以将跟踪视为另一种形式的中间件。核心抽象是span。一个请求涉及多个微服务，你记录这些span并将日志与它们关联起来。
- en: 'Here is the tracing middleware, which is similar to the logging middleware,
    except that it starts a span for the `GetLinks()` method instead of logging. As
    usual, there is the factory function that returns a `linkManagerMiddleware` function
    that calls the next middleware in the chain. The factory function accepts a tracer,
    which can start and finish a span:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 这是跟踪中间件，类似于日志中间件，不同之处在于它为`GetLinks()`方法启动一个span，而不是记录日志。像往常一样，有一个工厂函数返回一个`linkManagerMiddleware`函数，调用链中的下一个中间件。工厂函数接受一个跟踪器，它可以启动和结束一个span：
- en: '[PRE47]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let''s add the following function to create a Jaeger tracer:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加以下函数来创建一个Jaeger跟踪器：
- en: '[PRE48]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then, the `Run()` function creates a new tracer and a tracing middleware that
    it hooks up to the chain of middlewares:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`Run()`函数创建一个新的跟踪器和一个跟踪中间件，将其挂接到中间件链上：
- en: '[PRE49]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'After running the smoke test, we can search the logs for reports of spans.
    We expect three spans since the smoke test calls `GetLinks()` three times:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 运行完烟雾测试后，我们可以搜索日志以查找span的报告。我们期望有三个span，因为烟雾测试调用了`GetLinks()`三次：
- en: '[PRE50]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: There is much more to tracing and Jaeger. This is barely starting to scratch
    the surface. I encourage you to read more on it, experiment with it, and integrate
    it into your systems.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪和Jaeger还有很多内容。这只是刚刚开始涉及到表面。我鼓励你多了解它，尝试它，并将其整合到你的系统中。
- en: Summary
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered a large number of topics, including self-healing,
    autoscaling, logging, metrics, and distributed tracing. Monitoring a distributed
    system is tough. Just installing and configuring the various monitoring services
    like Fluentd, Prometheus, and Jaeger is a non-trivial project. Managing the interactions
    between them and how your services support logging, instrumentation, and tracing
    adds another level of complexity. We've seen how Go-kit, with its middleware concept,
    makes it somewhat easier to add those operational concerns in a decoupled way
    from the core business logic. Once you have all the monitoring for those systems
    in place, there's a new set of challenges to take into account – how do you gain
    insights from all the data? How can you integrate it into your alerting and incident
    response process? How can you continuously improve your understanding of the system
    and improve your processes? These are all hard questions that you'll have to answer
    for yourself, but you may find some guidance in the *Further reading* section
    that follows.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了许多主题，包括自愈、自动扩展、日志记录、度量和分布式跟踪。监控分布式系统很困难。仅仅安装和配置各种监控服务如Fluentd、Prometheus和Jaeger就是一个不小的项目。管理它们之间的交互以及你的服务如何支持日志记录、仪器化和跟踪增加了另一层复杂性。我们已经看到，Go-kit的中间件概念使得以一种与核心业务逻辑解耦的方式更容易地添加这些运营关注点。一旦你为这些系统建立了所有的监控，就会有一系列新的挑战需要考虑
    - 你如何从所有的数据中获得洞察？你如何将其整合到你的警报和事件响应流程中？你如何不断改进对系统的理解和改进你的流程？这些都是你必须自己回答的难题，但你可能会在接下来的*进一步阅读*部分中找到一些指导。
- en: In the next chapter, we will look at the exciting world of service meshes and
    Istio. Service meshes are a true innovation that can really offload many operational
    concerns from the services and let them focus on their core domain. However, a
    service mesh like Istio has a large surface area and there is a significant learning
    curve to overcome. Do the benefits of the service mesh compensate for the added
    complexity? We'll find out soon.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨服务网格和Istio这个令人兴奋的世界。服务网格是一个真正的创新，可以真正地减轻服务的许多运营问题，让它们专注于它们的核心领域。然而，像Istio这样的服务网格有着广泛的应用范围，需要克服相当大的学习曲线。服务网格的好处是否能够弥补增加的复杂性？我们很快就会找出答案。
- en: Further reading
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Refer to the following links to find out more about what was covered in this
    chapter:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下链接，了解本章涵盖的更多内容：
- en: '**Kubernetes federation**: [https://github.com/kubernetes-sigs/federation-v2](https://github.com/kubernetes-sigs/federation-v2)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes federation**: [https://github.com/kubernetes-sigs/federation-v2](https://github.com/kubernetes-sigs/federation-v2)'
- en: '**Kubernetes autoscaler**: [https://github.com/kubernetes/autoscaler](https://github.com/kubernetes/autoscaler)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes autoscaler**: [https://github.com/kubernetes/autoscaler](https://github.com/kubernetes/autoscaler)'
- en: '**The hunt for a logger interface**: [https://go-talks.appspot.com/github.com/ChrisHines/talks/structured-logging/structured-logging.slide#1](https://go-talks.appspot.com/github.com/ChrisHines/talks/structured-logging/structured-logging.slide#1)'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**The hunt for a logger interface**: [https://go-talks.appspot.com/github.com/ChrisHines/talks/structured-logging/structured-logging.slide#1](https://go-talks.appspot.com/github.com/ChrisHines/talks/structured-logging/structured-logging.slide#1)'
- en: '**Gradener**: [https://gardener.cloud](https://gardener.cloud)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gradener**: [https://gardener.cloud](https://gardener.cloud)'
- en: '**Prometheus**: [https://prometheus.io/docs/introduction/overview/](https://prometheus.io/docs/introduction/overview/)'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**: [https://prometheus.io/docs/introduction/overview/](https://prometheus.io/docs/introduction/overview/)'
- en: '**Fluentd**: [https://www.fluentd.org/](https://www.fluentd.org/)'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fluentd**: [https://www.fluentd.org/](https://www.fluentd.org/)'
- en: '**Cluster-level logging**: [https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures](https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cluster-level logging**: [https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures](https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures)'
- en: '**Monitoring best practices**: [https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit#](https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit#)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Monitoring best practices**: [https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit#](https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit#)'
- en: '**Jaeger**: [https://github.com/jaegertracing/jaeger](https://github.com/jaegertracing/jaeger)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jaeger**: [https://github.com/jaegertracing/jaeger](https://github.com/jaegertracing/jaeger)'
