- en: '2: Kubernetes principles of operation'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2：Kubernetes操作原则
- en: In this chapter, we’ll learn about the major components needed to build a Kubernetes
    cluster and deploy an app. The aim of the game is to give you an overview of the
    major concepts. But don’t worry if you don’t understand everything straight away,
    we’ll cover most things again as we progress through the book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将学习构建Kubernetes集群和部署应用程序所需的主要组件。游戏的目的是为您提供主要概念的概述。但是如果您不立刻理解一切，不要担心，随着我们在书中的进展，我们将再次涵盖大部分内容。
- en: 'We’ll divide the chapter as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按以下方式划分本章：
- en: Kubernetes from 40K feet
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从40K英尺高度看Kubernetes
- en: Masters and nodes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点和节点
- en: Packaging apps
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打包应用程序
- en: Declarative configuration and desired state
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明性配置和期望状态
- en: Pods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pods
- en: Deployments
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Services
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务
- en: Kubernetes from 40K feet
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从40K英尺高度看Kubernetes
- en: At the highest level, Kubernetes is an orchestrator of cloud-native microservices
    apps. This is just a fancy name for an application that’s made from lots of small
    independent services that work together to form a useful app.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高层次上，Kubernetes是云原生微服务应用程序的编排器。这只是一个由许多小独立服务组成的应用程序的花哨名称，它们共同工作形成一个有用的应用程序。
- en: Let’s look at a quick analogy.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个快速的类比。
- en: In the real world, a football (soccer) team is made of individuals. No two are
    the same, and each has a different role to play in the team - some defend, some
    attack, some are great at passing, some are great at shooting…. Along comes the
    coach, and he or she gives everyone a position and organizes them into a team
    with a purpose. We go from Figure 2.1 to Figure 2.2.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，一个足球（足球）队由个体组成。没有两个是相同的，每个人在团队中扮演不同的角色 - 有些防守，有些进攻，有些擅长传球，有些擅长射门... 教练来了，他或她给每个人一个位置，并将他们组织成一个有目的的团队。我们从图2.1到图2.2。
- en: '![Figure 2.1](Image00005.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1](Image00005.jpg)'
- en: Figure 2.1
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1
- en: '![Figure 2.2](Image00006.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2](Image00006.jpg)'
- en: Figure 2.2
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2
- en: The coach also makes sure that the team maintains its formation, sticks to the
    plan, and deals with any injuries. Well guess what… microservices apps in the
    Kubernetes world are the same!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 教练还确保团队保持队形，坚持计划，并处理任何伤病。好吧，猜猜… Kubernetes世界中的微服务应用程序也是一样的！
- en: Stick with me on this…
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 跟着我…
- en: We start out with lots of individual specialised services - some serve web pages,
    some do authentication, some do searches, others persist data. Kubernetes comes
    along - a bit like the coach in the football analogy – and organizes everything
    into a useful app and keeps things running smoothly.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从许多个体化的专业服务开始 - 有些提供网页，有些进行身份验证，有些进行搜索，其他一些持久化数据。Kubernetes出现了 - 就像足球类比中的教练一样
    - 将所有东西组织成一个有用的应用程序，并保持一切运行顺利。
- en: In the sports world we call this *coaching* . In the application world we call
    it *orchestration* .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在体育界，我们称之为*教练*。在应用程序世界中，我们称之为*编排*。
- en: Kubernetes is an *orchestrator* .
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个*编排器*。
- en: To make this happen, we start out with an app, package it up and give it to
    the cluster (Kubernetes). The cluster is made up of one or more *masters* , and
    a bunch of *nodes* .
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们从一个应用程序开始，打包它并将其交给集群（Kubernetes）。集群由一个或多个*主节点*和一堆*节点*组成。
- en: The masters are in-charge of the cluster and make all the scheduling decisions.
    They also monitor the cluster, implement changes, and respond to events. For this
    reason, we often refer to the masters as the *control plane* .
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点负责集群并做出所有调度决策。他们还监视集群，实施更改并响应事件。因此，我们经常将主节点称为*控制平面*。
- en: The nodes are where application services run, and we sometimes call them the
    *data plane* . They have a reporting line back to the masters, and constantly
    watch for new work assignments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 节点是应用程序服务运行的地方，有时我们称它们为*数据平面*。它们向主节点汇报，并不断观察新的工作任务。
- en: 'To run applications on a Kubernetes cluster we follow this simple pattern:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Kubernetes 集群上运行应用程序，我们遵循这个简单的模式：
- en: Write the application as small independent services in our favourite languages.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用我们喜欢的语言将应用程序编写为小型独立服务。
- en: Package each service in its own container.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个服务打包在自己的容器中。
- en: Wrap each container in its own Pod.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个容器包装在自己的 Pod 中。
- en: Deploy Pods to the cluster via higher-level objects such as; *Deployments, DaemonSets,
    StafeulSets, CronJobs etc.*
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过更高级别的对象（例如；*Deployments, DaemonSets, StafeulSets, CronJobs 等）将 Pod 部署到集群中。
- en: We’re still near the beginning of the book and you’re not expected to know what
    all of these terms mean yet. But at a high-level, *Deployments* offer scalability
    and rolling updates, *DaemonSets* run one instance of a Pod on every node in the
    cluster, *StatefulSets* are for stateful components of your app, and *CronJobs*
    are for work that needs to run at set times. There are more options, but these
    will do for now.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然处在书的开头阶段，不要指望你已经知道所有这些术语的含义。但在高层次上，*Deployments* 提供了可伸缩性和滚动更新，*DaemonSets*
    在集群中的每个节点上运行一个 Pod 实例，*StatefulSets* 用于应用程序的有状态组件，*CronJobs* 用于需要在设定时间运行的工作。还有更多选项，但现在这些就够了。
- en: Kubernetes likes to manage applications *declaratively* . This is a pattern
    where we describe how we want our application to look and feel in a set of YAML
    files, `POST` these files to Kubernetes, then sit back while Kubernetes makes
    it all happen.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 喜欢以声明方式管理应用程序。这是一种模式，我们在一组 YAML 文件中描述我们希望应用程序的外观和感觉，将这些文件发送到 Kubernetes，然后坐下来，让
    Kubernetes 完成所有工作。
- en: But it doesn’t stop there. Kubernetes constantly watches the different parts
    of our application to make sure it’s running exactly the way it should. If something
    isn’t as it should be, Kubernetes tries to fix it.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但事情并不止于此。Kubernetes 不断监视我们应用程序的不同部分，以确保它运行的方式完全符合预期。如果有什么不对劲，Kubernetes 会尝试修复它。
- en: That’s the big picture. Let’s dig a bit deeper.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个大局观。让我们深入一点。
- en: Masters and nodes
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主节点和节点
- en: A Kubernetes cluster is made of masters and nodes. These are Linux hosts that
    can be VMs, bare metal servers in your data center, or instances on a private
    or public cloud.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群由主节点和节点组成。这些是可以是虚拟机、数据中心中的裸金属服务器，或者是私有或公共云中的实例的 Linux 主机。
- en: Masters (control plane)
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 主节点（控制平面）
- en: A Kubernetes master is a collection of system services that make up the control
    plane of the cluster.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 主节点是构成集群控制平面的系统服务的集合。
- en: The simplest setups run all the master *services* on a single host. However,
    multi-master HA is becoming more and more important, and is a **must have** for
    production environments. This is why the major cloud providers implement highly
    available masters as part of their Kubernetes-as-a-Service platforms such as AKS,
    EKS, and GKE.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的设置在单个主机上运行所有主服务。然而，多主高可用性对于生产环境变得越来越重要，并且对于生产环境来说是**必不可少**的。这就是为什么主要的云提供商在其
    Kubernetes 作为服务平台中实现高可用性主节点，如 AKS、EKS 和 GKE。
- en: It’s also considered a good practice **not** to run application workloads on
    masters. This allows masters to concentrate entirely on managing the cluster.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个被认为是一个好的实践**不要**在主节点上运行应用程序工作负载。这使得主节点可以完全集中于管理集群。
- en: Let’s take a quick look at the major pieces of a Kubernetes master that make
    up the control plane.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下组成控制平面的 Kubernetes 主节点的主要部分。
- en: The API server
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: API 服务器
- en: The API server is the front door into Kubernetes. It exposes a RESTful API that
    we `POST` YAML configuration files to. These YAML files, which we sometimes call
    *manifests* , contain the desired state of our application. This includes things
    like; which container image to use, which ports to expose, and how many Pod replicas.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: API服务器是进入Kubernetes的前门。它公开了一个RESTful API，我们可以通过它向服务器发送YAML配置文件。这些YAML文件，有时我们称之为*清单*，包含了我们应用程序的期望状态。这包括诸如要使用哪个容器镜像、要暴露哪些端口以及有多少个Pod副本等内容。
- en: All requests to the API Server are subject to authentication and authorization
    checks, but once these are done, the config in the YAML file is validated, persisted
    to the cluster store, and deployed to the cluster.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对API服务器的所有请求都要经过身份验证和授权检查，但一旦完成这些步骤，YAML文件中的配置将被验证，持久化到集群存储中，并部署到集群中。
- en: You can think of the API server as the brains of the cluster - where the smarts
    are implemented.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将API服务器视为集群的大脑 - 智能实现的地方。
- en: The cluster store
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 集群存储
- en: If the API server is the brains of the cluster, the *cluster store* is its memory.
    It’s the only stateful part of the control plane, and it persistently stores the
    entire configuration and state of the cluster. As such, it’s a vital component
    of the cluster - no cluster store, no cluster!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果API服务器是集群的大脑，那么*集群存储*就是它的记忆。它是控制平面中唯一有状态的部分，并且持久地存储了整个集群的配置和状态。因此，它是集群的重要组成部分
    - 没有集群存储，就没有集群！
- en: The cluster store is based on **etcd** , a popular distributed database. As
    it’s the *single source of truth* for the cluster, you should take care to protect
    it and provide adequate ways to recover when things go wrong.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 集群存储基于**etcd**，这是一个流行的分布式数据库。由于它是集群的*唯一真相来源*，您应该小心保护它，并提供足够的恢复方式以应对出现问题时的情况。
- en: The controller manager
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 控制器管理器
- en: The controller manager is a *controller of controllers* and is a bit of a monolith.
    Although it runs as a single process, it implements several control loops that
    watch the cluster and respond to events. Some of these control loops include;
    the node controller, the endpoints controller, and the namespace controller. Each
    one generally runs as a background watch-loop that is constantly watching the
    API Server for changes – the aim of the game is to ensure the *current state*
    of the cluster matches the *desired state* (more on this shortly).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器管理器是*控制器的控制器*，有点像一个单体。虽然它作为一个单一的进程运行，但它实现了几个控制循环，监视集群并响应事件。其中一些控制循环包括：节点控制器、端点控制器和命名空间控制器。每个控制器通常作为一个后台监视循环运行，不断地监视API服务器的变化
    - 游戏的目标是确保集群的*当前状态*与*期望状态*匹配（稍后会详细介绍）。
- en: '**Note:** Throughout the book we’ll use terms like *control loop, watch loop,*
    and *reconciliation loop* to mean the same thing.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：**在整本书中，我们将使用*控制循环*、*监视循环*和*协调循环*等术语来表示相同的意思。'
- en: The scheduler
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 调度器
- en: At a high level, the scheduler watches for new work and assigns it to nodes.
    Behind the scenes, it evaluates affinity and anti-affinity rules, constraints,
    and resource management.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，调度器会监视新的工作并将其分配给节点。在幕后，它评估亲和性和反亲和性规则、约束和资源管理。
- en: The cloud controller manager
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 云控制器管理器
- en: If you’re running your cluster on a supported public cloud platform, such as
    AWS, Azure, or GCP, your control plane will be running a *cloud controller manager*
    . It’s job is to manage integrations with your underlying cloud platform, such
    as nodes, load-balancers, and storage.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在受支持的公共云平台（如AWS、Azure或GCP）上运行集群，则您的控制平面将运行一个*云控制器管理器*。它的工作是管理与底层云平台的集成，如节点、负载均衡器和存储。
- en: Control Plane summary
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 控制平面摘要
- en: Kubernetes masters run all of the cluster’s control plane services. Think of
    it as brains of the cluster - where all the control and scheduling decisions are
    made. Behind the scenes, a master is made up of lots of small specialized services.
    These include the API server, the cluster store, the controller manager, and the
    scheduler.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的主节点运行着整个集群的控制平面服务。可以把它看作是集群的大脑 - 所有控制和调度决策都是在这里做出的。在幕后，主节点由许多小型专门的服务组成。这些包括API服务器、集群存储、控制器管理器和调度器。
- en: The API Server is the front-end into the control plane and the only component
    in the control plane that we interact with directly. By default, it exposes a
    RESTful endpoint on port 443.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: API服务器是控制平面的前端，也是我们直接交互的控制平面中唯一的组件。默认情况下，它在端口443上公开一个RESTful端点。
- en: Figure 2.3 shows a high-level view of a Kubernetes master (control plane).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3显示了Kubernetes主节点（控制平面）的高层视图。
- en: '![Figure 2.3 - Kubernetes Master](Image00007.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 - Kubernetes主节点](Image00007.jpg)'
- en: Figure 2.3 - Kubernetes Master
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 - Kubernetes主节点
- en: Nodes
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 节点
- en: '*Nodes* are the workers of a Kubernetes cluster. At a high-level they do three
    things:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*节点*是Kubernetes集群的工作者。在高层次上，它们有三个功能：'
- en: Watch the API Server for new work assignments
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监视API服务器以获取新的工作任务
- en: Execute new work assignments
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行新的工作任务
- en: Report back to the control plane
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向控制平面报告
- en: As we can see from Figure 2.4, they’re are a bit simpler than *masters* . Let’s
    look at the three major components of a node.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从图2.4可以看出，它们比*主节点*简单一些。让我们来看一下节点的三个主要组件。
- en: '![Figure 2.4 - Kubernetes Node (formerly Minion)](Image00008.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 - Kubernetes节点（以前称为Minion）](Image00008.jpg)'
- en: Figure 2.4 - Kubernetes Node (formerly Minion)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 - Kubernetes节点（以前称为Minion）
- en: Kubelet
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Kubelet
- en: The Kubelet is the main Kubernetes agent that runs on all nodes in the cluster.
    In fact, it’s common to use the terms *node* and *kubelet* interchangeably. You
    install the kubelet on a Linux host, which registers the host with the cluster
    as a *node* . It then watches the API server for new work assignments. Any time
    it sees one, it carries out the task and maintains a reporting channel back to
    the master.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Kubelet是在集群中所有节点上运行的主要Kubernetes代理。事实上，通常可以互换使用术语*节点*和*kubelet*。您在Linux主机上安装kubelet，它会将主机注册为*节点*加入集群。然后它会监视API服务器以获取新的工作任务。每当它看到一个任务，它就会执行该任务并保持与主节点的报告通道。
- en: If the kubelet can’t run a particular work task, it reports back to the master
    and lets the control plane decide what actions to take. For example, if a Pod
    fails on a node, the kubelet is **not** responsible for finding another node to
    run it on. It simply reports back to the control plane and the control plane decides
    what to do.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果kubelet无法运行特定的工作任务，它会向主节点报告，并让控制平面决定采取什么行动。例如，如果一个Pod在一个节点上失败，kubelet **不**负责找到另一个节点来运行它。它只是向控制平面报告，由控制平面决定如何处理。
- en: Container runtime
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 容器运行时
- en: The Kubelet needs a container runtime to perform container-related tasks – things
    like pulling images, and starting and stopping containers.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Kubelet需要一个容器运行时来执行与容器相关的任务 - 诸如拉取镜像、启动和停止容器等。
- en: In the early days, Kubernetes had native support for a few container runtimes
    such as Docker. More recently, it has moved to a plugin model called the Container
    Runtime Interface (CRI). This is an abstraction layer for external (3rd-party)
    container runtimes to plug in to. Basically, the CRI masks the internal machinery
    of Kubernetes and exposes a clean documented interface for 3rd-party container
    runtimes to interface with.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，Kubernetes原生支持一些容器运行时，比如Docker。最近，它已经转移到了一个名为容器运行时接口（CRI）的插件模型。这是一个用于外部（第三方）容器运行时插入的抽象层。基本上，CRI掩盖了Kubernetes的内部机制，并为第三方容器运行时提供了一个清晰的文档化接口。
- en: The CRI is the supported method for integrating runtimes into Kubernetes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: CRI是将运行时集成到Kubernetes中的支持方法。
- en: There are lots of container runtimes available for Kubernetes. `cri-containerd`
    is a community-based open-source project porting the CNCF `containerd` runtime
    to the CRI interface. It has a lot of support and is replacing Docker as the most
    popular container runtime used in Kubernetes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有很多可用的容器运行时。`cri-containerd`是一个基于社区的开源项目，将CNCF的`containerd`运行时移植到CRI接口。它得到了很多支持，并且正在取代Docker成为Kubernetes中最流行的容器运行时。
- en: '**Note:** `containerd` (pronounced “container-dee”) is the container supervisor
    and runtime logic stripped out of the Docker Engine. It was donated to the CNCF
    by Docker, Inc. and has a lot of community support. Other CRI-compliant container
    runtimes exist.'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：**`containerd`（发音为“container-dee”）是从Docker Engine中剥离出来的容器监督者和运行时逻辑。它由Docker，Inc.捐赠给了CNCF，并得到了很多社区支持。还有其他符合CRI标准的容器运行时存在。'
- en: Kube-proxy
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Kube-proxy
- en: The last piece of the *node* puzzle is the kube-proxy. This runs on every node
    in the cluster and is responsible for local networking. For example, it makes
    sure each node gets its own unique IP address, and implements local IPTABLES or
    IPVS rules to handle routing and load-balancing of certain traffic types.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*node*谜题的最后一部分是kube-proxy。它在集群中的每个节点上运行，并负责本地网络。例如，它确保每个节点都有自己独特的IP地址，并实现本地的IPTABLES或IPVS规则来处理某些流量类型的路由和负载均衡。'
- en: Now that we understand the fundamentals of masters and nodes, let’s switch gears
    and look at how we package applications to run on Kubernetes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们了解了主节点和节点的基本原理，让我们转换方向，看看如何将应用程序打包运行在Kubernetes上。
- en: Packaging apps
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 打包应用程序
- en: 'In order for an application to run on a Kubernetes cluster it needs to tick
    a few boxes. These include:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让应用程序在Kubernetes集群上运行，它需要满足一些条件。这些条件包括：
- en: Packaged as a container
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打包为一个容器
- en: Wrapped in a Pod
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包装在Pod中
- en: Deployed via a manifest file (Pod, Deployment. DaemonSet…)
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过清单文件部署（Pod，Deployment. DaemonSet…）
- en: It goes like this… We write our code in our favourite language. We build that
    into a container image and store it in a registry. At this point, our code is
    *containerized* .
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下…我们用我们喜欢的语言编写代码。我们将其构建成一个容器镜像并存储在注册表中。此时，我们的代码就是*containerized*的。
- en: Next, we define a Kubernetes Pod to hold our containerized app. At the kind
    of high level we’re at, a Pod is just a wrapper that allows containers to run
    on a Kubernetes cluster. Once we’ve defined a Pod for our container, we’re ready
    to deploy it on the cluster.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个Kubernetes Pod来容纳我们的容器化应用程序。在我们目前的高级别上，Pod只是一个包装器，允许容器在Kubernetes集群上运行。一旦我们为我们的容器定义了一个Pod，我们就可以在集群上部署它了。
- en: Kubernetes offers several objects for deploying and managing Pods. The most
    common is the *Deployment* , which offers scalability, self-healing, and rolling
    updates. They’re defined in a YAML files and specify things like - which Pod to
    deploy and how many replicas to deploy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了几种对象来部署和管理Pods。最常见的是*Deployment*，它提供了可伸缩性、自愈性和滚动更新。它们在YAML文件中定义，并指定诸如
    - 部署哪个Pod以及部署多少个副本等内容。
- en: Figure 2.5 shows application code packaged as a *container* , running inside
    a *Pod* , managed by a *Deployment* .
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5显示了打包为*container*的应用程序代码，运行在*Pod*内，由*Deployment*管理。
- en: '![Figure 2.5 - Kubernetes Node (formerly Minion)](Image00009.gif)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 - Kubernetes节点（以前是Minion）](Image00009.gif)'
- en: Figure 2.5 - Kubernetes Node (formerly Minion)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 - Kubernetes节点（以前是Minion）
- en: Once everything is defined in the *Deployment* YAML file, we `POST` it to the
    cluster as the *desired state* of our application and let Kubernetes implement
    it.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在*Deployment* YAML文件中定义了所有内容，我们就将其作为我们应用程序的*desired state*发布到集群中，让Kubernetes来实现它。
- en: Speaking of desired state…
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 说到desired state…
- en: The declarative model and desired state
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 声明模型和desired state
- en: The *declarative model* and the concept of *desired state* are two things at
    the very heart of Kubernetes. Take them away and Kubernetes crumbles!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*声明模型*和*期望状态*的概念是Kubernetes核心的两个要素。如果把它们拿走，Kubernetes就会崩溃！'
- en: 'In Kubernetes, the declarative model works like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，声明模型的工作方式如下：
- en: We declare the desired state of an application (microservice) in a manifest
    file
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在清单文件中声明了应用程序（微服务）的期望状态
- en: We POST it to the Kubernetes API server
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将其POST到Kubernetes API服务器
- en: Kubernetes stores this in the cluster store as the application’s *desired state*
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes将这些存储在集群存储中作为应用程序的*期望状态*
- en: Kubernetes implements the desired state on the cluster
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes在集群上实现了期望状态
- en: Kubernetes implements watch loops to make sure the *current state* of the application
    doesn’t vary from *desired state*
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes实现了监视循环，以确保应用程序的*当前状态*与*期望状态*不变
- en: Let’s look at each step in a bit more detail.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看每个步骤。
- en: Manifest files are written in simple YAML, and they tell Kubernetes how we want
    an application to look. We call this is the *desired state* . It includes things
    such as; which image to use, how many replicas to have, which network ports to
    listen on, and how to perform updates.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 清单文件是用简单的YAML编写的，它们告诉Kubernetes我们希望应用程序看起来是什么样子。我们称之为*期望状态*。它包括诸如要使用哪个镜像，要有多少副本，要监听哪些网络端口以及如何执行更新等内容。
- en: Once we’ve created the manifest, we `POST` it to the API server. The most common
    way of doing this is with the `kubectl` command-line utility. This POSTs the manifest
    as a request to the control plane, usually on port 443.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了清单，我们就会使用`kubectl`命令行实用程序将其`POST`到API服务器。这样做的最常见方式是使用`kubectl`命令行实用程序。这将清单作为请求POST到控制平面，通常在端口443上。
- en: Once the request is authenticated and authorized, Kubernetes inspects the manifest,
    identifies which controller to send it to (e.g. the *Deployments controller* ),
    and records the config in the cluster store as part of the cluster’s overall *desired
    state* . Once this is done, the work gets scheduled on the cluster. This includes
    the hard work of pulling images, starting containers, and building networks.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦请求经过身份验证和授权，Kubernetes会检查清单，确定要将其发送到哪个控制器（例如*部署控制器*），并将配置记录在集群存储中作为集群整体*期望状态*的一部分。完成这些工作后，工作会被安排在集群上。这包括拉取镜像、启动容器和构建网络的艰苦工作。
- en: Finally, Kubernetes sets up background reconciliation loops that constantly
    monitor the state of the cluster. If the *current state* of the cluster varies
    from the *desired state* , Kubernetes will perform whatever tasks are necessary
    to reconcile the issue.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kubernetes设置了后台协调循环，不断监视集群的状态。如果集群的*当前状态*与*期望状态*不符，Kubernetes将执行必要的任务来协调解决问题。
- en: '![Figure 2.6](Image00010.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6](Image00010.jpg)'
- en: Figure 2.6
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6
- en: It’s important to understand that what we’ve described is the opposite of the
    traditional *imperative model* . The imperative model is where we issue long lists
    of platform-specific commands to build things.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，我们所描述的是传统*命令模型*的相反。命令模型是指我们发出一长串特定于平台的命令来构建东西的模型。
- en: Not only is the declarative model a lot simpler than long lists of imperative
    commands, it also enables self-healing, scaling, and lends itself to version control
    and self-documentation! It does this by telling the cluster *how things should
    look* . If they stop looking like this, the cluster notices the discrepancy and
    does all of the hard work to reconcile the situation (self-heals).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 声明模型不仅比长串的命令简单得多，而且还能实现自愈、扩展，并且适合版本控制和自我记录！它通过告诉集群*事物应该是什么样子*来实现这一点。如果它们停止看起来像这样，集群会注意到差异并做出所有艰苦的工作来协调情况（自我修复）。
- en: But the declarative story doesn’t end there - things go wrong, and things change.
    When they do, the ***current state*** of the cluster no longer matches the ***desired
    state*** . As soon as this happens, Kubernetes kicks into action and attempts
    to bring the two back into harmony.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 但声明性的故事并不止于此-事情会出错，事情会改变。当这些事情发生时，集群的***当前状态***不再与***期望状态***匹配。一旦发生这种情况，Kubernetes就会开始行动，并尝试将两者重新调和。
- en: Let’s look at an example.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子。
- en: Assume we have an app with a desired state that includes 10 replicas of a web
    front-end Pod. If a node that was running two replicas fails, the *current state*
    will be reduced to 8 replicas, but the *desired state* will still be 10\. This
    will be observed by a reconciliation loop and Kubernetes will schedule two new
    replicas on other nodes in the cluster.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个应用程序，期望状态包括10个web前端Pod的副本。如果运行两个副本的节点失败，*当前状态*将减少到8个副本，但*期望状态*仍将是10个。协调循环将观察到这一点，并且Kubernetes将在集群中的其他节点上安排两个新副本。
- en: The same thing will happen if we intentionally scale the desired number of replicas
    up or down. We could even change the image we want to use. For example, if the
    app is currently using `v2.00` of an image, and we update the desired state to
    use `v2.01` , Kubernetes will notice the discrepancy and go through the process
    of updating all replicas so that they are using the new image specified in the
    *desired state* .
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有意地将期望的副本数量增加或减少，同样的事情也会发生。我们甚至可以更改我们想要使用的镜像。例如，如果应用程序当前使用图像的`v2.00`，并且我们更新期望状态以使用`v2.01`，Kubernetes将注意到差异并经过更新所有副本的过程，以便它们使用*期望状态*中指定的新图像。
- en: To be clear. Instead of writing a long list of commands that will update every
    replica to the new version, we simply tell Kubernetes we want the new version,
    and Kubernetes does the hard work for us.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要清楚。我们不是写一长串命令来更新每个副本到新版本，而是简单地告诉Kubernetes我们想要新版本，Kubernetes会为我们做艰苦的工作。
- en: Despite how simple this might seem, it’s extremely powerful! It’s also at the
    very heart of how Kubernetes operates. We give Kubernetes a declarative manifest
    that describes how we want an application to look. This forms the basis of the
    application’s desired state. The Kubernetes control plane records it, implements
    it, and runs background reconciliation loops that constantly check what is running
    is what we’ve asked for. When current state matches desired state, the world is
    a happy place. When it doesn’t, Kubernetes gets busy and fixes it.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这看起来很简单，但它非常强大！这也是Kubernetes运行的核心。我们给Kubernetes一个声明性清单，描述了我们希望应用程序的外观。这构成了应用程序期望状态的基础。Kubernetes控制平面记录它，实施它，并运行后台协调循环，不断检查正在运行的内容是否符合我们要求的内容。当当前状态与期望状态匹配时，世界是一个快乐的地方。当不匹配时，Kubernetes会忙起来并修复它。
- en: Pods
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pods
- en: In the VMware world, the atomic unit of scheduling is the virtual machine (VM).
    In the Docker world, it’s the container. Well… in the Kubernetes world, it’s the
    ***Pod*** .
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在VMware世界中，调度的原子单位是虚拟机（VM）。在Docker世界中，是容器。嗯...在Kubernetes世界中，是***Pod***。
- en: '![Figure 2.7 - Atomic units of scheduling](Image00011.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 - 调度的原子单位](Image00011.jpg)'
- en: Figure 2.7 - Atomic units of scheduling
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 - 调度的原子单位
- en: Pods and containers
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pods和容器
- en: It’s true that Kubernetes runs containerized apps. But you cannot run a container
    directly on a Kubernetes cluster - containers must **always** run inside of Pods!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes确实运行容器化的应用程序。但是你不能直接在Kubernetes集群上运行容器-容器必须**始终**运行在Pod内部！
- en: 'The simplest model is to run a single container per Pod. However, there are
    advanced use-cases that run multiple containers inside of a single Pod. These
    *multi-container Pods* are beyond the scope of what we’re discussing here, but
    powerful examples include:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的模型是在一个Pod中运行一个单独的容器。然而，有一些高级用例在单个Pod内运行多个容器。这些*多容器Pod*超出了我们在这里讨论的范围，但强大的例子包括：
- en: Service meshes.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格。
- en: Web containers supported by a *helper* container that pulls the latest content.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由*helper*容器支持的Web容器，该容器拉取最新内容。
- en: Containers with a tightly coupled log scraper tailing the logs off to a logging
    service somewhere else.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器与紧密耦合的日志刮取器，将日志传送到其他地方的日志服务。
- en: These are just three simple examples. Figure 2.8 shows a multi-container Pod.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是三个简单的例子。图2.8显示了一个多容器Pod。
- en: '![Figure 2.8](Image00012.gif)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8](Image00012.gif)'
- en: Figure 2.8
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8
- en: Pod anatomy
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pod解剖
- en: At the highest-level, a *Pod* is a ring-fenced environment to run containers.
    The Pod itself doesn’t actually run anything, it’s just a sandbox for hosting
    containers. Keeping it high level, you ring-fence an area of the host OS, build
    a network stack, create a bunch of kernel namespaces, and run one or more containers
    in it - that’s a Pod.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高级别，*Pod*是一个用于运行容器的环境。Pod本身实际上并不运行任何东西，它只是一个用于托管容器的沙箱。保持高层次，您将一个主机操作系统的区域划分出来，构建一个网络堆栈，创建一堆内核命名空间，并在其中运行一个或多个容器
    - 这就是一个Pod。
- en: If you’re running multiple containers in a Pod, they all share the **same environment**
    - things like the IPC namespace, shared memory, volumes, network stack etc. As
    an example, this means that all containers in the same Pod will share the same
    IP address (the Pod’s IP). This is shown in Figure 2.8.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在一个Pod中运行多个容器，它们都共享**相同的环境** - 诸如IPC命名空间、共享内存、卷、网络堆栈等。例如，这意味着同一Pod中的所有容器将共享相同的IP地址（Pod的IP）。这在图2.8中显示。
- en: '![Figure 2.9](Image00013.gif)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9](Image00013.gif)'
- en: Figure 2.9
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9
- en: If two containers in the same Pod need to talk to each other (container-to-container
    within the Pod) they can use the Pod’s `localhost` interface as shown in Figure
    2.10.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果同一Pod中的两个容器需要相互通信（Pod内的容器对容器），它们可以使用Pod的`localhost`接口，如图2.10所示。
- en: '![Figure 2.10](Image00014.gif)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10](Image00014.gif)'
- en: Figure 2.10
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10
- en: Multi-container Pods are ideal when you have requirements for tightly coupled
    containers that may need to share memory and storage etc. However, if you don’t
    **need** to tightly couple your containers, you should put them in their own Pods
    and loosely couple them over the network - this keeps things clean by each container
    only performing a single task.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当您需要紧密耦合的容器，并且可能需要共享内存和存储等要求时，多容器Pod是理想的。但是，如果您**不需要**紧密耦合您的容器，您应该将它们放在自己的Pod中，并通过网络松散耦合它们
    - 这样每个容器只执行单个任务，保持清洁。
- en: Pods as the atomic unit
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pod作为原子单位
- en: Pods are also the minimum unit of scheduling in Kubernetes. If you need to scale
    your app, you add or remove Pods. You **do not** scale by adding more containers
    to an existing Pod! Multi-container Pods are only for situations where two different,
    but complimentary, containers need to share resources. Figure 2.11 shows how to
    scale the `nginx` front-end of an app using multiple Pods as the unit of scaling.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Pod也是Kubernetes中调度的最小单位。如果需要扩展应用程序，可以添加或删除Pod。您**不**通过向现有Pod添加更多容器来扩展！多容器Pod仅用于两个不同但互补的容器需要共享资源的情况。图2.11显示了如何使用多个Pod作为扩展单元来扩展应用程序的`nginx`前端。
- en: '![Figure 2.11 - Scaling with Pods](Image00015.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11 - 使用Pod进行扩展](Image00015.jpg)'
- en: Figure 2.11 - Scaling with Pods
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 - 使用Pod进行扩展
- en: The deployment of a Pod is an atomic operation. This means that a Pod is either
    entirely deployed, or not deployed at all. There is never a situation where you
    have a partially deployed Pod servicing requests. The entire Pod either comes
    up and is put into service, or it doesn’t, and it fails.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Pod的部署是一个原子操作。这意味着一个Pod要么完全部署，要么根本不部署。永远不会出现部分部署的Pod来处理请求的情况。整个Pod要么启动并投入使用，要么不启动，失败了。
- en: A Pod can only exist on a single node. This is also true of multi-container
    Pods.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Pod只能存在于一个节点上。多容器Pod也是如此。
- en: Pod lifecycle
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pod生命周期
- en: Pods are mortal. They’re created, they live, and they die. If they die unexpectedly,
    we don’t bring them back to life! Instead, Kubernetes starts a new one in its
    place. But despite the fact that the new Pod looks, smells, and feels like the
    old one, it’s not! It’s a shiny new Pod with a shiny new ID and IP address.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Pods是有寿命的。它们被创建，生存，然后死亡。如果它们意外死亡，我们不会让它们复活！相反，Kubernetes会在原地启动一个新的Pod。但尽管新的Pod看起来、闻起来、感觉起来都像旧的，但它不是！它是一个全新的Pod，有全新的ID和IP地址。
- en: This has implications on how we should build our applications. Don’t build them
    so that they are tightly coupled to a particular instance of a Pod. Instead, build
    them so that when Pods fail, a totally new one (with a new ID and IP address)
    can pop up somewhere else in the cluster and seamlessly take its place.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们构建应用程序的方式有影响。不要构建它们与特定实例的Pod紧密耦合。相反，构建它们，以便当Pod失败时，一个全新的（带有新ID和IP地址）可以在集群的其他地方弹出并无缝地取代它。
- en: Deployments
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: We normally deploy Pods indirectly as part of something bigger. Examples include;
    *Deployments* , *DaemonSets* , and *StatefulSets* .
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常间接部署Pod作为更大的一部分。例如; *部署*，*守护进程集*和*有状态集*。
- en: For example, a Deployment is a higher-level Kubernetes object that wraps around
    a set of Pods and adds features such as scaling, zero-downtime updates, and versioned
    rollbacks.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，部署是一个更高级别的Kubernetes对象，它包装了一组Pod，并添加了诸如扩展、零停机更新和版本回滚等功能。
- en: Behind the scenes, they implement a controller and a watch loop that is always
    watching the cluster to make sure that the current state matches the desired state.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，它们实现了一个控制器和一个监视循环，始终监视集群，以确保当前状态与期望状态匹配。
- en: Deployments have existed in Kubernetes since version 1.2, and were promoted
    to GA (stable) in 1.9\. You’ll see them a lot.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 自Kubernetes 1.2版本以来就存在部署，而在1.9版本中被提升为GA（稳定）版本。你会经常看到它们。
- en: Services
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务
- en: We’ve just learned that Pods are mortal and can die. However, if they’re deployed
    via Deployments or DaemonSets, they get replaced when they fail. But the new ones
    come with totally different IPs! This also happens when we perform scaling operations
    - scaling up adds new Pods with new IP addresses, whereas scaling down takes existing
    Pods away. Events like these cause a lot of IP churn.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚了解到Pods是有寿命的，可能会死亡。然而，如果它们通过部署或守护进程集部署，它们在失败时会被替换。但新的Pod会有完全不同的IP！当我们进行扩展操作时，也会发生这种情况——扩展会添加具有新IP地址的新Pod，而缩减会带走现有的Pod。这些事件会导致大量的IP变动。
- en: The take-home point is that **Pods are unreliable** . But this poses a challenge…
    Assume we’ve got a microservices app with a bunch of Pods performing video rendering.
    How will this work if other parts of the app that need to use the rendering service
    can’t rely on the Pods being there when they need them?
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是**Pods是不可靠的**。但这带来了一个挑战...假设我们有一个微服务应用程序，有一堆Pod执行视频渲染。如果应用程序的其他部分需要使用渲染服务，但不能依赖Pod在需要时存在，那该怎么办？
- en: This is where *Services* come in to play. **Services provide reliable networking
    for a set of Pods.**
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是*服务*发挥作用的地方。**服务为一组Pod提供可靠的网络。**
- en: Figure 2.12 shows the uploader microservice talking to the renderer microservice
    via a Service. The Service is providing a reliable name and IP, and is load-balancing
    requests across the two renderer Pods behind it.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12显示了上传微服务通过服务与渲染器微服务进行通信。服务提供可靠的名称和IP，并在其后面的两个渲染器Pods之间进行请求的负载均衡。
- en: '![Figure 2.12](Image00016.gif)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图2.12](Image00016.gif)'
- en: Figure 2.12
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12
- en: Digging in to a bit more detail. Services are fully-fledged objects in the Kubernetes
    API - just like Pods and Deployments. They have a front-end that consists of a
    stable DNS name, IP address, and port. On the back-end, they load-balance across
    a dynamic set of Pods. Pods come and go, the Service observes this, automatically
    updates itself, and continues to provide that stable networking endpoint.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 再深入一点。服务是Kubernetes API中的完整对象 - 就像Pods和部署一样。它们有一个前端，包括稳定的DNS名称、IP地址和端口。在后端，它们在一组动态的Pods之间进行负载均衡。Pods会不断地出现和消失，服务会观察到这一点，自动更新自己，并继续提供稳定的网络端点。
- en: The same applies if we scale the number of Pods up or down. New Pods are seamlessly
    added to the Service, whereas terminated Pods are seamlessly removed.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们扩展或缩减Pods的数量，情况也是一样的。新的Pods会无缝地添加到服务中，而终止的Pods也会无缝地被移除。
- en: So that’s the job of a Service – it’s a stable network abstraction point that
    load-balances traffic across a dynamic set of Pods.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是服务的工作-它是一个稳定的网络抽象点，可以在一组动态的Pods之间进行流量负载均衡。
- en: Connecting Pods to Services
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将Pods连接到服务
- en: Services use *labels* and a *label selector* to know which set of Pods to load-balance
    requests to. The Service has a *label selector* that contains all of the *labels*
    a Pod must have in order for it to receive traffic from the Service.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 服务使用*标签*和*标签选择器*来知道要将请求负载均衡到哪组Pods。服务有一个包含所有*标签*的*标签选择器*，一个Pod必须具有这些*标签*才能从服务中接收流量。
- en: 'Figure 2.13 shows a Service configured to send traffic to all Pods on the cluster
    with the following three labels:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13显示了一个配置为将流量发送到集群上所有带有以下三个标签的Pods的服务：
- en: zone=prod
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: zone=prod
- en: env=be
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: env=be
- en: ver=1.3
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ver=1.3
- en: Both Pods in the diagram have all three labels, so the Service will load-balance
    traffic to them both.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的两个Pod都具有这三个标签，因此服务将对它们进行流量负载均衡。
- en: '![Figure 2.13](Image00017.gif)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图2.13](Image00017.gif)'
- en: Figure 2.13
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13
- en: Figure 2.14 shows a similar setup. However, an additional Pod, on the right,
    does not match the set of labels configured in the Service’s label selector. This
    means the Service will not load balance requests to it.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14显示了类似的设置。然而，右侧的另一个Pod与服务标签选择器中配置的标签集不匹配。这意味着服务不会将请求负载均衡到它。
- en: '![Figure 2.14](Image00018.gif)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图2.14](Image00018.gif)'
- en: Figure 2.14
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14
- en: One final thing about Services. They only send traffic to **healthy Pods** .
    This means a Pod that is failing health-checks will not receive traffic from the
    Service.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 关于服务的最后一件事。它们只会将流量发送到**健康的Pods**。这意味着未能通过健康检查的Pod将不会从服务中接收流量。
- en: That’s the basics - Services bring stable IP addresses and DNS names to the
    unstable world of Pods!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是基础知识 - 服务将稳定的IP地址和DNS名称带入了不稳定的Pods世界！
- en: Chapter summary
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 章节总结
- en: In this chapter, we introduced some of the major components of a Kubernetes
    cluster.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Kubernetes集群的一些主要组件。
- en: The masters is where the control plane components run. Under-the-hood, they’re
    a combination of several system-services, including the API Server that exposes
    the public REST interface to the control plane. Masters make all of the deployment
    and scheduling decisions, and multi-master HA is important for production-grade
    environments.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点是控制平面组件运行的地方。在幕后，它们是几个系统服务的组合，包括公共REST接口到控制平面的API服务器。主节点做出所有部署和调度决策，多主高可用对于生产级环境非常重要。
- en: Nodes are where user applications run. Each node runs a service called the `kubelet`
    that registers the node with the cluster and communicates with the control plane.
    This includes receiving new work tasks and reporting back about them. Nodes also
    have a container runtime and the `kube-proxy` service. The container runtime,
    such as Docker or containerd, is responsible for all container-related operations.
    The `kube-proxy` service is responsible for networking on the node.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 节点是用户应用程序运行的地方。每个节点运行一个名为`kubelet`的服务，该服务将节点注册到集群并与控制平面通信。这包括接收新的工作任务并报告它们的情况。节点还具有容器运行时和`kube-proxy`服务。容器运行时，如Docker或containerd，负责所有与容器相关的操作。`kube-proxy`服务负责节点上的网络。
- en: We also talked about some of the major Kubernetes API objects such as Pods,
    Deployments, and Services. The Pod is the basic building-block. Deployments add
    self-healing, scaling and updates. Services add stable networking and load-balancing.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还谈到了一些主要的Kubernetes API对象，如Pods、Deployments和Services。Pod是基本构建块。Deployments添加了自愈、扩展和更新功能。Services添加了稳定的网络和负载均衡。
- en: Now that we know the basics, we’re going to start getting into the detail.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了基础知识，我们将开始深入了解细节。
