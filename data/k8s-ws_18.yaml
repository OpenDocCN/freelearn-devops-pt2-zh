- en: 18\. Upgrading Your Cluster without Downtime
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 18. 在没有停机的情况下升级你的集群
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we will discuss how to upgrade your cluster without downtime.
    We will first understand the need to keep your Kubernetes cluster up to date.
    Then, we will understand basic application deployment strategies that can help
    zero-downtime upgrades of the Kubernetes cluster. We will then put these strategies
    into action by performing an upgrade on a Kubernetes cluster with no downtime
    for your application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何在没有停机的情况下升级你的集群。我们将首先了解保持你的Kubernetes集群最新的需求。然后，我们将了解基本的应用部署策略，可以帮助实现Kubernetes集群的零停机升级。然后，我们将通过在没有应用停机的情况下对Kubernetes集群进行升级来将这些策略付诸实践。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: We learned how to set up a multi-node Kubernetes platform on AWS using kops
    in *Chapter 11*, *Build Your Own HA Cluster*. In this chapter, you will learn
    about upgrading the Kubernetes platform to a new version. We will walk you through
    hands-on examples of the steps that are required to upgrade the Kubernetes platform.
    These exercises will also equip you with the skills required to maintain a Kubernetes
    cluster.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第11章《构建你自己的HA集群》中学习了如何在AWS上使用kops搭建多节点Kubernetes平台。在本章中，你将学习如何将Kubernetes平台升级到新版本。我们将通过实际示例为你演示升级Kubernetes平台所需的步骤。这些练习还将使你具备维护Kubernetes集群所需的技能。
- en: Different organizations set up and maintain their Kubernetes clusters in different
    ways. You saw in *Chapter 12*, *Your Application and HA*, that there are numerous
    ways to set up a cluster. We will present a simple technique to upgrade your cluster
    and, depending on the cluster you are dealing with, the exact techniques and steps
    that you will need to take for upgrading may be different, although the basic
    principles and precautions that we will mention here will be applicable regardless
    of how you go about upgrading your cluster.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的组织以不同的方式设置和维护他们的Kubernetes集群。在第12章《你的应用和HA》中，你看到了设置集群的多种方式。我们将介绍一个简单的技术来升级你的集群，根据你处理的集群的不同，你需要采取的确切技术和步骤可能会有所不同，尽管我们在这里提到的基本原则和预防措施将适用于你升级集群的方式。
- en: The Need to Upgrade Your Kubernetes Cluster
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级你的Kubernetes集群的需求
- en: Building up your business application and putting it out in the world is only
    half the game. Making your application usable by customers in a secure, scalable,
    and consistent way is the other half and the one that you have to keep working
    on. To be able to execute this other half well, you need a rock-solid platform.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 建立起你的业务应用并将其推向世界只是游戏的一半。让你的应用能够以安全、可扩展和一致的方式被客户使用是另一半，也是你必须不断努力的一半。为了能够很好地执行这另一半，你需要一个坚固的平台。
- en: 'In today''s highly competitive environment, delivery of the latest features
    to customers in a timely manner is important to give your business an edge. This
    platform has to not only be dependable but also provide new and updated features
    to keep up with the demands of running modern applications. Kubernetes is a fast-moving
    platform and is well suited for such a dynamic environment. The pace of development
    and advancement of Kubernetes is evidenced by the number of commits in the official
    Kubernetes GitHub repository. Let''s take a look at the following screenshot:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今竞争激烈的环境中，及时向客户提供最新功能对于让你的业务获得优势至关重要。这个平台不仅必须可靠，还必须提供新的和更新的功能，以满足运行现代应用的需求。Kubernetes是一个快速发展的平台，非常适合这样一个动态的环境。Kubernetes的开发和进步速度可以从官方Kubernetes
    GitHub存储库的提交数量中得到证明。让我们来看一下下面的截图：
- en: '![Figure 18.1: Daily commits to the Kubernetes project during the period August
    25–31, 2019'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.1：2019年8月25日至31日期间对Kubernetes项目的每日提交'
- en: '](image/B14870_18_01.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_01.jpg)'
- en: 'Figure 18.1: Daily commits to the Kubernetes project during the period August
    25–31, 2019'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.1：2019年8月25日至31日期间对Kubernetes项目的每日提交
- en: The orange bar graph represents the commits per week and, as you can see, they
    are averaging over 100 per week. The green line graph underneath shows the commits
    for the week of August 25 through August 31\. That's more than 50 commits just
    on a Tuesday.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 橙色条形图代表每周的提交次数，您可以看到平均每周超过100次。下面的绿线图显示了8月25日至8月31日的提交次数。仅在一个星期的星期二就有超过50次提交。
- en: 'By now, it''s clear that Kubernetes is advancing at a fast pace, but you may
    still be unsure about whether you need to update the version of Kubernetes on
    your cluster. The following are some of the reasons why it is important to keep
    the platform up to date:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，很明显Kubernetes正在快速发展，但您可能仍然不确定是否需要更新集群上的Kubernetes版本。以下是一些重要原因，说明为什么保持平台更新至关重要：
- en: '**New features**: The Kubernetes community is continuously adding new features
    to satisfy the needs of modern applications. Your software team may come up with
    a new software component that may be dependent on a newer Kubernetes feature.
    Thus, sticking to an older version of Kubernetes will hold back the development
    of *your* software.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新功能**：Kubernetes社区不断添加新功能，以满足现代应用程序的需求。您的软件团队可能会开发一个依赖于较新Kubernetes功能的新软件组件。因此，坚持使用较旧版本的Kubernetes将阻碍*您*软件的开发。'
- en: '**Security patches**: There are many moving parts in the Kubernetes platform.
    It has not only the Kubernetes binaries that need to be patched but also lots
    of Linux features, such as iptables and cgroups. If there are vulnerabilities
    in any of the components used by Kubernetes, you may need to patch the underlying
    component, such as the OS itself. Having a consistent way to upgrade is extremely
    important in keeping the Kubernetes ecosystem as secure as possible.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全补丁**：Kubernetes平台中有许多组件在不断变化。不仅需要修补Kubernetes二进制文件，还需要修补许多Linux功能，如iptables和cgroups。如果Kubernetes使用的任何组件存在漏洞，您可能需要修补底层组件，如操作系统本身。以一种一致的方式进行升级对于尽可能保持Kubernetes生态系统的安全性非常重要。'
- en: 'For example, there was a vulnerability in versions 1.0–1.12 of the Kubernetes
    API server that resulted in the API server possibly consuming lots of resources
    due to an invalid YAML or JSON payload. You can find more details about this vulnerability
    at this link: [https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在Kubernetes API服务器的1.0–1.12版本中存在一个漏洞，导致API服务器可能因为无效的YAML或JSON负载而消耗大量资源。您可以在此链接找到有关此漏洞的更多详细信息：[https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253)
- en: '**Better handling of existing features**: The Kubernetes team not only adds
    new features but also keeps on improving existing features for stability and performance.
    These improvements may be useful for your existing applications or your automation
    scripts. So, keeping your platform updated is a good idea from this perspective,
    too.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好地处理现有功能**：Kubernetes团队不仅添加新功能，还不断改进现有功能以提高稳定性和性能。这些改进可能对您现有的应用程序或自动化脚本有用。因此，从这个角度来看，保持平台更新也是一个好主意。'
- en: Kubernetes Components – Refresher
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes组件 – 复习
- en: 'By now, you are already aware of the basic components of the Kubernetes platform.
    Just as a refresher, let''s revisit the major components:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经了解了Kubernetes平台的基本组件。作为一个复习，让我们重新审视一下主要组件：
- en: The API server is responsible for exposing RESTful Kubernetes APIs and is stateless.
    All users on your cluster, Kubernetes master components, kubectl clients, worker
    nodes, and maybe even your application all need to interact with the API server.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 服务器负责公开 RESTful Kubernetes API，并且是无状态的。您集群上的所有用户、Kubernetes 主控组件、kubectl
    客户端、工作节点，甚至可能是您的应用程序都需要与 API 服务器进行交互。
- en: A key-value store (the etcd server) stores the objects and provides a persistent
    backend to the API server.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键值存储（etcd 服务器）存储对象并为 API 服务器提供持久后端。
- en: The scheduler and controller manager act to attain the state of the cluster
    and objects stored in etcd.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度程序和控制器管理器用于实现集群的状态和存储在 etcd 中的对象。
- en: kubelet is a program that runs on every worker node and behaves like an agent
    to perform the work as directed by Kubernetes master components.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubelet 是在每个工作节点上运行的程序，类似于代理，按照 Kubernetes 主控组件的指示执行工作。
- en: When we update the platform, as you will see in the later sections, we are going
    to utilize these components and upgrade them as separate modules.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们更新平台时，正如您将在后面的部分中看到的，我们将利用这些组件并将它们作为单独的模块进行升级。
- en: A Word of Caution
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 警告
- en: Kubernetes versions are marked as `A.B.C` and follow the semantic versioning
    concepts. `A` is the major version, `B` is the minor version, and `C` is the patch
    release. As per the Kubernetes documentation, "*in* [*highly available (HA) clusters*](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)*,
    the newest and oldest kube-apiserver instances must be within one minor version.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 版本标记为 `A.B.C`，遵循语义化版本概念。`A` 是主要版本，`B` 是次要版本，`C` 是补丁发布。根据 Kubernetes
    文档，"*在* [*高可用 (HA) 集群*](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)
    *中，最新和最旧的 kube-apiserver 实例必须在一个次要版本内。*'
- en: 'The following is the safest approach when planning your upgrade:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划升级时，以下是最安全的方法：
- en: Always upgrade to the latest patched release of your current minor version first.
    For example, if you are on `1.14.X`, first upgrade to the latest available version
    for the `1.14.X` release train. This will make sure that the platform has all
    the available fixes applied for the version of your cluster. The latest patch
    may have bug fixes, which might provide you with a smoother path toward the next
    minor version, which, in our example, would be `1.15.X`.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终首先升级到当前次要版本的最新修补版本。例如，如果您使用的是 `1.14.X`，首先升级到 `1.14.X` 发行系列的最新可用版本。这将确保平台已应用了该集群版本的所有可用修复程序。最新的修补程序可能有
    bug 修复，这可能为您提供通往下一个次要版本的更顺畅的路径，在我们的示例中将是 `1.15.X`。
- en: Upgrade to the next minor version. Avoid jumping over multiple minor versions,
    even if this is possible, as generally, API compatibility is within one minor
    release. During the upgrade, the Kubernetes platform will be running two different
    versions of an API because we upgrade one node at a time. For example, it is better
    to go from `1.14` to `1.15`, and not to `1.16`.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级到下一个次要版本。尽量避免跨越多个次要版本，即使可能，因为通常 API 兼容性在一个次要发布版本内。在升级过程中，Kubernetes 平台将同时运行两个不同版本的
    API，因为我们一次只升级一个节点。例如，最好从 `1.14` 升级到 `1.15`，而不是升级到 `1.16`。
- en: Another important thing to consider is to see whether the newer version needs
    some updated libraries from the underlying Linux OS. Although, in general, patch
    releases don't require any underlying component upgrades, keeping the underlying
    OS up to date should also be on top of your list to provide a safe and consistent
    environment for the Kubernetes platform.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的事情要考虑的是，看看新版本是否需要来自底层 Linux 操作系统的一些更新的库。尽管一般来说，补丁版本不需要任何底层组件的升级，但保持底层操作系统的最新状态也应该是您的首要任务，以为
    Kubernetes 平台提供一个安全和一致的环境。
- en: The Upgrade Process
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级过程
- en: In this section, you will see the steps required to upgrade the Kubernetes platform.
    Note that upgrading the underlying OS is not covered here. To meet the requirement
    of zero-downtime upgrades, you must have an HA Kubernetes cluster with a minimum
    of three masters and etcd servers, which enables frictionless upgrades. The process
    will take one node out of the three and upgrade it. The upgraded component then
    will rejoin the cluster, and then we take the second node and apply the upgrade
    process to it. Since, at any given time, at least two of the servers are kept
    available, the cluster will remain available during the upgrade.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，您将看到升级Kubernetes平台所需的步骤。请注意，这里不涵盖升级底层操作系统。为了满足零停机升级的要求，您必须拥有一个具有至少三个主节点和etcd服务器的HA
    Kubernetes集群，这样可以实现无摩擦的升级。该过程将使三个节点中的一个脱离集群并进行升级。然后升级后的组件将重新加入集群，然后我们将对第二个节点应用升级过程。由于在任何给定时间，至少有两个服务器保持可用，因此在升级过程中集群将保持可用。
- en: Some Considerations for kops
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kops的一些考虑因素
- en: We have guided you through the creation of an HA Kubernetes cluster in *Chapter
    11*, *Build Your Own HA Cluster*. Hence, in this chapter, we will walk you through
    upgrading the same cluster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在*第11章*中指导您创建了一个HA Kubernetes集群。因此，在本章中，我们将指导您升级相同的集群。
- en: As mentioned in that chapter, there are various ways of deploying and managing
    a Kubernetes cluster. We have opted for kops, which has built-in tools for upgrading
    Kubernetes components. We will be leveraging them in this chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如该章节中所述，部署和管理Kubernetes集群有各种方式。我们选择了kops，它具有用于升级Kubernetes组件的内置工具。我们将在本章中利用它们。
- en: 'The versioning of kops is set to be analogous to the minor version of Kubernetes
    it implements. For example, kops version `1.14.x` implements Kubernetes version
    `1.14.x`. For more details on this, please refer to this link: [https://kops.sigs.k8s.io/welcome/releases/](https://kops.sigs.k8s.io/welcome/releases/).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: kops的版本设置为与其实现的Kubernetes的次要版本类似。例如，kops版本`1.14.x`实现了Kubernetes版本`1.14.x`。有关更多详细信息，请参阅此链接：[https://kops.sigs.k8s.io/welcome/releases/](https://kops.sigs.k8s.io/welcome/releases/)。
- en: Note
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In the HA cluster we created in *Chapter 11*, *Build Your Own HA Cluster*, we
    deployed three master nodes, which host all the Kubernetes master plane components,
    including the etcd.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们在*第11章*中创建的HA集群中，我们部署了三个主节点，这些节点承载了所有Kubernetes主平面组件，包括etcd。
- en: An overview of the Upgrade Process
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级过程概述
- en: 'The entire upgrade process can be diagrammatically summarized as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 整个升级过程可以用图表总结如下：
- en: '![Figure 18.2: The recommended upgrade process'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.2：推荐的升级过程'
- en: '](image/B14870_18_02.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_02.jpg)'
- en: 'Figure 18.2: The recommended upgrade process'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.2：推荐的升级过程
- en: 'Let''s take a quick look at each step before we move on to the implementation:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续实施之前，让我们快速查看每个步骤：
- en: '**Read the release notes**'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读发布说明
- en: 'These will indicate any special considerations that might be necessary during
    an upgrade. The release notes for each version are available on GitHub at this
    link: [https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些将指示在升级过程中可能需要的任何特殊注意事项。每个版本的发布说明都可以在GitHub的此链接上找到：[https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG)。
- en: '**Back up the etcd datastore**'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**备份etcd数据存储**'
- en: As you have learned earlier, etcd stores the entire state of the cluster. A
    backup of etcd would allow you to restore the state of your datastore, if needed.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您之前学到的那样，etcd存储了集群的整个状态。etcd的备份可以让您在需要时恢复数据存储的状态。
- en: '**Back up the nodes as an optional failsafe**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**备份节点作为可选的故障保护**'
- en: This may come in handy if the upgrade process does not go as planned and you
    want to revert to a previous state. Cloud vendors (such as AWS, GCP, Azure, and
    others) enable you to take a snapshot of the hosts. If you are running in a private
    data center and using hypervisors for your machines, your hypervisor provider
    (for example, VMware) may provide tools to take snapshots of the nodes. Taking
    snapshots is beyond the scope of this book, but nonetheless, it is a useful step
    before you start upgrading your Kubernetes platform.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果升级过程不顺利，并且您想要恢复到先前的状态，这可能会派上用场。云供应商（如AWS、GCP、Azure等）使您能够对主机进行快照。如果您在私有数据中心运行并为您的机器使用虚拟化技术，您的虚拟化提供商（例如VMware）可能会提供工具来对节点进行快照。在开始升级Kubernetes平台之前，进行快照超出了本书的范围，但尽管如此，这是一个有用的步骤。
- en: '**Upgrade the etcd if required**'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有必要，升级etcd
- en: The more recent versions of the tools used to deploy and manage a Kubernetes
    cluster (such as kops in our case) usually take care of this automatically. Even
    so, this is an important consideration, especially if you are not using any tools
    such as kops.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 用于部署和管理Kubernetes集群的工具的更新版本（例如我们的kops）通常会自动处理这一点。即便如此，这是一个重要的考虑因素，特别是如果您没有使用kops等工具。
- en: Check and verify whether the new version of Kubernetes needs a different version
    of the etcd store. This is not always necessary, but may be required depending
    on your version. For example, Kubernetes version `1.13` needs etcd v3, while prior
    versions work with etcd v2.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 检查并验证新版本的Kubernetes是否需要不同版本的etcd存储。这并不总是必要的，但根据您的版本可能需要。例如，Kubernetes版本`1.13`需要etcd
    v3，而较早版本可以使用etcd v2。
- en: 'You will know whether you need to upgrade etcd from reading the release notes
    (*step 1*). For example, when the earlier version of etcd was phased out in version
    1.13, it was explicitly mentioned in the release notes: [https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.13.md#urgent-upgrade-notes](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.13.md#urgent-upgrade-notes).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过阅读发布说明（*步骤1*）可以确定是否需要升级etcd。例如，当较早版本的etcd在1.13版本中被淘汰时，在发布说明中明确提到了这一点：[https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.13.md#urgent-upgrade-notes](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.13.md#urgent-upgrade-notes)。
- en: '**Upgrade the master components**'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级主要组件
- en: 'Log in to the bastion host and upgrade the version of kops based on the desired
    version of Kubernetes. This compatibility matrix should be a useful guide: [https://kops.sigs.k8s.io/welcome/releases/#compatibility-matrix](https://kops.sigs.k8s.io/welcome/releases/#compatibility-matrix).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 登录到堡垒主机，并根据期望的Kubernetes版本升级kops的版本。这个兼容矩阵应该是一个有用的指南：[https://kops.sigs.k8s.io/welcome/releases/#compatibility-matrix](https://kops.sigs.k8s.io/welcome/releases/#compatibility-matrix)。
- en: Run the upgrade on the first master node, verify that it is updated correctly,
    and then repeat the same steps for all other master nodes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个主节点上运行升级，验证其是否正确更新，然后对所有其他主节点重复相同的步骤。
- en: '**Upgrade the worker node groups**'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级工作节点组
- en: As you have seen in *Chapter 11*, *Build Your Own HA Cluster*, kops allows you
    to manage the nodes using instance groups, which is tied to the autoscaling group,
    in the case of AWS. Run the upgrade on the first instance group of worker nodes.
    To verify that the nodes were successfully upgraded, you need to check that the
    nodes are upgraded to the desired version of Kubernetes and whether pods are scheduled
    on the upgraded nodes. Repeat the same steps for all other instance groups of
    worker nodes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在*第11章*，*构建您自己的HA集群*中看到的，kops允许您使用实例组来管理节点，这与AWS的自动扩展组相关联。在工作节点的第一个实例组上运行升级。要验证节点是否成功升级，您需要检查节点是否升级到所需版本的Kubernetes，以及是否在升级后的节点上调度了pod。对所有其他工作节点的实例组重复相同的步骤。
- en: '**Verify that the upgrade process succeeded**'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**验证升级过程是否成功**'
- en: Check whether all the nodes are upgraded and all your applications are running
    as intended.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 检查所有节点是否已升级，并且所有应用程序是否按预期运行。
- en: The Importance of Automation
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化的重要性
- en: As you have seen from this overview, there are several steps required to upgrade
    the cluster. Given the number of releases and patches, you may need to do this
    often. Since the process is well documented, it is highly recommended that you
    consider using an automation tool, such as Ansible or Puppet, to automate this
    whole process. All the preceding steps can be fully automated, and you have a
    repeatable way to upgrade your cluster. Automation, however, will not be covered
    in this chapter as this is beyond the scope of this book.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从概述中可以看出，升级集群需要几个步骤。考虑到发布和补丁的数量，您可能经常需要这样做。由于该过程有很好的文档记录，强烈建议您考虑使用自动化工具，如Ansible或Puppet，来自动化整个过程。所有前面的步骤都可以完全自动化，您可以重复升级集群的方式。但是，本章不涵盖自动化，因为这超出了本书的范围。
- en: Backing up the etcd Datastore
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 备份etcd数据存储
- en: etcd stores the state of the entire cluster. So, taking a snapshot of etcd allows
    us to restore the entire cluster to the state when the snapshot was taken. This
    may come in handy if you want to revert the cluster to a previous state.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: etcd存储整个集群的状态。因此，对etcd进行快照可以让我们将整个集群恢复到快照被拍摄时的状态。如果您想将集群恢复到先前的状态，这可能会很有用。
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before you begin with any exercises, make sure that the cluster is set up and
    available as per the instructions in *Chapter 11*, *Build Your Own HA Cluster*,
    and that you can access the nodes from your computer via SSH. It is also recommended
    that you take snapshots of the nodes before starting the upgrade process. This
    is especially beneficial because in this chapter, you will upgrade the cluster
    two times – once during the exercises and once during the activity.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始任何练习之前，请确保按照*第11章*，*构建您自己的HA集群*中的说明设置并可用集群，并且您可以通过SSH从计算机访问节点。还建议您在开始升级过程之前对节点进行快照。这是特别有益的，因为在本章中，您将对集群进行两次升级-一次在练习期间，一次在活动期间。
- en: Now, before we move on to the first exercise, we need to understand a bit more
    about etcd. The way that it works is that it runs as a pod on your cluster in
    the `kube-system` namespace (as you have seen in *Chapter 2*, *An Overview of
    Kubernetes*) and exposes an API, which is used to write data to it. Whenever the
    Kubernetes API server wants to persist any data to etcd, it will use etcd's API
    to access it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们进行第一个练习之前，我们需要更多地了解etcd。它的工作方式是在您的集群中作为一个pod在`kube-system`命名空间中运行（正如您在*第2章*，*Kubernetes概述*中看到的），并公开一个API，用于向其写入数据。每当Kubernetes
    API服务器想要将任何数据持久化到etcd时，它将使用etcd的API来访问它。
- en: 'For backing up etcd, we will also need to access its API and use a built-in
    function to save a snapshot. For that, we will use a command-line client called
    `etcdctl`, which is already present in the etcd pod. Detailed coverage of this
    tool and the etcd API is not necessary for our purposes and so we are not including
    it in this book. You can learn more about it at this link: [https://github.com/etcd-io/etcd/tree/master/etcdctl](https://github.com/etcd-io/etcd/tree/master/etcdctl).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了备份etcd，我们还需要访问其API并使用内置函数保存快照。为此，我们将使用一个名为`etcdctl`的命令行客户端，它已经存在于etcd pod中。对于我们的目的，不需要详细介绍此工具和etcd
    API，因此我们不在本书中包含它。您可以在此链接了解更多信息：[https://github.com/etcd-io/etcd/tree/master/etcdctl](https://github.com/etcd-io/etcd/tree/master/etcdctl)。
- en: Now, let's see how we can use etcdctl to back up etcd in the following exercise.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在以下练习中使用etcdctl来备份etcd。
- en: 'Exercise 18.01: Taking a Snapshot of the etcd Datastore'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习18.01：对etcd数据存储进行快照
- en: 'In this exercise, we will see how to take a snapshot of the etcd store. As
    mentioned in the previous section, a manual upgrade of etcd may not be required,
    depending on your upgrade path. However, backing up etcd is essential. For this,
    and all the following exercises and activities, use the same machine (your laptop
    or desktop) that you used to perform *Exercise 11.01*, *Setting Up Our Kubernetes
    Cluster*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将看到如何对etcd存储进行快照。如前一节所述，根据您的升级路径，可能不需要手动升级etcd，但备份etcd是必不可少的。对于此操作和所有后续的练习和活动，请使用相同的机器（您的笔记本电脑或台式机），您用来执行*练习11.01*，*设置我们的Kubernetes集群*。
- en: 'We have used kops to install the cluster. Kops uses two different etcd clusters
    – one for events generated by Kubernetes components, and the second one for everything
    else. You can see these pods by issuing the following command:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经使用kops安装了集群。Kops使用两个不同的etcd集群 - 一个用于Kubernetes组件生成的事件，另一个用于其他所有内容。您可以通过发出以下命令来查看这些pods：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This should get the details of the etcd pods. You should see an output similar
    to the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该获取etcd pods的详细信息。您应该看到类似以下的输出：
- en: '![Figure 18.3: Getting the list of etcd-manager pods'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.3：获取etcd-manager pods的列表'
- en: '](image/B14870_18_03.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_03.jpg)'
- en: 'Figure 18.3: Getting the list of etcd-manager pods'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.3：获取etcd-manager pods的列表
- en: 'By default, kops'' `etcd-manager` function creates backups every 15 minutes.
    The location of the backups is the same S3 storage used by the kops tool. In *Exercise
    11.01*, you configured the S3 bucket to store kops'' state. Let''s query the bucket
    to see whether a backup is available there:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，kops的`etcd-manager`功能每15分钟创建一次备份。备份的位置与kops工具使用的S3存储相同。在*练习11.01*中，您配置了S3存储桶以存储kops的状态。让我们查询存储桶，看看那里是否有备份可用：
- en: '[PRE1]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You should see a response similar to this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似这样的响应：
- en: '![Figure 18.4: Getting a list of available backups'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.4：获取可用备份列表'
- en: '](image/B14870_18_04.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_04.jpg)'
- en: 'Figure 18.4: Getting a list of available backups'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.4：获取可用备份列表
- en: You can see that the backups are taken automatically every 15 minutes and timestamps
    of the backups are marked. We will use the `Key` of the latest backup, highlighted
    in the preceding screenshot, in the next step.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到备份每15分钟自动进行，并且备份的时间戳已标记。我们将在下一步中使用在上一张截图中突出显示的最新备份的“Key”。
- en: 'The next step is to get the backup from the S3 bucket. We can use AWS CLI commands
    to get the backup that we need:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是从S3存储桶获取备份。我们可以使用AWS CLI命令来获取我们需要的备份：
- en: '[PRE2]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that this command contains the name of the bucket, the `Key` of the file
    from the previous step, and the filename that we want to use while saving the
    file. Use the `Key` that you get for your instance in the output of the previous
    step. You should see a response similar to this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此命令包含存储桶的名称，上一步中文件的`Key`，以及我们在保存文件时要使用的文件名。使用在上一步的输出中获取的`Key`。您应该看到类似于此的响应：
- en: '![Figure 18.5: Saving the etcd backup from our S3 bucket'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.5：从我们的S3存储桶中保存etcd备份'
- en: '](image/B14870_18_05.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_05.jpg)'
- en: 'Figure 18.5: Saving the etcd backup from our S3 bucket'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.5：从我们的S3存储桶中保存etcd备份
- en: Note that we have used the `date` command to generate the filename. This is
    a very common technique used by system administrators to make sure that any files
    are not overwritten.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用`date`命令生成文件名。这是系统管理员常用的技术，用于确保不会覆盖任何文件。
- en: Note
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意
- en: 'If you want to recover your etcd instance using this backup, you can find the
    recovery instructions at this link: [https://kops.sigs.k8s.io/operations/etcd_backup_restore_encryption/](https://kops.sigs.k8s.io/operations/etcd_backup_restore_encryption/).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用此备份恢复您的etcd实例，您可以在此链接找到恢复说明：[https://kops.sigs.k8s.io/operations/etcd_backup_restore_encryption/](https://kops.sigs.k8s.io/operations/etcd_backup_restore_encryption/)。
- en: 'Verify that the backup file is created:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证备份文件是否已创建：
- en: '[PRE3]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should see the following response:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 18.6: Confirming the saved etcd backup'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.6：确认保存的etcd备份'
- en: '](image/B14870_18_06.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_06.jpg)'
- en: 'Figure 18.6: Confirming the saved etcd backup'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.6：确认保存的etcd备份
- en: You should be able to see the snapshot that we created in the response.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够在响应中看到我们创建的快照。
- en: In this exercise, you have seen how to generate a backup of the etcd datastore.
    This backup is the state of Kubernetes and could be useful not only if your upgrade
    is hit by any issues, but also to restore the cluster for any other reason, such
    as **Disaster Recovery** (**DR**) scenarios.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您已经学会了如何生成etcd数据存储的备份。这个备份是Kubernetes的状态，不仅在您的升级遇到任何问题时可能有用，而且在任何其他情况下恢复集群也可能有用，比如**灾难恢复**（**DR**）场景。
- en: Draining a Node and Making It Non-Schedulable
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排空节点并使其不可调度
- en: Before we start to upgrade any nodes (master or worker), we need to make sure
    that no pods (including the pods for the master components) are running on this
    node. This is an important step to prepare any node to be upgraded. Furthermore,
    the node needs to be marked as unschedulable. An unschedulable node is a flag
    for the scheduler to not schedule any pods in this node.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始升级任何节点（主节点或工作节点）之前，我们需要确保没有任何pod（包括主要组件的pod）在此节点上运行。这是准备升级任何节点的重要步骤。此外，该节点需要标记为不可调度。不可调度的节点是调度程序不在此节点调度任何pod的标志。
- en: We can use the `drain` command to mark the node as un-schedulable and to evict
    all the pods. The `drain` command will not delete any DaemonSet pods unless we
    tell the flag to do so. One of the reasons for this behavior is that DaemonSet
    pods cannot be scheduled on any other nodes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`drain`命令将节点标记为不可调度，并驱逐所有pod。`drain`命令不会删除任何DaemonSet pod，除非我们告诉标志这样做。这种行为的原因之一是，DaemonSet
    pod 不能被调度到任何其他节点上。
- en: Note that the `drain` command waits for the graceful termination of the pods
    and it is highly recommended to wait for all the pods to terminate gracefully
    in production environments. Let's see this in action in the following exercise.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`drain`命令等待优雅终止pod，并强烈建议在生产环境中等待所有pod优雅地终止。让我们在以下练习中看到这一点。
- en: 'Exercise 18.02: Draining All the Pods from the Nodes'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习18.02：从节点中排空所有的Pod
- en: 'In this exercise, we will remove all the pods running on a node. Once all the
    pods are removed, we will change the node back to schedulable so that it can accept
    new workloads. This is when the node has been upgraded and ready to take new pods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将删除在一个节点上运行的所有pods。一旦所有的pods都被移除，我们将把节点改回可调度状态，以便它可以接受新的工作负载。这是当节点已经升级并准备接受新的pods时。
- en: 'Get a list of all the nodes:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取所有节点的列表：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You should see a response similar to this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这样的响应：
- en: '![Figure 18.7: Getting a list of nodes'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.7：获取节点列表'
- en: '](image/B14870_18_07.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_07.jpg)'
- en: 'Figure 18.7: Getting a list of nodes'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.7：获取节点列表
- en: In this example, we have two worker nodes and three master nodes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有两个worker节点和三个master节点。
- en: 'Create a new namespace called `upgrade-demo`:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`upgrade-demo`的新命名空间：
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should see the following response:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '[PRE6]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Run a bunch of pods to simulate a workload. Create a file named `multiple-pods.yaml`
    with the following content:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行一堆pods来模拟工作负载。创建一个名为`multiple-pods.yaml`的文件，其中包含以下内容：
- en: '[PRE7]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The deployment will create four replicas of the pods.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 部署将创建四个pods的副本。
- en: 'Now, use the config to create the deployment:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用配置来创建部署：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should see this response:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '[PRE9]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Verify that they are running on the worker pods:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证它们是否在worker pods上运行：
- en: '[PRE10]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Your output should look like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输出应该是这样的：
- en: '![Figure 18.8: Verifying whether the pods are running on the worker nodes'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.8：验证pods是否在worker节点上运行'
- en: '](image/B14870_18_08.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_08.jpg)'
- en: 'Figure 18.8: Verifying whether the pods are running on the worker nodes'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.8：验证pods是否在worker节点上运行
- en: Note that the pods are distributed among both worker nodes by the default scheduler
    behavior.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，默认调度程序行为会将pods分布在两个worker节点之间。
- en: 'Use the `drain` command to evict all the pods from any of the nodes. This command
    will also mark the node as unschedulable:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`drain`命令从任何节点中驱逐所有的pods。这个命令也会将节点标记为不可调度：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Use the name of your node that you obtain from the output of the previous step.
    Note that we have passed a flag to ignore the daemon sets. You should see the
    following response:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您从上一步的输出中获得的节点的名称。注意，我们传递了一个标志来忽略daemon sets。您应该看到以下响应：
- en: '![Figure 18.9: Draining a node'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.9：排水节点'
- en: '](image/B14870_18_09.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_09.jpg)'
- en: 'Figure 18.9: Draining a node'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.9：排水节点
- en: If we don't set the `--ignore-daemonsets` flag and there are some DaemonSet
    pods on the node, `drain` will not proceed without this flag. We recommend using
    this flag because your cluster may be running some essential pods as a DaemonSet
    –for example, a Fluentd pod that collects logs from all other pods on the node
    and sends them to the central logging server. You may want this log collection
    pod to be available until the very last minute.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不设置`--ignore-daemonsets`标志，并且节点上有一些DaemonSet pods，`drain`将不会在没有这个标志的情况下继续进行。我们建议使用这个标志，因为您的集群可能正在运行一些关键的pods作为DaemonSet
    - 例如，一个从节点上的所有其他pods收集日志并将它们发送到中央日志服务器的Fluentd pod。您可能希望在最后一刻之前保留这个日志收集pod的可用性。
- en: 'Verify that all the pods are drained from this node. To do that, get a list
    of the pods:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证所有的pods是否已经从该节点排空。为此，获取一个列表的pods：
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see the following response:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 18.10: Checking whether the pods have been moved away from the drained
    node'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.10：检查pods是否已经从排空的节点移开'
- en: '](image/B14870_18_10.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_10.jpg)'
- en: 'Figure 18.10: Checking whether the pods have been moved away from the drained
    node'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.10：检查pods是否已经从排空的节点移开
- en: In the preceding screenshot, you can see that all the pods are running on the
    other node. We only had two worker nodes in our cluster, and so all the pods were
    scheduled on the lone schedulable node. If we had several available worker nodes,
    the pods would have been distributed among them by the scheduler.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，您可以看到所有的pod都在另一个节点上运行。我们的集群中只有两个工作节点，所以所有的pod都被调度到了唯一可调度的节点上。如果我们有几个可用的工作节点，调度器会将pod分布在它们之间。
- en: 'Let''s describe our drained node and make a few important observations:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们描述一下我们的排水节点并做一些重要的观察：
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use the name of the node that you drained in *step 6*. This will give a pretty
    long output, but there are two sections worth observing:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您在*步骤6*中排水的节点名称。这将产生一个相当长的输出，但有两个值得观察的部分：
- en: '![Figure 18.11: Checking taints and the unschedulable status of our drained
    node'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.11：检查我们排水节点的污点和不可调度状态'
- en: '](image/B14870_18_11.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_11.jpg)'
- en: 'Figure 18.11: Checking taints and the unschedulable status of our drained node'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.11：检查我们排水节点的污点和不可调度状态
- en: 'The preceding screenshot shows that our node is marked as unschedulable. Next,
    find the section like the following in your output:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示我们的节点被标记为不可调度。接下来，在您的输出中找到以下类似的部分：
- en: '![Figure 18.12: Examining the non-terminated pods on the drained node'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.12：检查排水节点上的非终止pod'
- en: '](image/B14870_18_12.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_12.jpg)'
- en: 'Figure 18.12: Examining the non-terminated pods on the drained node'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.12：检查排水节点上的非终止pod
- en: This shows that the only non-terminated pods running on our system have names
    starting with `kube-proxy` and `weave-net`. The first pod implements `kube-proxy`,
    which is the component that manages pod and service network rules on nodes. The
    second pod is `weave-net`, which implements virtual networking for our cluster
    (note that your networking provider depends on the type of network you have selected).
    Since we added a flag to exclude DaemonSets in *step 6*, these pods, which are
    managed by a DaemonSet, are still running.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们系统上唯一正在运行的非终止pod的名称以`kube-proxy`和`weave-net`开头。第一个pod实现了`kube-proxy`，它是管理节点上的pod和服务网络规则的组件。第二个pod是`weave-net`，它为我们的集群实现了虚拟网络（请注意，您的网络提供程序取决于您选择的网络类型）。由于我们在*步骤6*中添加了一个排除DaemonSets的标志，这些由DaemonSet管理的pod仍在运行。
- en: 'Once you drain the pod in *step 6*, you will be able to upgrade the node. Even
    though upgrading is not part of this exercise, we just want to make the node schedulable
    again. For that, use the following command:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您在*步骤6*中排水了pod，您就可以升级节点。即使升级不是本练习的一部分，我们只是想让节点再次可调度。为此，请使用以下命令：
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You should see a response similar to this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于以下内容的响应：
- en: '[PRE15]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Verify that the node is schedulable again. Check the `Taints` section in the
    following output:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证节点是否再次可调度。检查以下输出中的“污点”部分：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should see a response similar to the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于以下内容的响应：
- en: '![Figure 18.13: Checking the taints and unschedulable statuses of our uncordoned
    node'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.13：检查我们未封锁节点的污点和不可调度状态'
- en: '](image/B14870_18_13.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_13.jpg)'
- en: 'Figure 18.13: Checking the taints and unschedulable statuses of our uncordoned
    node'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.13：检查我们未封锁节点的污点和不可调度状态
- en: The preceding screenshot shows that the node is now schedulable, and the taint
    that we observed in *step 8* has been removed.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示节点现在是可调度的，并且我们在*步骤8*中观察到的污点已经被移除。
- en: In this exercise, you have seen how to remove all the pods from the node and
    mark the node as unschedulable. This will make sure that no new pod will be scheduled
    in this node and we can work on upgrading this node. We also learned how to make
    the node schedulable again so that we can continue using it after completing the upgrade.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您已经看到如何从节点中删除所有的pod并将节点标记为不可调度。这将确保在该节点中不会安排新的pod，并且我们可以开始升级该节点。我们还学习了如何使节点再次可调度，以便在完成升级后继续使用它。
- en: Upgrading Kubernetes Master Components
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级Kubernetes主要组件
- en: 'When you are running Kubernetes in any capacity that is important for your
    organization, you will be running the platform in an HA configuration. To achieve
    that, the typical configuration is at least three replicas of master components,
    running on three different nodes. This allows you to upgrade single nodes from
    one minor version to the next, one by one, while still maintaining API compatibility
    when an upgraded node rejoins the cluster because Kubernetes provides compatibility
    across one minor version. This means the master components can be on different
    versions when you are upgrading each node at a time. The following table provides
    a logical flow of the versions. Let''s assume you are upgrading from version 1.14
    to 1.15:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当您以任何重要程度运行Kubernetes对您的组织很重要时，您将以HA配置运行平台。为了实现这一点，典型的配置至少是三个主要组件的副本，运行在三个不同的节点上。这允许您逐个将单个节点从一个次要版本升级到下一个次要版本，同时在升级后重新加入集群时仍然保持API兼容性，因为Kubernetes提供了一次次要版本的兼容性。这意味着在逐个升级每个节点时，主要组件可以处于不同的版本。以下表格提供了版本的逻辑流。假设您正在从版本1.14升级到1.15：
- en: '![Figure 18.14: Upgrade plan for three master nodes'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.14：三个主节点的升级计划'
- en: '](image/B14870_18_14.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_14.jpg)'
- en: 'Figure 18.14: Upgrade plan for three master nodes'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.14：三个主节点的升级计划
- en: In the following exercise, we will proceed with upgrading the Kubernetes master components.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将继续升级Kubernetes主要组件。
- en: 'Exercise 18.03: Upgrading Kubernetes Master Components'
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习18.03：升级Kubernetes主要组件
- en: In this exercise, you will upgrade all the master components on the Kubernetes
    master nodes. This exercise assumes that you are still logged in to the bastion
    host of your cluster.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将升级Kubernetes主节点上的所有主要组件。此练习假定您仍然登录到集群的堡垒主机。
- en: 'In this exercise, we are demonstrating the process on a smaller number of nodes
    for the sake of simplicity, but the process of upgrading a large number of nodes
    would be the same. However, for a seamless upgrade, three master nodes are a minimum,
    and your applications should be HA and running on at least two worker nodes:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们演示了一个较少数量的节点的过程，以简化操作，但是升级大量节点的过程是相同的。然而，为了实现无缝升级，三个主节点是最少的，并且您的应用程序应该是HA，并且至少在两个工作节点上运行：
- en: 'Run the kops validator to validate the existing cluster:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行kops验证器来验证现有的集群：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should see a response similar to the following:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的响应：
- en: '![Figure 18.15: Validating our kops cluster'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.15：验证我们的kops集群'
- en: '](image/B14870_18_15.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_15.jpg)'
- en: 'Figure 18.15: Validating our kops cluster'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.15：验证我们的kops集群
- en: This is a truncated version of the output. It shows the major infrastructure
    components of your cluster.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出的截断版本。它显示了集群的主要基础设施组件。
- en: 'List all the nodes in your cluster:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出集群中的所有节点：
- en: '[PRE18]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should see a response similar to this:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似这样的响应：
- en: '![Figure 18.16: Getting a list of the nodes'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.16：获取节点列表'
- en: '](image/B14870_18_16.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_16.jpg)'
- en: 'Figure 18.16: Getting a list of the nodes'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.16：获取节点列表
- en: Notice that we have three master nodes and all of them are on version 1.15.7.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们有三个主节点，它们都在1.15.7版本上。
- en: Note
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this exercise, we are showcasing the upgrade from Kubernetes version 1.15.7
    to 1.15.10\. You can apply the same steps to upgrade to the version of Kubernetes
    supported by kops at the time when you perform this exercise. Just remember our
    earlier advice of upgrading to the latest patch version first (which is what we
    are doing here).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们展示了从Kubernetes版本1.15.7升级到1.15.10。您可以应用相同的步骤来升级到kops在您执行此练习时支持的Kubernetes版本。只需记住我们之前的建议，先升级到最新的补丁版本（这就是我们在这里所做的）。
- en: 'Use the `kops upgrade cluster` command to see what update is available:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kops upgrade cluster`命令查看可用的更新：
- en: '[PRE19]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Note that this command will not directly run the update, but it will give you
    the latest update version possible. The `NAME` environment variable holds the
    name of your cluster. You should see an output similar to the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个命令不会直接运行更新，但它会给出可能的最新更新版本。`NAME`环境变量保存了您的集群名称。您应该看到类似以下的输出：
- en: '![Figure 18.17: Checking the available cluster version'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.17：检查可用的集群版本'
- en: '](image/B14870_18_17.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_17.jpg)'
- en: 'Figure 18.17: Checking the available cluster version'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.17：检查可用的集群版本
- en: You can see from the preceding screenshot that the `OLD` version is `1.15.7`,
    which is our current version, and an update is available to the `NEW` version
    of `1.15.10`, which is our target version.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从前面的截图中看到，`OLD`版本是`1.15.7`，这是我们当前的版本，`NEW`版本是`1.15.10`，这是我们的目标版本。
- en: 'Once you verify the changes from the command in *step 4*, run the same command
    with a `--yes` flag. This will mark the desired state of the cluster in the kops
    state store:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您验证了*步骤4*中的命令的更改，使用`--yes`标志运行相同的命令。这将在kops状态存储中标记集群的期望状态：
- en: '[PRE20]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You should see an output similar to the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的输出：
- en: '![Figure 18.18: Upgrading the kops cluster configuration'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.18：升级kops集群配置'
- en: '](image/B14870_18_18.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_18.jpg)'
- en: 'Figure 18.18: Upgrading the kops cluster configuration'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.18：升级kops集群配置
- en: This output indicates that the desired version of the Kubernetes cluster is
    recorded in the updated kops configuration. In the next step, we will ask kops
    to update the cloud or cluster resources to match the new specifications – that
    is, Kubernetes version `1.15.10`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出表明了Kubernetes集群的期望版本已记录在更新的kops配置中。在下一步中，我们将要求kops更新云或集群资源以匹配新的规格-即Kubernetes版本`1.15.10`。
- en: 'Now, let''s run the following command so that kops updates the cluster to match
    the updated kops configuration:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们运行以下命令，以便kops更新集群以匹配更新的kops配置：
- en: '[PRE21]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This will give a long output that will end in a similar way to the following screenshot:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生一个长输出，最终会以类似以下的方式结束：
- en: '![Figure 18.19: Updating our cluster infrastructure as per'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.19：根据我们集群升级的要求更新我们的集群基础架构'
- en: the requirements of our cluster upgrade
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们集群升级的要求
- en: '](image/B14870_18_19.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_19.jpg)'
- en: 'Figure 18.19: Updating our cluster infrastructure as per the requirements of
    our cluster upgrade'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.19：根据我们集群升级的要求更新我们的集群基础架构
- en: This has updated the cluster infrastructure to match the updated kops configuration.
    Next, we need to perform an upgrade of the Kubernetes master components running
    on this infrastructure.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经更新了集群基础架构，以匹配更新的kops配置。接下来，我们需要对运行在这个基础架构上的Kubernetes主组件进行升级。
- en: 'If you are running several instances of your master/worker nodes on different
    instance groups, then you can control which instance group is receiving the updates.
    For that, let''s get the name of our instance group first. Use the following command
    to get the names:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您在不同实例组上运行多个主/工作节点实例，那么您可以控制哪个实例组接收更新。为此，让我们首先获取我们实例组的名称。使用以下命令获取名称：
- en: '[PRE22]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should see a response as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 18.20: Getting a list of the instance groups'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.20：获取实例组列表'
- en: '](image/B14870_18_20.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_20.jpg)'
- en: 'Figure 18.20: Getting a list of the instance groups'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.20：获取实例组列表
- en: 'In this step, kops will update the Kubernetes cluster to match the kops specifications.
    Let''s upgrade the first master node to the new version using a rolling update:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，kops将更新Kubernetes集群以匹配kops规范。让我们使用滚动更新将第一个主节点升级到新版本：
- en: '[PRE23]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note that this command will only apply changes if you specify the `--yes` flag.
    This command may take time based on your node configuration. Be patient and watch
    the logs to see whether there are any errors. After some time, you should see
    a successful message similar to the one in the following screenshot:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此命令只会在您指定`--yes`标志时应用更改。根据您的节点配置，此命令可能需要一些时间。请耐心等待并观察日志，看是否有任何错误。过一段时间后，您应该看到类似以下截图中的成功消息：
- en: '![Figure 18.21: Applying a rolling update to our first instance group'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.21：对我们的第一个实例组应用滚动更新'
- en: '](image/B14870_18_21.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_21.jpg)'
- en: 'Figure 18.21: Applying a rolling update to our first instance group'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.21：对我们的第一个实例组应用滚动更新
- en: 'Verify that the node is upgraded to the target version, which is `1.15.10`,
    in our case:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证节点是否已升级到目标版本，即`1.15.10`，在我们的情况下：
- en: '[PRE24]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This should give a response similar to the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该给出类似以下的响应：
- en: '![Figure 18.22: Checking whether the master components on the node have been
    upgraded'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.22：检查节点上的主要组件是否已升级'
- en: '](image/B14870_18_22.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_22.jpg)'
- en: 'Figure 18.22: Checking whether the master components on the node have been
    upgraded'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.22：检查节点上的主要组件是否已升级
- en: You can see that the first master node is on the `1.15.10` version.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到第一个主节点的版本为`1.15.10`。
- en: 'Verify that the pods are running on the newly upgraded node:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证新升级的节点上是否正在运行pod：
- en: '[PRE25]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Use the name of the node that you upgraded in the previous steps. This will
    give a long output. Look for the `Non-terminated Pod` section, as shown in the
    following screenshot:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您在之前步骤中升级的节点的名称。这将给出一个很长的输出。查找`Non-terminated Pod`部分，如下截图所示：
- en: '![Figure 18.23: Checking whether our upgraded node is running pods'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.23：检查我们升级的节点是否正在运行pod'
- en: '](image/B14870_18_23.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_23.jpg)'
- en: 'Figure 18.23: Checking whether our upgraded node is running pods'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.23：检查我们升级的节点是否正在运行pod
- en: Note
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Repeat *steps 7* to *9* for all additional master nodes, using the appropriate
    names of the corresponding instance groups while updating and verifying.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 重复*步骤7*至*9*，对所有额外的主节点进行更新和验证，使用相应实例组的适当名称。
- en: 'Verify that kops has successfully updated the master nodes:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证kops是否成功更新了主节点：
- en: '[PRE26]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You should see the following output:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下输出：
- en: '![Figure 18.24: Checking whether all the master nodes have been upgraded'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.24：检查所有主节点是否已升级'
- en: '](image/B14870_18_24.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_24.jpg)'
- en: 'Figure 18.24: Checking whether all the master nodes have been upgraded'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.24：检查所有主节点是否已升级
- en: As mentioned earlier, this is a dry run, and the output shows which nodes require
    an update. Since all of them show `STATUS` as `Ready`, we know that they have
    been updated. By contrast, you can see that `nodes` (the worker nodes) return
    `NeedsUpdate`, since we have not updated them yet.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这是一个干跑，输出显示哪些节点需要更新。由于它们都显示`STATUS`为`Ready`，我们知道它们已经更新。相比之下，您可以看到`nodes`（工作节点）返回`NeedsUpdate`，因为我们还没有更新它们。
- en: 'Verify that all the master nodes have been upgraded to the desired version:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证所有主节点是否已升级到所需版本：
- en: '[PRE27]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should see a response similar to the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的响应：
- en: '![Figure 18.25: Checking the version of Kubernetes on all the master nodes'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.25：检查所有主节点上Kubernetes的版本'
- en: '](image/B14870_18_25.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_25.jpg)'
- en: 'Figure 18.25: Checking the version of Kubernetes on all the master nodes'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.25：检查所有主节点上Kubernetes的版本
- en: As you can see, all the master nodes are running version `1.15.10`, which is
    the desired version.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，所有主节点都在运行版本`1.15.10`，这是期望的版本。
- en: In this exercise, you have seen how to upgrade the master nodes of the Kubernetes
    cluster without any downtime for users. One node update at a time will make sure
    that enough master servers are available (a minimum of three are required for
    this to work) and the users and the cluster are not getting impacted during the
    update.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您已经看到了如何在不影响用户的情况下升级Kubernetes集群的主节点。逐个节点更新将确保有足够的主服务器可用（至少需要三个才能正常工作），并且在更新期间不会影响用户和集群。
- en: Note
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When you apply a rolling update to an instance group, kops will roll out the
    update through the nodes within the instance group by taking only one node offline
    at a time. On top of that, in this exercise, we applied a rolling update to only
    one instance group at a time. Eventually, what you should achieve is a situation
    where only one node from your cluster is taken offline at a time. Remember this
    if you choose to automate this process.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当您对实例组应用滚动更新时，kops将通过逐个将节点脱机来滚动更新实例组中的节点。除此之外，在这个练习中，我们一次只对一个实例组应用滚动更新。最终，您应该实现的是集群中只有一个节点被逐个脱机。如果您选择自动化这个过程，请记住这一点。
- en: Upgrading Kubernetes Worker Nodes
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级Kubernetes工作节点
- en: Although Kubernetes supports compatibility between master (API server) and worker
    nodes (kubelet) within one minor version, it is highly recommended that you upgrade
    the master and worker nodes in one go. Using kops, upgrading worker nodes is similar
    to upgrading master nodes. Due to the backward compatibility within one minor
    version, the worker nodes may still work if they are not version-matched by the
    master nodes, but it is strongly discouraged to run different versions of Kubernetes
    on worker and master nodes since this may create problems for the cluster.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Kubernetes支持主节点（API服务器）和工作节点（kubelet）在一个次要版本内的兼容性，但强烈建议您一次性升级主节点和工作节点。使用kops，升级工作节点类似于升级主节点。由于在一个次要版本内的向后兼容性，如果工作节点与主节点的版本不匹配，工作节点可能仍然可以工作，但强烈不建议在工作节点和主节点上运行不同版本的Kubernetes，因为这可能会为集群创建问题。
- en: 'However, the following considerations are of extreme importance if you want
    to keep your application online during the upgrade:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您希望在升级过程中保持应用程序在线，以下考虑非常重要：
- en: Make sure that your applications are configured to be highly available. This
    means that you should have at least two pods, each on different nodes, for each
    of your applications. If this is not the case, your applications may experience
    downtime once you evict the pods from the nodes.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您的应用程序配置为高可用。这意味着您应该为每个应用程序至少在不同节点上拥有两个pod。如果不是这种情况，一旦您从节点中驱逐pod，您的应用程序可能会出现停机时间。
- en: If you are running stateful components, make sure that the state of these components
    is backed up, or that your applications are designed to be able to withstand partial
    unavailability of the stateful components.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您运行有状态的组件，请确保这些组件的状态已备份，或者您的应用程序设计能够承受有状态组件的部分不可用。
- en: For example, let's say that you are running a database with a single master
    node and multiple read replicas. Once the node that is running the master replica
    of your database evicts the database pod, if your applications are not correctly
    configured to handle this scenario, they will suffer a downtime. This has nothing
    to do with the upgrade of the Kubernetes cluster, but it is important to understand
    how your applications behave during an upgrade and to ensure that they are properly
    configured to be fault-tolerant.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在运行一个具有单个主节点和多个读取副本的数据库。一旦运行数据库主副本的节点驱逐数据库pod，如果您的应用程序没有正确配置来处理这种情况，它们将遭受停机时间。这与Kubernetes集群的升级无关，但重要的是要了解您的应用程序在升级期间的行为，并确保它们被正确配置为容错。
- en: Now that we have understood the requirements to ensure the uptime of your application,
    let's see how we can upgrade the worker nodes in the following exercise.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了确保应用程序的正常运行时间的要求，让我们看看如何在以下练习中升级工作节点。
- en: 'Exercise 18.04: Upgrading the Worker Nodes'
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习18.04：升级工作节点
- en: 'In this exercise, we will upgrade all the worker nodes of the Kubernetes cluster.
    Worker nodes are the host of your applications:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将升级Kubernetes集群的所有工作节点。工作节点是您的应用程序的主机。
- en: 'Get the list of instance groups for your worker nodes:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取工作节点的实例组列表：
- en: '[PRE28]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should see a response similar to the following:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的响应：
- en: '![Figure 18.26: Getting a list of the instance groups'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.26：获取实例组列表'
- en: '](image/B14870_18_26.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_26.jpg)'
- en: 'Figure 18.26: Getting a list of the instance groups'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.26：获取实例组列表
- en: From this image, we can see that the name of the instance group for our worker
    nodes is `nodes`.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图像中，我们可以看到我们的工作节点实例组的名称是`nodes`。
- en: 'Verify that the nodes are ready:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证节点是否准备就绪：
- en: '[PRE29]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You should see a response similar to this:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这样的响应：
- en: '![Figure 18.27: Checking node status'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.27：检查节点状态'
- en: '](image/B14870_18_27.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_27.jpg)'
- en: 'Figure 18.27: Checking node status'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.27：检查节点状态
- en: If we had multiple instance groups, we would be upgrading each instance group
    one by one. However, our task here is simple since we have just one – that is, `nodes`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有多个实例组，我们将逐个升级每个实例组。然而，我们的任务很简单，因为我们只有一个 - 那就是`nodes`。
- en: 'Run the kops rolling update for the `nodes` instance group **without** the
    `--yes` flag. This will provide you with a summary of what will be updated with
    the `kops rolling-update` command:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`kops rolling update`命令，针对`nodes`实例组**不**使用`--yes`标志。这将为您提供使用`kops rolling-update`命令将要更新的摘要：
- en: '[PRE30]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note that we have changed the verbosity value in the preceding command to get
    more detailed logs.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经在前面的命令中更改了详细日志的详细程度。
- en: 'Let''s break down this command:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解这个命令：
- en: – The `node-interval` flag sets the minimum delay between different node restarts.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '- `node-interval`标志设置不同节点重新启动之间的最小延迟。'
- en: – The `instance-group` flag states which instance group the rolling update should
    be applied to.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '- `instance-group`标志指定滚动更新应该应用到哪个实例组。'
- en: – The `post-drain-delay` flag sets the delay after draining the node before
    it can be restarted. Remember from earlier in this chapter that the drain operation
    will wait for the graceful termination of pods. This delay will be applied after
    that.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '- `post-drain-delay`标志设置在排空节点之后重新启动之前的延迟。请记住，在本章的前面部分，排空操作将等待pod的正常终止。这个延迟将在此之后应用。'
- en: The `node-interval` and `post-drain-delay` flags provide an option to control
    the rate of change in the cluster. The value of these options partially depends
    on the type of application you are running. For example, if you are running a
    log agent DaemonSet on the nodes, you may want to give enough time for the pod
    to flush the content to a central logging server.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '`node-interval`和`post-drain-delay`标志提供了控制集群变化速率的选项。这些选项的值部分取决于您正在运行的应用程序类型。例如，如果您在节点上运行一个日志代理DaemonSet，您可能希望给足够的时间让pod将内容刷新到中央日志服务器。'
- en: Note
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We did not use these delays when we performed a rolling update in the previous
    case since in that case, the instance groups each had just one node in them. Here,
    we have three nodes in this instance group.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个案例中，我们在执行滚动更新时没有使用这些延迟，因为在那种情况下，实例组中每个只有一个节点。在这里，这个实例组中有三个节点。
- en: – The `logtosterr` flag outputs all the logs to the **stderr** stream so that
    we can see them in our terminal output.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '- `logtosterr`标志将所有日志输出到**stderr**流，以便我们可以在终端输出中看到它们。'
- en: – The `v` flag sets the verbosity of the logs that we will see.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '- `v`标志设置我们将看到的日志的详细程度。'
- en: 'This command will show the following output:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将显示以下输出：
- en: '![Figure 18.28: Performing a dry run of the rolling update'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.28：执行滚动更新的干跑'
- en: '](image/B14870_18_28.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_28.jpg)'
- en: 'Figure 18.28: Performing a dry run of the rolling update'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.28：执行滚动更新的干跑
- en: 'Now, run the upgrade. Use the same command as the previous step with the addition
    of the `--yes` flag. This tells kops to perform the upgrade:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，运行升级。使用与上一步相同的命令，并添加`--yes`标志。这告诉kops执行升级：
- en: '[PRE31]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Kops will drain a node, wait for the post drain delay time, and then upgrade
    and restart the node. This will be repeated for each node, one by one. You will
    see a long log in the terminal, and this process may take up to half an hour to
    complete. In your terminal, you should start seeing the logs, as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Kops将排空一个节点，等待排空后的延迟时间，然后升级并重新启动节点。这将逐个节点重复进行。您将在终端中看到一个很长的日志，这个过程可能需要长达半个小时才能完成。在您的终端中，您应该开始看到日志，如下所示：
- en: '![Figure 18.29: Starting the rolling update process'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.29：开始滚动更新过程'
- en: '](image/B14870_18_29.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_29.jpg)'
- en: 'Figure 18.29: Starting the rolling update process'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.29：开始滚动更新过程
- en: 'After a while, you will see that the cluster upgrade is finished with a success
    message, as shown:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 过一会儿，您将看到集群升级已经完成，并显示成功消息，如下所示：
- en: '![Figure 18.30: Rolling update completion message'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.30：滚动更新完成消息'
- en: '](image/B14870_18_30.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_30.jpg)'
- en: 'Figure 18.30: Rolling update completion message'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.30：滚动更新完成消息
- en: Keen readers will notice, in *Figure 18.29*, that in the author's logs, the
    cluster upgrade started at around 3:05 and finished, as can be seen in *Figure
    18.29*, at around 3:25\. The total time is around 20 minutes for three nodes.
    We had set a delay of 3 minutes for each node after stopping it and 3 minutes
    for each node after draining all the pods. So, the waiting time for each node
    adds up to 6 minutes. With three nodes in the instance group, the total wait time
    is 6 × 3 = 18 minutes.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 细心的读者会注意到，在*图18.29*中，作者的日志显示，集群升级在大约3:05开始，如*图18.29*所示，大约在3:25完成。三个节点的总时间约为20分钟。我们在停止每个节点后设置了3分钟的延迟，以及在排空所有pod后设置了3分钟的延迟。因此，每个节点的等待时间加起来为6分钟。在实例组中有三个节点，总等待时间为6×3=18分钟。
- en: 'Verify that the worker nodes are updated to the target version – that is, `1.15.10`:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证工作节点是否已更新到目标版本-即`1.15.10`：
- en: '[PRE32]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You should see the following response:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 18.31: Checking the version of Kubernetes on worker nodes'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.31：检查工作节点上的Kubernetes版本'
- en: '](image/B14870_18_31.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_31.jpg)'
- en: 'Figure 18.31: Checking the version of Kubernetes on worker nodes'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.31：检查工作节点上Kubernetes的版本
- en: 'Verify that the pods are in a running state:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证pod是否处于运行状态：
- en: '[PRE33]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You should see all pods with `STATUS` set to `Running`, as in this screenshot:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到所有的pod的`STATUS`都设置为`Running`，就像这个截图中一样：
- en: '![Figure 18.32: Checking the status of our pods'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '![图18.32：检查我们的pod的状态'
- en: '](image/B14870_18_32.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_32.jpg)'
- en: 'Figure 18.32: Checking the status of our pods'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.32：检查我们的pod的状态
- en: 'In this exercise, you have seen how easy it is to upgrade the worker nodes
    through kops. However, we do not recommend upgrading all worker nodes in one go
    for production clusters and strongly recommend creating instance groups for worker
    nodes. The following are some strategies that can be used for production-grade clusters:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您已经看到了通过kops升级工作节点是多么容易。但是，我们不建议一次性升级所有生产集群的工作节点，并强烈建议为工作节点创建实例组。以下是一些可用于生产级集群的策略：
- en: Don't keep all of your worker nodes in a single instance group. Create multiple
    instance groups for different sets of worker nodes. By default, kops creates only
    one instance group, but you can change this behavior to create many instance groups
    for worker nodes. We recommend having different worker instance groups for infrastructure
    components (such as monitoring and logging), ingress, critical applications, non-critical
    applications, and static applications. This will help you apply the upgrade to
    less critical parts of your cluster first. This strategy would help limit any
    issues in the upgrade process, keeping them to a minimum while isolating the affected
    nodes from the rest of the cluster.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要将所有的工作节点都放在一个实例组中。为不同的工作节点集创建多个实例组。默认情况下，kops只创建一个实例组，但您可以更改此行为，为工作节点创建多个实例组。我们建议为基础设施组件（如监控和日志记录）、入口、关键应用程序、非关键应用程序和静态应用程序创建不同的工作实例组。这将帮助您首先将升级应用于集群中不太关键的部分。这种策略将有助于限制升级过程中的任何问题，并将受影响的节点与集群的其余部分隔离开来。
- en: If you are running the cluster in the cloud, you can provision new nodes on
    demand. Thus, it may be a good idea to create a sister instance group for upgrades.
    This new instance group should be running the upgraded version of Kubernetes.
    Now, cordon and drain all the pods from the old instance group. The Kubernetes
    scheduler will see that the new nodes are available and will automatically move
    all your pods to the new nodes. Once this is complete, you can just delete the
    old instance group and your upgrade is complete.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您在云中运行集群，可以根据需要提供新节点。因此，创建一个姐妹实例组进行升级可能是一个好主意。这个新的实例组应该运行升级后的Kubernetes版本。现在，从旧的实例组中关闭和排空所有的pod。Kubernetes调度器将看到新节点可用，并自动将所有pod移动到新节点。完成后，您只需删除旧的实例组，升级就完成了。
- en: This strategy needs a bit of planning, especially if you are running stateful
    applications on the cluster. This strategy also assumes that you are able to provision
    new nodes on demand, since creating a sister instance group may require temporary
    additional hardware, which may be a challenge for an on-premises data center.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略需要一些规划，特别是如果您在集群上运行有状态的应用程序。这种策略还假定您能够根据需要提供新节点，因为创建一个姐妹实例组可能需要临时的额外硬件，这对于自建数据中心可能是一个挑战。
- en: Notice that these are advanced strategies and are beyond the scope of this book.
    However, you can find more information about it at [https://kops.sigs.k8s.io/tutorial/working-with-instancegroups/](https://kops.sigs.k8s.io/tutorial/working-with-instancegroups/).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些都是高级策略，超出了本书的范围。但是，您可以在[https://kops.sigs.k8s.io/tutorial/working-with-instancegroups/](https://kops.sigs.k8s.io/tutorial/working-with-instancegroups/)找到更多信息。
- en: Now that you have seen all the steps required to upgrade your cluster, you can
    bring it all together in the following activity.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到升级集群所需的所有步骤，您可以在以下活动中将它们整合起来。
- en: 'Activity 18.01: Upgrading the Kubernetes Platform from Version 1.15.7 to 1.15.10'
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动18.01：将Kubernetes平台从版本1.15.7升级到1.15.10
- en: 'In this activity, you will upgrade the Kubernetes platform from version `1.15.7`
    to version `1.15.10`. Here, we will bring together everything that we have learned
    in this chapter. These guidelines should help you to complete the activity:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，您将把Kubernetes平台从版本`1.15.7`升级到版本`1.15.10`。在这里，我们将整合本章学到的所有内容。以下准则应该帮助您完成这个活动：
- en: Note
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this activity, we are showcasing the upgrade from Kubernetes version `1.15.7`
    to `1.15.10`. You can apply the same steps to upgrade to the version of Kubernetes
    supported by kops at the time when you perform this activity.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们展示了从Kubernetes版本`1.15.7`升级到`1.15.10`的过程。您可以应用相同的步骤来升级到kops在您执行此活动时支持的Kubernetes版本。
- en: Using *Exercise 11.01*, *Setting Up Our Kubernetes Cluster*, set up a fresh
    cluster running Kubernetes version `1.15.7`. If you are using the cloud to spin
    up machines, you can take a snapshot of the machines (your cloud vendor may charge
    you for this) before the upgrade to quickly rerun the upgrade again.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*练习11.01*，*设置我们的Kubernetes集群*，建立一个运行Kubernetes版本`1.15.7`的新集群。如果您正在使用云来启动机器，您可以在升级之前对机器进行快照（您的云供应商可能会向您收费），以便快速重新运行升级。
- en: Upgrade kops to the version you want to upgrade on the master or bastion node.
    For this activity, we need to have version `1.15`.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将kops升级到您想要在主节点或堡垒节点上升级的版本。对于这个活动，我们需要版本`1.15`。
- en: Upgrade one of the master nodes to Kubernetes version `1.15.10`.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将其中一个主节点升级到Kubernetes版本`1.15.10`。 '
- en: Verify that the master node is back in service and in the `Ready` state.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证主节点是否已恢复服务并处于“Ready”状态。
- en: Similarly, upgrade all the other master nodes.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，升级所有其他主节点。
- en: 'Verify that all the master nodes are upgraded to the desired version, as in
    the following screenshot:![Figure 18.33: Upgraded version of Kubernetes on master
    nodes'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证所有主节点是否已升级到所需版本，如下截图所示：![图18.33：主节点上的Kubernetes升级版本
- en: '](image/B14870_18_33.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_33.jpg)'
- en: 'Figure 18.33: Upgraded version of Kubernetes on master nodes'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.33：主节点上的Kubernetes升级版本
- en: Now, upgrade the worker nodes.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，升级工作节点。
- en: 'Verify that the pods are running successfully on the newly upgraded nodes.
    Finally, you should be able to verify that your pods are running on the new node,
    as follows:![Figure 18.34: Pods running on upgraded worker nodes'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证Pod是否成功运行在新升级的节点上。最后，您应该能够验证您的Pod正在新节点上运行，如下所示：![图18.34：运行在升级后的工作节点上的Pod
- en: '](image/B14870_18_34.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_18_34.jpg)'
- en: 'Figure 18.34: Pods running on upgraded worker nodes'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.34：运行在升级后的工作节点上的Pod
- en: Note
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The solution to this activity can be found at the following address: [https://packt.live/304PEoD](https://packt.live/304PEoD).'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在以下地址找到：[https://packt.live/304PEoD](https://packt.live/304PEoD)。
- en: Summary
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have learned that keeping your Kubernetes platform up to
    date is very important when it comes to providing a secure and reliable foundation
    for running your applications. In this fast-moving digital world, many businesses
    rely on critical applications and keeping them available, even though upgrading
    the underlying platform is important.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经了解到，保持Kubernetes平台的最新状态对于提供安全可靠的应用程序运行基础非常重要。在这个快速发展的数字世界中，许多企业依赖于关键应用程序，并保持它们可用，即使升级底层平台也很重要。
- en: You have seen that a no-downtime upgrade of the platform is possible if you
    have set up the cluster in a high availability configuration to start with. However,
    the platform does not guarantee the availability of your applications unless you
    have designed and deployed your application in a fault-tolerant manner. One factor
    is to make sure that you have multiple instances of your application running and
    that the application is designed to handle the termination of these instances
    gracefully.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到，如果您一开始就以高可用性配置设置了集群，那么平台的无停机升级是可能的。然而，除非您以容错的方式设计和部署应用程序，否则平台不能保证应用程序的可用性。一个因素是确保您的应用程序有多个实例运行，并且该应用程序被设计为优雅地处理这些实例的终止。
- en: With that taken into account, we have seen the important considerations for
    upgrading your cluster in a way that the platform itself does not cause downtime
    for your application. We looked at the upgrade process for the master nodes as
    well as worker nodes separately. The key takeaway from this chapter is the principles
    underlined at various instances that you can apply for different kinds of Kubernetes
    clusters managed by different tools.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们已经看到了升级集群的重要考虑因素，以确保平台本身不会导致应用程序的停机时间。我们分别研究了主节点和工作节点的升级过程。本章的关键要点是在不同情况下强调的原则，您可以将其应用于不同工具管理的不同类型的Kubernetes集群。
- en: As mentioned at the beginning of the chapter, keeping your platform up to date
    is important to keep up with the latest developments in DevOps and enable your
    application development team to continue delivering new features to your end customers.
    With the skills acquired from this chapter, you should be able to handle the upgrade
    of your platform without causing disruption to your customers.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章开头提到的，保持平台的最新状态对于跟上DevOps的最新发展并使您的应用开发团队能够继续向最终客户提供新功能是很重要的。通过本章获得的技能，您应该能够在升级平台时不会对客户造成中断。
- en: In the next chapter, we will discuss how to extend your Kubernetes platform
    with custom resources. Custom resources allow you to offer a Kubernetes native
    API experience for your own projects.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何使用自定义资源扩展您的Kubernetes平台。自定义资源允许您为自己的项目提供Kubernetes本机API体验。
