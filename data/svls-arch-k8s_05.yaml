- en: 5\. Production-Ready Kubernetes Clusters
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 生产就绪的Kubernetes集群
- en: Learning Objectives
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，您将能够：
- en: Identify the requirements of Kubernetes cluster setup
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别Kubernetes集群设置的要求
- en: Create a production-ready Kubernetes cluster in Google Cloud Platform (GCP)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Google Cloud Platform（GCP）中创建一个生产就绪的Kubernetes集群
- en: Manage cluster autoscaling to add new servers to a Kubernetes cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理集群自动缩放以向Kubernetes集群添加新服务器
- en: Migrate applications in production clusters
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移生产集群中的应用程序
- en: In this chapter, we will learn about the key considerations for the setup of
    Kubernetes. Following that, we will also study the different Kubernetes platform
    options. Then, we move on to creating a production-ready Kubernetes cluster in
    cloud platforms and performing administrative tasks.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习关于设置Kubernetes的关键考虑因素。随后，我们还将研究不同的Kubernetes平台选项。然后，我们将继续在云平台上创建一个生产就绪的Kubernetes集群，并执行管理任务。
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, we created Kubernetes clusters for the development
    environment and installed applications into it. In this chapter, the focus will
    be on production-ready Kubernetes clusters and how to administer them for better
    availability, reliability, and cost optimization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们为开发环境创建了Kubernetes集群，并将应用程序安装到其中。在本章中，重点将放在生产就绪的Kubernetes集群上，以及如何管理它们以获得更好的可用性、可靠性和成本优化。
- en: 'Kubernetes is the de facto system for managing microservices running as containers
    in the cloud. It is widely adopted in the industry by both start-ups and large
    enterprises for running various kinds of applications, including **data analysis
    tools**, **serverless apps**, and **databases**. Scalability, high availability,
    reliability, and security are the key features of Kubernetes that enable its adoption.
    Let''s assume that you have decided to use Kubernetes, and hence you need a reliable
    and observable cluster setup for development and production. There are critical
    considerations that depend on your requirements, budget, and team before choosing
    a Kubernetes provider and how to operate the applications. There are four key
    considerations to analyze:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是在云中管理作为容器运行的微服务的事实标准系统。它被行业广泛采用，包括初创公司和大型企业，用于运行各种类型的应用程序，包括数据分析工具、无服务器应用程序和数据库。可伸缩性、高可用性、可靠性和安全性是Kubernetes的关键特性，使其能够被广泛采用。假设您已决定使用Kubernetes，因此您需要一个可靠且可观察的集群设置用于开发和生产。在选择Kubernetes提供商以及如何操作应用程序之前，有一些关键的考虑因素取决于您的需求、预算和团队。有四个关键考虑因素需要分析：
- en: '**Service Quality:** Kubernetes runs microservices in a *highly available*
    and reliable way. However, it is critical to install and operate Kubernetes reliably
    and robustly. Let''s assume you have installed the Kubernetes control plane into
    a single node in the cluster, and it was disconnected due to a network problem.
    Since you have lost the Kubernetes API server connectivity, you will not be able
    to check the status of your applications and operate them. Therefore, it is essential
    to evaluate the service quality of the Kubernetes cluster you need for your production
    environment.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务质量：** Kubernetes以*高可用*和可靠的方式运行微服务。然而，安装和可靠地操作Kubernetes至关重要。假设您已将Kubernetes控制平面安装到集群中的单个节点，并且由于网络问题而断开连接。由于您已经失去了Kubernetes
    API服务器的连接，您将无法检查应用程序的状态和操作它们。因此，评估您在生产环境中所需的Kubernetes集群的服务质量至关重要。'
- en: '**Monitoring:** Kubernetes runs containers that are distributed to the nodes
    and enables checking their logs and statuses. Let''s assume that you rolled out
    a new version of your application yesterday. Today, you want to check how the
    latest version is working for any errors, crashes, and response time. Therefore,
    you need a monitoring system integrated into your Kubernetes cluster to capture
    logs and metrics. The collected data is essential for troubleshooting and diagnosis
    in a production-ready cluster.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控：** Kubernetes 运行分布到节点的容器，并能够检查它们的日志和状态。假设您昨天推出了应用程序的新版本。今天，您想要检查最新版本的运行情况，是否有错误、崩溃和响应时间。因此，您需要一个集成到
    Kubernetes 集群中的监控系统来捕获日志和指标。收集的数据对于生产就绪的集群中的故障排除和诊断至关重要。'
- en: '**Security:** Kubernetes components and client tools work in a secure way to
    manage the applications running in the cluster. However, you need to have specific
    roles and authorization levels defined for your organization to operate Kubernetes
    clusters securely. Hence, it is essential to choose a Kubernetes provider platform
    that you can securely connect to and share with your customers and colleagues.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性：** Kubernetes 组件和客户端工具以安全的方式工作，以管理集群中运行的应用程序。然而，您需要为您的组织定义特定的角色和授权级别，以安全地操作
    Kubernetes 集群。因此，选择一个可以安全连接并与客户和同事共享的 Kubernetes 提供者平台至关重要。'
- en: '**Operations:** Kubernetes is the host of all applications, including services
    with data compliance, auditing, and enterprise-level requirements. Let''s assume
    you are running the backend and frontend of your online banking application system
    on Kubernetes. For a chartered bank in your county, the audit logs of your applications
    should be accessible. Since you have deployed your entire system on Kubernetes,
    the platform should enable fetching audit logs, archiving them, and storing them.
    Therefore, the operational capability of the Kubernetes platform is essential
    for the production-ready cluster setup.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运维：** Kubernetes 是所有应用程序的主机，包括具有数据合规性、审计和企业级要求的服务。假设您正在 Kubernetes 上运行在线银行应用系统的后端和前端。对于您所在国家的特许银行，应用程序的审计日志应该是可访问的。由于您已经在
    Kubernetes 上部署了整个系统，平台应该能够获取审计日志、存档和存储它们。因此，Kubernetes 平台的运维能力对于生产就绪的集群设置至关重要。'
- en: In order to decide how to install and operate your Kubernetes clusters, these
    considerations will be discussed for the Kubernetes platform options in this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定如何安装和操作您的 Kubernetes 集群，本章将讨论这些考虑因素，以选择 Kubernetes 平台选项。
- en: Kubernetes Setup
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 设置
- en: Kubernetes is a flexible system that can be installed on various platforms from
    **Raspberry Pi** to high-end servers in **data centers**. Each platform comes
    with its advantages and disadvantages in terms of service quality, monitoring,
    security, and operations. Kubernetes manages applications as containers and creates
    an abstraction layer on the infrastructure. Let's imagine that you set up Kubernetes
    on the three old servers in your basement and then install the **Proof** **of**
    **Concept** (**PoC**) of your new project. When the project becomes successful,
    you want to scale your application and move to a cloud provider such as **Amazon
    Web Services** (**AWS**). Since your application is designed to run on Kubernetes
    and does not depend on the infrastructure, porting to another Kubernetes installation
    is straightforward.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个灵活的系统，可以安装在各种平台上，从**树莓派**到**数据中心**中的高端服务器。每个平台在服务质量、监控、安全性和运营方面都有其优势和劣势。Kubernetes将应用程序作为容器进行管理，并在基础架构上创建一个抽象层。假设你在地下室的三台旧服务器上安装了Kubernetes，然后安装了你的新项目的**概念验证**（**PoC**）。当项目取得成功后，你想要扩展你的应用程序并迁移到**亚马逊网络服务**（**AWS**）等云服务提供商。由于你的应用程序是设计运行在Kubernetes上，并且不依赖于基础设施，因此迁移到另一个Kubernetes安装是直接的。
- en: 'In the previous chapter, we studied the development environment setup using
    `minikube`, the official method of Kubernetes. In this section, production-level
    Kubernetes platforms will be presented. The Kubernetes platforms for production
    can be grouped into threes, with the following abstraction layers:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了使用`minikube`作为Kubernetes的官方方法来设置开发环境。在本节中，将介绍生产级别的Kubernetes平台。生产级别的Kubernetes平台可以分为三种，具有以下抽象层：
- en: '![Figure 5.1: Kubernetes platforms'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1：Kubernetes平台'
- en: '](image/C12607_05_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_01.jpg)'
- en: 'Figure 5.1: Kubernetes platforms'
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.1：Kubernetes平台
- en: Let's now look at each of these types, one by one.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们逐个看看这些类型。
- en: Managed Platforms
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 托管平台
- en: 'Managed platforms provide **Kubernetes as a Service**, and all underlying services
    run under the control of cloud providers. It is easy to set up and scale these
    clusters since the cloud providers handle all infrastructural operations. Leading
    cloud providers such as GCP, AWS, and Microsoft Azure have managed Kubernetes
    solution applications, intending to integrate other cloud services such as container
    registries, identity services, and storage services. The most popular managed
    Kubernetes solutions are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 托管平台提供**Kubernetes作为服务**，所有底层服务都在云提供商的控制下运行。由于云提供商处理所有基础设施操作，因此设置和扩展这些集群非常容易。领先的云提供商，如GCP、AWS和Microsoft
    Azure，都提供了托管的Kubernetes解决方案应用程序，旨在集成其他云服务，如容器注册表、身份服务和存储服务。最受欢迎的托管Kubernetes解决方案如下：
- en: '**Google Kubernetes Engine (GKE):** GKE is the most mature managed service
    on the market, and Google provides it as a part of GCP.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Kubernetes Engine (GKE):** GKE是市场上最成熟的托管服务，谷歌将其作为GCP的一部分提供。'
- en: '**Azure Kubernetes Service (AKS):** AKS is the Kubernetes solution provided
    by Microsoft as a part of the Azure platform.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Kubernetes Service (AKS):** AKS是微软提供的作为Azure平台一部分的Kubernetes解决方案。'
- en: '**Amazon Elastic Container Service for Kubernetes (EKS):** EKS is the managed
    Kubernetes of AWS.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon弹性容器服务（EKS）：** EKS是AWS的托管Kubernetes。'
- en: Turnkey Platforms
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 即插即用平台
- en: Turnkey solutions focus on installing and operating the Kubernetes control plane
    in the cloud or in on-premise systems. Users of turnkey platforms provide information
    about the infrastructure, and the turnkey platforms handle the Kubernetes setup.
    Turnkey platforms offer better flexibility in setup configurations and infrastructure
    options. These platforms are mostly designed by organizations with rich experience
    in Kubernetes and cloud systems such as **Heptio** or **CoreOS**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 即插即用解决方案专注于在云端或内部系统中安装和操作Kubernetes控制平面。即插即用平台的用户提供有关基础设施的信息，即插即用平台处理Kubernetes设置。即插即用平台在设置配置和基础设施选项方面提供更好的灵活性。这些平台大多由在Kubernetes和云系统方面拥有丰富经验的组织设计，如**Heptio**或**CoreOS**。
- en: If turnkey platforms are installed on cloud providers such as AWS, the infrastructure
    is managed by the cloud provider, and the turnkey platform manages Kubernetes.
    However, when the turnkey platform is installed on on-premise systems, in-house
    teams should handle the infrastructure operations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将即插即用平台安装在AWS等云提供商上，基础设施由云提供商管理，即插即用平台管理Kubernetes。然而，当即插即用平台安装在内部系统上时，内部团队应处理基础设施运营。
- en: Custom Platforms
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义平台
- en: Custom installation of Kubernetes is possible if your use case does not fit
    into any managed or turnkey solutions. For instance, you can use **Gardener**
    (https://gardener.cloud) or **OpenShift** (https://www.openshift.com) to install
    Kubernetes clusters to cloud providers, on-premise data centers, on-premise virtual
    machines (VMs), or bare-metal servers. While the custom platforms offer more flexible
    Kubernetes installations, they also come with special operations and maintenance
    efforts.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的用例不适用于任何托管或即插即用解决方案，则可以进行自定义安装Kubernetes。例如，您可以使用**Gardener**（https://gardener.cloud）或**OpenShift**（https://www.openshift.com）在云提供商、内部数据中心、内部虚拟机（VM）或裸金属服务器上安装Kubernetes集群。虽然自定义平台提供更灵活的Kubernetes安装，但也需要特殊的运营和维护工作。
- en: In the following sections, we will create a managed Kubernetes cluster in GKE
    and administer it. GKE offers the most mature platform and the superior customer
    experience on the market.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将在GKE中创建一个托管的Kubernetes集群并对其进行管理。GKE提供了市场上最成熟的平台和卓越的客户体验。
- en: Google Kubernetes Engine
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Kubernetes Engine
- en: GKE provides a managed Kubernetes platform backed by the experience that Google
    has of running containerized services for more than a decade. GKE clusters are
    production-ready and scalable, and they support upstream Kubernetes versions.
    In addition, GKE focuses on improving the development experience by eliminating
    the installation, management, and operation needs of Kubernetes clusters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: GKE提供了一个由Google在运行容器化服务方面拥有十多年经验支持的托管Kubernetes平台。GKE集群已经准备就绪并且可扩展，并支持上游Kubernetes版本。此外，GKE专注于通过消除Kubernetes集群的安装、管理和运营需求来改善开发体验。
- en: 'While GKE improves developer experience, it tries to minimize the cost of running
    Kubernetes clusters. It only charges for the nodes in the cluster and provides
    a Kubernetes control plane free of charge. In other words, GKE delivers a reliable,
    scalable, and robust Kubernetes control plane without any cost. For the servers
    that run the workload of your applications, the usual GCP Compute Engine pricing
    is applied. For instance, let''s assume that you will start with two `n1-standard-1`
    **(vCPUs: 1, RAM: 3.75 GB)** nodes:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GKE改善了开发者体验，但它试图最小化运行Kubernetes集群的成本。它只收取集群中的节点费用，并免费提供Kubernetes控制平面。换句话说，GKE提供了一个可靠、可扩展和强大的Kubernetes控制平面，而没有任何费用。对于运行应用程序工作负载的服务器，通常适用GCP计算引擎定价。例如，假设您将从两个`n1-standard-1`
    **（vCPUs：1，RAM：3.75 GB）**节点开始：
- en: 'The calculation would be as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计算如下：
- en: 1,460 total hours per month
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 每月总计1,460小时
- en: '**Instance type**: n1-standard-1'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**实例类型**：n1-standard-1'
- en: '**GCE Instance Cost**: USD 48.54'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**GCE实例成本**：48.54美元'
- en: '**Kubernetes Engine Cost**: USD 0.00'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes Engine成本**：0.00美元'
- en: '**Estimated Component Cost**: USD 48.54 per 1 month'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**预估组件成本**：每月48.54美元'
- en: 'If your application requires scalability with the higher usage and if you need
    10 servers instead of 2, the cost will also scale linearly:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的应用程序需要随着更高的使用量而扩展，如果您需要10台服务器而不是2台，成本也会线性增加：
- en: 7,300 total hours per month
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 每月总共7300小时
- en: '**Instance type**: n1-standard-1'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**实例类型**：n1-standard-1'
- en: '**GCE Instance Cost**: USD 242.72'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**GCE实例成本**：242.72美元'
- en: '**Kubernetes Engine Cost**: USD 0.00'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes Engine Cost**: USD 0.00'
- en: '**Estimated Component Cost**: USD 242.72 per 1 month'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**预估组件成本**：每月242.72美元'
- en: This calculation shows that GKE does not charge for the Kubernetes control plane
    and provides a reliable, scalable, and robust Kubernetes API for every cluster.
    In addition, the cost linearly increases for scaling clusters, which makes it
    easier to plan and operate Kubernetes clusters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算表明，GKE不会为Kubernetes控制平面收费，并为每个集群提供可靠、可扩展和强大的Kubernetes API。此外，扩展集群的成本是线性增加的，这使得规划和操作Kubernetes集群变得更加容易。
- en: In the following exercise, you will create a managed Kubernetes cluster in GKE
    and connect to it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，您将在GKE中创建一个托管的Kubernetes集群并连接到它。
- en: Note
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'In order to complete this exercise, you need to have an active GCP account.
    You can create an account on its official website: https://console.cloud.google.com/start.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个练习，您需要有一个活跃的GCP账户。您可以在其官方网站上创建一个账户：https://console.cloud.google.com/start。
- en: 'Exercise 13: Creating a Kubernetes Cluster on GCP'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习13：在GCP上创建Kubernetes集群
- en: In this exercise, we will create a Kubernetes cluster in GKE and connect to
    it securely to check node statuses. The Google Cloud Platform dashboard and CLI
    tools maintain a high level of developer experience. Therefore, if you need a
    production-ready Kubernetes cluster, you will have a fully functioning control
    plane and server nodes in less than 10 minutes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将在GKE中创建一个Kubernetes集群，并安全地连接到它以检查节点状态。Google Cloud Platform的仪表板和CLI工具保持了高水平的开发者体验。因此，如果您需要一个生产就绪的Kubernetes集群，您将在不到10分钟内拥有一个完全运行的控制平面和服务器节点。
- en: 'To complete the exercise, we need to ensure the following steps are executed:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成练习，我们需要确保执行以下步骤：
- en: 'Click **Kubernetes Engine** in the left menu under **Compute** on the Google
    Cloud Platform home page, as shown in the following figure:![Figure 5.2: Google
    Cloud Platform home page'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Google Cloud Platform主页的**计算**下的左侧菜单中点击**Kubernetes Engine**，如下图所示：![图5.2：Google
    Cloud Platform主页
- en: '](image/C12607_05_02.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_02.jpg)'
- en: 'Figure 5.2: Google Cloud Platform home page'
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.2：Google Cloud Platform主页
- en: 'Click **Create Cluster** on the **Clusters** page, as shown in the following
    figure:![Figure 5.3: Cluster view'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**集群**页面上点击**创建集群**，如下图所示：![图5.3：集群视图
- en: '](image/C12607_05_03.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_03.jpg)'
- en: 'Figure 5.3: Cluster view'
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.3：集群视图
- en: 'Select **Your first cluster** in the left from **Cluster templates** and write
    `serverless` as the name. Click **Create** at the end of the page, as shown in
    the following figure:![Figure 5.4: Cluster creation'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**集群模板**中从左侧选择**您的第一个集群**，并将`serverless`作为名称。点击页面底部的**创建**，如下图所示：![图5.4：集群创建
- en: '](image/C12607_05_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_04.jpg)'
- en: 'Figure 5.4: Cluster creation'
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.4：集群创建
- en: 'Wait a couple of minutes until the cluster icon becomes green and then click
    the **Connect** button, as you can see in the following figure:![Figure 5.5: Cluster
    list'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待几分钟，直到集群图标变成绿色，然后点击**连接**按钮，如下图所示：![图5.5：集群列表
- en: '](image/C12607_05_05.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_05.jpg)'
- en: 'Figure 5.5: Cluster list'
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.5：集群列表
- en: 'Click **Run in Cloud Shell** in the **Connect to the cluster** window, as shown
    in the following figure:![Figure 5.6: Connect to the cluster view'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**在云shell中运行**在**连接到集群**窗口中，如下图所示：![图5.6：连接到集群视图
- en: '](image/C12607_05_06.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_06.jpg)'
- en: 'Figure 5.6: Connect to the cluster view'
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.6：连接到集群视图
- en: 'Wait until the cloud shell is open and available and press *Enter* when the
    command is shown, as you can see in the following figure:![Figure 5.7: Cloud shell'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等到云shell打开并可用时，按下*Enter*，当命令显示时，如下图所示：![图5.7：云shell
- en: '](image/C12607_05_07.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_07.jpg)'
- en: 'Figure 5.7: Cloud shell'
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.7：云shell
- en: The output shows that the authentication data for the cluster is fetched, and
    the **kubeconfig** entry is ready to use.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，集群的认证数据已被获取，**kubeconfig**条目已准备就绪。
- en: 'Check the nodes with the following command in the cloud shell:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在云shell中使用以下命令检查节点：
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Since the cluster is created with a single node pool of one node, there is
    only one node connected to the cluster, as you can see in the following figure:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于集群是使用一个节点池创建的，只有一个节点连接到集群，如下图所示：
- en: '![Figure 5.8: Node list'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8：节点列表'
- en: '](image/C12607_05_08.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_08.jpg)'
- en: 'Figure 5.8: Node list'
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.8：节点列表
- en: 'Check for the pods running in the cluster with the following command in the
    cloud shell:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在云shell中使用以下命令检查集群中运行的pod：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Since GKE manages the control plane, there are no pods for `api-server`, `etcd`,
    or `scheduler` in the `kube-system` namespace. There are only networking and metrics
    pods running in the cluster, as shown in the following screenshot:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GKE管理控制平面，在`kube-system`命名空间中没有`api-server`、`etcd`或`scheduler`的pod。集群中只有网络和指标的pod在运行，如下截图所示：
- en: '![Figure 5.9: Pod list'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.9：Pod列表'
- en: '](image/C12607_05_09.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_09.jpg)'
- en: 'Figure 5.9: Pod list'
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.9：Pod列表
- en: With this exercise, you have created a production-ready Kubernetes cluster on
    GKE. Within a couple of minutes, GKE created a managed Kubernetes control plane
    and connected the servers to the cluster. In the following sections, administrating
    the clusters for production environments will be discussed, and the Kubernetes
    cluster from this exercise will be expanded.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个练习，您已经在GKE上创建了一个生产就绪的Kubernetes集群。在几分钟内，GKE创建了一个托管的Kubernetes控制平面，并将服务器连接到了集群。在接下来的章节中，将讨论管理生产环境中的集群，并扩展这个练习中的Kubernetes集群。
- en: Autoscaling Kubernetes Clusters
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动缩放Kubernetes集群
- en: 'Kubernetes clusters are designed to run scalable applications reliably. In
    other words, if the Kubernetes cluster runs **10 instances** of your application
    today, it should also support running **100 instances** in the future. There are
    two mainstream methods to reach this level of flexibility: *redundancy* and *autoscaling*.
    Let''s assume that the 10 instances of your application are running on 3 servers
    in your cluster. With the redundancy, you need at least 27 extra idle servers
    to be capable of running 100 instances in the future. It also means paying for
    the empty servers as well as operational and maintenance costs. With autoscaling,
    you need automated procedures to create or remove servers. Autoscaling ensures
    that there are no excessive idle servers and minimizes the costs while meeting
    the scalability requirements.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群旨在可靠地运行可扩展的应用程序。换句话说，如果Kubernetes集群今天运行您的应用程序的**10个实例**，它也应该支持在未来运行**100个实例**。有两种主流方法可以达到这种灵活性水平：*冗余*和*自动缩放*。假设您的应用程序的10个实例正在集群中的3台服务器上运行。通过冗余，您至少需要27台额外的空闲服务器来在未来运行100个实例。这也意味着支付空闲服务器的费用以及运营和维护成本。通过自动缩放，您需要自动化程序来创建或删除服务器。自动缩放确保没有过多的空闲服务器，并最大程度地减少成本，同时满足可扩展性要求。
- en: '**GKE Cluster Autoscaler** is the out-of-box solution for handling autoscaling
    in Kubernetes clusters. When it is enabled, it automatically adds new servers
    if there is no capacity left for the workload. Similarly, when the servers are
    underutilized, the autoscaler removes the redundant servers. Furthermore, the
    autoscaler has a minimum and maximum number of servers defined to avoid limitless
    increases or decreases. In the following exercise, the GKE cluster autoscaler
    will be enabled for the Kubernetes cluster. Then the automatic scaling of the
    servers will be demonstrated by changing the workload in the cluster.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**GKE集群自动缩放器**是处理Kubernetes集群中自动缩放的开箱即用解决方案。启用后，如果工作负载没有剩余容量，它会自动添加新服务器。同样，当服务器利用率不足时，自动缩放器会删除多余的服务器。此外，自动缩放器还定义了服务器的最小和最大数量，以避免无限增加或减少。在以下练习中，将为Kubernetes集群启用GKE集群自动缩放器。然后通过更改集群中的工作负载来演示服务器的自动缩放。'
- en: 'Exercise 14: Autoscaling a GKE Cluster in Production'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习14：在生产环境中为GKE集群启用自动缩放
- en: In this exercise, we will enable and utilize the GKE cluster autoscaler in a
    production cluster. Let's assume that you need a large number of replicas of your
    application running in the cluster. However, it is not currently possible since
    you have a low number of servers. Therefore, you need to enable autoscaling and
    see how new servers are created automatically.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将在生产集群中启用并利用GKE集群自动缩放器。假设您需要在集群中运行大量应用的副本。但是，由于服务器数量较少，目前不可能实现。因此，您需要启用自动缩放，并查看如何自动创建新服务器。
- en: 'To successfully complete the exercise, we need to ensure the following steps
    are executed:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功完成练习，我们需要确保执行以下步骤：
- en: 'Install `nginx` in the cluster by running the following command in the cloud
    shell:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在云shell中运行以下命令在集群中安装`nginx`：
- en: '[PRE2]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This command creates a deployment named `workload` from the `nginx` image,
    as depicted in the following figure:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令从`nginx`镜像创建名为`workload`的部署，如下图所示：
- en: '![Figure 5.10: Deployment creation'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.10：部署创建'
- en: '](image/C12607_05_10.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_10.jpg)'
- en: 'Figure 5.10: Deployment creation'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.10：部署创建
- en: 'Scale the `workload` deployment to 25 replicas by running the following command
    in the cloud shell:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在云shell中运行以下命令将`workload`部署扩展到25个副本：
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This command increases the number of replicas of the workload deployment, as
    shown in the following figure:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令增加了workload部署的副本数量，如下图所示：
- en: '![Figure 5.11: Deployment scaling up'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.11：部署扩展'
- en: '](image/C12607_05_11.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_11.jpg)'
- en: 'Figure 5.11: Deployment scaling up'
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.11：部署扩展
- en: 'Check the number of running pods with the following command:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查运行中的pod数量：
- en: '[PRE4]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Since there is only 1 node in the cluster, 25 replicas of `nginx` could not
    run in the cluster. Instead, only 5 instances are running currently, as shown
    in the following figure:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于集群中只有1个节点，因此无法在集群中运行25个`nginx`的副本。相反，目前只有5个实例正在运行，如下图所示：
- en: '![Figure 5.12: Deployment status'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.12：部署状态'
- en: '](image/C12607_05_12.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_12.jpg)'
- en: 'Figure 5.12: Deployment status'
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.12：部署状态
- en: 'Enable autoscaling for the node pool of the cluster using the following command:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令为集群的节点池启用自动扩展：
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Change the `zone` parameter if your cluster is running in another zone.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的集群在另一个区域运行，请更改`zone`参数。
- en: 'This command enables autoscaling for the Kubernetes cluster with a minimum
    of 1 and a maximum of 10 nodes, as shown in the following figure:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令启用了Kubernetes集群的自动扩展，最小节点数为1，最大节点数为10，如下图所示：
- en: '![Figure 5.13: Enabling autoscaler'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.13：启用自动缩放器'
- en: '](image/C12607_05_13.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_13.jpg)'
- en: 'Figure 5.13: Enabling autoscaler'
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.13：启用自动缩放器
- en: This command can take a couple of minutes to create the required resources with
    the **Updating serverless...** prompt.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令可能需要几分钟的时间来创建所需的资源，并显示“正在更新无服务器...”提示。
- en: 'Wait a couple of minutes and check for the number of nodes by using the following
    command:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待几分钟，然后使用以下命令检查节点数：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With autoscaling enabled, GKE ensures that there are enough nodes to run the
    workload in the cluster. The node pool is scaled up to four nodes, as shown in
    the following figure:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 启用自动缩放后，GKE确保集群中有足够的节点来运行工作负载。节点池扩展到四个节点，如下图所示：
- en: '![Figure 5.14: Node list'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.14：节点列表'
- en: '](image/C12607_05_14.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_14.jpg)'
- en: 'Figure 5.14: Node list'
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.14：节点列表
- en: 'Check the number of running pods with the following command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查运行中的pod数量：
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Since there are 4 nodes in the cluster, 25 replicas of `nginx` could run in
    the cluster, as shown in the following figure:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于集群中有4个节点，因此可以在集群中运行25个`nginx`的副本，如下图所示：
- en: '![Figure 5.15: Deployment status'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.15：部署状态'
- en: '](image/C12607_05_15.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_15.jpg)'
- en: 'Figure 5.15: Deployment status'
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.15：部署状态
- en: 'Delete the deployment with the following command:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除部署：
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output should be as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 5.16: Deployment deletion'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.16：部署删除'
- en: '](image/C12607_05_16.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_16.jpg)'
- en: 'Figure 5.16: Deployment deletion'
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.16：部署删除
- en: 'Disable autoscaling for the node pool of the cluster by using the following
    command:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令禁用集群的节点池的自动缩放：
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Change the `zone` parameter if your cluster is running in another zone.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的集群在另一个区域运行，请更改`zone`参数。
- en: 'You should see the output shown in the following figure:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下图中显示的输出：
- en: '![Figure 5.17: Disabling autoscaling'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.17：禁用自动缩放'
- en: '](image/C12607_05_17.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_17.jpg)'
- en: 'Figure 5.17: Disabling autoscaling'
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.17：禁用自动缩放
- en: In this exercise, we saw the GKE cluster autoscaler in action. When the autoscaler
    is enabled, it increases the number of servers when the cluster is out of capacity
    for the current workload. Although it seems straightforward, it is a compelling
    feature of Kubernetes platforms. It removes the burden of manual operations to
    check your cluster utilization and take action. It is even more critical for serverless
    applications where user demand is highly variable.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们看到了GKE集群自动缩放器的运行情况。当自动缩放器启用时，它会在集群对当前工作负载容量不足时增加服务器数量。尽管看起来很简单，但这是Kubernetes平台的一个引人注目的特性。它消除了手动操作的负担，以检查集群利用率并采取行动。对于用户需求变化很大的无服务器应用程序来说，这一点甚至更为关键。
- en: Let's assume you have deployed a serverless function to your Kubernetes cluster
    with autoscaling enabled. The cluster autoscaler will automatically increase the
    number of nodes when your functions are called frequently and then delete the
    nodes when your functions are not invoked. Therefore it is essential to check
    the autoscaling capability of the Kubernetes platform for serverless applications.
    In the following section, migrating applications in production environments will
    be discussed, as it is another important cluster administration task.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经在Kubernetes集群中部署了一个启用了自动缩放的无服务器函数。当您的函数频繁调用时，集群自动缩放器将自动增加节点数量，然后在您的函数不被调用时删除节点。因此，检查Kubernetes平台对无服务器应用程序的自动缩放能力是至关重要的。在接下来的部分中，将讨论在生产环境中迁移应用程序，这是另一个重要的集群管理任务。
- en: Application Migration in Kubernetes Clusters
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes集群中的应用迁移
- en: 'Kubernetes distributes applications to servers and keeps them running reliably
    and robustly. Servers in the cluster could be VMs or bare-metal server instances
    with different technical specifications. Let''s assume you have connected only
    standard VMs to your Kubernetes cluster and they are running various types of
    applications. If one of your upcoming data analytics libraries requires **GPUs**
    to operate faster, you need to connect servers with **GPUs**. Similarly, if your
    database application requires **SSD** disks for faster I/O operations, you need
    to connect servers with **SSD** access. These kinds of application requirements
    result in having different node pools in your cluster. Also, you need to configure
    the Kubernetes workload to run on the particular nodes. In addition to marking
    some nodes reserved for special types of workloads, **taints** are used. Similarly,
    pods are marked with **tolerations** if they are running specific types of workloads.
    Kubernetes supports workload distribution to special nodes with **taints** and
    **tolerations** working in harmony:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes将应用程序分发到服务器并保持它们可靠和稳健地运行。集群中的服务器可以是具有不同技术规格的VM或裸金属服务器实例。假设您只连接了标准VM到您的Kubernetes集群，并且它们正在运行各种类型的应用程序。如果您即将使用的数据分析库需要GPU来更快地运行，您需要连接具有GPU的服务器。同样，如果您的数据库应用程序需要SSD磁盘来进行更快的I/O操作，您需要连接具有SSD访问权限的服务器。这些应用程序要求导致在集群中有不同的节点池。此外，您需要配置Kubernetes工作负载在特定节点上运行。除了标记一些节点保留给特殊类型的工作负载外，还使用了污点。同样，如果pod运行特定类型的工作负载，它们将被标记为容忍。Kubernetes支持使用污点和容忍度协同工作来将工作负载分发到特殊节点。
- en: '**Taints** are applied to nodes to indicate that the node should not have any
    pods that do not tolerate the taints.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 污点是应用于节点的，表示该节点不应该有任何不容忍污点的pod。
- en: '**Tolerations** are applied to pods to allow pods to be scheduled on nodes
    with taints.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容忍度被应用于pod，允许pod被调度到具有污点的节点上。
- en: 'For instance, if you only want to run database instances on your nodes with
    **SSD**, you need first to taint your nodes:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您只想在具有SSD的节点上运行数据库实例，您需要首先对节点进行污点处理：
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With this command, `disk-node-1` will only accept pods that have the following
    tolerations in their definition:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个命令，`disk-node-1`将只接受具有以下容忍度的pod：
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Taints and tolerations work in harmony to assign pods to specific nodes as a
    part of the Kubernetes scheduler. In addition, Kubernetes supports securely removing
    the servers from the cluster by using the `kubectl drain` command. It is particularly
    helpful if you want to take some nodes for maintenance or retirement. In the following
    exercise, an application running in the Kubernetes cluster will be migrated to
    a particular set of new nodes.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 污点和容忍度协同工作，作为Kubernetes调度器的一部分，将pod分配给特定的节点。此外，Kubernetes支持使用`kubectl drain`命令安全地从集群中移除服务器。如果您想对一些节点进行维护或退役，这将非常有帮助。在下面的练习中，运行在Kubernetes集群中的应用程序将迁移到一组特定的新节点。
- en: 'Exercise 15: Migrating Applications Running in a GKE Cluster'
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习15：迁移在GKE集群中运行的应用程序
- en: This exercise aims to teach us to perform migration activities in a production
    cluster. Let's assume that you are running a backend application in your Kubernetes
    cluster. With the recent changes, you have enhanced your application with better
    memory management and want to run on servers with higher memory optimization.
    Therefore, you will create a new node pool and migrate your application instances
    into it.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习旨在教我们在生产集群中执行迁移活动。假设您在Kubernetes集群中运行一个后端应用程序。随着最近的变化，您已经改进了应用程序的内存管理，并希望在具有更高内存优化的服务器上运行。因此，您将创建一个新的节点池，并将应用程序实例迁移到其中。
- en: 'To successfully complete the exercise, we need to ensure the following steps
    are executed:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功完成练习，我们需要确保执行以下步骤：
- en: 'Install the backend application to the cluster by running the following command
    in the cloud shell:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在云shell中运行以下命令将后端应用程序安装到集群中：
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This command creates a deployment named `backend` from an `nginx` image, as
    you can see in the following figure:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令从`nginx`镜像创建名为`backend`的部署，如下图所示：
- en: '![Figure 5.18: Deployment creation'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.18：部署创建'
- en: '](image/C12607_05_18.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_18.jpg)'
- en: 'Figure 5.18: Deployment creation'
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '![图5.18：部署创建'
- en: 'Scale the `backend` deployment to `10` replicas by running the following command
    in the cloud shell:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在云shell中运行以下命令，将`backend`部署的副本数扩展到`10`：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This command increases the number of replicas of the backend deployment, as
    shown in the following figure:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令增加了后端部署的副本数，如下图所示：
- en: '![Figure 5.19: Deployment scaling up'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.19：部署扩展'
- en: '](image/C12607_05_19.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_19.jpg)'
- en: 'Figure 5.19: Deployment scaling up'
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.19：部署扩展
- en: 'Check the number of running `pods` and their nodes with the following command:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查正在运行的`pods`数量及其节点：
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'All 10 replicas of the deployment are running successfully on the 4 nodes,
    as you can see in the following figure:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的所有10个副本都在4个节点上成功运行，如下图所示：
- en: '![Figure 5.20: Deployment status'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.20：部署状态'
- en: '](image/C12607_05_20.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_20.jpg)'
- en: 'Figure 5.20: Deployment status'
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.20：部署状态
- en: 'Create a node pool in GCP with a higher memory:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GCP中创建一个具有更高内存的节点池：
- en: '[PRE15]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Change the `zone` parameter if your cluster is running in another zone.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的集群在另一个区域运行，请更改`zone`参数。
- en: 'This command creates a new node pool named `high-memory-pool` in the serverless
    cluster with the machine type `n1-highmem-2` and two servers, as you can see in
    the following figure:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令在无服务器集群中创建了一个名为`high-memory-pool`的新节点池，机器类型为`n1-highmem-2`，有两个服务器，如下图所示：
- en: '![Figure 5.21: Node pool creation'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.21：节点池创建'
- en: '](image/C12607_05_21.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_21.jpg)'
- en: 'Figure 5.21: Node pool creation'
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.21：节点池创建
- en: This command can take a couple of minutes to create the required resources with
    the **Creating node pool high-memory-pool** prompt.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令可能需要几分钟来创建所需的资源，并显示**创建节点池高内存池**提示。
- en: 'Wait for a couple of minutes and check the nodes in the cluster:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待几分钟并检查集群中的节点：
- en: '[PRE16]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This command lists the nodes in the cluster, and we expect to see two extra
    `high-memory` nodes, as shown in the following figure:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令列出了集群中的节点，我们期望看到两个额外的`high-memory`节点，如下图所示：
- en: '![Figure 5.22: Cluster nodes'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.22：集群节点'
- en: '](image/C12607_05_22.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_22.jpg)'
- en: 'Figure 5.22: Cluster nodes'
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.22：集群节点
- en: 'Drain the old nodes so that Kubernetes will migrate applications to new nodes:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 排空旧节点，以便Kubernetes将应用程序迁移到新节点：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This command removes the workloads from all nodes with the label `cloud.google.com/gke-nodepool=pool-1`,
    as shown in the following figure:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令从所有带有标签`cloud.google.com/gke-nodepool=pool-1`的节点中删除工作负载，如下图所示：
- en: '![Figure 5.23: Node removal'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.23：节点移除'
- en: '](image/C12607_05_23.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_23.jpg)'
- en: 'Figure 5.23: Node removal'
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.23：节点移除
- en: 'Check the running pods and their nodes with the following command:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查正在运行的pods及其节点：
- en: '[PRE18]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'All 10 replicas of the deployment are running successfully on the new `high-memory`
    node, as shown in the following figure:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的所有10个副本都成功运行在新的`high-memory`节点上，如下图所示：
- en: '![Figure 5.24: Deployment status'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.24：部署状态'
- en: '](image/C12607_05_24.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_24.jpg)'
- en: 'Figure 5.24: Deployment status'
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.24：部署状态
- en: 'Delete the old node pool with the following command:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除旧的节点池：
- en: '[PRE19]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Change the `zone` parameter if your cluster is running in another zone.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 更改`zone`参数，如果您的集群在另一个区域运行。
- en: 'This command deletes the old node pool, which is not being used, as you can
    see in the following figure:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将删除未使用的旧节点池，如下图所示：
- en: '![Figure 5.25: Node pool deletion'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.25：节点池删除'
- en: '](image/C12607_05_25.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_25.jpg)'
- en: 'Figure 5.25: Node pool deletion'
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.25：节点池删除
- en: In this exercise, we have migrated the running application to new nodes with
    better technical specs. Using the Kubernetes primitives and GKE node pools, it
    is possible to migrate applications to a particular set of nodes without downtime.
    In the following activity, you will use autoscaling and Kubernetes taints to run
    serverless functions while minimizing the cost.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们已经将正在运行的应用迁移到了具有更好技术规格的新节点。使用Kubernetes原语和GKE节点池，可以在没有停机时间的情况下将应用迁移到特定的节点集。在接下来的活动中，您将使用自动缩放和Kubernetes污点来运行无服务器函数，同时最大限度地降低成本。
- en: 'Activity 5: Minimizing the Costs of Serverless Functions in a GKE Cluster'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动5：在GKE集群中最大限度地降低无服务器函数的成本
- en: The aim of this activity to take administrative tasks on production clusters
    to run serverless functions while minimizing the costs. Let's assume that your
    backend application is already running in your Kubernetes cluster. Now you want
    to install some serverless functions to connect to the backend. However, backend
    instances are running memory-optimized servers, which are costly for also running
    serverless functions. Therefore, you need to add *preemptible* servers, which
    are cheaper. Preemptible VMs are already available in GCP; however, they have
    low service quality and a maximum lifespan of 24 hours. Therefore, you should
    configure the node pool to be autoscaled and only to run serverless functions.
    Otherwise, your backend instances could also be scheduled on preemptible VMs and
    degrade the overall performance.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的目的是在生产集群上执行管理任务，以运行无服务器函数，同时最大限度地降低成本。假设您的后端应用已经在Kubernetes集群中运行。现在，您希望安装一些无服务器函数来连接后端。然而，后端实例正在运行内存优化的服务器，这对于运行无服务器函数也是昂贵的。因此，您需要添加*可抢占*服务器，这些服务器更便宜。可抢占VM已经在GCP中可用；然而，它们具有较低的服务质量和最长寿命为24小时。因此，您应该配置节点池为自动缩放，并且只运行无服务器函数。否则，您的后端实例也可能被调度到可抢占VM上，并降低整体性能。
- en: 'At the end of the activity, you will have functions connecting to the backend
    instances, as shown in the following figure:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 活动结束时，您将拥有连接到后端实例的函数，如下图所示：
- en: '![Figure 5.26: Backend checker functions'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.26：后端检查器功能'
- en: '](image/C12607_05_26.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_26.jpg)'
- en: 'Figure 5.26: Backend checker functions'
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.26：后端检查器功能
- en: 'Backend instances will run on high-memory nodes and function instances will
    run on preemptible servers, as shown in the following figure:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 后端实例将在高内存节点上运行，功能实例将在可抢占服务器上运行，如下图所示：
- en: '![Figure 5.27: Kubernetes pods and the corresponding nodes'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.27：Kubernetes pods和相应的节点'
- en: '](image/C12607_05_27.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/C12607_05_27.jpg)'
- en: 'Figure 5.27: Kubernetes pods and the corresponding nodes'
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5.27：Kubernetes pods和相应的节点
- en: Note
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: In order to complete the activity, you should use the cluster from *Exercise
    15* with backend deployments running.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成活动，您应该使用来自*练习15*的集群，其中运行着后端部署。
- en: 'Execute the following steps to complete the activity:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成活动：
- en: Create a new node pool with preemptible servers.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个具有可抢占服务器的新节点池。
- en: Taint the preemptible servers to run only serverless functions.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给可抢占服务器打上标记，只运行无服务器函数。
- en: Create a Kubernetes service to reach backend pods.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Kubernetes服务以访问后端pod。
- en: Create a CronJob to connect to the backend service every minute. The CronJob
    definition should have tolerations to run on preemptible servers.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个CronJob，每分钟连接到后端服务。CronJob定义应该具有容忍性，可以在可抢占服务器上运行。
- en: Check the node assignments of the CronJob functions.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查CronJob函数的节点分配。
- en: Check the logs of the CronJob function instances.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查CronJob函数实例的日志。
- en: Clean the backend deployment and the serverless functions.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理后端部署和无服务器函数。
- en: Remove the Kubernetes cluster if you do not need it anymore.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果不再需要Kubernetes集群，请将其删除。
- en: Note
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to the activity can be found on page 412.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 活动的解决方案可以在第412页找到。
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we first described the four key considerations to analyze
    the requirements for the Kubernetes cluster setup. Then we studied the three groups
    of Kubernetes platforms: managed, turnkey, and custom. Each Kubernetes platform
    has been explained, along with their responsibility levels on infrastructure,
    Kubernetes, and applications. Following that, we created a production-ready Kubernetes
    cluster on GKE. Since Kubernetes is designed to run scalable applications, we
    studied how to deal with increasing or decreasing workload by autoscaling. Furthermore,
    we also looked at application migration without downtime in production clusters
    to illustrate how to move your applications to the servers with higher memory.
    Finally, we performed autoscaling and migration activities with a serverless function
    running in a production cluster to minimize the costs. Kubernetes and serverless
    applications work together to create reliable, robust, and scalable future-proof
    environments. Therefore, it is essential to know how to install and operate Kubernetes
    clusters for production.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先描述了分析Kubernetes集群设置要求的四个关键考虑因素。然后我们研究了三组Kubernetes平台：托管、即插即用和定制。每个Kubernetes平台都有解释，以及它们在基础设施、Kubernetes和应用程序上的责任水平。在那之后，我们在GKE上创建了一个可投入生产的Kubernetes集群。由于Kubernetes旨在运行可扩展的应用程序，我们研究了如何通过自动缩放来处理工作负载的增加或减少。此外，我们还研究了在生产集群中无需停机的应用程序迁移，以说明如何将应用程序移动到具有更高内存的服务器。最后，我们在生产集群中运行无服务器函数来执行自动缩放和迁移活动，以最大程度地降低成本。Kubernetes和无服务器应用程序共同工作，创建可靠、强大和可扩展的未来环境。因此，了解如何安装和操作生产环境的Kubernetes集群至关重要。
- en: In the next chapter, we will be studying the upcoming serverless features in
    Kubernetes. We will also study virtual kubelets in detail and deploy stateless
    containers on GKE.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究Kubernetes中即将推出的无服务器功能。我们还将详细研究虚拟kubelet，并在GKE上部署无状态容器。
