- en: Configuring Applications to Use Kubernetes Features
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置应用程序以使用Kubernetes功能
- en: The last chapter demonstrated how to work with a containerized Windows application
    in Kubernetes—now, we are going to extend our voting application to use more advanced
    features which make the orchestration even more robust and automated. Over the
    years, Kubernetes has been extended with a growing number of features, ranging
    from fine-grained **Role-Based Access Control** (**RBAC**) or Secrets management
    to autoscaling using **Horizontal Pod Autoscaler** (**HPA**), the holy grail of
    container orchestration. Of course, we are not able to cover all of them in the
    scope of this book, but we are going to include the most useful features that
    help running containerized Windows applications. Also, please bear in mind that
    some of the features are not available when you are running an on-premises Kubernetes
    cluster, for example, cloud-specific StorageClass provisioners—all of the examples
    we are going to present are assuming that you are running an AKS Engine Kubernetes
    cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章演示了如何在Kubernetes中处理容器化的Windows应用程序-现在，我们将扩展我们的投票应用程序，以使用更先进的功能，使编排更加健壮和自动化。多年来，Kubernetes已经扩展了越来越多的功能，从细粒度的基于角色的访问控制（RBAC）或Secrets管理到使用水平Pod自动缩放器（HPA）进行自动缩放，这是容器编排的圣杯。当然，我们无法在本书的范围内涵盖所有这些功能，但我们将包括一些最有用的功能，以帮助运行容器化的Windows应用程序。另外，请记住，当您运行本地Kubernetes集群时，一些功能是不可用的，例如特定于云的StorageClass提供程序-我们将要呈现的所有示例都假定您正在运行AKS
    Engine Kubernetes集群。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Using namespaces to isolate applications
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命名空间隔离应用程序
- en: Health monitoring using liveness and readiness probes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用活动探针和就绪探针进行健康监控
- en: Specifying resource limits and configuring autoscaling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定资源限制和配置自动缩放
- en: Managing application configuration using ConfigMaps and Secrets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ConfigMaps和Secrets管理应用程序配置
- en: Managing persistent data storage on Windows nodes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Windows节点上管理持久数据存储
- en: Configuring rolling updates for Deployment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为部署配置滚动更新
- en: RBAC
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RBAC
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将需要以下内容：
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Windows 10 Pro、企业版或教育版（1903版或更高版本，64位）
- en: Microsoft Visual Studio 2019 Community (or any other edition) if you want to
    edit the source code for the application and debug it—Visual Studio Code has limited
    support for the classic .NET Framework
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Visual Studio 2019 Community（或任何其他版本），如果您想编辑应用程序的源代码并对其进行调试-Visual
    Studio Code对经典.NET Framework的支持有限
- en: An Azure account
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Azure帐户
- en: Windows/Linux Kubernetes cluster deployed using AKS Engine, ready to deploy
    the voting application from the previous chapter
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AKS Engine部署的Windows/Linux Kubernetes集群，准备部署上一章的投票应用程序
- en: To follow along, you will need your own Azure account to create Azure resources
    for the Kubernetes cluster. If you haven't already created the account for the
    previous chapters, you can read more about how to obtain a limited free account
    for personal use at [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟着做，您需要自己的Azure帐户来为Kubernetes集群创建Azure资源。如果您之前还没有为前几章创建帐户，您可以阅读有关如何获取个人使用的有限免费帐户的更多信息[https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/)。
- en: Deploying a Kubernetes cluster using AKS Engine has been covered in [Chapter
    8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying a Hybrid Azure Kubernetes
    Service Engine Cluster*. Voting application Deployment to Kubernetes has been
    covered in [Chapter 10](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml), *Deploying
    Microsoft SQL Server 2019 and ASP.NET MVC Application*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AKS Engine部署Kubernetes集群已在[第8章](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml)中进行了介绍，*部署混合Azure
    Kubernetes服务引擎集群*。将投票应用程序部署到Kubernetes已在[第10章](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml)中进行了介绍，*部署Microsoft
    SQL Server 2019和ASP.NET MVC应用程序*。
- en: You can download the latest code samples for this chapter from the official
    GitHub repository, at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从官方GitHub存储库下载本章的最新代码示例，网址为[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11)。
- en: Using namespaces to isolate applications
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用命名空间隔离应用程序
- en: 'In the previous chapter, we already used a namespace (named `dev`) to logically
    group components of our application into a virtual cluster within an existing
    physical Kubernetes cluster. The general principle of namespaces is providing
    resource quotas and a scope for object names—names inside a given namespace must
    be unique, but they do not have to be unique across different namespaces. By default,
    Kubernetes provides the following namespaces out of the box:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们已经使用了一个命名空间（名为`dev`）来将应用程序的组件逻辑地分组到现有物理Kubernetes集群中的虚拟集群中。命名空间的一般原则是提供资源配额和对象名称的范围——给定命名空间内的名称必须是唯一的，但它们不必在不同的命名空间中是唯一的。默认情况下，Kubernetes提供以下开箱即用的命名空间：
- en: '`kube-system`: A namespace for objects created by the Kubernetes system, such
    as `kube-apiserver` or `kube-proxy` Pods.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-system`：由Kubernetes系统创建的对象的命名空间，例如`kube-apiserver`或`kube-proxy` Pods。'
- en: '`kube-public`: A namespace that can be read by all users, also not authenticated—it
    will be created in clusters that are bootstrapped by kubeadm and it is generally
    intended for system use.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-public`：一个可以被所有用户阅读的命名空间，也不需要经过身份验证——它将在由kubeadm引导的集群中创建，并且通常用于系统使用。'
- en: '`default`: A namespace for objects with no other namespace.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default`：没有其他命名空间的对象的命名空间。'
- en: 'Depending on your needs and the size of your team, you may be more comfortable
    with using just object labels (small teams) or separating the objects at namespace
    level (large team):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的需求和团队的规模，您可能更愿意仅使用对象标签（小团队）或在命名空间级别分隔对象（大团队）：
- en: For small teams, where a single developer is capable of understanding the whole
    system (around 10 microservices) and where the whole development environment can
    be hosted using local clusters, such as minikube or kubeadm deployment running
    on VMs, it is possible to stick just to the default namespace for your production
    services. Alternatively, you may use a dedicated namespace for production workloads
    and a separate one for the development/staging environment.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于小团队，其中单个开发人员能够理解整个系统（大约10个微服务），并且整个开发环境可以使用本地集群（如在VM上运行的minikube或kubeadm部署）进行托管，可以仅使用默认命名空间来部署生产服务。或者，您可以为生产工作负载使用专用命名空间，并为开发/分段环境使用单独的命名空间。
- en: For rapidly growing medium-sized teams, where a single developer is not working
    in the scope of the whole system, it may be easier to provide dedicated namespaces
    for each sub-team, especially if it is not possible to create the whole development
    environment on a local Kubernetes cluster.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于快速增长的中等规模团队，在这种团队中，单个开发人员不在整个系统范围内工作，为每个子团队提供专用的命名空间可能更容易，特别是如果在本地Kubernetes集群上无法创建整个开发环境。
- en: For large teams, where sub-teams operate almost independently, it may be a good
    idea to have separate production and development namespaces for each team. You
    may also think about using resource quotas per each namespace and using RBAC.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大型团队，子团队几乎独立运作，为每个团队单独创建生产和开发命名空间可能是一个好主意。您还可以考虑为每个命名空间使用资源配额和使用RBAC。
- en: For enterprise organizations, where individual teams may not even be aware of
    other teams, it may be easier to create separate clusters instead of dividing
    a single cluster using namespaces. This makes resource and billing management
    easier and provides better boundaries between deployments in case of issues.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于企业组织来说，个别团队甚至可能不知道其他团队的存在，创建单独的集群可能比使用命名空间来划分单个集群更容易。这样可以更轻松地管理资源和计费，并在出现问题时提供更好的部署边界。
- en: When creating a Service object, namespaces influence what is the **Fully-Qualified
    Domain Name** (**FQDN**) for the DNS entry of the Service. The FQDNs have a form
    of `<service-name>.<namespace-name>.svc.cluster.local`—this means that if you
    use `<service-name>` when calling a Service from a Pod, the call will be scoped
    to the namespace where this Pod is running. Note that cross-namespace calls to
    Services are possible but then you need to specify the FQDN.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建服务对象时，命名空间会影响服务的**完全限定域名**（**FQDN**）。FQDN的形式为`<service-name>.<namespace-name>.svc.cluster.local`—这意味着如果您在Pod中调用服务时使用`<service-name>`，调用将被限定在此Pod所在的命名空间。请注意，跨命名空间调用服务是可能的，但您需要指定FQDN。
- en: Let's demonstrate how you can create a namespace for your objects.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们演示如何为您的对象创建一个命名空间。
- en: Creating namespaces
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建命名空间
- en: 'To create a namespace named `prod`, you can use the following imperative command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个名为`prod`的命名空间，您可以使用以下命令：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As in the case of other objects, it is generally recommended to use declarative
    object configuration management and apply manifest files to the Kubernetes cluster.
    The following `namespace-prod.yaml` manifest file will create the `prod` namespace,
    additionally specifying the `ResourceQuota` object, which determines the total
    CPU and memory quota for this namespace:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他对象一样，通常建议使用声明性对象配置管理，并将清单文件应用到Kubernetes集群。以下的`namespace-prod.yaml`清单文件将创建`prod`命名空间，另外指定了`ResourceQuota`对象，用于确定此命名空间的总CPU和内存配额：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To apply the manifest file, execute the following command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用清单文件，请执行以下命令：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, you can use the `kubectl describe` command to check how many resources
    are used in our namespace:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用`kubectl describe`命令来检查我们的命名空间中使用了多少资源。
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Resource quotas in Kubernetes are highly customizable and can be applied to
    different resources and scoped using sophisticated selectors. You can read more
    about this in the official documentation at [https://kubernetes.io/docs/concepts/policy/resource-quotas/](https://kubernetes.io/docs/concepts/policy/resource-quotas/).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的资源配额是高度可定制的，可以应用于不同的资源，并使用复杂的选择器进行范围限定。您可以在官方文档中了解更多信息：[https://kubernetes.io/docs/concepts/policy/resource-quotas/](https://kubernetes.io/docs/concepts/policy/resource-quotas/)。
- en: Now, when you know how to manage namespaces, let's see how you can use them
    efficiently with `kubectl` commands.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经知道如何管理命名空间，让我们看看如何使用`kubectl`命令有效地使用它们。
- en: kubectl commands and namespaces
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kubectl 命令和命名空间
- en: '`kubectl` commands, which operate on namespace-scoped objects by convention,
    use the `--namespace` or `-n` flag to specify the namespace that should be used
    for the command. If you need to query for objects in all namespaces, you can use
    the `--all-namespaces` flag instead. For example, to list all Pods in the `prod`
    namespace, use the following command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`命令按照惯例操作命名空间范围的对象，使用`--namespace`或`-n`标志来指定应用于命令的命名空间。如果您需要查询所有命名空间中的对象，可以使用`--all-namespaces`标志。例如，要列出`prod`命名空间中的所有Pods，请使用以下命令：'
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the previous chapters, you have used this construct a lot. However, it is
    good to know that if no namespace is provided for the command, it will use the
    namespace set as default in the current kubeconfig context. In other words, it
    does not have to be the default namespace—it all depends on your context settings.
    We have covered contexts in depth in [Chapter 6](791e78c0-f625-4232-9907-36e25ec2767d.xhtml), *Interacting
    with Kubernetes Clusters*—for completeness, we will show how to change the namespace
    used in the current context. To set the `prod` namespace permanently in your current
    context, use the following command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，您经常使用了这个构造。但是，值得知道的是，如果命令没有提供命名空间，它将使用当前kubeconfig上下文中设置为默认的命名空间。换句话说，它不一定是默认的命名空间
    - 这完全取决于您的上下文设置。我们在[第6章](791e78c0-f625-4232-9907-36e25ec2767d.xhtml)中深入讨论了上下文，*与Kubernetes集群交互*
    - 为了完整起见，我们将展示如何更改当前上下文中使用的命名空间。要在当前上下文中永久设置`prod`命名空间，请使用以下命令：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, any command that supports specifying namespace will use the `prod` namespace
    by default.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，任何支持指定命名空间的命令将默认使用`prod`命名空间。
- en: Deleting namespaces
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除命名空间
- en: 'Similar to other objects, deleting namespaces is recommended to be done imperatively.
    To delete the `prod` namespace, execute the following command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他对象类似，建议以命令方式删除命名空间。要删除`prod`命名空间，请执行以下命令：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Please note that this command deletes all objects within this namespace, which
    means it is a highly destructive command and should be used with caution!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此命令将删除此命名空间中的所有对象，这意味着这是一个极具破坏性的命令，应谨慎使用！
- en: In the next section, we will see how you can use probes to configure containers
    monitoring for liveness and readiness.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何使用探针配置容器监视活动性和就绪性。
- en: Health monitoring using liveness and readiness probes
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用活动性和就绪性探针进行健康监控
- en: 'In Kubernetes, probes are used by kubelet to determine the state of a Pod—you
    can use them to customize how you check whether a Pod is ready to serve your traffic
    or a container needs to be restarted. There are three types of probes that you
    can configure for each container running in a Pod:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，探针由kubelet用于确定Pod的状态 - 您可以使用它们来自定义如何检查Pod是否准备好为您的流量提供服务，或者容器是否需要重新启动。您可以为在Pod中运行的每个容器配置三种类型的探针：
- en: '**Readiness probe**: This is used to determine whether a given container is
    ready to accept traffic. A Pod is considered ready only if all of its containers
    are ready. Pods that are not ready will be removed from Service Endpoints until
    they become ready again.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**就绪探针**：用于确定给定容器是否准备好接受流量。只有当Pod的所有容器都准备就绪时，Pod才被视为准备就绪。不准备就绪的Pod将从服务端点中删除，直到它们再次准备就绪为止。'
- en: '**Liveness** **probe**: This is used to detect whether a container needs to
    be restarted. This can help in situations when a container has been stuck in a
    deadlock or other issues when the container process is alive but unable to operate properly.
    Restarting the container may increase the availability of Pods in that case.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活动性探针**：用于检测容器是否需要重新启动。这可以帮助解决容器陷入死锁或其他问题的情况，当容器进程处于活动状态但无法正常运行时。重新启动容器可能会增加该情况下Pod的可用性。'
- en: '**Startup** **probe**: This is an additional probe used for determining whether
    a container has been fully started—readiness and liveness probes are disabled
    until this probe returns successfully. This is especially useful for containers
    that have a long startup time due to some initialization. In this way, you can
    avoid premature kills by the liveness probe.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启动探针**：这是用于确定容器是否已完全启动的附加探针-在此探针成功返回之前，就绪和存活探针都是禁用的。这对于由于某些初始化而具有长启动时间的容器特别有用。通过这种方式，您可以避免存活探针的过早终止。'
- en: By default, there are no probes configured on Pod containers. However, Kubernetes
    will serve traffic only if the Pod containers have been started (in the Docker
    sense) and restart the containers if they crash (depending on your restart policy
    of course).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Pod容器上没有配置探针。但是，只有在Pod容器已启动（在Docker意义上）并且重新启动容器（当然取决于您的重新启动策略）后，Kubernetes才会提供流量。
- en: 'All types of probes can be configured using three types of handler actions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所有类型的探针都可以使用三种类型的处理程序操作进行配置：
- en: Running a command (`exec`)—if a given command running in the container returns
    non-zero exit code, the probe is in a failed state.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行命令（`exec`）-如果容器中运行的给定命令返回非零退出代码，则探针处于失败状态。
- en: Executing an HTTP GET request (`httpGet`)—the probe is in a successful state
    only if the container responds to the HTTP GET request with an HTTP code greater
    than or equal to 200 and less than 400.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行HTTP GET请求（`httpGet`）-只有当容器对HTTP GET请求做出大于或等于200且小于400的HTTP代码响应时，探针才处于成功状态。
- en: Opening a TCP socket to the container on a specified port (`tcpSocket`)—the
    probe is in a successful state if the connection can be established.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在指定端口向容器打开TCP套接字（`tcpSocket`）-如果可以建立连接，则探针处于成功状态。
- en: You should additionally consider using the termination grace period for your
    Pods to properly manage a containerized application life cycle and make your application
    gracefully exit when a SIGTERM signal is received ([https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace)).
    Please note that, for Windows Pods, the termination grace period is not supported
    as of Kubernetes 1.17.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应考虑使用终止优雅期限来正确管理Pod的容器化应用程序生命周期，并在接收到SIGTERM信号时使应用程序优雅地退出（[https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace)）。请注意，对于Windows
    Pod，截止优雅期限在Kubernetes 1.17版本中不受支持。
- en: There are a couple of caveats and best practices when working with probes that
    are true for any large distributed system with many dependent components. We will
    go through the details when explaining each type of probes—the voting application
    source code reflecting the examples can be found in the official GitHub repository,
    at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src).
    First, let's take a look at the most popular probe, the readiness probe.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理具有许多依赖组件的大型分布式系统时，使用探针时存在一些注意事项和最佳实践。我们将在解释每种类型的探针时详细介绍细节-反映示例的投票应用程序源代码可以在官方GitHub存储库中找到，网址为[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src)。首先，让我们看一下最受欢迎的探针，即就绪探针。
- en: Readiness probes
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 就绪探针
- en: Readiness probes are used in Kubernetes to determine whether a Pod container
    is ready to accept traffic incoming from a Kubernetes Service—Pods that are not
    ready (a Pod is ready only if all of its containers are considered ready) will
    be removed from the Service Endpoints list until they become ready again. In other
    words, it is a signal for notifying that a given Pod can be used for requests
    incoming to the Service.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中使用就绪探针来确定 Pod 容器是否准备好接受来自 Kubernetes 服务的流量——不准备好的 Pod（只有所有容器都被认为准备好的
    Pod 才算准备好）将从服务端点列表中删除，直到它们再次准备好。换句话说，这是一个通知给定 Pod 可以用于服务请求的信号。
- en: 'There are a couple of established best practices for readiness probes that
    you should consider:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 就就绪探针而言，有一些已经建立的最佳实践是您应该考虑的：
- en: Use this probe whenever your containers may not be ready to properly serve traffic
    as soon as the container is started.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要您的容器可能无法在容器启动后立即准备好为流量提供适当的服务，就使用此探针。
- en: Ensure that you check the cache warm-up or database migration status during
    readiness probe evaluation. You may also consider starting the actual process
    of a warm-up if it hasn't been started yet, but use this approach with caution—a readiness
    probe will be executed constantly throughout the life cycle of a Pod, which means
    you shouldn't do any costly operations for every request. Alternatively, you may
    want to use a startup probe for this purpose, newly-introduced in Kubernetes 1.16.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在就绪探针评估期间检查缓存预热或数据库迁移状态。您还可以考虑在尚未启动的情况下启动预热的实际过程，但要谨慎使用——就绪探针将在 Pod 的生命周期中不断执行，这意味着您不应该为每个请求执行任何昂贵的操作。或者，您可能希望为此目的使用在
    Kubernetes 1.16 中新引入的启动探针。
- en: For microservice applications that expose HTTP endpoints, consider always configuring
    the `httpGet` readiness probe. This will ensure that all cases are covered when
    a container is successfully running but the HTTP server is not fully initialized.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于暴露 HTTP 端点的微服务应用程序，考虑始终配置 `httpGet` 就绪探针。这将确保在容器成功运行但 HTTP 服务器尚未完全初始化时，所有情况都得到覆盖。
- en: It is a good idea to use a separate, dedicated HTTP endpoint for readiness checks
    in your application, for example, a common convention is using `/health`.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序中为就绪检查使用一个单独的专用 HTTP 端点是一个好主意，例如，一个常见的约定是使用 `/health`。
- en: If you are checking the state of dependencies (external database and logging
    services) in this type of probe, be careful with shared dependencies, such as
    SQL Server in the voting application. In this case, you should consider using
    a probe timeout, which is greater than the maximum allowed timeout for the external
    dependency— otherwise, you may get cascading failures and lower availability instead
    of occasionally increased latency.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您在此类探针中检查依赖项（外部数据库和日志记录服务）的状态，请注意共享依赖项，例如投票应用程序中的 SQL Server。在这种情况下，您应该考虑使用探针超时，该超时大于外部依赖项的最大允许超时时间，否则可能会出现级联故障，可用性降低，而不是偶尔增加的延迟。
- en: 'For web applications hosted using **IIS** (short for **Internet Information
    Services**), a readiness probe makes a lot of sense—the IIS App Pool needs to
    be fully started and database migrations may not be applied yet. As an example,
    we will configure a simple readiness probe for our voting application, which will
    look as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用 IIS（Internet Information Services 的缩写）托管的 Web 应用程序，就绪探针非常有意义——IIS 应用程序池需要完全启动，数据库迁移可能尚未应用。例如，我们将为我们的投票应用程序配置一个简单的就绪探针，如下所示：
- en: The ASP.NET MVC application will implement a dedicated controller serving `/health`
    requests.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ASP.NET MVC 应用程序将实现一个专用控制器，用于提供 `/health` 请求。
- en: Pending database migrations will be checked. Note that this will indirectly
    verify the database connection status, which might be not desirable in some cases.
    Therefore, we will use a probe timeout larger than 30 seconds (the default SQL
    command timeout).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将检查未决的数据库迁移。请注意，这将间接验证数据库连接状态，这在某些情况下可能是不可取的。因此，我们将使用大于30秒的探针超时（默认的SQL命令超时）。
- en: Controller actions will return a simple JSON. The HTTP status will be 503 in
    case of a failed check and 200 in case of success.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器操作将返回一个简单的JSON。在检查失败的情况下，HTTP状态将为503，在成功的情况下为200。
- en: 'To add a readiness probe for the voting application, follow these steps:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要为投票应用程序添加就绪探针，请按照以下步骤进行：
- en: 'The implementation of a health check controller action can be found in the `HealthController`
    class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs))
    and looks as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 健康检查控制器操作的实现可以在`HealthController`类中找到（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs)），如下所示：
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Additionally, you need to remember to modify routing configuration for your
    application in the `RouteConfig` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs)),
    before the default route map:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另外，您需要记住在`RouteConfig`类（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/App_Start/RouteConfig.cs)）中修改应用程序的路由配置，然后是默认路由映射。
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As in the previous chapter, build a Docker image of the application, tag it
    as 1.1.0 version, and push it to Docker Hub. In our demonstration case, we will
    be using the `packtpubkubernetesonwindows/voting-application:1.1.0` image.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与上一章一样，构建应用程序的Docker镜像，将其标记为1.1.0版本，并将其推送到Docker Hub。在我们的演示案例中，我们将使用`packtpubkubernetesonwindows/voting-application:1.1.0`镜像。
- en: 'Modify the Deployment manifest file, `voting-application.yaml`, to include
    the following readiness probe configuration for the `frontend` container:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改部署清单文件`voting-application.yaml`，以包括`frontend`容器的以下就绪探针配置：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The probe is configured to call the `/health` endpoint, which will execute
    the controller action that we have previously implemented. The important parts
    in the probe configuration are the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 探针被配置为调用`/health`端点，这将执行我们之前实现的控制器操作。探针配置中的重要部分如下：
- en: '`initialDelaySeconds` is set to `30` seconds to allow IIS for full initialization.
    It turns out that too early calls to applications running on IIS under `ServiceMonitor.exe` supervision
    may result in premature exits of the container (maybe a bug in the `ServiceMonitor.exe` implementation).'
  id: totrans-86
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`initialDelaySeconds`设置为`30`秒，以允许IIS完全初始化。原来，对在`ServiceMonitor.exe`监督下运行的应用程序进行过早调用可能会导致容器过早退出（也许是`ServiceMonitor.exe`实现中的一个错误）。
- en: '`timeoutSeconds` is set to `40` seconds to exceed the SQL Server database timeout,
    which is set by default to `30` seconds.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds`设置为`40`秒，以超过默认设置为`30`秒的SQL Server数据库超时。'
- en: Now, apply the manifest file using the `kubectl apply -f .\voting-application-readiness-probe.yaml`
    command.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`kubectl apply -f .\voting-application-readiness-probe.yaml`命令应用清单文件。
- en: Inspect the rollout process using the `kubectl get pods -n dev` and `kubectl
    describe` commands as usual. In the Pod events, you can verify whether the Pod
    had any readiness failures.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样，使用`kubectl get pods -n dev`和`kubectl describe`命令来检查部署过程。在Pod事件中，你可以验证Pod是否有任何就绪失败。
- en: In the web browser, when you navigate to the application, you should not experience
    any IIS App Pool startup delays —the web server will be warmed up by readiness
    checks.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Web浏览器中，当你导航到应用程序时，你不应该遇到任何IIS应用程序池启动延迟——Web服务器将通过就绪检查进行预热。
- en: Now, let's take a look at another probe that determines the liveness status
    of a Pod container.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看另一个确定Pod容器存活状态的探针。
- en: Liveness probes
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存活探针
- en: The second type of probe is the liveness probe, which can be configured similarly
    to the readiness probe in the manifest. Liveness probes are used to determine
    whether a Pod container needs to be restarted. This type of probe may be useful
    in recovering deadlocks or other types of issues in the container when the process
    has not exited but is not able to handle any operations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种探针是存活探针，它可以在清单中类似于就绪探针进行配置。存活探针用于确定是否需要重新启动Pod容器。当进程尚未退出但无法处理任何操作时，这种类型的探针可能对恢复死锁或其他类型的容器问题有用。
- en: 'Similar to readiness probes, there are a couple of guidelines on how and when
    you should use liveness probes:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 与就绪探针类似，关于何时以及如何使用存活探针，有一些指导方针。
- en: Liveness probes should be used with caution. The wrong configuration of this
    probe can result in cascading failures in your services and container restart
    loops. As a quick experiment, you can redeploy the voting application manifest
    where you replace the readiness probe with a liveness probe, with similar configuration
    but very short timeouts and delays—you will experience multiple random crashes
    and poor availability of the application!
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存活探针应该谨慎使用。错误的配置可能导致服务和容器重启循环中的级联故障。作为一个快速实验，你可以重新部署投票应用程序清单，其中用存活探针替换就绪探针，配置类似但超短的超时和延迟——你将遇到多次随机崩溃和应用程序的可用性不佳！
- en: Do not use liveness probes unless you have a good reason for this. A good reason
    may, for example, be a known issue with a deadlock in your application that has
    an as yet unknown root cause.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非你有充分的理由，否则不要使用活跃探针。一个充分的理由可能是你的应用程序中存在一个已知的死锁问题，但尚未找到根本原因。
- en: Execute simple and fast checks that determine the status of the process, not
    its dependencies. In other words, you do not want to check external dependencies'
    statuses in the liveness probe—this can lead to cascading failures due to an avalanche
    of container restarts and overloading a small subset of Service Pods.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行简单快速的检查来确定进程的状态，而不是它的依赖关系。换句话说，在存活探针中不要检查外部依赖的状态——这可能会导致由于大量容器重启而产生级联故障，并且会过载一小部分服务Pod。
- en: If your process running in the container is able to crash or exit whenever it
    encounters an unrecoverable error, you probably do not need a liveness probe at
    all.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的容器中运行的进程能够在遇到无法恢复的错误时崩溃或退出，那么你可能根本不需要存活探针。
- en: Use conservative settings for `initialDelaySeconds` to avoid any premature container
    restarts and falling into a restart loop.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用保守的`initialDelaySeconds`设置，以避免任何过早的容器重启并陷入重启循环。
- en: 'Web applications hosted by IIS can be a good candidate for using a liveness
    probe if you do not know exactly what is going under the hood of the `ServiceMonitor.exe`
    and `LogMonitor.exe` entry point processes. In theory, they should crash the container
    whenever there is a problem with IIS or IIS App Pool, but let''s assume we need
    to implement these checks ourselves. We will implement a liveness probe that will
    check whether IIS App Pool is running using the `exec` handler. To do that, follow
    these steps:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不确定`ServiceMonitor.exe`和`LogMonitor.exe`入口进程的内部情况，那么由IIS托管的Web应用程序可能是使用活动探针的一个很好的选择。理论上，它们应该在IIS或IIS应用程序池出现问题时使容器崩溃，但让我们假设我们需要自己实现这些检查。我们将实现一个活动探针，它将使用`exec`处理程序检查IIS应用程序池是否正在运行。为此，请按照以下步骤进行操作：
- en: 'Modify the `voting-application.yaml` manifest file with `Deployment` for our
    application. Add the following liveness probe configuration for the `frontend`
    container:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Deployment`为我们的应用程序修改`voting-application.yaml`清单文件。为`frontend`容器添加以下活动探针配置：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The probe is configured so that it executes a PowerShell command, `if ((Get-WebAppPoolState
    DefaultAppPool).Value -ne "Started") { throw "Default IIS App Pool is NOT started"
    }`, which checks whether the default IIS App Pool is in a `Started` state. If
    it is not, an exception will be thrown and the PowerShell process will exit with
    non-zero exit code causing the probe to go into a failed state.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 探针被配置为执行PowerShell命令，`if ((Get-WebAppPoolState DefaultAppPool).Value -ne "Started")
    { throw "Default IIS App Pool is NOT started" }`，该命令检查默认的IIS应用程序池是否处于“Started”状态。如果不是，则将抛出异常，并且PowerShell进程将以非零退出代码退出，导致探针进入失败状态。
- en: Now, apply the manifest file using the `kubectl apply -f .\voting-application-readiness-probe.yaml` command.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`kubectl apply -f .\voting-application-readiness-probe.yaml`命令应用清单文件。
- en: Again, inspect the rollout process using the `kubectl get pods -n dev` and `kubectl
    describe` commands. In the Pod events, you may verify whether the Pods had any
    liveness failures.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用`kubectl get pods -n dev`和`kubectl describe`命令检查滚动升级过程。在Pod事件中，您可以验证Pod是否有任何活动失败。
- en: When using the `exec` handler, you should carefully analyze how the chosen command
    behaves. The `exec` handler has been reported to cause zombie process bloat in
    some cases.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`exec`处理程序时，您应该仔细分析所选命令的行为。据报道，`exec`处理程序在某些情况下会导致僵尸进程膨胀。
- en: Finally, let's take a quick look at the last type of probe, the startup probe.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们快速看一下最后一种类型的探针，即启动探针。
- en: Startup probes
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动探针
- en: Startup probes have been recently introduced in Kubernetes 1.16 to support cases
    when a container may require more time for initialization than `initialDelaySeconds
    + failureThreshold * periodSeconds` set in the readiness probe. In general, you
    should use the same handler configuration for startup probes that you would for
    readiness probes but use larger delays. If a container is not ready within `initialDelaySeconds
    + failureThreshold * periodSeconds` for a readiness probe, then the container
    will be killed and subject to the Pod's restart policy.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在Kubernetes 1.16中引入了启动探针，以支持容器可能需要比设置在就绪探针中的`initialDelaySeconds + failureThreshold
    * periodSeconds`更多时间进行初始化的情况。通常情况下，您应该为启动探针使用与就绪探针相同的处理程序配置，但使用更长的延迟。如果容器在`initialDelaySeconds
    + failureThreshold * periodSeconds`内未准备好进行就绪探针，则容器将被终止，并受到Pod的重启策略的影响。
- en: 'Our voting application does not need a dedicated startup probe, but an example
    definition in the Deployment manifest file could look like this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的投票应用程序不需要专门的启动探针，但在部署清单文件中的示例定义可能如下所示：
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the next section, we will focus on assigning resource limits for Pods and
    how to configure autoscaling for our voting application.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将专注于为Pod分配资源限制以及如何为我们的投票应用程序配置自动缩放。
- en: Specifying resource limits and configuring autoscaling
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定资源限制和配置自动缩放
- en: 'As a container orchestrator, Kubernetes comes out of the box with two important
    features that help to manage your cluster resources:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 作为容器编排器，Kubernetes默认提供了两个重要功能，帮助管理您的集群资源：
- en: Resource requests and limits for Pod containers
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod容器的资源请求和限制
- en: HPA, which allows automatic scaling of your Deployments or StatefulSets based
    on CPU resource usage (stable support), memory resource usage (beta support),
    or custom metrics (also beta support)
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPA，它允许根据CPU资源使用情况（稳定支持）、内存资源使用情况（beta支持）或自定义指标（也是beta支持）自动扩展您的部署或有状态集
- en: Let's first take a look at specifying resource requests and limits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看一下指定资源请求和限制。
- en: Resource requests and limits
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源请求和限制
- en: When you create a Pod, it is possible to specify how much compute resources
    its containers require—we already performed a short exercise on assigning resources
    for the voting application in the last chapter. In general, compute resources
    are CPU and RAM memory—Kubernetes is also able to manage other resources, such
    as HugePages on Linux or ephemeral storage on the local node.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当您创建一个Pod时，可以指定其容器需要多少计算资源 - 我们已经在上一章中对投票应用程序分配资源进行了简短的练习。一般来说，计算资源是CPU和RAM内存
    - Kubernetes还能够管理其他资源，例如Linux上的HugePages或本地节点上的临时存储。
- en: The Kubernetes resource model provides an additional distinction between two
    classes of resources: compressible and incompressible. In short, a compressible
    resource can be easily throttled, without severe consequences. A perfect example
    of such a resource is the CPU—if you need to throttle CPU usage for a given container,
    the container will operate normally, just slower. On the other end, we have incompressible
    resources that cannot be throttled without bad consequences—memory allocation
    is an example of such a resource.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes资源模型提供了两类资源之间的额外区分：可压缩和不可压缩。简而言之，可压缩资源可以轻松进行限流，而不会造成严重后果。这样的资源的一个完美例子是CPU
    - 如果您需要限制给定容器的CPU使用率，容器将正常运行，只是速度较慢。另一方面，我们有不可压缩资源，如果不加限制会造成严重后果 - 内存分配就是这样一个资源的例子。
- en: There are two great design proposal documents that describe the Kubernetes resource
    model ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md))
    and resource quality of service ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md)).
    We highly recommend reading them to fully understand the vision of Kubernetes
    resource management and which features are already implemented.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有两份很棒的设计提案文件描述了Kubernetes资源模型（[https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md)）和资源服务质量（[https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md)）。我们强烈建议阅读它们，以充分了解Kubernetes资源管理的愿景以及已经实现的功能。
- en: 'You can specify two values for a Pod container regarding resource allocation:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为Pod容器指定两个值，关于资源分配：
- en: '`requests`: This specifies the guaranteed amount of a given resource provided
    by the system. You can also think of this the other way round—this is the amount
    of a given resource that the Pod container requires from the system to function
    properly. Pod scheduling is dependent on the `requests` value (not `limits`).'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`：这指定了系统提供的特定资源的保证数量。你也可以反过来想，这是Pod容器从系统中需要的特定资源的数量，以便正常运行。Pod的调度取决于`requests`值（而不是`limits`）。'
- en: '`limits`: This specifies the maximum amount of a given resource provided by
    the system. If specified together with `requests`, this value must be greater
    than or equal to `requests`. Depending on whether the resource is compressible
    or incompressible, exceeding the limit has different consequences—compressible
    resources (CPU) will be throttled whereas incompressible resources (memory) can
    result in container kill.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limits`：这指定了系统提供的特定资源的最大数量。如果与`requests`一起指定，这个值必须大于或等于`requests`。根据资源是可压缩还是不可压缩，超出限制会产生不同的后果——可压缩资源（CPU）将被限制，而不可压缩资源（内存）可能会导致容器被杀死。'
- en: Using different values of `requests` and `limits` allows for resource overcommit,
    which is useful for efficiently handling short bursts of resource usage while
    allowing better resource utilization on average. If you do not specify limits
    at all, the container can consume as much of the resource on a node as it wants.
    This can be controlled by namespace resource quotas (introduced earlier in this
    chapter) and limit ranges—you can read more about these objects in the documentation
    at [https://kubernetes.io/docs/concepts/policy/limit-range/](https://kubernetes.io/docs/concepts/policy/limit-range/).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的`requests`和`limits`值允许资源超额分配，这对于有效处理资源使用的短暂突发情况并在平均情况下更好地利用资源是有用的。如果根本不指定限制，容器可以在节点上消耗任意数量的资源。这可以通过命名空间资源配额（本章前面介绍的）和限制范围来控制——你可以在文档中阅读更多关于这些对象的信息[https://kubernetes.io/docs/concepts/policy/limit-range/](https://kubernetes.io/docs/concepts/policy/limit-range/)。
- en: We covered the details of resource management support on Windows nodes in Kubernetes
    in [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes Concepts
    and Windows Support*. The important bit is that Windows currently lacks support
    for an out-of-memory killer (some support for memory limiting may be available
    with incoming Hyper-V containers features in Kubernetes). This means that exceeding
    the `limits` value set for memory for Windows containers will not result in any
    throttling or container restart. Here, the rule of thumb is to carefully manage
    scheduling using `requests` for memory and monitoring for any sudden memory paging.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Kubernetes中的Windows节点上涵盖了资源管理支持的详细信息，详见[第4章](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml)，*Kubernetes概念和Windows支持*。重要的是，Windows目前缺乏对内存杀手的支持（Kubernetes中即将推出的Hyper-V容器功能可能会提供一些内存限制的支持）。这意味着超出Windows容器内存的`limits`值不会导致任何限制或容器重启。在这里，经验法则是仔细使用`requests`来管理内存调度，并监视任何突然的内存分页。
- en: 'Before we dive into the configuration details, we need to look at what are
    the units for measuring CPU resources and memory in Kubernetes. For CPU resources,
    the base unit is **Kubernetes CPU** (**KCU**) where `1`is equivalent to, for example,
    1 vCPU on Azure, 1 Core on GCP, or 1 hyperthreaded core on a bare-metal machine.
    Fractional values are allowed: `0.1` can be also specified as `100m` (milliCPUs).
    For memory, the base unit is a byte; you can, of course, specify standard unit
    prefixes such as `M`, `Mi`, `G`, or `Gi`.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入配置细节之前，我们需要了解 Kubernetes 中用于测量 CPU 资源和内存的单位是什么。对于 CPU 资源，基本单位是**Kubernetes
    CPU**（**KCU**），其中`1`等同于例如 Azure 上的 1 个 vCPU，GCP 上的 1 个 Core，或者裸机上的 1 个超线程核心。允许使用小数值：`0.1`也可以指定为`100m`（毫CPU）。对于内存，基本单位是字节；当然，您可以指定标准单位前缀，如`M`，`Mi`，`G`或`Gi`。
- en: 'To demonstrate how to use resource `limits` and `requests`, follow these steps:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示如何使用资源`limits`和`requests`，请按照以下步骤操作：
- en: 'Modify the `voting-application.yaml` Deployment manifest so that it does not
    specify any update `strategy` and has resource allocation set for CPU and memory:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`voting-application.yaml`部署配置，使其不指定任何更新`strategy`，并为 CPU 和内存设置资源分配：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For memory, we follow the current recommendations for Windows nodes—we only
    specify how much memory we would like to request. For the CPU to simulate resource
    exhaustion, we specify a large requested value that will consume all of the cluster
    CPU for Windows nodes. The reason for this is that two nodes with Azure VM type Standard_D2_v3
    have two vCPUs each and with five replicas running, we would need five vCPUs in
    total. The update `strategy` needs to be removed to avoid any deadlocks during
    the rollout.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内存，我们遵循 Windows 节点的当前建议——我们只指定了想要请求多少内存。为了模拟资源耗尽，我们指定了一个大的请求值，将消耗 Windows
    节点的所有集群 CPU。这是因为两个具有 Azure VM 类型 Standard_D2_v3 的节点每个都有两个 vCPU，并且运行五个副本，我们总共需要五个
    vCPU。需要删除更新`strategy`以避免在部署过程中出现任何死锁。
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application.yaml`命令应用配置文件。
- en: 'Now, carefully observe the creation of new Pods in your Deployment. You will
    notice there are Pods that show the `Pending` status:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，仔细观察您的部署中新 Pod 的创建。您会注意到有一些 Pod 显示`Pending`状态：
- en: '[PRE13]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This is expected, as the `voting-application-frontend-54bbbbd655-phdhr` Pod
    cannot be scheduled to any node because there are no available CPU resources.
    To check what is the actual reason, describe the Pod and check `Events`:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是预期的，因为`voting-application-frontend-54bbbbd655-phdhr` Pod 无法被调度到任何节点，因为没有可用的
    CPU 资源。要检查实际原因，描述 Pod 并检查 `Events`：
- en: '[PRE14]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As expected, the Pod cannot be scheduled due to insufficient CPU resources on
    all nodes that match the node selector. Let's fix the issue by lowering the `requests`
    and `limits` CPU values for the Pod container—modify the `voting-application.yaml`
    manifest file so that `requests` is set to `250m` and `limits` is set to `500m`
    for the CPU.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如预期的那样，由于所有匹配节点选择器的节点上都没有足够的 CPU 资源，Pod 无法被调度。让我们通过降低 Pod 容器的 `requests` 和
    `limits` CPU 值来解决这个问题——修改 `voting-application.yaml` 配置文件，使 `requests` 设置为 `250m`，`limits`
    设置为 `500m`。
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml` command
    and observe the successful Deployment.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application.yaml`命令应用配置文件，并观察成功的部署。
- en: Now that you know how to allocate and manage resources for your containers,
    we can demonstrate how to use autoscaling for your application using the HPA.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何为您的容器分配和管理资源，我们可以演示如何使用 HPA 对您的应用程序进行自动缩放。
- en: HPA
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HPA
- en: The true power of Kubernetes comes with autoscaling implemented by the HPA,
    which is a dedicated controller backed by the `HorizontalPodAutoscaler` API object.
    At a high level, the goal of the HPA is to automatically scale the number of replicas
    in a Deployment or StatefulSet depending on the current CPU utilization or other custom
    metrics (including multiple metrics at once). The details of the algorithm that
    determines the target number of replicas based on metric values can be found at [https://kubernetes.io/docs/tasks/run-application/horizontal-Pod-autoscale/#algorithm-details](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details).
    HPAs are highly configurable and in this book, we will cover a standard scenario
    for when we would like to autoscale based on target CPU usage.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的真正力量在于HPA实现的自动扩展，它是由`HorizontalPodAutoscaler` API对象支持的专用控制器。在高层次上，HPA的目标是根据当前CPU利用率或其他自定义指标（包括同时使用多个指标）自动扩展部署或StatefulSet中副本的数量。根据指标值确定目标副本数量的算法的详细信息可以在[https://kubernetes.io/docs/tasks/run-application/horizontal-Pod-autoscale/#algorithm-details](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details)找到。HPA是高度可配置的，在本书中，我们将介绍基于目标CPU使用率自动扩展的标准场景。
- en: 'Our voting application exposes features that do not require much CPU, which
    means that it may be hard to trigger autoscaling on demand. To solve this, we
    will add a dedicated controller action that can simulate a constant CPU load with
    a given target percentage value. The source code for the `packtpubkubernetesonwindows/voting-application:1.2.0`
    Docker image for stress simulation can be found at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src).
    If you want to customize the application yourself, open your solution in Visual
    Studio 2019 and follow these steps:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的投票应用程序公开了不需要太多CPU的功能，这意味着可能很难按需触发自动扩展。为了解决这个问题，我们将添加一个专用的控制器动作，可以模拟具有给定目标百分比值的恒定CPU负载。用于压力模拟的`packtpubkubernetesonwindows/voting-application:1.2.0`
    Docker镜像的源代码可以在[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src)找到。如果您想自定义应用程序，请在Visual
    Studio 2019中打开您的解决方案，并按照以下步骤操作：
- en: 'Define the `StressCpuWorker` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs)),
    which contains the main worker code for simulating CPU stress:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`StressCpuWorker`类（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs)），其中包含用于模拟CPU压力的主要工作代码：
- en: '[PRE15]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code will start several threads, the number of which will be equal to the
    currently available processor count in the environment, and each logical processor
    will be then stressed for `this.targetCpuLoad` milliseconds by doing almost empty
    `while` loops. For the rest of the 100-millisecond "segment", the thread will
    be sleeping—this means that, on average, we should have all available CPUs loaded
    to `this.targetCpuLoad` percent. Of course, it depends on how many processors
    are allotted to the container—this number may vary depending on your `requests`
    and `limits` values; you can always check the Pod logs to see what number of logical
    processors were available for this Pod. Also, please note that even if there are
    two logical processors available to the container, it doesn't mean that the container
    will be able to fully utilize them; the load may be throttled depending on the `limits`
    value.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将启动多个线程，数量将等于环境中当前可用的处理器数量，然后通过几乎空的`while`循环来对每个逻辑处理器进行`this.targetCpuLoad`毫秒的压力测试。在剩余的100毫秒“段”中，线程将进入睡眠状态——这意味着平均而言，我们应该将所有可用的CPU负载到`this.targetCpuLoad`百分比。当然，这取决于分配给容器的处理器数量——这个数字可能会根据您的`requests`和`limits`值而变化；您可以随时检查Pod日志，以查看此Pod可用的逻辑处理器数量。另请注意，即使容器有两个逻辑处理器可用，也不意味着容器能够充分利用它们；负载可能会受到`limits`值的限制。
- en: 'In the `HomeController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs)),
    add a new controller action that will be available via the `/Home/StressCpu?value={targetPercent}`
    route. Please note that we allow this action to be performed via a GET request
    (instead of PUT) to make the interaction easy when using a web browser. Additionally,
    inject `IStressCpuWorker` into the constructor—the final action implementation
    will be as follows:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`HomeController`类中（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs)），添加一个新的控制器操作，可以通过`/Home/StressCpu?value={targetPercent}`路由访问。请注意，我们允许通过GET请求（而不是PUT）执行此操作，以便在使用Web浏览器时交互更加简单。此外，将`IStressCpuWorker`注入到构造函数中——最终操作实现如下：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This implementation will enable CPU stressing if you provide a positive value
    and for a negative value, stressing will be disabled.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提供正值，此实现将启用CPU压力测试；如果提供负值，将禁用压力测试。
- en: 'Configure dependency injection in the `NinjectWebCommon` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs)).
    Ensure that the `StressCpuWorker` class is resolved as a singleton:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`NinjectWebCommon`类中配置依赖注入（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs)）。确保`StressCpuWorker`类被解析为单例：
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Build the Docker image with the tag `1.2.0` and push it to your repository,
    exactly as we did before.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标签`1.2.0`构建Docker镜像，并将其推送到您的存储库，就像我们之前做的那样。
- en: 'With the image ready, we can proceed with deploying a new version of the voting
    application and configure autoscaling. To do that, execute the following steps:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好镜像后，我们可以继续部署投票应用的新版本并配置自动缩放。为此，请执行以下步骤：
- en: 'Modify the `voting-application.yaml` manifest file and ensure that you use
    the `1.2.0` tag of the image and that `resources` is specified as follows:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`voting-application.yaml`清单文件，并确保您使用图像的`1.2.0`标记，并且`resources`指定如下：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In a PowerShell window, apply the manifest file using the `kubectl apply -f
    .\voting-application.yaml` command.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在PowerShell窗口中，使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
- en: 'Wait for the Deployment to finish and observe the CPU usage by Pods using this
    command:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待部署完成，并使用此命令观察Pod的CPU使用情况：
- en: '[PRE19]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: When the IIS App Pool is fully initialized, the CPU usage for each Pod should
    stabilize around `150m`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当IIS应用程序池完全初始化时，每个Pod的CPU使用率应稳定在`150m`左右。
- en: 'Create the `hpa.yaml` manifest file for the HPA:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为HPA创建`hpa.yaml`清单文件：
- en: '[PRE20]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This HPA will automatically scale the `voting-application-frontend` Deployment
    to between `1` and `8` replicas, trying to target `60` percent CPU usage. Please
    note that this target usage is high and in production environments, you should
    consider using lower, more appropriate values. This manifest file is roughly the
    same as for the HPA created imperatively using the `kubectl autoscale deployment/voting-application-frontend
    -n dev --cpu-percent=60 --min=1 --max=8` command.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此HPA将自动将`voting-application-frontend`部署扩展到`1`到`8`个副本之间，尝试将CPU使用率定位到`60`％。请注意，此目标使用率较高，在生产环境中，您应考虑使用更低、更合适的值。此清单文件与使用`kubectl
    autoscale deployment/voting-application-frontend -n dev --cpu-percent=60 --min=1
    --max=8`命令创建的HPA大致相同。
- en: Apply the manifest file using the `kubectl apply -f .\hpa.yaml` command.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\hpa.yaml`命令应用清单文件。
- en: 'HPAs are subject to delay for cooldown to avoid thrashing (that is, the replica
    count fluctuating frequently). The default delay is five minutes. This means that
    you should expect some delay until the HPA scales the Deployment after you apply
    it. Monitor the status of the HPA using the `kubectl describe` command:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA受到延迟的影响，以避免频繁波动（即副本计数频繁波动）。默认延迟为五分钟。这意味着在应用后，您应该期望一些延迟，直到HPA扩展部署。使用`kubectl
    describe`命令监视HPA的状态：
- en: '[PRE21]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Over time, you will notice that the HPA will tend to scale down to a single
    replica as there is not enough CPU load.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，您会注意到HPA倾向于缩减到单个副本，因为CPU负载不足。
- en: 'Let''s increase the CPU load using our dedicated endpoint. In the web browser,
    go to the following URL: `http://<serviceExternalIp>/Home/StressCpu?value=90`.
    This will start stressing the CPU at a target level of 90%—bear in mind that,
    depending on how the logical processors are allocated for your Pods, the actual
    usage may be different.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用我们的专用端点增加CPU负载。在Web浏览器中，转到以下URL：`http://<serviceExternalIp>/Home/StressCpu?value=90`。这将开始以90％的目标水平压力CPU-请记住，根据Pod分配的逻辑处理器的方式，实际使用情况可能会有所不同。
- en: You can perform multiple requests to ensure that more Pods in the Deployment
    start stressing the CPU.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以执行多个请求，以确保部署中的更多Pod开始对CPU施加压力。
- en: 'After a while, observe what happens in the HPA events:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过一段时间，观察HPA事件中发生了什么：
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The Deployment was automatically scaled up as the CPU resource utilization was
    above the 60% target! After more Pods are added, the average utilization will
    decrease because not all Pods are performing CPU stressing.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CPU资源利用率超过了60％的目标，部署会自动扩展！添加更多Pod后，平均利用率将下降，因为并非所有Pod都在执行CPU压力测试。
- en: For AKS and an AKS Engine cluster, it is possible to leverage the cluster autoscaler
    to automatically adjust the number of nodes in your cluster depending on the resource
    demands. You can read more in the official Azure documentation ([https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler))
    and in the guide for configuring the cluster autoscaler on Azure ([https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md)).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AKS和AKS Engine集群，可以利用集群自动缩放器根据资源需求自动调整集群中节点的数量。您可以在官方Azure文档([https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler))和Azure上配置集群自动缩放器的指南中阅读更多信息([https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md))。
- en: Congratulations, you have successfully configured the HPA for the voting application.
    The next Kubernetes feature that we are going to demonstrate is using ConfigMaps
    and Secrets for injecting configuration data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您已成功为投票应用程序配置了HPA。我们接下来要演示的Kubernetes功能是使用ConfigMaps和Secrets注入配置数据。
- en: Managing application configuration using ConfigMaps and Secrets
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ConfigMaps和Secrets管理应用程序配置
- en: 'To provide configuration for an application running on Kubernetes, there are
    a couple of possible approaches, documented in [https://kubernetes.io/docs/tasks/inject-data-application/](https://kubernetes.io/docs/tasks/inject-data-application/):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为在Kubernetes上运行的应用程序提供配置，有几种可能的方法，记录在[https://kubernetes.io/docs/tasks/inject-data-application/](https://kubernetes.io/docs/tasks/inject-data-application/)中：
- en: Passing arguments to the container commands
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向容器命令传递参数
- en: Defining system environment variables for the container
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为容器定义系统环境变量
- en: Mounting ConfigMaps or Secrets as container volumes
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将ConfigMaps或Secrets挂载为容器卷
- en: Optionally wrapping everything up using PodPresets
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地，使用PodPresets将所有内容包装起来。
- en: This section will focus on using ConfigMaps and Secrets, which are, in many
    aspects, similar but have very different purposes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍使用ConfigMaps和Secrets，它们在许多方面都很相似，但目的却非常不同。
- en: First, let's take a look at Secrets. In almost every application, you will have
    to manage sensitive information for accessing dependencies, such as passwords,
    OAuth tokens, or certificates. Putting such information in a Docker image as hardcoded
    values is out of the question due to obvious security concerns and very limited
    flexibility. Similarly, defining a password directly in the Pod manifest file
    is not recommended—manifest files are intended to be kept in source control and
    this definitely is not a place for storing such sensitive information. To manage
    this type of information, Kubernetes offers Secret objects, which can hold technically
    any type of data consisting of key-value pairs. Optionally, it is possible to
    encrypt Secrets at rest in `etcd`, which is recommended in production scenarios.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看看Secrets。在几乎每个应用程序中，您都必须管理访问依赖项的敏感信息，例如密码、OAuth令牌或证书。将这些信息作为硬编码值放入Docker镜像是不可能的，因为存在明显的安全问题和非常有限的灵活性。同样，直接在Pod清单文件中定义密码是不推荐的——清单文件应该保存在源代码控制中，绝对不是存储这种敏感信息的地方。为了管理这种类型的信息，Kubernetes提供了Secret对象，它可以保存技术上任何类型的由键值对组成的数据。可选地，可以在`etcd`中对Secrets进行加密，这在生产场景中是推荐的。
- en: 'We will now demonstrate how to create a generic (opaque) Secret using `kubectl`.
    You can also use manifest files for this purpose but how you generate these manifest
    files depends on your CI/CD pipelines (you do not want to check in these manifest
    files to your source control!). To create a Secret for a SQL Server password,
    execute the following steps:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将演示如何使用`kubectl`创建一个通用（不透明）的Secret。您也可以使用清单文件来实现这个目的，但是如何生成这些清单文件取决于您的CI/CD流水线（您不希望将这些清单文件提交到源代码控制中！）。要为SQL
    Server密码创建一个Secret，请执行以下步骤：
- en: Open a PowerShell window.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个PowerShell窗口。
- en: 'Assuming that you would like to create a Secret named `mssql` in the `dev`
    namespace, which holds `S3cur3P@ssw0rd` under the `SA_PASSWORD` key, execute the
    following command:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设您想在`dev`命名空间中创建一个名为`mssql`的Secret，其中`SA_PASSWORD`键下保存着`S3cur3P@ssw0rd`，则执行以下命令：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, the Secret can be consumed as a volume mounted in the container (as a
    file or a directory) or used to define environment variables for a container.
    In the case of the voting application, it is easier to use the Secret with a SQL
    Server password as an environment variable. This is achieved in the following
    way in the Deployment manifest:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，该Secret可以作为容器中的卷（作为文件或目录）来使用，或者用于为容器定义环境变量。对于投票应用程序，更容易使用具有SQL Server密码的Secret作为环境变量。在部署清单中，可以通过以下方式实现这一点：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The key concept here is using `secretKeyRef` to reference a value for the `SA_PASSWORD`
    key from the `mssql` Secret that we have just created. The value is injected into
    the `MSSQL_SA_PASSWORD` environment variable (but you can check that it is not
    possible to see the value when using `kubectl describe`!), which can be accessed
    by the application running in the container. In our case, we use this variable
    to define another environment variable named `CONNECTIONSTRING_VotingApplication`.
    This is a common pattern when you need to create, for example, a connection string
    that has to include a password but please bear in mind that it may be a less secure
    solution than using volumes.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键概念是使用`secretKeyRef`来引用我们刚刚创建的`mssql` Secret中`SA_PASSWORD`键的值。该值被注入到`MSSQL_SA_PASSWORD`环境变量中（但是当使用`kubectl
    describe`时，您无法看到该值！），应用程序在容器中运行时可以访问该值。在我们的情况下，我们使用这个变量来定义另一个环境变量，名为`CONNECTIONSTRING_VotingApplication`。当您需要创建一个包含密码的连接字符串时，这是一个常见的模式，但请记住，这可能比使用卷更不安全。
- en: 'There is one significant difference between consuming Secrets as environment
    variables and as mounted volumes: the Secret data provided via a volume will be updated
    if the Secret changes. Depending on your needs and implementation details, you
    may want to choose to mount Secrets as volumes. This, of course, requires your
    application to be aware of possible changes to the Secrets file, which means it
    needs to actively monitor the filesystem and refresh any credential providers,
    connection strings, or certificates, which are often kept in memory. Approaching
    Secrets as immutable configuration values is the best option (both when mounted
    as a volume and as environment variables) and makes your application more predictable
    and less complex. But if your architecture has limitations that prefer as few
    Pod restarts as possible, then injecting Secrets as a volume and implementing
    automatic refresh in your application is be the suggested solution.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Secrets作为环境变量和作为挂载卷时，有一个重要的区别：通过卷提供的Secret数据将在Secret更改时进行更新。根据您的需求和实现细节，您可能希望选择将Secrets作为卷进行挂载。当然，这要求您的应用程序意识到Secrets文件可能发生变化，这意味着它需要积极监视文件系统，并刷新任何凭据提供者、连接字符串或证书，这些通常保存在内存中。将Secrets作为不可变的配置值是最佳选择（无论是作为卷挂载还是作为环境变量），这样可以使您的应用程序更可预测，更简单。但是，如果您的架构有限制，希望尽可能少地重新启动Pod，那么将Secrets作为卷进行注入，并在应用程序中实现自动刷新可能是建议的解决方案。
- en: 'From a security perspective, injecting Secrets as environment variables is less
    secure on Linux as, when having root privileges, you can enumerate all environment
    variables for a process from `/proc/<pid>/environ`. On Windows nodes, the issue
    is even more complex: you can still access environment variables for processes
    but volumes cannot currently use the in-memory filesystem. This means that Secrets
    are then stored directly on the node''s disk storage.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 从安全的角度来看，将Secrets作为环境变量注入在Linux上是不太安全的，因为当具有root权限时，您可以从`/proc/<pid>/environ`中枚举出一个进程的所有环境变量。在Windows节点上，问题更加复杂：您仍然可以访问进程的环境变量，但卷目前无法使用内存文件系统。这意味着Secrets会直接存储在节点的磁盘存储上。
- en: To store non-sensitive configuration data for your application, Kubernetes offers
    ConfigMap objects. This is another concept that you can use to fully decouple
    Docker images (your build artifacts) from the runtime configuration data. From
    an API perspective, the concept is similar to Secrets—you can store key-value
    pairs and inject them either as environment variables for the container or mount
    them using a volume as a file or a directory. To demonstrate this, we will create
    a ConfigMap for storing a configuration file, `customErrors.config`, referenced
    in the `Web.config` file for the ASP.NET MVC application and mount it using a
    volume.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了存储应用程序的非敏感配置数据，Kubernetes提供了ConfigMap对象。这是另一个概念，您可以使用它来完全解耦Docker镜像（构建产物）和运行时配置数据。从API的角度来看，这个概念类似于Secrets——您可以存储键值对，并将它们注入到容器的环境变量中，或者使用卷将它们挂载为文件或目录。为了演示这一点，我们将创建一个ConfigMap来存储一个名为`customErrors.config`的配置文件，该文件在ASP.NET
    MVC应用程序的`Web.config`文件中被引用，并使用卷进行挂载。
- en: As mentioned in [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes
    Concepts and Windows Support*, as of Kubernetes 1.17, there is no support for
    mounting a volume `subPath` as a file on Windows. This means that it is not possible
    to easily override the whole `Web.config` file for the ASP.NET MVC using ConfigMap.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第4章](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml)中所述，*Kubernetes概念和Windows支持*，截至Kubernetes
    1.17版本，不支持在Windows上将卷`subPath`挂载为文件。这意味着无法轻松地使用ConfigMap覆盖整个ASP.NET MVC的`Web.config`文件。
- en: 'Please follow these steps:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下步骤操作：
- en: 'First, we need to perform a small change to the voting application source code
    ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src)).
    We will extract the `<customErrors>` node from the `<system.web>` node to a separate
    file in a subdirectory. In the `Web.config` file, change the `<system.web>` node
    to this:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要对投票应用程序源代码进行一些小的更改（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/10_voting-application-configmap-src)）。我们将从`<system.web>`节点中提取`<customErrors>`节点到一个子目录中的单独文件中。在`Web.config`文件中，将`<system.web>`节点更改为：
- en: '[PRE25]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create the `customErrors.config` file in the `config` directory with the following
    contents. We will override it using a ConfigMap in the next steps:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`config`目录中创建`customErrors.config`文件，内容如下。我们将在接下来的步骤中使用ConfigMap进行覆盖：
- en: '[PRE26]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Build a Docker image with the `1.3.0` tag and publish it to Docker Hub, as in
    the previous examples.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`1.3.0`标签构建一个Docker镜像，并将其发布到Docker Hub，就像之前的示例一样。
- en: 'Create the `voting-application-customerrors-config.yaml` manifest file for
    a ConfigMap definition that has the following form and contains the file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config))
    as `data`:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`voting-application-customerrors-config.yaml`清单文件，用于定义具有以下形式的ConfigMap，并包含文件（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config)）作为`data`：
- en: '[PRE27]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: It is possible to create ConfigMaps imperatively using `kubectl`, but we would
    like to demonstrate the structure of the ConfigMap manifest file. The important
    part is to keep proper indentation when using a YAML multiline string for bigger
    config files (`|`).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`kubectl`命令以命令方式创建ConfigMaps，但我们想演示ConfigMap清单文件的结构。重要的部分是在使用YAML多行字符串时保持正确的缩进以适应更大的配置文件（`|`）。
- en: Apply the manifest file using the `kubectl apply -f .\voting-application-customerrors-config.yaml`
    command.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application-customerrors-config.yaml`命令应用清单文件。
- en: 'Modify the `voting-application.yaml` manifest file for Deployment to mount
    our ConfigMap as a directory in the container (remember to use the new Docker
    image tag):'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`voting-application.yaml`清单文件以在容器中将我们的ConfigMap作为目录挂载（记得使用新的Docker镜像标签）：
- en: '[PRE28]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The important part here is to reference the `voting-application-customerrors-config`
    ConfigMap as a volume (`customerrors-config-volume`) and mount it to `C:\inetpub\wwwroot\config\`
    in the container. If `subPath` mounts were currently supported on Windows, we
    could override just a single file instead of the whole directory.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重要部分是将`voting-application-customerrors-config` ConfigMap作为卷（`customerrors-config-volume`）引用，并将其挂载到容器中的`C:\inetpub\wwwroot\config\`。如果当前在Windows上支持`subPath`挂载，我们可以只覆盖单个文件而不是整个目录。
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
- en: Now, navigate to the `http://<serviceExternalIp>/Home/StressCpu` address in
    your browser. This will trigger an exception—we did not provide the required request
    parameter in the URL. You should see a custom error page that just informs that `An
    error occurred while processing your request`.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在浏览器中导航到`http://<serviceExternalIp>/Home/StressCpu`地址。这将触发一个异常-我们没有在URL中提供所需的请求参数。您应该会看到一个自定义错误页面，只是通知“在处理您的请求时发生错误”。
- en: 'Turn off the custom errors page and modify the `voting-application-customerrors-config.yaml`
    manifest file for ConfigMap so that it contains the node:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭自定义错误页面，并修改`voting-application-customerrors-config.yaml`清单文件的ConfigMap，使其包含节点：
- en: '[PRE29]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Apply the manifest file using the `kubectl apply -f .\voting-application-customerrors-config.yaml` command.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application-customerrors-config.yaml`命令应用清单文件。
- en: Depending on whether IIS is able to watch for changes in the `C:\inetpub\wwwroot\config\`
    directory, the IIS App Pool may not be reloaded in the Pod. In such a case, `exec`
    into the container and execute the `Restart-WebAppPool DefaultAppPool` command.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 根据IIS是否能够监视`C:\inetpub\wwwroot\config\`目录中的更改，IIS应用程序池可能不会在Pod中重新加载。在这种情况下，`exec`进入容器并执行`Restart-WebAppPool
    DefaultAppPool`命令。
- en: Navigate to `http://<serviceExternalIp>/Home/StressCpu` again. If your IIS App
    Pool has been reloaded, you will see full exception details instead of the custom
    error page.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次导航到`http://<serviceExternalIp>/Home/StressCpu`。如果您的IIS应用程序池已重新加载，您将看到完整的异常详细信息，而不是自定义错误页面。
- en: In this way, we have demonstrated how to use Secrets and ConfigMaps in Windows
    Pods. Now, it is time to familiarize ourselves with managing persistent data storage
    on Windows nodes.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经演示了如何在Windows Pods中使用Secrets和ConfigMaps。现在，是时候熟悉在Windows节点上管理持久数据存储了。
- en: Managing persistent data storage on Windows nodes
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Windows节点上管理持久数据存储
- en: 'In [Chapter 4](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml), *Kubernetes Concepts
    and Windows Support*, we have already covered some storage-related concepts in
    Kubernetes, such as **PersistentVolumes** (**PV**), **PersistentVolumeClaims**
    (**PVC**), and **StorageClasses** (**SC**), and how they are supported in Windows
    workloads. Managing state and storage in containerized applications and using
    StatefulSets is a broad and complex topic that is not in the scope of this book—the
    official documentation offers a good introduction, which can be found at [https://kubernetes.io/docs/concepts/storage/](https://kubernetes.io/docs/concepts/storage/).
    The key takeaway for PersistentVolume support for Windows Pods is that you can
    use some of the existing volume plugins but not all. On Windows, there is support
    for the following:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](118e3c89-786e-4718-ba67-6c38928e2a42.xhtml) *Kubernetes概念和Windows支持*中，我们已经涵盖了Kubernetes中一些与存储相关的概念，如**PersistentVolumes**（**PV**）、**PersistentVolumeClaims**（**PVC**）和**StorageClasses**（**SC**），以及它们在Windows工作负载中的支持。在容器化应用程序中管理状态和存储以及使用StatefulSets是一个广泛且复杂的主题，不在本书的范围内——官方文档提供了一个很好的介绍，可以在[https://kubernetes.io/docs/concepts/storage/](https://kubernetes.io/docs/concepts/storage/)找到。对于Windows
    Pods的PersistentVolume支持的关键要点是，您可以使用一些现有的卷插件，但不是全部。在Windows上，支持以下内容：
- en: 'In-tree volume plugins: azureDisk, azureFile, gcePersistentDisk, awsElasticBlockStore
    (since 1.16), and vsphereVolume (since 1.16)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树内卷插件：azureDisk、azureFile、gcePersistentDisk、awsElasticBlockStore（自1.16版起）和vsphereVolume（自1.16版起）
- en: 'FlexVolume plugins: SMB and iSCSI'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FlexVolume插件：SMB和iSCSI
- en: CSI volume plugins (out-of-tree plugins)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSI卷插件（树外插件）
- en: This means that, for Windows nodes, in the case of AKS or AKS Engine clusters,
    you are limited to using the azureDisk and azureFile in-tree volume plugins and
    technically, you can combine the FlexVolume SMB plugin with Azure Files SMB Share.
    For on-premises scenarios, you have to rely on the FlexVolume SMB or iSCSI plugins
    configured to use your own storage or connect to SMB shares exposed as external
    cloud services. If you are running on vSphere, you can, of course, leverage the
    vsphereVolume plugin. In general, handling PersistentVolumes for hybrid Windows/Linux
    clusters running on-premises is still hard.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，对于Windows节点，在AKS或AKS Engine集群的情况下，您只能使用azureDisk和azureFile in-tree卷插件，从技术上讲，您可以将FlexVolume
    SMB插件与Azure Files SMB共享相结合。对于本地场景，您必须依赖于配置为使用自己的存储或连接到作为外部云服务公开的SMB共享的FlexVolume
    SMB或iSCSI插件。如果您在vSphere上运行，当然可以利用vsphereVolume插件。总的来说，在本地运行的混合Windows/Linux集群中处理持久卷仍然很困难。
- en: For on-premises clusters, using Rook ([https://rook.io/](https://rook.io/))
    to orchestrate storage and integrate with Kubernetes is a good solution. Unfortunately,
    there is no support for Windows yet, even for consuming the volumes.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本地集群，使用Rook（[https://rook.io/](https://rook.io/)）来编排存储并与Kubernetes集成是一个很好的解决方案。不幸的是，即使是用于消耗卷的Windows也没有支持。
- en: Our voting application is already using PersistentVolumes for SQL Server running
    in a Linux Pod—in this case, we have been using StorageClass with the `kubernetes.io/azure-disk`
    provisioner, which internally uses the azureDisk volume plugin. This scenario
    concerned Linux Pods—now, we will use PersistentVolumes for Windows Pods. The
    voting application does not have any particular need for persisting data in frontend
    containers but as a pure example, we will show how to store a voting log for each
    Pod.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的投票应用程序已经在Linux Pod中运行SQL Server时使用了PersistentVolumes - 在这种情况下，我们一直在使用StorageClass与`kubernetes.io/azure-disk`供应程序，它在内部使用azureDisk卷插件。这种情况涉及Linux
    Pod - 现在，我们将为Windows Pod使用PersistentVolumes。投票应用程序在前端容器中没有特定的数据持久化需求，但作为一个纯粹的例子，我们将展示如何为每个Pod存储一个投票日志。
- en: 'The source code for this change is available at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src).
    We will not go into implementation details but the change is simple:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 此更改的源代码可在[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src)上找到。我们不会详细介绍实现细节，但更改很简单：
- en: Add a new `VoteLogManager` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs)),
    which manages the `C:\data\voting.log` file—you can add new votes to the log and
    read the log contents. This log file will be persisted using Kubernetes PersistentVolume.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加一个新的`VoteLogManager`类（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs)），它管理`C:\data\voting.log`文件
    - 您可以向日志中添加新的投票并读取日志内容。此日志文件将使用Kubernetes PersistentVolume进行持久化。
- en: For each vote that is added in the `SurveyController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/SurveysController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/SurveysController.cs)),
    inform `VoteLogManager`.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`SurveyController`类中添加每个投票后，通知`VoteLogManager`。
- en: In the `HomeController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/HomeController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/HomeController.cs)),
    add a new controller action, `VotingLog`, which returns the contents of the voting
    log. Then, you can access the voting log for the currently serving replica using
    `http://<serviceExternalIp>/Home/VotingLog`.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`HomeController`类中添加一个新的控制器操作`VotingLog`，返回投票日志的内容。然后，您可以使用`http://<serviceExternalIp>/Home/VotingLog`访问当前提供的副本的投票日志。
- en: 'To deploy the application, perform the following steps:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署应用程序，请执行以下步骤：
- en: Build a Docker image with the tag `1.4.0` for the voting application and push
    it to Docker Hub as in previous examples.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为投票应用程序构建一个标记为`1.4.0`的Docker镜像，并像之前的示例一样将其推送到Docker Hub。
- en: 'We need to convert our Deployment into a StatefulSet. Therefore, you first
    need to delete the Deployment from the cluster:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将部署转换为StatefulSet。因此，您首先需要从集群中删除部署：
- en: '[PRE30]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Create the `StorageClass` manifest, `sc.yaml`, with the following contents.
    We will use the `kubernetes.io/azure-disk` provisioner to use the azureDisk Volume
    plugin:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`StorageClass`清单`sc.yaml`，内容如下。我们将使用`kubernetes.io/azure-disk`提供程序来使用azureDisk卷插件：
- en: '[PRE31]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Apply the manifest file using the `kubectl apply -f sc.yaml` command.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f sc.yaml`命令应用清单文件。
- en: 'Convert the Deployment into a StatefulSet and use the `1.4.0` version of the
    Docker image. The full manifest file can be found at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml).
    We highlight the changes that are needed compared to the previous `voting-application.yaml`
    manifest file as follows:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将部署转换为StatefulSet，并使用Docker镜像的`1.4.0`版本。完整的清单文件可以在[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml)找到。我们将需要的更改与之前的`voting-application.yaml`清单文件进行对比，如下所示：
- en: '[PRE32]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: StatefulSet requires providing a Service name that is responsible for this StatefulSet
    (`1`). On top of that, we define `volumeClaimTemplates` (`4`), which will be used
    for creating a dedicated PersistentVolumeClaim for each Pod replica in this StatefulSet.
    We reference this PVC for mounting the volume as the `C:/data` directory in the
    container (`3`), where `voting.log` will be persisted. Additionally, we also need
    to give proper read/write permissions to the `C:/data` directory to the IIS App
    Pool user—otherwise, the web application will not be able to access our PersistentVolume.
    This is achieved using `icasls.exe` executed in an `init` container (`2`). Note
    that you need to first start IIS (`iisreset.exe /START`) to have the IIS App Pool
    user properly created before assigning the permission!
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet需要提供负责此StatefulSet的服务名称（`1`）。除此之外，我们还定义了`volumeClaimTemplates`（`4`），用于为此StatefulSet中的每个Pod副本创建专用的PersistentVolumeClaim。我们引用此PVC来将卷挂载为容器中的`C:/data`目录（`3`），其中`voting.log`将被持久化。此外，我们还需要为IIS
    App Pool用户提供适当的读/写权限以访问`C:/data`目录，否则Web应用程序将无法访问我们的PersistentVolume。这是通过在`init`容器（`2`）中执行`icasls.exe`来实现的。请注意，您需要首先启动IIS（`iisreset.exe
    /START`）以便在分配权限之前正确创建IIS App Pool用户！
- en: Apply the manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
- en: When the StatefulSet is ready, navigate to the application in the web browser
    and vote a few times.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当StatefulSet准备就绪时，打开网页浏览器并投几次票。
- en: 'Open `http://<serviceExternalIp>/Home/VotingLog` in a web browser and, depending
    on which Pod replica you have reached, you will see different results:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页浏览器中打开`http://<serviceExternalIp>/Home/VotingLog`，根据您到达的Pod副本不同，您将看到不同的结果：
- en: '![](assets/a40d5661-8380-427f-88ca-7e156f2419d7.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a40d5661-8380-427f-88ca-7e156f2419d7.png)'
- en: 'Good, so now we know that writing to the directory in a container works as
    expected. But let''s prove that this directory is indeed backed by a PersistentVolume
    mount. To do that, perform the following steps:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们知道在容器中写入目录的操作正常工作。但让我们证明这个目录确实由PersistentVolume挂载支持。为此，请执行以下步骤：
- en: 'Scale down `statefulset` to `0` replicas. This will remove all of the Pods
    for the StatefulSet:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`statefulset`缩减到`0`个副本。这将删除StatefulSet的所有Pod：
- en: '[PRE33]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Wait until all Pods are terminated, and observe using the `kubectl get pods
    -n dev` command.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待所有Pod终止，并使用`kubectl get pods -n dev`命令观察。
- en: 'Scale up `statefulset`, for example, to `5` replicas:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展`statefulset`，例如，到`5`个副本：
- en: '[PRE34]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Wait for the Pods to create and become ready. It may take a few minutes due
    to our readiness probes.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待Pod创建并变为就绪。由于我们的就绪探针，这可能需要几分钟。
- en: Navigate to `http://<serviceExternalIp>/Home/VotingLog` in your web browser.
    You should see exactly the same voting log for each Pod replica as before. This
    shows that all Pods have the same PersistentVolumes mounted as previously.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页浏览器中导航至`http://<serviceExternalIp>/Home/VotingLog`。您应该看到每个Pod副本的投票日志完全相同。这表明所有Pod都像以前一样挂载了相同的PersistentVolumes。
- en: Congratulations! You have successfully mounted azureDisk PersistentVolumes in
    a Windows Pod for the voting application. Next, we will take a look at how you
    can configure rolling updates for your application.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功在Windows Pod中为投票应用程序挂载了azureDisk持久卷。接下来，我们将看看如何为您的应用程序配置滚动更新。
- en: Configuring rolling updates for Deployments
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为`Deployments`配置滚动更新
- en: In production scenarios, you will definitely need a deployment strategy that
    provides zero downtime updates for your application. As a container orchestrator,
    Kubernetes comes with different building blocks that can be used for implementing
    blue-green Deployments, canary Deployments, or rolling Deployments. A Kubernetes
    Deployment object has full support for performing a rolling update Deployment—in
    this type of Deployment, the new version of the application is rolled out by gradually
    swapping old replicas with new replicas, all of which are behind the same Service.
    This means that, during the rollout, the end user will reach either the old or
    new version of the application.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产场景中，您肯定需要一种部署策略，为您的应用程序提供零停机更新。作为容器编排器，Kubernetes 提供了不同的构建模块，可用于实现蓝绿部署、金丝雀部署或滚动部署。Kubernetes
    部署对象完全支持执行滚动更新部署——在这种部署类型中，应用程序的新版本通过逐渐交换旧副本与新副本来推出，所有这些副本都在同一个服务后面。这意味着，在推出过程中，最终用户将访问应用程序的旧版本或新版本之一。
- en: To ensure real zero downtime updates of your Deployments in Kubernetes, you
    need to configure proper probes, especially readiness. In this way, the user will
    be redirected to a replica only if this replica can properly respond to the request.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保在 Kubernetes 中对部署进行真正的零停机更新，您需要配置适当的探测器，特别是就绪性。通过这种方式，只有当副本能够正确响应请求时，用户才会被重定向到一个副本。
- en: 'Let''s see how you can implement rolling deployment for the voting application.
    In fact, we have already been using this approach in the previous examples and
    now we will explain the configuration in more detail. Follow these steps:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何为投票应用程序实现滚动部署。实际上，在先前的示例中，我们已经在使用这种方法，现在我们将更详细地解释配置。按照以下步骤：
- en: Delete the StatefulSet, which we created in the previous section, using the `kubectl
    delete statefulset -n dev voting-application-frontend` command.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl delete statefulset -n dev voting-application-frontend` 命令删除我们在上一节中创建的
    StatefulSet。
- en: Let's revert back to the `voting-application.yaml` Deployment manifest file
    that we used for the HPA demonstration. You can find the file in the GitHub repository
    at [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml).
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们回到我们用于 HPA 演示的 `voting-application.yaml` 部署清单文件。您可以在 GitHub 仓库中找到该文件，网址为
    [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml)。
- en: 'The rolling update deployment is configured in the following way:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动更新部署的配置如下：
- en: '[PRE35]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The key part for defining rolling update deployment for your Deployment object
    is `strategy`. To configure the rolling update, you need to use `type` with the
    `RollingUpdate` value (which is also the default value). The alternative is using
    recreate, which will simply kill all Pods before creating new Pods—generally,
    you do not want to use this strategy type in production unless it is combined
    with more complex patterns such as blue-green deployments. For the `RollingUpdate`
    type, you can define `maxUnavailable`, which says how many Pods can be in a non-ready
    state during the update. Similarly, `maxSurge` defines the maximum number of Pods
    that can be created over the desired number of Pods during the deployment. You
    can specify these values as a number or percentage—by default, they are both set
    to 25%. To better understand what these numbers mean in practice, let''s analyze
    our example. With the desired number of replicas being `5`, when you trigger the
    Deployment rollout, the following sequence of events may happen:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为Deployment对象定义滚动更新部署的关键部分是`strategy`。要配置滚动更新，您需要使用`type`和`RollingUpdate`值（这也是默认值）。另一种方法是使用recreate，它将简单地杀死所有Pod，然后创建新的Pod——通常情况下，除非与更复杂的模式（如蓝绿部署）结合使用，您不希望在生产中使用这种策略类型。对于`RollingUpdate`类型，您可以定义`maxUnavailable`，它表示在更新期间有多少个Pod可以处于非就绪状态。同样，`maxSurge`定义了在部署期间可以创建的Pod的最大数量，超过所需Pod数量。您可以将这些值指定为数字或百分比——默认情况下，它们都设置为25%。为了更好地理解这些数字在实践中的含义，让我们分析一下我们的例子。当您触发Deployment的部署时，希望的副本数量为`5`，可能会发生以下事件序列：
- en: A new Pod is created. Now, we have six Pods in total, so we have reached the
    limit set by `maxSurge`.
  id: totrans-257
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个新的Pod。现在，我们总共有六个Pod，所以我们已经达到了`maxSurge`设置的限制。
- en: '`maxUnavailable` is set to `1`, and we have five Pods ready, so one old Pod
    can be terminated. We have five Pods in total, with four ready.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxUnavailable`设置为`1`，我们有五个就绪的Pod，所以可以终止一个旧的Pod。我们总共有五个Pod，其中四个是就绪的。'
- en: A new Pod is created. We again have six Pods in total but four ready. The rollout
    has to wait until more Pods become ready.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个新的Pod。现在我们总共有六个Pod，但只有四个是就绪的。部署必须等待更多的Pod就绪才能继续。
- en: One of the new Pods becomes ready. We have six Pods in total, five ready, which
    means that one old Pod can be terminated and then a new Pod is created.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中一个新的Pod就绪了。我们总共有六个Pod，其中五个是就绪的，这意味着一个旧的Pod可以被终止，然后创建一个新的Pod。
- en: This process gradually continues until all five new Pods become ready.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程逐渐持续，直到所有五个新的Pod都就绪为止。
- en: Let's see how it works in practice. First, apply the manifest file using the `kubectl
    apply -f .\voting-application.yaml` command—this will create the initial version
    of the application.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看它在实践中是如何工作的。首先，使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件——这将创建应用的初始版本。
- en: 'Rollouts for existing Deployments can be done imperatively by live-editing
    the object or using the `kubectl rollout` command. In general, it is better to
    use the declarative approach: change the manifest file and apply it again. Change
    the container image tag to `packtpubkubernetesonwindows/voting-application:1.4.0`
    in the manifest file and apply using the `kubectl apply -f .\voting-application.yaml` command.'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对现有部署的滚动更新可以通过实时编辑对象或使用`kubectl rollout`命令来进行。一般来说，最好使用声明性方法：更改清单文件，然后再次应用。在清单文件中将容器镜像标签更改为`packtpubkubernetesonwindows/voting-application:1.4.0`，然后使用`kubectl
    apply -f .\voting-application.yaml`命令进行应用。
- en: 'Quickly after that, start observing `rollout status` using the following command:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在那之后，立即开始使用以下命令观察`rollout status`：
- en: '[PRE36]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: During the rollout, you can use commands such as `kubectl rollout undo -n dev
    deployment/voting-application-frontend` or `kubectl rollout pause -n dev deployment/voting-application-frontend`
    to control the Deployment rollout. However, you can still achieve the same just
    by modifying the manifest file and applying it again—this even includes pausing.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在部署过程中，您可以使用诸如`kubectl rollout undo -n dev deployment/voting-application-frontend`或`kubectl
    rollout pause -n dev deployment/voting-application-frontend`之类的命令来控制部署的滚动。但是，您也可以通过修改清单文件并再次应用来实现相同的效果，甚至包括暂停。
- en: You can try accessing the application during the rollout. We have properly configured
    the readiness probes so you will not experience any unexpected responses from
    the application!
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以在部署过程中尝试访问应用程序。我们已经正确配置了就绪探针，因此您不会遇到应用程序的意外响应！
- en: StatefulSets also have a customizable strategy for rollouts. Due to state persistence,
    the strategy is a bit different from Deployments. You can read more in the official
    documentation, at [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets也具有可定制的部署策略。由于状态持久性，该策略与部署的策略有些不同。您可以在官方文档中阅读更多内容，网址为[https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies)。
- en: 'Now, let''s focus on another important topic in Kubernetes: **Role-Based Access
    Control** (**RBAC**).'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们专注于Kubernetes中的另一个重要主题：基于角色的访问控制（RBAC）。
- en: Role-Based Access Control
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于角色的访问控制
- en: Kubernetes comes with a built-in RBAC mechanism that allows you to configure
    fine-grained sets of permissions and assign them to users, groups, and service
    accounts (subjects). In this way, as a cluster administrator, you can control
    how cluster users (internal and external) interact with the API Server, which
    API resources they can access, and which actions (verbs) they can perform.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes带有内置的RBAC机制，允许您配置细粒度的权限集并将其分配给用户、组和服务账户（主体）。通过这种方式，作为集群管理员，您可以控制集群用户（内部和外部）与API服务器的交互方式，他们可以访问哪些API资源以及可以执行哪些操作（动词）。
- en: Authentication in Kubernetes is highly configurable and extensible; you can
    read more in the official documentation, at [https://kubernetes.io/docs/reference/access-authn-authz/authentication/](https://kubernetes.io/docs/reference/access-authn-authz/authentication/).
    In AKS Engine clusters, it is possible to easily integrate with **Azure Active
    Directory** (**AAD**); you can find more details at [https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)[.](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的身份验证是高度可配置和可扩展的；您可以在官方文档中阅读更多内容，网址为[https://kubernetes.io/docs/reference/access-authn-authz/authentication/](https://kubernetes.io/docs/reference/access-authn-authz/authentication/)。在AKS
    Engine集群中，可以轻松集成Azure Active Directory（AAD）；您可以在[https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)找到更多详细信息。
- en: 'Using RBAC involves two groups of API resources:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RBAC涉及两组API资源：
- en: '`Role` and `ClusterRole`: They define a set of permissions. Each rule in `Role`
    says which verb(s) are allowed for which API resource(s). The only difference
    between `Role` and `ClusterRole` is that `Role` is namespace-scoped whereas `ClusterRole`
    is not.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Role`和`ClusterRole`：它们定义了一组权限。`Role`中的每个规则都说明了允许对哪些API资源使用哪些动词。`Role`和`ClusterRole`之间唯一的区别是`Role`是命名空间范围的，而`ClusterRole`不是。'
- en: '`RoleBinding` and `ClusterRoleBinding`: They associate users or a set of users
    with a given role. Similarly, `RoleBinding` is namespace-scoped, `ClusterRoleBinding`
    is cluster-wide. `ClusterRoleBinding` works with `ClusterRole`, and `RoleBinding` works
    with either `ClusterRole` or `Role`.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RoleBinding`和`ClusterRoleBinding`：它们将用户或一组用户与给定角色关联起来。类似地，`RoleBinding`是命名空间范围的，`ClusterRoleBinding`是集群范围的。`ClusterRoleBinding`与`ClusterRole`配合使用，`RoleBinding`与`ClusterRole`或`Role`配合使用。'
- en: 'Kubernetes uses a permissive RBAC model—there are no deny rules; everything
    is denied by default, and you have to define allow rules. Using RBAC is well documented
    and all of the features have been presented in the official documentation, available
    at [https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/).
    There are two key points you should consider for your RBAC strategy:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用宽松的RBAC模型 - 没有拒绝规则；默认情况下拒绝一切，并且您必须定义允许规则。RBAC的使用有详细的文档，并且所有功能都在官方文档中介绍，可在[https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)上找到。您应该考虑RBAC策略的两个关键点：
- en: Use the principle of least privilege. Your applications should have access to
    their own resources only (it is recommended that you run each application using
    a dedicated service account that has access to Secrets or ConfigMaps for the very
    application). Users should have restricted access depending on their role in the
    project (for example, a QA engineer may be fine with just read-only access to
    the cluster).
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最小权限原则。您的应用程序应仅访问其自己的资源（建议您使用具有对该应用程序的Secrets或ConfigMaps访问权限的专用服务帐户来运行每个应用程序）。用户应根据其在项目中的角色拥有受限制的访问权限（例如，QA工程师可能只需要对集群具有只读访问权限）。
- en: Assign `RoleBinding` to groups instead of individual users. This will make your
    permission management much easier. Note that this requires integrating with external
    authentication providers to function best.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`RoleBinding`分配给组而不是单个用户。这将使您的权限管理更加容易。请注意，这需要与外部身份验证提供程序集成才能发挥最佳作用。
- en: 'Let''s demonstrate how to use `Role` and `RoleBinding` for the voting application
    to restrict access to the Deployment to a minimum set of ConfigMaps and Secrets
    that are needed. We will do that for the ASP.NET MVC application, and using a
    similar approach for SQL Server can be an additional exercise. For this, we will
    use the voting application Docker image, `packtpubkubernetesonwindows/voting-application:1.3.0`,
    which we used for demonstrating ConfigMaps. This Deployment requires both ConfigMaps
    and Secrets at runtime. Please follow these steps to configure RBAC:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们演示如何使用`Role`和`RoleBinding`来限制对部署的访问权限，使其仅能访问最少的所需ConfigMaps和Secrets。我们将为ASP.NET
    MVC应用程序执行此操作，并且使用类似的方法可以作为额外的练习用于SQL Server。为此，我们将使用用于演示ConfigMaps的投票应用程序Docker镜像`packtpubkubernetesonwindows/voting-application:1.3.0`。此部署在运行时需要ConfigMaps和Secrets。请按照以下步骤配置RBAC：
- en: 'Create the `serviceaccount.yaml` manifest file for the dedicated ServiceAccount,
    named `voting-application`:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`serviceaccount.yaml`清单文件，用于专用ServiceAccount，命名为`voting-application`：
- en: '[PRE37]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Apply the manifest file using the `kubectl apply -f .\serviceaccount.yaml` command.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\serviceaccount.yaml`命令应用清单文件。
- en: 'Create the `role.yaml` manifest file for `Role` for reading Secrets and ConfigMaps
    for the application:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`Role`创建`role.yaml`清单文件，用于读取应用程序的Secrets和ConfigMaps：
- en: '[PRE38]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Use the `kubectl auth reconcile -f .\role.yaml` command to apply `Role`. Using
    `kubectl auth reconcile` is recommended over `kubectl apply`.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl auth reconcile -f .\role.yaml`命令来应用`Role`。建议使用`kubectl auth reconcile`而不是`kubectl
    apply`。
- en: 'Create the `rolebinding.yaml` manifest file for `RoleBinding`, which associates
    our ServiceAccount with the preceding role:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`RoleBinding`创建`rolebinding.yaml`清单文件，将我们的ServiceAccount与前面的角色关联起来：
- en: '[PRE39]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Use the `kubectl auth reconcile -f .\rolebinding.yaml` command to apply `RoleBinding`.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl auth reconcile -f .\rolebinding.yaml`命令应用`RoleBinding`。
- en: Check whether RBAC allows access to the ConfigMap for the ServiceAccount. You
    can use the `kubectl auth can-i get configmap/voting-application-customerrors-config
    -n dev --as system:serviceaccount:dev:voting-application` command or visualize
    all accessible API resources using the `kubectl auth can-i --list -n dev --as
    system:serviceaccount:dev:voting-application` command.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查RBAC是否允许ServiceAccount访问ConfigMap。您可以使用`kubectl auth can-i get configmap/voting-application-customerrors-config
    -n dev --as system:serviceaccount:dev:voting-application`命令，或者使用`kubectl auth
    can-i --list -n dev --as system:serviceaccount:dev:voting-application`命令可视化所有可访问的API资源。
- en: 'Modify the `voting-application.yaml` manifest file so that the Deployment uses
    the `voting-application` ServiceAccount:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`voting-application.yaml`清单文件，使部署使用`voting-application` ServiceAccount：
- en: '[PRE40]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Apply the Deployment manifest file using the `kubectl apply -f .\voting-application.yaml`
    command.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\voting-application.yaml`命令应用部署清单文件。
- en: You can perform a similar operation for users in your cluster, for example,
    by defining Roles that allow read-only access to all API resources.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以执行类似的操作，例如通过定义允许对所有API资源进行只读访问的角色来为集群中的用户进行操作。
- en: Congratulations! You have successfully set up RBAC for the voting application.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功为投票应用程序设置了RBAC。
- en: Summary
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we demonstrated several commonly used, advanced features of
    Kubernetes. First, you learned what the purpose of namespaces in Kubernetes is
    and how to manage them. Then, we introduced readiness, liveness, and startup probes,
    which are used for monitoring the life cycle of Pod containers—and we provided
    you with a set of recommended practices when working with probes and how to avoid
    common pitfalls. The next step was learning how to specify Pod resource requests
    and limits and how to combine this with autoscaling using the HPA. To inject configuration
    data (including sensitive passwords) into our application, we used ConfigMaps
    and Secrets. On top of that, we have demonstrated how to use PersistentVolumes
    (backed by the azureDisk Volume plugin) in StatefulSets running on Windows nodes.
    And lastly, you learned how to approach rolling updates for Deployment objects
    and what the purpose of RBAC in Kubernetes is.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们演示了Kubernetes的几个常用高级功能。首先，您了解了Kubernetes中命名空间的目的以及如何管理它们。然后，我们介绍了就绪、存活和启动探针，这些用于监视Pod容器的生命周期，并为您提供了一组在处理探针时的推荐实践以及如何避免常见陷阱。接下来是学习如何指定Pod资源请求和限制，以及如何结合HPA进行自动缩放。为了将配置数据（包括敏感密码）注入到我们的应用程序中，我们使用了ConfigMaps和Secrets。除此之外，我们还演示了如何在运行在Windows节点上的StatefulSets中使用PersistentVolumes（由azureDisk
    Volume插件支持）。最后，您了解了如何处理部署对象的滚动更新，以及Kubernetes中RBAC的目的。
- en: The next chapter will focus on development workflows with Kubernetes and how
    you can cooperate with other developers when creating Kubernetes applications.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将重点介绍使用Kubernetes的开发工作流程，以及在创建Kubernetes应用程序时如何与其他开发人员合作。
- en: Questions
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: When should you consider using Kubernetes namespaces?
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时应考虑使用Kubernetes命名空间？
- en: What is the difference between readiness and liveness probes?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就绪和存活探针之间有什么区别？
- en: What are the risks of using a liveness probe with inappropriate configuration?
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不当配置的存活探针有哪些风险？
- en: What is the difference between resource `requests` and `limits` values for Pod
    containers?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod容器的资源`requests`和`limits`值有什么区别？
- en: What is the purpose of delay for cooldown in the HPA?
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA中冷却延迟的目的是什么？
- en: What is the difference between ConfigMaps and Secrets?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ConfigMaps和Secrets之间有什么区别？
- en: What is `volumeClaimTemplates` in StatefulSet spec?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: StatefulSet规范中的`volumeClaimTemplates`是什么？
- en: Why should you ensure the proper configuration of readiness probes when using
    rolling updates for Deployments?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用滚动更新部署时，为什么要确保就绪探针的正确配置？
- en: What are the most important rules of thumb when using RBAC in Kubernetes?
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kubernetes中使用RBAC时，最重要的经验法则是什么？
- en: You can find answers to these questions in the *Assessment* of this book.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的*评估*部分找到这些问题的答案。
- en: Further reading
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information about Kubernetes features and how to manage applications,
    please refer to the following Packt books:'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关Kubernetes功能和应用程序管理的更多信息，请参考以下Packt图书：
- en: '*The Complete Kubernetes Guide* by Jonathan Baier, Gigi Sayfan, Et al ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)).'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*The Complete Kubernetes Guide* by Jonathan Baier, Gigi Sayfan, Et al ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)).'
- en: '*Getting Started with Kubernetes - Third Edition* by Jonathan Baier, Jesse
    White ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)).'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Getting Started with Kubernetes - Third Edition* by Jonathan Baier, Jesse
    White ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)).'
- en: '*Kubernetes for Developers* by Joseph Heck ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes for Developers* by Joseph Heck ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)).'
