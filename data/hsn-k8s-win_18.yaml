- en: Monitoring Kubernetes Applications Using Prometheus
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Prometheus监控Kubernetes应用程序
- en: Kubernetes as a containers orchestrator is a complex, distributed system that
    requires monitoring and alerting to function properly at scale. At the same time,
    you need to monitor your applications running on Kubernetes in the same manner—if
    you do not have monitoring and alerting in place, you have no idea how your application
    behaves, whether any failures occur, or whether you should scale up your workload.
    In fact, the challenges connected with monitoring and alerting are among the most
    often-reported blockers for the adoption of Kubernetes by enterprises.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作为容器编排器的Kubernetes是一个复杂的分布式系统，需要监控和警报才能在规模上正常运行。同时，您需要以相同的方式监控在Kubernetes上运行的应用程序——如果没有监控和警报，您就不知道应用程序的行为如何，是否发生任何故障，或者是否应该扩展工作负载。事实上，与监控和警报相关的挑战是企业采用Kubernetes时最常报告的阻碍之一。
- en: Fortunately, over the years, the market has boomed with multiple solutions for
    log aggregation, telemetry gathering, alerting, and even dedicated **Application
    Performance Management** (**APM**) systems. We can choose from different Software-as-a-Service
    (**SaaS**) solutions or open source systems that can be hosted on-premises, all
    dedicated just for Kubernetes clusters!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，多年来，市场上涌现出了多种日志聚合、遥测收集、警报甚至专门的**应用性能管理**（**APM**）系统的解决方案。我们可以选择不同的软件即服务（**SaaS**）解决方案或开源系统，这些系统可以在本地托管，专门用于Kubernetes集群！
- en: 'But there is the other side of the coin: we are constrained to solutions that
    can support Windows containers and Windows-based Kubernetes nodes. Production-grade
    support for Windows in Kubernetes is very recent and there are no turnkey solutions
    that work just out of the box. Therefore, this chapter aims to provide an overview
    of the available monitoring solutions for Kubernetes in general and explore how
    you can implement your own solution that supports Windows nodes.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但是另一面是：我们受限于可以支持Windows容器和基于Windows的Kubernetes节点的解决方案。在Kubernetes中对Windows的生产级支持是非常近期的，没有可以立即使用的一揽子解决方案。因此，本章旨在概述Kubernetes的可用监控解决方案，并探讨如何实现支持Windows节点的自己的解决方案。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Available monitoring solutions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的监控解决方案
- en: Provisioning observable Windows nodes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供可观察的Windows节点
- en: Deploying Prometheus using a Helm chart
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Helm图表部署Prometheus
- en: Windows Performance Counters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows性能计数器
- en: Monitoring .NET applications using `prometheus-net`
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`prometheus-net`监控.NET应用程序
- en: Configuring dashboards and alerts in Grafana
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Grafana中配置仪表板和警报
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章，您将需要以下内容：
- en: Windows 10 Pro, Enterprise, or Education (version 1903 or later, 64-bit) installed
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Windows 10 Pro、企业版或教育版（1903版或更高版本，64位）
- en: Microsoft Visual Studio 2019 Community (or any other edition) if you want to
    edit the source code for the application and debug it—Visual Studio Code has limited
    support for classic .NET Framework
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Visual Studio 2019 Community（或任何其他版本），如果您想编辑应用程序的源代码并进行调试——Visual
    Studio Code对经典.NET Framework的支持有限
- en: Helm installed
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已安装Helm
- en: An Azure account
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure账户
- en: A Windows/Linux Kubernetes cluster deployed using AKS Engine, ready to deploy
    the voting application from the previous chapter
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AKS Engine部署的Windows/Linux Kubernetes集群，准备部署上一章中的投票应用程序
- en: To follow along, you will need your own Azure account to create Azure resources
    for the Kubernetes cluster. If you haven't already created the account for the
    previous chapters, you can read more about how to obtain a limited free account
    for personal use here: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟进，您将需要自己的Azure帐户来为Kubernetes集群创建Azure资源。如果您还没有为之前的章节创建帐户，您可以在此处阅读有关如何获取用于个人使用的有限免费帐户的更多信息：[https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/)。
- en: Deploying a Kubernetes cluster using AKS Engine has been covered in [Chapter
    8](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml), *Deploying a Hybrid Azure Kubernetes
    Service Engine Cluster*. The voting application Deployment to Kubernetes has been
    covered in [Chapter 10](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml), *Deploying
    Microsoft SQL Server 2019 and ASP.NET MVC Application*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AKS Engine部署Kubernetes集群已在[第8章](ab695a0d-05dc-48f8-8c41-bbd167cfbfa6.xhtml)中进行了介绍，*部署混合Azure
    Kubernetes服务引擎集群*。将投票应用程序部署到Kubernetes已在[第10章](4e5931bc-4267-4631-a5fe-bc140827257d.xhtml)中进行了介绍，*部署Microsoft
    SQL Server 2019和ASP.NET MVC应用程序*。
- en: You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从官方GitHub存储库下载本章的最新代码示例：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14)。
- en: Available monitoring solutions
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可用的监控解决方案
- en: 'The word monitoring is commonly used as an umbrella term that covers the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 单词“监控”通常被用作一个涵盖以下内容的总称：
- en: '**Observability**: Providing observability for your components means exposing information
    about their inner state so that you can access the data easily and do reasoning
    about the actual state of your components. In other words, if something is observable,
    you can understand it. A well-known example of a feature that provides observability
    is logging. Your applications produce logs so that you can examine the flow and
    the current state of your application. There are three pillars of observability:
    logging, distributed tracing, and metrics. Distributed tracing provides insight
    into the flow of a request going through multiple services, for example, using
    correlation IDs. Metrics can be just numeric information exposed by your application,
    for example, counters or gauges.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可观察性：**为您的组件提供可观察性意味着公开有关其内部状态的信息，以便您可以轻松访问数据并对组件的实际状态进行推理。换句话说，如果某物是可观察的，您就可以理解它。提供可观察性的一个众所周知的特性示例是日志记录。您的应用程序生成日志，以便您可以检查应用程序的流程和当前状态。可观察性有三个支柱：日志记录、分布式跟踪和指标。分布式跟踪提供了对请求流经多个服务的洞察，例如使用关联ID。指标可以是应用程序公开的数字信息，例如计数器或量规。'
- en: '**Monitoring:** This means collecting observable data for your components and
    storing it so that it can be analyzed.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控：**这意味着收集组件的可观察数据并存储它，以便进行分析。'
- en: '**Analysis and Alerting:** Based on collected monitoring data, you can perform
    analysis, create rules when a component is considered unhealthy, and configure
    alerting for your team. More complex scenarios involve, for example, anomaly detection
    and machine learning.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析和警报：**基于收集的监控数据，您可以进行分析，当组件被视为不健康时创建规则，并为您的团队配置警报。更复杂的情况涉及异常检测和机器学习。'
- en: 'In Kubernetes, monitoring has even more dimensions than monitoring a single
    application. Generally, you can divide the monitoring of a Kubernetes cluster
    into the following separate areas:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，监控比监控单个应用程序还要复杂。通常，您可以将Kubernetes集群的监控划分为以下几个独立的领域：
- en: Monitoring hardware and operating system infrastructure of Kubernetes nodes
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控Kubernetes节点的硬件和操作系统基础设施
- en: Monitoring container runtime
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控容器运行时
- en: Monitoring Kubernetes components and resources themselves
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控Kubernetes组件和资源本身
- en: Monitoring containerized applications running in the cluster
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控在集群中运行的容器化应用程序
- en: 'And finally, you can look at monitoring systems from the perspective of how
    the solution is hosted and related to Kubernetes:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以从托管解决方案与Kubernetes相关的角度来查看监控系统：
- en: '**On-premises** **monitoring**: Using your own cloud or bare-metal infrastructure,
    you either provide a separate cluster just for running monitoring tools or use
    the same cluster as for applications. The second solution is much easier but can
    be considered only for small Kubernetes clusters. You want to separate application
    and monitoring workloads; you especially don''t want monitoring to negatively influence
    your application''s performance. An example of this approach is deploying your
    own Prometheus ([https://prometheus.io/](https://prometheus.io/)) instance to
    collect metrics in your Kubernetes cluster, together with a log analytics solution
    such as the **Elasticsearch, Logstash, Kibana** (**ELK**) stack ([https://www.elastic.co/what-is/elk-stack](https://www.elastic.co/what-is/elk-stack)).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地监控**：使用自己的云或裸金属基础设施，您可以为运行监控工具提供单独的集群，或者使用与应用程序相同的集群。第二种解决方案更容易，但只能考虑用于小型Kubernetes集群。您希望分开应用程序和监控工作负载；您特别不希望监控对应用程序的性能产生负面影响。这种方法的一个示例是部署自己的Prometheus
    ([https://prometheus.io/](https://prometheus.io/))实例来收集Kubernetes集群中的指标，以及日志分析解决方案，例如**Elasticsearch,
    Logstash, Kibana** (**ELK**) stack ([https://www.elastic.co/what-is/elk-stack](https://www.elastic.co/what-is/elk-stack))。'
- en: '**Internal SaaS** **monitoring**: If you are running in the cloud, you can
    use SaaS offerings provided by your cloud service provider, for example, on Azure,
    you can use Azure Monitor ([https://azure.microsoft.com/en-us/services/monitor/](https://azure.microsoft.com/en-us/services/monitor/)).
    Such solutions often easily integrate with other managed services, such as AKS.
    Additionally, for log monitoring, you can leverage Log Analytics in Azure Monitor
    ([https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal](https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal)).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部SaaS监控**：如果您在云中运行，可以使用云服务提供商提供的SaaS产品，例如在Azure上，您可以使用Azure Monitor ([https://azure.microsoft.com/en-us/services/monitor/](https://azure.microsoft.com/en-us/services/monitor/))。这些解决方案通常很容易与其他托管服务集成，例如AKS。此外，对于日志监控，您可以利用Azure
    Monitor中的Log Analytics ([https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal](https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal))。'
- en: '**External SaaS monitoring**: In this case, you use a dedicated, generic SaaS
    offering from an external company that can monitor your cluster running in any
    cloud or even on-premises. The market of monitoring platforms is big—well-known
    examples are New Relic ([https://newrelic.com/platform](https://newrelic.com/platform))
    and Dynatrace ([https://www.dynatrace.com/technologies/kubernetes-monitoring/](https://www.dynatrace.com/technologies/kubernetes-monitoring/)).'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部SaaS监控**：在这种情况下，您可以使用外部公司提供的专用通用SaaS产品来监控在任何云中甚至本地运行的集群。监控平台的市场很大，其中一些知名的例子是New
    Relic ([https://newrelic.com/platform](https://newrelic.com/platform))和Dynatrace
    ([https://www.dynatrace.com/technologies/kubernetes-monitoring/](https://www.dynatrace.com/technologies/kubernetes-monitoring/))。'
- en: Generally, using internal SaaS monitoring is cheaper than external SaaS but
    you risk more vendor lock-in and increase your dependency ona given cloud service
    provider. Using on-premises monitoring, which you deploy yourself, is the most
    flexible and cheapest, but you have to consider the management and operations
    overhead that comes with an additional large application.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，使用内部SaaS监控比使用外部SaaS更便宜，但您面临更多的供应商锁定风险，并增加了对特定云服务提供商的依赖性。使用您自己部署的本地监控是最灵活和最便宜的，但您必须考虑随之而来的管理和运营开销，因为这需要额外的大型应用程序。
- en: There is still the question of what to monitor. You can learn more about the
    Four Golden Signals in the following online book from Google: [https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/).
    Find out about the **USE** (short for**Utilization Saturation and Errors**) method
    in the following article: [http://www.brendangregg.com/usemethod.html](http://www.brendangregg.com/usemethod.html).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 关于监控的问题仍然存在。您可以在谷歌的以下在线书籍中了解更多关于四个黄金信号的信息：[https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/)。在以下文章中了解**USE**（即**Utilization
    Saturation and Errors**）方法：[http://www.brendangregg.com/usemethod.html](http://www.brendangregg.com/usemethod.html)。
- en: And now, hybrid Windows/Linux Kubernetes clusters come into the picture. It
    is important to know that monitoring Windows machines is quite different from
    monitoring Linux machines—you cannot use the same monitoring agents; they have
    to be dedicated to a given operating system.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，混合Windows/Linux Kubernetes集群进入了视野。重要的是要知道，监控Windows机器与监控Linux机器有很大不同——您不能使用相同的监控代理；它们必须专门针对特定的操作系统。
- en: Even in the case of Docker, the way it integrates into the operating system
    is different from Linux and Windows, which also means that the container runtime
    monitoring must be done differently. This is the reason why currently there are no
    turnkey solutions for monitoring Windows nodes in Kubernetes. The closest to providing
    this is the Container Monitoring solution in Azure Monitor ([https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers](https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers)),
    which can provide telemetry data for Windows containers but does not integrate
    with hybrid AKS or AKS Engine yet. You can still, of course, configure it manually
    on the machines that are part of AKS Engine.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在Docker的情况下，它与操作系统的集成方式与Linux和Windows不同，这也意味着容器运行时监控必须以不同的方式进行。这就是为什么目前在Kubernetes中没有用于监控Windows节点的即插即用解决方案的原因。提供最接近的是Azure
    Monitor中的容器监控解决方案（[https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers](https://docs.microsoft.com/en-us/azure/azure-monitor/insights/containers)），它可以为Windows容器提供遥测数据，但尚未与混合AKS或AKS
    Engine集成。当然，您仍然可以在AKS Engine的机器上手动配置它。
- en: So, what other solution do we have? As a more generic solution, we propose deploying
    a Prometheus instance that will be able to monitor metrics from Linux workloads
    by default and can be extended to monitor Windows nodes and containers.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们还有什么其他解决方案吗？作为更通用的解决方案，我们建议部署一个Prometheus实例，它将能够默认监控来自Linux工作负载的指标，并可以扩展到监控Windows节点和容器。
- en: Distributed tracing and aggregating logs in your cluster are complex monitoring
    topics on their own. In this book, we will cover metrics monitoring only. If you
    are interested in logging solutions for Kubernetes, please check the official
    documentation: [https://kubernetes.io/docs/concepts/cluster-administration/logging/](https://kubernetes.io/docs/concepts/cluster-administration/logging/).
    For distributed tracing, consider reading about Jaeger: [https://www.jaegertracing.io/](https://www.jaegertracing.io/).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的集群中进行分布式跟踪和聚合日志是复杂的监控主题。在本书中，我们只会涵盖度量监控。如果您对Kubernetes的日志记录解决方案感兴趣，请查看官方文档：[https://kubernetes.io/docs/concepts/cluster-administration/logging/](https://kubernetes.io/docs/concepts/cluster-administration/logging/)。对于分布式跟踪，请考虑阅读关于Jaeger的信息：[https://www.jaegertracing.io/](https://www.jaegertracing.io/)。
- en: Let's take a look at how we can provide metric monitoring for hybrid Kubernetes
    clusters using Prometheus.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Prometheus为混合Kubernetes集群提供度量监控。
- en: Prometheus and monitoring Windows nodes
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus和监控Windows节点
- en: 'Prometheus ([https://prometheus.io/](https://prometheus.io/)) is an open source
    monitoring system for metrics, which uses the PromQL language for exploring time
    series data. It utilizes the concept of exporters and the HTTP pull model where
    exporters expose the data on a specified HTTP endpoint and are periodically scraped
    by the Prometheus server. Alternatively, it can use the HTTP push model, which
    is generally not recommended but sometimes useful. The format used for exposing
    metrics is a simple text format where each line represents one value of a metric,
    which has roughly the following form:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus ([https://prometheus.io/](https://prometheus.io/)) 是一个用于度量监控的开源系统，使用PromQL语言来探索时间序列数据。它利用了“exporters”和HTTP拉取模型的概念，其中exporters在指定的HTTP端点上公开数据，并定期被Prometheus服务器抓取。另外，它还可以使用HTTP推送模型，通常不建议使用，但有时会很有用。用于公开度量的格式是一个简单的文本格式，其中每一行代表一个度量的值，大致形式如下：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Prometheus stores all data as time series, which are streams of readings for
    the same metric throughout the time—the exporters expose only the current value
    of a metric and Prometheus is responsible for storing the history as a time series.
    In this example, `http_requests_total` is the name of the metric, `method` is
    a label name, `"post"` is the label value, and `190` is the value of the metric
    right now. Labels are used for providing dimensions for your time series data,
    which can then be used for various operations such as filtering and aggregating
    in PromQL. The general format for a single reading is `<metric name>{<label name>=<label
    value>, ...} <metric_value>`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus将所有数据存储为时间序列，这些时间序列是同一度量的读数流，覆盖了整个时间范围。exporters仅公开度量的当前值，而Prometheus负责将历史存储为时间序列。在这个例子中，`http_requests_total`是度量的名称，`method`是标签名称，`"post"`是标签值，`190`是当前的度量值。标签用于为您的时间序列数据提供维度，然后可以在PromQL中用于各种操作，如过滤和聚合。单个读数的一般格式是`<metric
    name>{<label name>=<label value>, ...} <metric_value>`。
- en: You can read more about this format in the official documentation: [https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md](https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md)[. ](https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在官方文档中阅读更多关于这种格式的信息：[https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md](https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md)。
- en: 'On top of Prometheus, you will commonly use Alertmanager for configuring alerting
    and Grafana ([https://grafana.com/](https://grafana.com/)) or Kibana ([https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana))
    for dashboards and visualizations. The following diagram shows the architecture
    of Prometheus at a high level and how it monitors Linux workloads running in Kubernetes:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在Prometheus之上，您通常会使用Alertmanager来配置警报和Grafana（[https://grafana.com/](https://grafana.com/)）或Kibana（[https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)）来创建仪表板和可视化。以下图表显示了Prometheus在高层次上的架构以及它如何监视在Kubernetes中运行的Linux工作负载：
- en: '![](assets/959c13db-97a5-495b-8d3d-26cc3b30e464.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/959c13db-97a5-495b-8d3d-26cc3b30e464.png)'
- en: Common Prometheus architecture for monitoring Linux containers on Kubernetes
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于监视Kubernetes上Linux容器的常见Prometheus架构
- en: 'Apart from standard Prometheus components, there are two key exporters running on
    eachLinux node in the cluster: **cAdvisor**, which exposes container runtime metrics,
    and **Node** **Exporter**,which is responsible for exposing the operating system
    and hardware metrics. For Windows, we can use a similar scheme but we need to
    use different exporters, as shown in the following diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的Prometheus组件之外，在集群中每个Linux节点上运行着两个关键的导出器：**cAdvisor**，它公开容器运行时指标，以及**Node
    Exporter**，它负责公开操作系统和硬件指标。对于Windows，我们可以使用类似的方案，但我们需要使用不同的导出器，如下图所示：
- en: '![](assets/df756732-0303-496d-8a54-2d0270aef7ec.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/df756732-0303-496d-8a54-2d0270aef7ec.png)'
- en: Possible Prometheus architecture for monitoring Windows containers on Kubernetes
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 用于监视Kubernetes上Windows容器的可能的Prometheus架构
- en: In this case, to expose OS and hardware metrics, we use WMI Exporter, which
    is dedicated to Windows machines. It can also expose some Docker metrics, but
    we additionally can turn on the experimentalfeature of exposing metrics with Docker
    Engine natively, without an additional exporter. You can read more about this
    Docker feature in the documentation: [https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为了公开操作系统和硬件指标，我们使用专门用于Windows机器的WMI Exporter。它还可以公开一些Docker指标，但我们还可以打开使用Docker
    Engine本地公开指标的实验性功能，而无需额外的导出器。您可以在文档中阅读更多关于这个Docker功能的信息：[https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/)。
- en: Generally, on Windows, it is more problematic to deploy exporters as Kubernetes
    DaemonSets that gather OS metrics. As mentioned in the previous chapters, on Windows,
    you cannot run privileged containers so you will not have access to container
    runtime information. This is the main reason why monitoring Windows containers
    in Kubernetes is a bit harder than Linux containers—we have to configure the exporters
    outside of the Kubernetes cluster, directly on the host. Now, let's see how you
    can achieve that in an on-premises scenario and AKS Engine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，在Windows上，部署导出器作为收集操作系统指标的Kubernetes DaemonSets更加困难。正如前几章中提到的，在Windows上，您无法运行特权容器，因此无法访问容器运行时信息。这就是为什么在Kubernetes中监视Windows容器比监视Linux容器要困难一些的主要原因——我们必须在Kubernetes集群之外直接在主机上配置导出器。现在，让我们看看在本地场景和AKS
    Engine中如何实现这一点。
- en: Provisioning observable Windows nodes
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供可观察的Windows节点
- en: The HTTP pull model that Prometheus uses perfectly aligns with the separation
    of concerns between observability and monitoring itself. The component or machine
    is responsible for exposing appropriate data and metrics—it allows being observed—and
    Prometheus periodically consumes the available data in the process called scraping.
    This means that if you have a way of exposing metrics in Prometheus format at
    some HTTP endpoint, you can use Prometheus for monitoring! It can be hardware
    telemetry exposed by a system service or even your own metrics accessible by an
    additional HTTP endpoint in your .NET application.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus使用的HTTP拉模型与可观察性和监视本身之间的关注点分离完全一致。组件或机器负责暴露适当的数据和指标-它允许被观察-而Prometheus定期消耗可用数据，这个过程称为抓取。这意味着如果您有一种方法可以在某个HTTP端点以Prometheus格式暴露指标，您就可以使用Prometheus进行监视！它可以是系统服务暴露的硬件遥测，甚至是您在.NET应用程序中通过额外的HTTP端点访问的自己的指标。
- en: 'Now, there is the question of how to gather the metrics data on the Windows
    operating system and expose it. We are interested in the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有一个问题，如何在Windows操作系统上收集指标数据并将其暴露出来。我们对以下内容感兴趣：
- en: Hardware-related metrics, for example, CPU, memory, network, and I/O metrics
    for the host machine
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与主机机器相关的指标，例如CPU、内存、网络和I/O指标
- en: Metrics for processes and the host operating system itself and performance counters
    in general
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程和主机操作系统本身的指标以及性能计数器通常
- en: Metrics for the container runtime itself
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时本身的指标
- en: Metrics for individual containers
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个容器的指标
- en: In the case of bare-metal machines, additionally, information about hardware
    metrics such as CPU temperature and ECC memory correction counts
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在裸机上，此外，关于硬件指标的信息，如CPU温度和ECC内存校正计数。
- en: For Prometheus, the support for exporters on Windows is still expanding but
    currently, we can already collect most of the preceding metrics. In general, WMI
    Exporter ([https://github.com/martinlindhe/wmi_exporter](https://github.com/martinlindhe/wmi_exporter))
    is the recommended exporter for collecting all hardware-related and OS-related
    metrics on Windows. For the Docker runtime and containers, we can use an experimental
    feature of Docker ([https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/))
    that enables exposing the metrics in Prometheus format. Additionally, WMI Exporter
    can expose some useful Docker containers metrics when the container collector
    is enabled in the configuration.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Prometheus来说，在Windows上支持出口器的支持仍在扩展，但目前，我们已经可以收集大部分前述的指标。总的来说，WMI Exporter（[https://github.com/martinlindhe/wmi_exporter](https://github.com/martinlindhe/wmi_exporter)）是在Windows上收集所有与硬件和操作系统相关的指标的推荐出口器。对于Docker运行时和容器，我们可以使用Docker的一个实验性功能（[https://docs.docker.com/config/thirdparty/prometheus/](https://docs.docker.com/config/thirdparty/prometheus/)）来以Prometheus格式暴露指标。此外，当在配置中启用容器收集器时，WMI
    Exporter还可以暴露一些有用的Docker容器指标。
- en: If you are interested in any other Windows Performance Counters, you can use
    Telegraf ([https://www.influxdata.com/time-series-platform/telegraf/](https://www.influxdata.com/time-series-platform/telegraf/))
    to expose them as metrics in Prometheus format. We will do that in the next sections
    as there are very valid use cases for monitoring Windows Performance Counters
    on the host as well as inside a container.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对任何其他Windows性能计数器感兴趣，可以使用Telegraf（[https://www.influxdata.com/time-series-platform/telegraf/](https://www.influxdata.com/time-series-platform/telegraf/)）将它们暴露为Prometheus格式的指标。我们将在接下来的部分中进行这样的操作，因为在主机上监视Windows性能计数器以及容器内部都有非常有效的用例。
- en: Installing WMI Exporter and enabling Metrics Server in Docker
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装WMI Exporter并在Docker中启用Metrics Server
- en: 'Now, we know a bit of the theory of how to make a Windows machine observable
    for Prometheus and which components can fulfill our requirements. The installation
    of WMI Exporter is fairly simple if you use Chocolatey:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对如何使Windows机器对Prometheus可观察以及哪些组件可以满足我们的要求有了一些了解。如果您使用Chocolatey，WMI Exporter的安装非常简单：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This command will install the exporter with the default configuration and expose
    the metrics at the endpoint, `http://0.0.0.0:9182`, as described in the documentation
    for the package: [https://chocolatey.org/packages/prometheus-wmi-exporter.install](https://chocolatey.org/packages/prometheus-wmi-exporter.install).
    For our use case, we need some specific collectors enabled and this information
    can be passed to the installer as a parameter. Additionally, we should make the
    installation unattended and install Chocolatey if it is missing on the machine—our
    PowerShell script would look like the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将使用默认配置安装导出器，并在端点`http://0.0.0.0:9182`上公开指标，如软件包文档中所述：[https://chocolatey.org/packages/prometheus-wmi-exporter.install](https://chocolatey.org/packages/prometheus-wmi-exporter.install)。对于我们的用例，我们需要启用一些特定的收集器，并且这些信息可以作为参数传递给安装程序。此外，我们应该使安装无人值守，并在机器上安装Chocolatey（如果缺少）-我们的PowerShell脚本将如下所示：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To enable Metrics Server, in Docker Engine at `http://0.0.0.0:9323`, we can
    create another small PowerShell script:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Docker Engine中启用Metrics Server，位于`http://0.0.0.0:9323`，我们可以创建另一个小的PowerShell脚本：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, you have to consider how you are going to perform the installation. For
    on-premises Deployments, consider the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您必须考虑如何执行安装。对于本地部署，请考虑以下内容：
- en: If you use automation for creating your Kubernetes cluster, for example, Ansible,
    then you can add additional post-configuration steps.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用自动化创建Kubernetes集群，例如Ansible，那么您可以添加额外的后配置步骤。
- en: If you use bare-metal images or VM images for your machines in the cluster,
    you can embed the installation steps in the image provisioning process.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您在集群中为您的机器使用裸机映像或VM映像，您可以将安装步骤嵌入到映像配置过程中。
- en: If you manage your machines using Ansible or PowerShell Desired State Configuration,
    you can also trigger the installation using these tools.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用Ansible或PowerShell Desired State Configuration来管理您的机器，您也可以使用这些工具触发安装。
- en: 'In the case of cloud Deployments, everything depends on whether you are using
    managed or unmanaged clusters:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在云部署的情况下，一切取决于您是使用托管还是非托管集群：
- en: For managed Deployments such as AKS, you are limited to what the service allows;
    for example, you can use VMSS with Custom Script Extensions.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于像AKS这样的托管部署，您受到服务允许的限制；例如，您可以使用带有自定义脚本扩展的VMSS。
- en: For unmanaged Deployments, you can use the same techniques as for on-premises
    Deployments, for example, providing a custom VM image with preinstalled services,
    or use solutions specifically for your cloud service provider.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于非托管部署，您可以使用与本地部署相同的技术，例如提供预安装服务的自定义VM映像，或者使用专门针对您的云服务提供商的解决方案。
- en: 'For AKS Engine specifically, you have three options:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AKS Engine，您有三个选项：
- en: For development and testing purposes, you can use RDP or SSH to connect to the
    Windows machine and perform the installation manually.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于开发和测试目的，您可以使用RDP或SSH连接到Windows机器并手动执行安装。
- en: You can use a custom VM image for Windows nodes ([https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md)).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以为Windows节点使用自定义VM映像（[https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/windows-vhd.md)）。
- en: You can use AKS Engine extensions ([https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md)),
    which are implemented as Custom Script Extensions running as a part of the Deployment.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用AKS Engine扩展([https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md))，它们作为部署的一部分运行的自定义脚本扩展。
- en: We are going to demonstrate how you can customize your AKS Engine cluster Deployment
    using a dedicated extension.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何使用专用扩展自定义AKS Engine集群部署。
- en: Using extensions for AKS Engine
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AKS Engine的扩展
- en: AKS Engine extensions are a feature that enables additional customization steps
    as post-provisioning steps in the Deployment. For example, you can execute any
    PowerShell script that you provide through the extensions repository. The repository
    can be any HTTP server that follows a convention in directory naming—this also
    includes raw GitHub repository access endpoints. To learn more about how the extensions
    work, please refer to the official documentation: [https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md).
    You can use the `winrm` extension as a good base to understand the implementation
    details: [https://github.com/Azure/aks-engine/tree/master/extensions/winrm](https://github.com/Azure/aks-engine/tree/master/extensions/winrm).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: AKS Engine扩展是一项功能，它允许在部署的后期步骤中进行额外的自定义步骤。例如，您可以通过扩展存储库执行任何提供的PowerShell脚本。存储库可以是遵循目录命名约定的任何HTTP服务器，这也包括原始的GitHub存储库访问端点。要了解有关扩展如何工作的更多信息，请参阅官方文档：[https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/extensions.md)。您可以使用`winrm`扩展作为了解实现细节的良好基础：[https://github.com/Azure/aks-engine/tree/master/extensions/winrm](https://github.com/Azure/aks-engine/tree/master/extensions/winrm)。
- en: Using extensions is possible during the cluster Deployment only. You cannot
    enable an extension on a running cluster. Additionally, due to the SQL Server
    Helm chart requiring four volumes to be mounted on a single node, we need to use
    a larger VM type for Linux nodes, for example, Standard_D4_v3, which supports
    up to eight volumes. You can read more about the maximum number of volumes mounted
    per VM in the documentation: [https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群部署期间可以使用扩展。您不能在运行的集群上启用扩展。此外，由于SQL Server Helm图表需要在单个节点上挂载四个卷，我们需要为Linux节点使用更大的VM类型，例如Standard_D4_v3，该类型支持最多八个卷。您可以在文档中阅读有关每个VM挂载的最大卷数：[https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general)。
- en: 'In the GitHub repository for this book, you can find an extension that installs
    WMI Exporter and enables Docker Metrics Server on Windows: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters/).
    Let''s see how the extension is built and how to deploy a new AKS Engine cluster
    with the extension:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的GitHub存储库中，您可以找到一个安装WMI Exporter并在Windows上启用Docker Metrics Server的扩展：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/03_aks-engine-windows-extensions/extensions/prometheus-exporters/)。让我们看看扩展是如何构建的，以及如何使用扩展部署新的AKS
    Engine集群：
- en: 'The PowerShell script, `v1/installExporters.ps1`, performs the custom installation
    logic and has the following contents:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PowerShell脚本`v1/installExporters.ps1`执行自定义安装逻辑，并具有以下内容：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: It will install WMI Exporter using Chocolatey, enable the Metrics Server for
    Docker, and restart Docker afterward.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它将使用Chocolatey安装WMI Exporter，为Docker启用Metrics Server，并在之后重新启动Docker。
- en: 'The `v1/template.json` JSON file contains an ARM template that triggers the
    PowerShell script, the key part of which is as follows:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`v1/template.json` JSON文件包含一个ARM模板，触发PowerShell脚本的关键部分如下：'
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This configures properties for the Custom Script Extension, which will download
    the installation script and execute it with parameters that you pass in the cluster
    apimodel.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为自定义脚本扩展配置属性，该扩展将下载安装脚本，并使用您在集群apimodel中传递的参数执行它。
- en: '`v1/template-link.json` is a generic file that has placeholders to be replaced
    by AKS Engine. In this way, your template will be linked to the Deployment.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`v1/template-link.json`是一个通用文件，其中包含要由AKS Engine替换的占位符。这样，您的模板将链接到部署。'
- en: Now, create a GitHub repository and push the extension. Ensure that you follow
    the directory naming convention, for example, the full path in the repository
    to `template.json` should be `extensions/prometheus-exporters/v1/template.json`.
    In the examples, we are going to use the following GitHub repository: [https://github.com/ptylenda/aks-engine-windows-extensions](https://github.com/ptylenda/aks-engine-windows-extensions).
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个GitHub仓库并推送扩展。确保您遵循目录命名约定，例如，存储库中`template.json`的完整路径应为`extensions/prometheus-exporters/v1/template.json`。在示例中，我们将使用以下GitHub仓库：[https://github.com/ptylenda/aks-engine-windows-extensions](https://github.com/ptylenda/aks-engine-windows-extensions)。
- en: 'Now, modify your AKS Engine cluster apimodel so that it uses the extension
    for all Windows nodes ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json))
    and ensure that you are using `vmSize` for the Linux node pool, which is capable
    of mounting more than four volumes:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，修改您的AKS Engine集群apimodel，使其为所有Windows节点使用扩展（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/kubernetes-windows-template.json)），并确保您使用`vmSize`用于Linux节点池，该节点池能够挂载超过四个卷：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As `rootURL`, you need to provide the HTTP address for raw access to your GitHub
    repository with the extension. Additionally, we are passing `'/EnabledCollectors:cpu,cs,container,dns,logical_disk,logon,memory,net,os,process,service,system,tcp'`
    as parameters to the extension, which will be used when executing the PowerShell
    script.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 作为`rootURL`，您需要提供GitHub仓库的原始访问的HTTP地址，该地址带有扩展。此外，我们将`'/EnabledCollectors:cpu,cs,container,dns,logical_disk,logon,memory,net,os,process,service,system,tcp'`作为参数传递给扩展，这些参数将在执行PowerShell脚本时使用。
- en: 'Now, deploy the cluster in the same way as in the previous chapters. You can
    also use our usual PowerShell script: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1).'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，以与前几章相同的方式部署集群。您也可以使用我们通常的PowerShell脚本：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/04_aks-engine-cluster-with-extensions/CreateAKSEngineClusterWithWindowsNodes.ps1)。
- en: When the Deployment is finished, use the `kubectl get nodes -o wide` command
    to determine the private IP of one of your Windows nodes, for example, `10.240.0.65`.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当部署完成后，使用`kubectl get nodes -o wide`命令来确定其中一个Windows节点的私有IP，例如`10.240.0.65`。
- en: 'SSH to the master node using the `ssh azureuser@<dnsPrefix>.<azureLocation>.cloudapp.azure.com` command and
    check whether the Windows node exports metrics on ports `9323` and `9182`:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ssh azureuser@<dnsPrefix>.<azureLocation>.cloudapp.azure.com`命令SSH到主节点，并检查Windows节点是否在端口`9323`和`9182`上导出指标：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Congratulations! Now your Windows nodes in AKS Engine cluster are exposing metrics
    that can be scraped by Prometheus. In the next section, we will install Prometheus
    in our cluster and configure it to monitor both Linux and Windows nodes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！现在您的AKS Engine集群中的Windows节点正在公开可以被Prometheus抓取的指标。在下一节中，我们将在我们的集群中安装Prometheus，并配置它来监视Linux和Windows节点。
- en: Deploying Prometheus using a Helm chart
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Helm图表部署Prometheus
- en: 'Our cluster infrastructure is now observable—we can deploy Prometheus with
    appropriate configuration files and start monitoring the cluster. To deploy Prometheus,
    we have several options:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群基础设施现在是可观察的 - 我们可以部署带有适当配置文件的Prometheus并开始监视集群。要部署Prometheus，我们有几个选项：
- en: Deploy it manually using multiple manifest files.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动使用多个清单文件部署它。
- en: Use the `stable/prometheus` Helm chart ([https://github.com/helm/charts/tree/master/stable/prometheus](https://github.com/helm/charts/tree/master/stable/prometheus)).
    This chart provides Prometheus, Alertmanager, Pushgateway, Node Exporter (for
    Linux nodes), and kube-state-metrics.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`stable/prometheus` Helm图表（[https://github.com/helm/charts/tree/master/stable/prometheus](https://github.com/helm/charts/tree/master/stable/prometheus)）。该图表提供了Prometheus、Alertmanager、Pushgateway、Node
    Exporter（用于Linux节点）和kube-state-metrics。
- en: Use the `stable/prometheus-operator` Helm chart ([https://github.com/helm/charts/tree/master/stable/prometheus-operator](https://github.com/helm/charts/tree/master/stable/prometheus-operator))
    or `kube-prometheus` ([https://github.com/coreos/kube-prometheus](https://github.com/coreos/kube-prometheus)).
    These solutions aim at providing a way to quickly provision multiple Prometheus
    clusters in your Kubernetes cluster.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`stable/prometheus-operator` Helm图表（[https://github.com/helm/charts/tree/master/stable/prometheus-operator](https://github.com/helm/charts/tree/master/stable/prometheus-operator)）或`kube-prometheus`（[https://github.com/coreos/kube-prometheus](https://github.com/coreos/kube-prometheus)）。这些解决方案旨在提供一种快速在Kubernetes集群中部署多个Prometheus集群的方法。
- en: In our case, the best choice is to use the `stable/prometheus` Helm chart as
    it requires minimum configuration and is not as complex as the generic Prometheus
    Operator. In production environments, running at a large scale, you should definitely
    consider using Prometheus Operator so that you can easily deploy multiple Prometheus
    clusters for different needs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，最好的选择是使用`stable/prometheus` Helm图表，因为它需要最少的配置，并且不像通用的Prometheus Operator那样复杂。在生产环境中，运行大规模，您应该考虑使用Prometheus
    Operator，这样您就可以轻松地为不同的需求部署多个Prometheus集群。
- en: Installing Helm charts
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Helm图表
- en: 'To deploy Prometheus using Helm chart, perform the following steps:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Helm图表部署Prometheus，请执行以下步骤：
- en: 'We are going to deploy our monitoring solution in a separate namespace named
    `monitoring`. Additionally, we need `StorageClass` defined for Prometheus data
    persistence. Create the `prereq.yaml` manifest file with the following contents:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在名为`monitoring`的单独命名空间中部署我们的监控解决方案。此外，我们需要为Prometheus数据持久性定义`StorageClass`。创建名为`prereq.yaml`的清单文件，内容如下：
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Apply the manifest file using the `kubectl apply -f .\prereq.yaml` command.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\prereq.yaml`命令应用清单文件。
- en: 'Now, we need to define values for the `stable/prometheus` Helm chart ([https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)).
    This chart is highly configurable, so check whether you need to override any additional
    values. Create the `helm-values_prometheus.yaml` file and start editing it with
    the following contents ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml)):'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要为`stable/prometheus` Helm图表（[https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)）定义值。这个图表是高度可配置的，所以请检查是否需要覆盖任何其他值。创建`helm-values_prometheus.yaml`文件，并开始编辑它，内容如下（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/05_helm_prometheus/helm-values_prometheus.yaml)）：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The most important part is ensuring that the proper `nodeSelector` is set for
    all components so that the Pods do not get accidentally scheduled on Windows machines.
    Additionally, we need to provide the name of `storageClass`, which will be used
    for handling PVCs. Another solution could be setting `azure-disk` as the default
    `storageClass` in the cluster. In the Helm chart configuration, you can also influence
    scraping settings, such as how often you would like to execute the scrape jobs.
    And finally, we are exposing both Prometheus and Alertmanager using the `LoadBalancer`
    Service—this is, of course, valid only for development and testing purposes in
    order not to use `kubectl proxy` (which requires additional configuration for
    Grafana) or use jump boxes.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的部分是确保为所有组件设置适当的`nodeSelector`，以便Pod不会意外地被调度到Windows机器上。此外，我们需要提供`storageClass`的名称，用于处理PVC。另一个解决方案可能是在集群中将`azure-disk`设置为默认的`storageClass`。在Helm图表配置中，您还可以影响抓取设置，例如您希望多久执行一次抓取作业。最后，我们使用`LoadBalancer`服务公开了Prometheus和Alertmanager——当然，这仅适用于开发和测试目的，以便不使用`kubectl
    proxy`（这需要对Grafana进行额外配置）或使用跳板机。
- en: For production scenarios, consider either limiting access to Prometheus to a
    private network or expose it behind Ingress, use HTTPS, and provide a safe authentication
    method. For example, you can integrate Nginx Ingress with Azure Active Directory
    ([https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/](https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产场景，请考虑将对Prometheus的访问限制在私有网络内，或者在其后面暴露Ingress，使用HTTPS，并提供安全的身份验证方法。例如，您可以将Nginx
    Ingress与Azure Active Directory集成（[https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/](https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/)）。
- en: Be careful when setting small `scrape_interval` values. Scraping in too short
    intervals may cause excessive load for your nodes and Pods and result in instability
    of the system. You should always evaluate how expensive your exporters are in
    terms of CPU usage and RAM memory.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置较小的`scrape_interval`值时要小心。太短的抓取间隔可能会导致节点和Pod的过载，并导致系统不稳定。您应该始终评估您的导出器在CPU使用和RAM内存方面的成本。
- en: 'Continue editing the `helm-values_prometheus.yaml` file and provide scraping
    configuration for Prometheus. We need to ensure that our WMI Exporter and Docker
    Engine metrics server are scraped by the Prometheus server. You can see the following
    configuration for the Docker Engine metrics server only; the configuration for
    WMI Exporter is almost the same apart from the port number:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续编辑`helm-values_prometheus.yaml`文件，并为Prometheus提供抓取配置。我们需要确保我们的WMI Exporter和Docker
    Engine指标服务器被Prometheus服务器抓取。您只能看到Docker Engine指标服务器的以下配置；WMI Exporter的配置几乎相同，除了端口号：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Prometheus scrape configurations can get a bit complex; you can check the official
    documentation for a detailed explanation: [https://prometheus.io/docs/prometheus/latest/configuration/configuration/](https://prometheus.io/docs/prometheus/latest/configuration/configuration/).
    The basic configuration scrapes API resources that are annotated with `prometheus.io/scrape:
    ''true''`, so, for example, if you want your own application Pod to be scraped,
    you need to use this annotation (together with `prometheus.io/port`). Additionally,
    you can configure scraping based on API resources directly (`kubernetes_sd_configs`),
    in this case, `node`. After that, we perform various operations on the labels
    that were returned by the API for the node: we ensure that the final value of
    the `__address__` special label contains the required `9323` port, and we define `__metrics_path__`
    as `/metrics` so in the end, we will be scraping this HTTP endpoint: `http://<nodeAddress>:9323/metrics`.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prometheus抓取配置可能会变得有点复杂；您可以查看官方文档以获取详细说明：[https://prometheus.io/docs/prometheus/latest/configuration/configuration/](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)。基本配置会抓取带有`prometheus.io/scrape:
    ''true''`注释的API资源，因此，例如，如果您希望抓取自己的应用Pod，您需要使用此注释（以及`prometheus.io/port`）。此外，您可以根据API资源直接配置抓取（`kubernetes_sd_configs`），在这种情况下是`node`。之后，我们对节点API返回的标签执行各种操作：我们确保`__address__`特殊标签的最终值包含所需的`9323`端口，并且我们将`__metrics_path__`定义为`/metrics`，因此最终，我们将抓取此HTTP端点：`http://<nodeAddress>:9323/metrics`。'
- en: 'Use the `values` file to install the Helm chart for Prometheus as the `prometheus`
    release:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`values`文件安装Prometheus的Helm图表作为`prometheus`发布：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'While the installation proceeds, you can already define the `helm-values_grafana.yaml`
    values file for the `stable/grafana` Helm chart, which we are going to use to
    deploy Grafana for Prometheus:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装进行的同时，您可以为`stable/grafana` Helm图表定义`helm-values_grafana.yaml`值文件，我们将使用它来部署Prometheus的Grafana：
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Similarly, we need to ensure that Grafana is scheduled on Linux nodes only.
    Again, we expose the Service using load balancer—you should consider a different
    strategy for production Deployments or at least provide proper authentication
    for this public endpoint. The last important thing is ensuring that our Prometheus
    instance is added as the default data source in Grafana. Here, you should use
    the Service name to use discovery via the DNS name.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们需要确保Grafana仅安排在Linux节点上。同样，我们使用负载均衡器公开服务-您应该考虑不同的生产部署策略，或者至少为此公共端点提供适当的身份验证。最后一个重要的事情是确保我们的Prometheus实例被添加为Grafana中的默认数据源。在这里，您应该使用服务名称通过DNS名称进行发现。
- en: 'Install the `stable/grafana` Helm chart as the `grafana` release using the
    following command:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将`stable/grafana` Helm图表安装为`grafana`发布：
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, wait for all Pods to be ready and services to receive external IPs:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，等待所有Pod准备就绪并且服务接收到外部IP：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point, you have three web UIs that you can access:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您有三个可以访问的Web UI：
- en: The Prometheus server (in our example, accessible at `http://40.78.42.14`)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus服务器（在我们的示例中，可在`http://40.78.42.14`访问）
- en: Alertmanager (`http://40.78.81.58`)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alertmanager（`http://40.78.81.58`）
- en: Grafana (`http://104.40.19.54`)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana（`http://104.40.19.54`）
- en: Verifying the Deployment
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证部署
- en: 'Verify whether you can access your external IPs for the Services and perform
    some basic operations:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 验证您是否可以访问服务的外部IP并执行一些基本操作：
- en: Open the web UI for your Prometheus server.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的Prometheus服务器的Web UI。
- en: Navigate to Status and choose Targets.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到状态并选择目标。
- en: 'Scroll down to the `windows-nodes-docker-metrics-server` and `windows-nodes-wmi-exporter
    targets` scraped by the jobs. They should be green and be executed without errors—if
    this is not the case, you need to verify your scraping configuration. For debugging
    purposes, you can introduce changes directly to the appropriate ConfigMap in the
    cluster:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到由作业抓取的`windows-nodes-docker-metrics-server`和`windows-nodes-wmi-exporter
    targets`。它们应该是绿色的，并且在没有错误的情况下执行——如果不是这种情况，您需要验证您的抓取配置。出于调试目的，您可以直接向集群中的适当ConfigMap引入更改。
- en: '![](assets/24f22213-a81b-49db-8c42-c9e19b2b4e1e.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/24f22213-a81b-49db-8c42-c9e19b2b4e1e.png)'
- en: 'Navigate to Graph in the menu at the top and switch to the Graph tab below
    the Execute button. Run an example query, `rate(wmi_net_bytes_total[60s])`, which
    plots the average number of bytes received by and sent to Windows nodes per seconds
    based on the last 60 seconds of the `wmi_net_bytes_total` counter metric:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在顶部菜单中导航到图形，并在“执行”按钮下方切换到“图形”选项卡。运行一个示例查询，`rate(wmi_net_bytes_total[60s])`，它将根据最后60秒的`wmi_net_bytes_total`计数器指标绘制每秒接收和发送到Windows节点的平均字节数：
- en: '![](assets/917ed898-b0d8-43e7-aae8-dde7d2032748.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/917ed898-b0d8-43e7-aae8-dde7d2032748.png)'
- en: Open the Grafana web UI and log in with the credentials that you provided in
    the Helm chart.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Grafana Web UI，并使用您在Helm图表中提供的凭据登录。
- en: Click + in the menu and choose Dashboard, then select Add Query.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在菜单中点击+，选择仪表板，然后选择添加查询。
- en: 'Enter an example PromQL query, `wmi_memory_available_bytes / (1024 * 1024 *
    1024)`, which will plot the available memory on Windows nodes in GB:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入一个示例PromQL查询，`wmi_memory_available_bytes / (1024 * 1024 * 1024)`，它将以GB为单位绘制Windows节点上的可用内存：
- en: '![](assets/cbee5da2-ea08-45ab-93be-1bed3201b7bd.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/cbee5da2-ea08-45ab-93be-1bed3201b7bd.png)'
- en: Now, we have a confirmation that our monitoring setup is working correctly!
    You can explore PromQL in depth in the official documentation: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/).
    It is a broad and powerful language that can implement most of your **Service
    Level Indicators** (**SLIs**) to monitor your **Service Level Objectives** (**SLOs**).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们确认我们的监控设置正常工作！您可以在官方文档中深入了解PromQL：[https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)。这是一种广泛而强大的语言，可以实现大部分您的**服务水平指标**（**SLIs**）来监视您的**服务水平目标**（**SLOs**）。
- en: In the next section, we will explore how you can configure exporting of any
    Windows Performance Counter using Telegraf.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何配置使用Telegraf导出任何Windows性能计数器。
- en: Windows Performance Counters
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Windows性能计数器
- en: Windows provides a feature called Performance Counters, which are used to provide
    information on how well the operating system, service, application, or driver
    is performing. Normally, you use **Windows Management Instrumentation** (**WMI**)
    to get individual metrics values and use more advanced applications such as Perfmon
    for visualizing the performance data locally. For .NET Framework applications,
    you can read multiple counters provided directly by the runtime; you can find
    a list of the counters in the documentation: [https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters](https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters).
    Having access to these metrics, you can easily monitor unusual spikes in the number
    of exceptions thrown (even without analyzing logs) or analyze garbage collection
    issues. On top of that, many classic .NET Framework applications expose their
    own Performance Counters.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Windows提供了一个名为性能计数器的功能，用于提供有关操作系统、服务、应用程序或驱动程序的性能情况。通常，您使用**Windows管理工具**（**WMI**）来获取单个指标值，并使用更高级的应用程序（如Perfmon）来在本地可视化性能数据。对于.NET
    Framework应用程序，您可以直接读取运行时提供的多个计数器；您可以在文档中找到计数器的列表：[https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters](https://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/performance-counters)。有了这些指标，您可以轻松监视异常抛出数量的异常波动（甚至无需分析日志）或分析垃圾回收问题。此外，许多经典的.NET
    Framework应用程序还公开了自己的性能计数器。
- en: 'For Kubernetes, in addition to the standard Performance Counters collected
    by WMI Exporter (custom queries are not supported yet: [https://github.com/martinlindhe/wmi_exporter/issues/87](https://github.com/martinlindhe/wmi_exporter/issues/87)),
    there are two scenarios that you can consider:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kubernetes，除了WMI Exporter收集的标准性能计数器（尚不支持自定义查询：[https://github.com/martinlindhe/wmi_exporter/issues/87](https://github.com/martinlindhe/wmi_exporter/issues/87)），还有两种情况可以考虑：
- en: Collecting Performance Counters for applications running in a container
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集容器中运行的应用程序的性能计数器
- en: Collecting more Performance Counters from the Windows host machine
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集来自Windows主机的更多性能计数器
- en: Both of these can be solved using Telegraf ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)),
    which is a generic, extensible agent for collecting, processing, aggregating,
    and writing metrics. One of the input plugins that it supports is `win_perf_counter`
    ([https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters)),
    which can collect and transform any Performance Counters available on Windows.
    At the same time, Telegraf is capable of exposing the collected metrics in the
    Prometheus format using the `prometheus_client` output plugin ([https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client](https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client)).
    The complete solution requires preparing a configuration file, installing Telegraf
    as a Windows service, and ensuring that Prometheus scrapes the new endpoint.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个问题都可以使用Telegraf（[https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)）来解决，它是一个通用的、可扩展的代理，用于收集、处理、聚合和编写指标。它支持的输入插件之一是`win_perf_counter`（[https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters)），可以收集和转换Windows上可用的任何性能计数器。同时，Telegraf能够使用`prometheus_client`输出插件（[https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client](https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client)）以Prometheus格式公开收集的指标。完整的解决方案需要准备一个配置文件，将Telegraf安装为Windows服务，并确保Prometheus抓取新的端点。
- en: 'If you would like to collect more Performance Counters from the host machine,
    on AKS Engine, you can achieve it using custom extensions, exactly as we did for
    WMI Exporter and the Docker metrics server. We will demonstrate the first scenario:
    how you can enrich your Docker image so that your container running on Kubernetes
    exposes more metrics for Prometheus. Please note that you have to always consider
    whether it is a valid use case for you—embedding Telegraf in every single container
    in the cluster comes with increased CPU usage and RAM memory footprint. A general
    rule of thumb is that you should use this approach only for the key components
    that may require investigating complex performance problems or as an ad hoc action
    for debugging purposes.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要从主机机器收集更多性能计数器，在AKS Engine上，您可以使用自定义扩展来实现，就像我们为WMI Exporter和Docker指标服务器所做的那样。我们将演示第一个场景：如何丰富您的Docker镜像，以便在Kubernetes上运行的容器公开更多Prometheus指标。请注意，您必须始终考虑这是否对您来说是一个有效的用例——在集群中的每个容器中嵌入Telegraf会增加CPU使用率和RAM内存占用。一个一般的经验法则是，您应该仅对可能需要调查复杂性能问题的关键组件使用此方法，或者作为调试目的的临时操作。
- en: Extending a Docker image with the Telegraf service
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Telegraf服务扩展Docker镜像
- en: 'The installation process for Telegraf on Windows is simple: it requires unzipping
    the file, providing a proper configuration file, and registering Telegraf as a
    Windows service. To build a new version of Docker image for the voting application,
    which exposes Performance Counters at port `9273`, you can use the source code
    from the GitHub repository ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf))
    or execute the following steps on the previous version of the source code:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Windows上的Telegraf安装过程很简单：需要解压文件，提供适当的配置文件，并将Telegraf注册为Windows服务。要为投票应用程序构建新版本的Docker镜像，该镜像在端口`9273`上公开性能计数器，您可以使用GitHub存储库中的源代码([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/06_voting-application-telegraf))，或者在先前版本的源代码上执行以下步骤：
- en: 'In the root directory, create a new file, `telegraf.conf`, which contains the
    Telegraf configuration. You can find the contents of this file here: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf).
    We are presenting the significant parts only in the following:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在根目录中，创建一个名为`telegraf.conf`的新文件，其中包含Telegraf配置。您可以在此处找到此文件的内容：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/06_voting-application-telegraf/telegraf.conf)。我们只在以下列出了重要部分：
- en: '[PRE15]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We are using the `prometheus_client` output plugin and the `win_perf_counters`
    input plugin, which has a gathering of multiple Performance Counters configured.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用`prometheus_client`输出插件和`win_perf_counters`输入插件，它配置了多个性能计数器的收集。
- en: Add this file to `votingapplication.csproj` to include it in the build output.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此文件添加到`votingapplication.csproj`中，以便将其包含在构建输出中。
- en: 'Modify the `Dockerfile.production` file so that it includes the part that installs
    Telegraf, right at the beginning of the `runtime` stage:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`Dockerfile.production`文件，以便在`runtime`阶段的开头包含安装Telegraf的部分：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding commands download the latest release of Telegraf, install it as
    a Windows service, and provide the configuration from the previous steps.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令下载了Telegraf的最新版本，将其安装为Windows服务，并提供了之前步骤中的配置。
- en: Build the image with the tag 1.6.0 and push it to Docker Hub as in the previous
    chapters. In our case, it will be `packtpubkubernetesonwindows/voting-application:1.6.0`.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标签1.6.0构建镜像，并像在之前的章节中一样将其推送到Docker Hub。在我们的情况下，它将是`packtpubkubernetesonwindows/voting-application:1.6.0`。
- en: The Telegraf configuration can be modified at container runtime by mounting
    a custom ConfigMap into the `C:\telegraf\telegraf.d` directory in the container.
    This is a perfect use case for ConfigMaps.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Telegraf配置可以通过将自定义ConfigMap挂载到容器中的`C:\telegraf\telegraf.d`目录来在容器运行时进行修改。这是ConfigMaps的一个完美用例。
- en: Now, the Docker image is ready and it can be used in the Helm chart for the
    voting application.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Docker镜像已准备就绪，可以在投票应用程序的Helm图中使用。
- en: Deploying an observable version of the voting application
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署一个可观察的投票应用程序版本
- en: 'To be able to scrape Performance Counters exposed by Telegraf in the container,
    we need to update the Helm chart to include the new tag for the Docker image and
    update the Pod annotations for scraping. You can find the ready Helm chart at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm)
    or follow these steps using the previous version:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够抓取容器中Telegraf公开的性能计数器，我们需要更新Helm图以包括Docker镜像的新标签，并更新用于抓取的Pod注释。您可以在以下位置找到准备好的Helm图：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/07_voting-application-telegraf-helm)，或者按照以下步骤使用先前的版本：
- en: Open a PowerShell window in the root directory of the Helm chart.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Helm图的根目录中打开PowerShell窗口。
- en: In the `Chart.yaml` file, increment `appVersion` to be equal with the Docker
    image tag `1.6.0`. Also, increment the version of the chart itself to `0.3.0`.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chart.yaml`文件中，将`appVersion`增加到与Docker镜像标签`1.6.0`相等。同时，将图表本身的版本增加到`0.3.0`。
- en: 'In the `templates\service.yaml` file, add `annotations` for the Service so
    that Prometheus can start scrapping all Pods behind the Service at port `9273`:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`templates\service.yaml`文件中，为Service添加`annotations`，以便Prometheus可以开始在端口`9273`上抓取服务后面的所有Pod：
- en: '[PRE17]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Update the `templates\deployment.yaml` file so that the voting application
    frontend Pod exposes port `9273` where Telegraf exports the data at the `/metrics`
    endpoint:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`templates\deployment.yaml`文件，以便投票应用程序前端Pod在`9273`端口上公开Telegraf在`/metrics`端点处导出的数据：
- en: '[PRE18]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Ensure that the `dev-helm` namespace exists. Create the `dev-helm.yaml` manifest
    file:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保`dev-helm`命名空间存在。创建`dev-helm.yaml`清单文件：
- en: '[PRE19]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Apply the manifest file using the `kubectl apply -f .\dev-helm.yaml` command.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f .\dev-helm.yaml`命令应用清单文件。
- en: 'The Helm chart is ready to be deployed. Execute the following command in the
    root directory of the Helm chart for the voting application:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm图已准备就绪，可以在投票应用程序的Helm图的根目录中执行以下命令：
- en: '[PRE20]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Alternatively, if you have already installed a previous version of this chart
    in your cluster, use the `helm upgrade` command with the same arguments.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您已经在集群中安装了此图的先前版本，请使用相同的参数使用`helm upgrade`命令。
- en: Wait for the Deployment to finish; you can observe the progress in another PowerShell
    window using the `kubectl get pods -n dev-helm -w` command.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待部署完成；您可以使用`kubectl get pods -n dev-helm -w`命令在另一个PowerShell窗口中观察进度。
- en: 'At this point, the new version of the voting application is deployed to the
    cluster and Prometheus is already scraping the Pods using the `kubernetes-service-endpoints`
    scraping job, which is defined in the default configuration. Let''s verify whether
    everything is working correctly:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，投票应用程序的新版本已部署到集群中，并且Prometheus已经使用`kubernetes-service-endpoints`抓取作业来抓取Pod。这在默认配置中已经定义。让我们验证一下是否一切正常：
- en: Navigate in the web browser to the external IP for the voting application and
    create some traffic by using the website for a few minutes.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网络浏览器中导航到投票应用程序的外部IP，并使用网站创建一些流量，持续几分钟。
- en: Open the Prometheus server external IP in the web browser, open the Graph panel,
    and change the tab to Graph.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网络浏览器中打开Prometheus服务器的外部IP，在Graph面板中打开，并将选项卡切换到Graph。
- en: 'The Telegraf configuration is set up to output all metrics with the `win_`
    prefix. Let''s query one of these metrics, for example, `win_aspnet_app_Requests_Failed`,
    which is a counter for the number of failed requests in the ASP.NET application.
    Use the `rate(win_aspnet_app_Requests_Failed{app_kubernetes_io_name="voting-application"}[5m])` query,
    which gives the average per-second rate of failed requests in the last five minutes
    for the voting application for each Pod separately:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Telegraf配置设置为输出所有带有`win_`前缀的指标。让我们查询其中一个指标，例如`win_aspnet_app_Requests_Failed`，这是ASP.NET应用程序中失败请求的计数器。使用`rate(win_aspnet_app_Requests_Failed{app_kubernetes_io_name="voting-application"}[5m])`查询，该查询为每个Pod分别提供了过去五分钟内投票应用程序失败请求的平均每秒速率：
- en: '![](assets/6e13ec99-9e84-49d2-828f-cbe91a6193ff.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6e13ec99-9e84-49d2-828f-cbe91a6193ff.png)'
- en: Now, you may be wondering why we see a sudden increase in the number of failed
    requests at some point—you will most likely see the same situation in your Prometheus.
    The answer is failed health checks (readiness probes) for a few minutes after
    deploying the Helm chart. As you probably remember, the SQL Server Helm chart
    requires up to 10 minutes to fully deploy. This means that, for this interval
    in time, the readiness probe for the voting application Pods will fail with an
    HTTP 500 status code.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可能想知道为什么我们在某个时间点看到失败请求数量突然增加-您很可能会在您的Prometheus中看到相同的情况。答案是在部署Helm图表后的几分钟内出现了失败的健康检查（就绪探针）。您可能还记得，SQL
    Server Helm图表需要最多10分钟才能完全部署。这意味着在这段时间内，投票应用程序Pod的就绪探针将以HTTP 500状态代码失败。
- en: Calculating `rate` and `irate` requires at least two data points per interval
    in the time series. This means that you should use the interval value at least
    two times larger than the scraping interval. Otherwise, you will see missing data
    in the graph.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 计算`rate`和`irate`需要每个时间序列间隔至少两个数据点。这意味着您应该使用间隔值至少比抓取间隔大两倍。否则，您将在图表中看到缺失的数据。
- en: You can explore the other Performance Counters that we have exposed for each
    Pod—this configuration of Telegraf gets a large number of counters, such as the
    number of exceptions thrown in .NET CLR, the number of locks in .NET CLR (this
    may be very useful for detecting heavy-locking scenarios!), .NET CLR garbage collection
    statistics, or IIS performance counters.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以探索我们为每个Pod公开的其他性能计数器-Telegraf的这种配置获得了大量的计数器，例如.NET CLR中抛出的异常数量，.NET CLR中的锁定数量（这对于检测重锁定场景可能非常有用！），.NET
    CLR垃圾回收统计信息或IIS性能计数器。
- en: 'In the next section, we will add the last piece of the monitoring puzzle: exposing
    your own metrics directly from the .NET Framework application using the `prometheus-net`
    NuGet package.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将添加监控谜题的最后一部分：使用`prometheus-net` NuGet包直接从.NET Framework应用程序公开自己的指标。
- en: Monitoring .NET applications using prometheus-net
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用prometheus-net监控.NET应用程序
- en: 'As part of your monitoring infrastructure, you need to expose custom metrics,
    directly from your application, which provides additional instrumentation and
    insights into your business logic. The most popular programming languages have
    bindings for Prometheus—for C#, one of the libraries that provides integration
    with Prometheus is `prometheus-net` ([https://github.com/prometheus-net/prometheus-net](https://github.com/prometheus-net/prometheus-net)).
    You can use it with the classic .NET Framework and .NET Core as it is targeting
    .NET Standard 2.0\. The features include the following:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 作为监控基础设施的一部分，您需要直接从应用程序中公开自定义指标，这些指标提供了对业务逻辑的额外仪表和见解。最流行的编程语言都有与Prometheus集成的绑定，对于C#，提供与Prometheus集成的库之一是`prometheus-net`（[https://github.com/prometheus-net/prometheus-net](https://github.com/prometheus-net/prometheus-net)）。您可以将其用于经典的.NET
    Framework和.NET Core，因为它针对的是.NET Standard 2.0。其功能包括以下内容：
- en: Exporting counters and gauges
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导出计数器和仪表
- en: Measuring operation duration and creating a summary or histogram
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量操作持续时间，并创建摘要或直方图
- en: Tracking in-progress operations and creating gauges with the number of concurrently
    executed code blocks
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪正在进行的操作，并创建具有并发执行代码块数量的仪表
- en: Exception counting
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常计数
- en: Additionally, for ASP.NET Core applications, you can use a dedicated middleware
    package ([https://www.nuget.org/packages/prometheus-net.AspNetCore](https://www.nuget.org/packages/prometheus-net.AspNetCore))
    to export ASP.NET metrics. Unfortunately for classic ASP.NET MVC, there is no
    support for this feature, but it is possible to implement a similar functionality
    manually.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于ASP.NET Core应用程序，您可以使用专用的中间件包（[https://www.nuget.org/packages/prometheus-net.AspNetCore](https://www.nuget.org/packages/prometheus-net.AspNetCore)）来导出ASP.NET指标。不幸的是，对于经典的ASP.NET
    MVC，不支持此功能，但可以手动实现类似的功能。
- en: Installing the NuGet package and adding metrics
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装NuGet包并添加指标
- en: 'The library is provided as a NuGet package ([https://www.nuget.org/packages/prometheus-net](https://www.nuget.org/packages/prometheus-net)).
    To enable `prometheus-net` in the voting application, please follow the following
    steps or alternatively, you can use the ready version of source code available
    at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 该库提供为NuGet包（[https://www.nuget.org/packages/prometheus-net](https://www.nuget.org/packages/prometheus-net)）。要在投票应用程序中启用`prometheus-net`，请按照以下步骤操作，或者您可以使用可在以下位置找到的源代码的准备版本：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/08_voting-application-prometheus-net)：
- en: Open the voting application solution in Visual Studio 2019.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Visual Studio 2019中打开投票应用程序解决方案。
- en: Right-click the VotingApplication project and choose Manage NuGet Packages....
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击VotingApplication项目，然后选择管理NuGet包....
- en: Find the `prometheus-net` package and install it.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到`prometheus-net`包并安装它。
- en: 'We need to start an HTTP listener for exporting metrics. In the `Global.asax.cs`
    file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs)),
    in the `Application_Start` method at the beginning, add the following lines:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要启动一个HTTP监听器来导出指标。在`Global.asax.cs`文件（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Global.asax.cs)）中，在`Application_Start`方法的开头，添加以下行：
- en: '[PRE21]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This will expose the metrics at port `9274` at the `/metrics` endpoint at all
    network interfaces.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在所有网络接口的`/metrics`端口`9274`处公开指标。
- en: 'Using a custom HTTP listener inside an application running on IIS requires
    adding a network ACL rule to allow using this port for IIS AppPool user. Therefore,
    we need to extend the `Dockerfile.production` file to include the following command,
    for example, after Telegraf installation:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行在IIS上的应用程序内部使用自定义HTTP监听器需要添加网络ACL规则以允许IIS AppPool用户使用此端口。因此，我们需要扩展`Dockerfile.production`文件以包括以下命令，例如，在Telegraf安装后：
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Right now, the application is exposing very basic .NET performance counters.
    We would like to add some custom metrics that will be specific for our voting
    application. As an example, we are going to add two metrics:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，该应用程序正在公开非常基本的.NET性能计数器。我们想要添加一些自定义指标，这些指标将特定于我们的投票应用程序。例如，我们将添加两个指标：
- en: '**Counter**: This is for the number of votes that have been added to the database
    since the start of the application. We can then use the counter to, for example,
    calculate the average number of votes added per time interval.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**：这是自应用程序启动以来已添加到数据库的投票数。然后，我们可以使用计数器来，例如，计算每个时间间隔添加的平均投票数。'
- en: '**Histogram**:This is forthe duration to retrieve survey results and summarize
    them.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：这是用于检索调查结果并对其进行总结的持续时间。'
- en: 'To do that, please follow the following steps:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，请按照以下步骤进行：
- en: 'In the `SurveyController` class ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs)),
    define two metrics, `DbAddedVotesCount` and `GetSurveyResultOperationDuration`,
    as `static readonly` fields:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`SurveyController`类（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/08_voting-application-prometheus-net/Controllers/SurveysController.cs)）中，定义两个指标，`DbAddedVotesCount`和`GetSurveyResultOperationDuration`，作为`static
    readonly`字段：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Increment the `DbAddedVotesCount` counter in the `Vote` controller action,
    just after adding each `Vote` to the database:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Vote`控制器操作中递增`DbAddedVotesCount`计数器，在将每个`Vote`添加到数据库后：
- en: '[PRE24]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Measure the time of getting survey results to create the histogram. In the `Results`
    Controller Action, wrap the call to `GetSurveyResult` into the `using` block and
    use `GetSurveyResultOperationDuration` to measure the time:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量获取调查结果的时间以创建直方图。在`Results`控制器操作中，将对`GetSurveyResult`的调用包装到`using`块中，并使用`GetSurveyResultOperationDuration`来测量时间：
- en: '[PRE25]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'After these changes, at the metrics export endpoint, you will see your new
    metrics:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进行这些更改后，在指标导出端点，您将看到新的指标：
- en: '[PRE26]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Build a new version of Docker image, tag it as `1.7.0`, and push to Docker Hub.
    We are going to use the `packtpubkubernetesonwindows/voting-application:1.7.0`
    Docker image in the next section.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个新版本的Docker镜像，将其标记为`1.7.0`，并推送到Docker Hub。我们将在下一节中使用`packtpubkubernetesonwindows/voting-application:1.7.0`
    Docker镜像。
- en: As you can see, adding the functionality for exporting your own metrics is quite
    simple and self-explanatory—you do not need to introduce significant changes to
    your existing code base!
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，添加导出自定义指标的功能非常简单和自解释——您无需对现有代码库进行重大更改！
- en: Now, let's deploy the new version of our application and test the new metrics.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们部署应用程序的新版本并测试新的指标。
- en: Deploying the new version of the voting application
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署投票应用程序的新版本
- en: 'We have to modify the Helm chart in a similar way as we did in the last section.
    The Docker image has to be updated and new scraping port registered in annotations
    for the service—due to Prometheus not supporting multiple ports in a single scraping
    job ([https://github.com/prometheus/prometheus/issues/3756](https://github.com/prometheus/prometheus/issues/3756)),
    we need to add a second job which will use the new port. You can find the ready
    Helm chart at: [https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm) or
    follow these steps using the previous version:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须以与上一节相似的方式修改Helm图表。必须更新Docker镜像并在服务的注释中注册新的抓取端口-由于Prometheus不支持在单个抓取作业中使用多个端口（[https://github.com/prometheus/prometheus/issues/3756](https://github.com/prometheus/prometheus/issues/3756)），我们需要添加第二个作业，该作业将使用新端口。您可以在以下位置找到准备好的Helm图表：[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter14/09_voting-application-prometheus-net-helm)，或者按照以下步骤使用先前的版本：
- en: Open the PowerShell window in the root directory of the Helm chart.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Helm图表的根目录中打开PowerShell窗口。
- en: In the `Chart.yaml` file, increment `appVersion` to be equal to the Docker image
    tag, `1.7.0`. Also, increment the `version` of the chart to `0.4.0`.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chart.yaml`文件中，将`appVersion`增加到与Docker镜像标签`1.7.0`相等。还要将图表的`version`增加到`0.4.0`。
- en: 'In the `templates\service.yaml` file, add a new custom annotation, `prometheus.io/secondary-port`,
    for the Service for port `9274`. We will use this annotation in the new scraping
    job:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`templates\service.yaml`文件中，为端口`9274`的服务添加一个新的自定义注释`prometheus.io/secondary-port`。我们将在新的抓取作业中使用此注释：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Update the `templates\deployment.yaml` file so that the voting application
    frontend Pod exposes port `9274` where the application exposes metrics data at the `/metrics` endpoint:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`templates\deployment.yaml`文件，以便投票应用程序前端Pod在应用程序在`/metrics`端点处公开度量数据的端口`9274`。
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The Helm chart is ready. The Helm release for the voting application can be
    upgraded—execute the following command in the root directory of the Helm chart
    for the voting application:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm图表已准备就绪。可以升级投票应用程序的Helm发布-在投票应用程序的Helm图表的根目录中执行以下命令：
- en: '[PRE29]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Wait for the Deployment to finish, you can observe the progress in another PowerShell
    window using the `kubectl get pods -n dev-helm -w` command.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待部署完成，您可以使用`kubectl get pods -n dev-helm -w`命令在另一个PowerShell窗口中观察进度。
- en: 'The last step is adding a Prometheus scrape job that will handle `prometheus.io/secondary-port`
    annotations. In the future, it should be easier to use multiple ports for scraping,
    but for now, you have to add multiple jobs for such purposes:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是添加一个Prometheus抓取作业，该作业将处理`prometheus.io/secondary-port`注释。将来，使用多个端口进行抓取应该更容易，但目前，您必须为此目的添加多个作业：
- en: 'In the `helm-values_prometheus.yaml` file ([https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml))
    for the Prometheus Helm chart, add another extra scrape job. This job should have
    almost exactly the same definition as the default `kubernetes-service-endpoints`,
    which is present in [https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml](https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml) but
    with additional filtering:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Prometheus Helm图表的`helm-values_prometheus.yaml`文件（[https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter14/10_helm_prometheus-net/helm-values_prometheus.yaml)）中，添加另一个额外的抓取作业。这个作业的定义几乎与默认的`kubernetes-service-endpoints`完全相同，该默认作业位于[https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml](https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml)，但有额外的过滤：
- en: '[PRE30]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The following actions will keep only the targets that have the `prometheus.io/secondary-port`
    annotation defined and use it to define the final `__address__` for scraping.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 以下操作将仅保留具有定义的`prometheus.io/secondary-port`注释并使用它来定义用于抓取的最终`__address__`的目标。
- en: 'Upgrade the Helm release for Prometheus:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级Prometheus的Helm发布：
- en: '[PRE31]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: When the upgrade is finished, the only resource that gets updated is the ConfigMap, `prometheus-server`.
    You need to wait a short while before Prometheus reloads the configuration.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级完成后，唯一更新的资源是ConfigMap，`prometheus-server`。在Prometheus重新加载配置之前，您需要等待一小段时间。
- en: 'In the Prometheus web UI, navigate to Status and Targets and verify that scraping
    of the new port works correctly; you should see the `kubernetes-service-endpoints-secondary-ports`
    job with a green status:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Prometheus web UI中，导航到状态和目标，并验证新端口的抓取是否正常工作；您应该看到`kubernetes-service-endpoints-secondary-ports`作业的绿色状态：
- en: '![](assets/62032637-3245-4cb8-b4c3-f7adf67b2af5.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/62032637-3245-4cb8-b4c3-f7adf67b2af5.png)'
- en: Open the voting application web UI and add some votes over a few minutes' time.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开投票应用的Web UI，并在几分钟内添加一些投票。
- en: 'In the Prometheus web UI in the Graph tab, run an example query to verify that
    the solution works. For example, use `sum(votingapplication_db_added_votes)` to
    get the total number of votes added to the database from all Pods:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Prometheus web UI的Graph选项卡中，运行一个示例查询来验证解决方案是否有效。例如，使用`sum(votingapplication_db_added_votes)`来获取从所有Pod添加到数据库的投票总数：
- en: '![](assets/e3b783f9-ce68-4d56-ab53-40b0287fac5b.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e3b783f9-ce68-4d56-ab53-40b0287fac5b.png)'
- en: Our solution works! In this way, you can export any metrics that you define
    in your application code and create much more complex queries that can be used
    for monitoring and analysis purposes.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的解决方案有效！通过这种方式，您可以导出您在应用程序代码中定义的任何指标，并创建更复杂的查询，用于监视和分析目的。
- en: Now, it's time to configure a dashboard in Grafana and add some alerts.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候在Grafana中配置仪表板并添加一些警报了。
- en: Configuring dashboards and alerts in Grafana
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Grafana中配置仪表板和警报
- en: The web UI of the Prometheus server is very limited and in most cases is used
    just for performing basic ad hoc queries and checking the configuration. To create
    more advanced visualizations of the data in Prometheus, you can use Grafana ([https://grafana.com/](https://grafana.com/)),
    which is an open source analytics and monitoring solution with support for multiple
    databases. In the previous sections, we have already deployed Grafana using a
    Helm chart together with Prometheus.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus服务器的Web UI非常有限，在大多数情况下仅用于执行基本的即席查询和检查配置。要在Prometheus中创建更高级的数据可视化，可以使用Grafana（[https://grafana.com/](https://grafana.com/)），这是一个支持多个数据库的开源分析和监控解决方案。在之前的部分中，我们已经使用Helm图表部署了Grafana和Prometheus。
- en: 'Grafana offers multiple ways to visualize your monitoring data—ranging from
    simple **line** charts and gauges to complex heatmaps. You can find more information
    about how to create the visualizations in the official documentation: [https://grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/).
    For our application, we will demonstrate how to configure an example dashboard
    with the following visualizations:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana提供了多种可视化监控数据的方式，从简单的**线**图和仪表到复杂的热图。您可以在官方文档中找到有关如何创建可视化的更多信息：[https://grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/)。对于我们的应用程序，我们将演示如何配置一个示例仪表板，其中包括以下可视化：
- en: A line graph for CPU usage for Windows nodes
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows节点CPU使用率的折线图
- en: A gauge for the average number of requests per second handled by IIS in the
    last 5 minutes
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IIS在过去5分钟内处理的平均每秒请求数的仪表
- en: A line graph showing the number of votes added to the database in the last 5
    minutes
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示在过去5分钟内添加到数据库的投票数量的折线图
- en: A heatmap for visualizing the histogram of the duration of retrieving survey
    results
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于可视化检索调查结果持续时间的直方图的热图
- en: Of course, these graphs will not be enough to fully monitor your application
    but we would like to show the general principle of how to create the dashboards.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些图表将不足以完全监视您的应用程序，但我们想展示如何创建仪表板的一般原则。
- en: Adding visualizations
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加可视化
- en: 'First, let''s create the dashboard and add the first visualization for CPU
    usage for Windows nodes. Please perform the following steps:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建仪表板，并为Windows节点的CPU使用率添加第一个可视化。请执行以下步骤：
- en: Navigate to the Grafana web UI and log in with the credentials provided in the
    Helm chart release. The default is user `admin` and password `P@ssword`.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到Grafana Web UI，并使用Helm图表发布中提供的凭据登录。默认用户为`admin`，密码为`P@ssword`。
- en: From the side panel, click the + button and choose Dashboard.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从侧面板中，单击+按钮，然后选择仪表板。
- en: Click the Save Dashboard button and provide `voting application` as the name.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“保存仪表板”按钮，并提供`voting application`作为名称。
- en: Choose Add Query.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择添加查询。
- en: Provide the following query in the first metric: `100 - (avg by (instance) (irate(wmi_cpu_time_total{mode="idle"}[2m]))
    * 100)`. This query calculates the average CPU usage in the last two minutes using
    counters for the total CPU idle time.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个指标中提供以下查询：`100 - (avg by (instance) (irate(wmi_cpu_time_total{mode="idle"}[2m]))
    * 100)`。此查询使用总CPU空闲时间的计数器计算了过去两分钟的平均CPU使用率。
- en: In Legend, provide `{{instance}}` to use the node hostname as label.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在图例中，提供`{{instance}}`以使用节点主机名作为标签。
- en: From the left panel, choose Visualization. For the Y axis, in Unit choose Misc
    and select percent(0-100).
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择可视化。对于Y轴，在单位中选择Misc并选择百分比（0-100）。
- en: 'From the left panel, choose General. Change the Title to `Average CPU usage`.
    Your graph should show the CPU utilization for both Windows nodes:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择常规。将标题更改为`平均CPU使用率`。您的图表应显示Windows节点的CPU利用率：
- en: '![](assets/7a23e50d-3c25-4292-89c8-cd57a08a1a88.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7a23e50d-3c25-4292-89c8-cd57a08a1a88.png)'
- en: 'The next step is creating the gauge for the average number of requests per
    second handled by IIS in the last 5 minutes. Follow the following steps:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建仪表板，显示IIS在过去5分钟内处理的平均每秒请求数。按照以下步骤进行：
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回仪表板视图，单击添加面板，然后选择添加查询。
- en: Provide the following query in the first metric: `sum((rate(win_aspnet_app_Requests_Total[5m])))
    by (app_kubernetes_io_instance)`. This query calculates the per-second rate of
    requests in a 5-minute interval per each Pod and summarizes it globally by Kubernetes
    applications.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个指标中提供以下查询：`sum((rate(win_aspnet_app_Requests_Total[5m]))) by (app_kubernetes_io_instance)`。此查询计算了每个Pod的5分钟间隔内请求的每秒速率，并通过Kubernetes应用程序全局汇总。
- en: From the left panel, choose Visualization. Choose Gauge.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择“可视化”。选择仪表板。
- en: In the Display area, select Calc to be Last (not null) and in the Field area,
    change Unit to Throughput > request/sec (reqps).
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“显示”区域，选择 Calc 为 Last（非空），在“字段”区域，将单位更改为吞吐量 > 请求/秒（reqps）。
- en: 'From the left panel, choose General. Change the Title to `IIS average number
    of requests per second in the last 5m`. Your gauge is showing the current average
    number of requests per second:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择“常规”。将“标题”更改为“过去 5 分钟内的平均 IIS 请求次数”。您的仪表正在显示当前每秒的平均请求次数：
- en: '![](assets/dcb8f239-125b-4324-87c5-0c3f50480ae2.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dcb8f239-125b-4324-87c5-0c3f50480ae2.png)'
- en: 'We are going to add the third visualization, which shows a line graph with the
    number of votes added to the database in the last five minutes. Please follow
    these steps:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将添加第三个可视化，显示过去五分钟内添加到数据库的投票数的折线图。请按照以下步骤操作：
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回仪表板视图，点击“添加面板”，选择“添加查询”。
- en: 'Provide the following query in the first metric: `sum(irate(votingapplication_db_added_votes[5m]))
    by (app_kubernetes_io_instance) * 300`. This query calculates the rate of increase
    of the number of votes in a 5-minute interval per Pod and summarizes it globally
    by Kubernetes application. We need to multiply by `300` (5 minutes) as `irate`
    calculates the rate per second.'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个指标中提供以下查询：`sum(irate(votingapplication_db_added_votes[5m])) by (app_kubernetes_io_instance)
    * 300`。该查询计算了每个 Pod 在 5 分钟间隔内投票数量的增加率，并通过 Kubernetes 应用程序全局汇总。我们需要乘以 `300`（5 分钟）因为
    `irate` 计算的是每秒的速率。
- en: Set Legend format to `Votes in the last 5 minutes`.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图例格式设置为“过去 5 分钟内的投票数”。
- en: 'From the left panel, choose General. Change the Title to `Number of votes added
    to the database in the last 5m`. Now your graph should look like the following:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择“常规”。将“标题”更改为“过去 5 分钟内添加到数据库的投票数”。现在您的图应该如下所示：
- en: '![](assets/3ee5af6b-c88a-4b1b-8079-0569ed13003a.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3ee5af6b-c88a-4b1b-8079-0569ed13003a.png)'
- en: 'And finally, we are going to add the last visualization, which is a heatmap
    for visualizing the histogram of the duration of retrieving survey results. Heatmaps
    are the most effective way of visualizing histogram changes over time and, recently,
    Grafana was extended with native support for heatmaps for Prometheus histogram
    metrics. To create the visualization, perform the following steps:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将添加最后一个可视化，即用于可视化检索调查结果持续时间直方图的热图。热图是可视化直方图随时间变化的最有效方式，最近，Grafana 扩展了对
    Prometheus 直方图指标的热图的本机支持。执行以下步骤创建可视化：
- en: Return to the dashboard view, click Add Panel, and choose Add Query.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回仪表板视图，点击“添加面板”，选择“添加查询”。
- en: 'Provide the following query in the first metric: `sum(increase(votingapplication_getsurveyresult_duration_seconds_bucket[2m]))
    by (le)`. This query will transform our histogram data—we determine the absolute
    increase rate for each bucket in the last two minutes and summarize each bucket
    with the `le` label, which is the bucket identifier (`le` is short for **less
    or equal**—Prometheus histograms are cumulative). In this way, we have buckets
    that are global per whole application, not individual Pods.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个指标中提供以下查询：`sum(increase(votingapplication_getsurveyresult_duration_seconds_bucket[2m]))
    by (le)`。该查询将转换我们的直方图数据——我们确定了最近两分钟内每个桶的绝对增长率，并用标签 `le` 汇总每个桶，这是桶的标识符（`le` 是 **小于或等于**
    的缩写—Prometheus 直方图是累积的）。这样，我们就有了整个应用程序全局的桶，而不是单独的 Pod。
- en: Change Legend format to `{{le}}` and set Format to `Heatmap`.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图例格式更改为 `{{le}}`，并将格式设置为 `热图`。
- en: From the left panel, choose Visualization. Choose Heatmap.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择“可视化”。选择“热图”。
- en: In the Y Axis area, for Unit, choose Time > seconds (s) and for Format choose
    Time series buckets. Set Decimals to `1` to have neat numbers display. Set Space
    to `0` and Round to `2`—our heatmap has a relatively large number of buckets,
    so it will make the display much smoother.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Y轴区域，对于单位，选择时间>秒（s），对于格式，选择时间序列桶。将小数设置为`1`以显示整洁的数字。将空间设置为`0`，将舍入设置为`2` - 我们的热图具有相对较多的桶，因此它将使显示更加平滑。
- en: In the Display area, turn on Show legend and Hide zero.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在显示区域，打开显示图例和隐藏零。
- en: 'From the left panel, choose General. Change the Title to `Heatmap for duration
    of getting survey results`. Check your heatmap, especially after stressing the
    main web page in multiple browser tabs with autorefresh! Heatmaps generally look
    better in the dark theme (which you can change in the Configuration menu globally):'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板中选择常规。将标题更改为`获取调查结果持续时间的热图`。检查您的热图，特别是在多个浏览器选项卡中对主网页进行压力测试后！热图通常在暗色主题下看起来更好（您可以在全局的配置菜单中更改）：
- en: '![](assets/e1008a8e-6d1b-4753-b83d-5429e1945e24.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e1008a8e-6d1b-4753-b83d-5429e1945e24.png)'
- en: You can clearly see how this operation was performing during stress testing
    with around 300 requests per minute.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以清楚地看到在每分钟约300次请求的压力测试期间，此操作的执行情况。
- en: 'And lastly, return to the dashboard view, save all changes, and reorder the
    visualizations as you wish:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，返回仪表板视图，保存所有更改，并按您的意愿重新排列可视化：
- en: '![](assets/a5bfd5a6-da09-47a0-af08-80ab5f6e7705.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a5bfd5a6-da09-47a0-af08-80ab5f6e7705.png)'
- en: In the next subsection, we will show how to configure email alerting in Grafana.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将展示如何在Grafana中配置电子邮件警报。
- en: Configuring alerting
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置警报
- en: Grafana, apart from creating visualizations and dashboards, is capable of defining alerting
    rules and sending notifications to multiple channels. You can find a list of supported
    notification channels in the official documentation: [https://grafana.com/docs/grafana/latest/alerting/notifications/](https://grafana.com/docs/grafana/latest/alerting/notifications/).
    The alerts are tied to particular visualizations so you need to have a proper
    visualization for your use case first. We are going to demonstrate how to create
    an alert for high CPU usage on a node.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana除了创建可视化和仪表板外，还能够定义警报规则并向多个渠道发送通知。您可以在官方文档中找到支持的通知渠道列表：[https://grafana.com/docs/grafana/latest/alerting/notifications/](https://grafana.com/docs/grafana/latest/alerting/notifications/)。警报与特定的可视化相关联，因此您首先需要为您的用例创建适当的可视化。我们将演示如何在节点上创建高CPU使用率的警报。
- en: 'First, we need to configure an email notification channel, so please follow
    these steps:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要配置一个电子邮件通知渠道，请按照以下步骤操作：
- en: 'Grafana requires SMTP configuration to send emails. Obtain these details for
    your email provider and modify the Grafana Helm chart values file, `helm-values_grafana.yaml`,
    so that it contains the node:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grafana需要SMTP配置来发送电子邮件。获取您的电子邮件提供商的详细信息，并修改Grafana Helm图表值文件`helm-values_grafana.yaml`，以便其中包含节点：
- en: '[PRE32]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Please note that if you would like to use Gmail, you will need to generate an
    app password if you have 2FA enabled.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果您想使用Gmail，如果启用了2FA，则需要生成应用程序密码。
- en: 'Upgrade the Helm release for Grafana:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级Grafana的Helm版本：
- en: '[PRE33]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: After the upgrade is finished, navigate to the Grafana web UI. From the left
    panel, open Alerting and select Notification channels.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级完成后，转到Grafana Web UI。从左侧面板中打开警报，并选择通知渠道。
- en: Click New channel.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击新通道。
- en: Fill in the Name, select type Email, and provide email addresses.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写名称，选择电子邮件类型，并提供电子邮件地址。
- en: Click Send Test to test whether your SMTP configuration is correct. If you have
    any problems, check the logs for the Grafana Pod. After a few minutes, you should
    receive the test email in your inbox.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“发送测试”以测试您的SMTP配置是否正确。如果有任何问题，请检查Grafana Pod的日志。几分钟后，您应该会在收件箱中收到测试电子邮件。
- en: 'When you have confirmed that your notification channel is working correctly,
    we can continue with creating the alert itself. We would like to receive an alert
    when average CPU usage on a node is above 80 percent for more than five minutes.
    Please follow these steps to configure such an alert:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 当您确认您的通知渠道正常工作时，我们可以继续创建警报本身。我们希望在节点的平均CPU使用率超过80％超过五分钟时收到警报。请按照以下步骤配置此类警报：
- en: Open our dashboard and choose the Average CPU usage visualization. From the
    menu for the visualization, choose Edit.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开我们的仪表板，选择平均CPU使用率可视化。从可视化菜单中，选择编辑。
- en: From the left panel, open Alert and click Create Alert.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧面板打开警报，然后单击创建警报。
- en: 'Configure the alert as shown in the following:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下所示配置警报：
- en: '![](assets/11fe4ac2-3e68-4a9b-ab71-2ebed85a5874.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/11fe4ac2-3e68-4a9b-ab71-2ebed85a5874.png)'
- en: Choose your notification channel and optionally customize the notification message.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您的通知渠道，并可选择自定义通知消息。
- en: Save the dashboard. You will notice that the dashboard has a heart icon indicating
    the alert status.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存仪表板。您会注意到仪表板上有一个心形图标，表示警报状态。
- en: 'Now, we need to test our rule by creating some load. We can reuse our `StressCpu`
    action that we created in the previous chapters. Follow these steps to perform
    the test:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要通过创建一些负载来测试我们的规则。我们可以重用在前几章中创建的`StressCpu`操作。按照以下步骤执行测试：
- en: In your web browser, navigate to `http://<applicationExternalIp>/Home/StressCpu?value=100` and
    repeat this action a few times to ensure that a few Pods start to stress the node
    enough.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的网络浏览器中，导航至`http://<applicationExternalIp>/Home/StressCpu?value=100`，并重复此操作几次，以确保一些Pod开始足够地压力节点。
- en: 'Check the dashboard. You will notice that the health is still green but the
    metric is already in the red zone:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查仪表板。您会注意到健康状况仍然是绿色的，但指标已经处于红色区域：
- en: '![](assets/243aeff0-3922-46aa-ace8-69fea39d69cd.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/243aeff0-3922-46aa-ace8-69fea39d69cd.png)'
- en: 'Wait for five minutes from the point when the average usage for the last five
    minutes is above 80 percent. You should receive an email via your notification
    channel:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待五分钟，从平均使用率在过去五分钟内超过80％的时间点开始。您应该通过您的通知渠道收到一封电子邮件：
- en: '![](assets/2c59c431-414c-4afd-95e8-d32fd01c49f7.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2c59c431-414c-4afd-95e8-d32fd01c49f7.png)'
- en: Congratulations! You have successfully configured dashboards for the voting
    application in Grafana and tested alerting features for our monitoring system.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功为Grafana中的投票应用程序配置了仪表板，并测试了我们监控系统的警报功能。
- en: Summary
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this long chapter, you learned how to set up monitoring of your application
    running in Windows containers on Kubernetes. First, we took a look at available
    monitoring solutions and determined which fit our use case with Windows nodes—the
    best choice currently is using a dedicated instance of Prometheus together with
    Grafana. Next, you learned how to make Windows nodes observable in terms of hardware,
    operating system, and container runtime using WMI Exporter and the experimental
    Docker Engine metrics service. We have shown how you can install and configure
    these agents on an AKS Engine cluster using extensions.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一长章中，您学会了如何在Kubernetes上运行的Windows容器中设置监控。首先，我们看了可用的监控解决方案，并确定了哪些适合我们的Windows节点的用例——目前最好的选择是使用专用的Prometheus实例与Grafana一起。接下来，您学会了如何使用WMI
    Exporter和实验性的Docker Engine指标服务使Windows节点在硬件、操作系统和容器运行时方面可观察。我们已经展示了如何在AKS Engine集群上使用扩展安装和配置这些代理。
- en: The next step was the Deployment of Prometheus and Grafana using Helm charts.
    You needed to ensure that Prometheus scraping jobs are capable of discovering
    the new metrics endpoints on Windows nodes. After that, we focused on monitoring inside the
    container and Windows Performance Counters—we exposed several counters using Telegraf
    and configured scraping of the new endpoint by Prometheus. Additionally, you learned
    how to use the `prometheus-net` library to export custom metrics to Prometheus
    directly from your application code. And finally, as the cherry on top, we showed
    you how to configure a sample dashboard in Grafana for the voting application
    and how to enable email alerting for high CPU usage on Windows nodes.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤是使用Helm图表部署Prometheus和Grafana。您需要确保Prometheus抓取作业能够在Windows节点上发现新的指标端点。之后，我们专注于监控容器内部和Windows性能计数器-我们使用Telegraf公开了几个计数器，并配置了Prometheus对新端点的抓取。此外，您还学会了如何使用`prometheus-net`库直接从应用程序代码向Prometheus导出自定义指标。最后，作为锦上添花，我们向您展示了如何为投票应用程序在Grafana中配置示例仪表板，以及如何为Windows节点上的高CPU使用率启用电子邮件警报。
- en: The next chapter will focus on disaster recovery and the Kubernetes backup strategy.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将重点介绍灾难恢复和Kubernetes备份策略。
- en: Questions
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why is observability the key concept in monitoring solutions?
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么可观测性是监控解决方案中的关键概念？
- en: What components can you use to monitor Windows nodes using Prometheus?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用哪些组件来使用Prometheus监视Windows节点？
- en: When should you use Prometheus Operator?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时应该使用Prometheus Operator？
- en: Why do you need to configure extra scrape jobs in Prometheus for Windows nodes?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么您需要为Windows节点在Prometheus中配置额外的抓取作业？
- en: How can you export any Windows Performance Counters from Windows containers
    to Prometheus?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将Windows容器中的任何Windows性能计数器导出到Prometheus？
- en: What is the benefit of using the `prometheus-net` library?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`prometheus-net`库的好处是什么？
- en: How can you configure more than one port for scraping a single Service in Prometheus?
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在Prometheus中为单个服务配置多个端口进行抓取？
- en: What are the benefits of using a heatmap for the visualization of Prometheus
    histograms?
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用热图可视化Prometheus直方图有哪些好处？
- en: You can find answers to these questions in the *Assessments* of this book.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的*评估*中找到这些问题的答案。
- en: Further reading
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information about Kubernetes features and monitoring the cluster in
    general, please refer to the following Packt books:'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关Kubernetes功能和一般集群监控的更多信息，请参考以下Packt图书：
- en: '*The Complete Kubernetes Guide* ([https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)).'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*完整的Kubernetes指南*（[https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide](https://www.packtpub.com/virtualization-and-cloud/complete-kubernetes-guide)）。'
- en: '*Getting Started with Kubernetes - Third Edition* ([https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始使用Kubernetes-第三版*（[https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)）。'
- en: '*Kubernetes for Developers* ([https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)).'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*面向开发人员的Kubernetes*（[https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers)）。'
- en: 'You can learn more about Prometheus in the following Packt book:'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在以下Packt图书中了解更多关于Prometheus的信息：
- en: '*Hands-On Infrastructure Monitoring with Prometheus* ([https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)[).](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《使用Prometheus进行实时基础设施监控》（[https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)）。
