- en: Service Mesh - Working with Istio
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务网格 - 与Istio一起工作
- en: In this chapter, we will review the hot topic of service meshes and, in particular,
    Istio. This is exciting because service meshes are a real game changer. They remove
    many complicated tasks from services into independent proxies. This is a huge
    win, especially in a polyglot environment, where different services are implemented
    in different programming languages or if you need to migrate some legacy applications
    into your cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾服务网格和特别是Istio这一热门话题。这令人兴奋，因为服务网格是一个真正的游戏改变者。它将许多复杂的任务从服务中移出到独立的代理中。这是一个巨大的胜利，特别是在多语言环境中，不同的服务是用不同的编程语言实现的，或者如果你需要将一些遗留应用迁移到你的集群中。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What a service mesh is
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格是什么
- en: What Istio brings to the table
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio为我们带来了什么
- en: Delinkcious on Istio
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio上的Delinkcious
- en: Alternatives to Istio
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio的替代方案
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will work with Istio. I chose to use **Google Kubernetes
    Engine** (**GKE**) in this chapter because Istio can be enabled on GKE as an add-on
    and doesn''t require you to install it. This has the following two benefits:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Istio。我选择在本章中使用**Google Kubernetes Engine**（**GKE**），因为Istio可以作为附加组件在GKE上启用，无需您安装它。这有以下两个好处：
- en: It saves time on installation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它节省了安装时间
- en: It demonstrates that Delinkcious can run in the cloud and not just locally
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它展示了Delinkcious可以在云中运行，而不仅仅是在本地
- en: 'To install Istio, you simply have to enable it in the GKE console and select
    an mTLS mode, which is the mutual authentication between services. I chose permissive,
    which means that the internal communication inside the cluster is not encrypted
    by default, and the services will accept both encrypted and non-encrypted connections.
    You can override it per service. For production clusters, I recommend using the
    strict mTLS mode, where all connections must be encrypted:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Istio，您只需在GKE控制台中启用它，并选择mTLS模式，这是服务之间的相互认证。我选择了宽容模式，这意味着集群内部通信默认情况下不加密，服务将接受加密和非加密连接。您可以针对每个服务进行覆盖。对于生产集群，我建议使用严格的mTLS模式，其中所有连接必须加密：
- en: '![](assets/d238fcb7-04c2-42cd-afcc-b988619fbac2.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d238fcb7-04c2-42cd-afcc-b988619fbac2.png)'
- en: 'Istio gets installed in its own `istio-system` namespace, as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Istio将安装在自己的`istio-system`命名空间中，如下所示：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: You can find the updated Delinkcious application at [https://github.com/the-gigi/delinkcious/releases/tag/v0.11](https://github.com/the-gigi/delinkcious/releases/tag/v0.11).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/the-gigi/delinkcious/releases/tag/v0.11](https://github.com/the-gigi/delinkcious/releases/tag/v0.11)找到更新的Delinkcious应用程序。
- en: What is a service mesh?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是服务网格？
- en: Let's start by reviewing the problems microservices face compared to monoliths,
    see how service mesh addresses them, and then you'll see why I'm so excited about
    them. When designing and writing Delinkcious, the application code was fairly
    simple. We keep track of users, their links, and their follower/following relationships.
    We also do some link checking and store recent links in the news service. Finally,
    we expose all of this functionality through an API.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先回顾一下微服务面临的问题，与单体应用相比，看看服务网格是如何解决这些问题的，然后你就会明白我为什么对它们如此兴奋。在设计和编写Delinkcious时，应用代码相当简单。我们跟踪用户、他们的链接以及他们的关注/被关注关系。我们还进行一些链接检查，并将最近的链接存储在新闻服务中。最后，我们通过API公开所有这些功能。
- en: Comparing monoliths to microservices
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将单体应用与微服务进行比较
- en: It would have been pretty easy to implement all this functionality in a single
    monolith. It would also be pretty simple to deploy, monitor, and debug a Delinkcious
    monolith. However, as Delinkcious grows in functionality, as well as users and
    the team developing it, the downsides of monolith applications become much more
    pronounced. That's why we embarked on this journey with the microservice-based
    approach. However, along the way, we had to write a lot of code, install a lot
    of additional tools, and configure many components that have nothing to do with
    the Delinkcious application itself. We wisely took advantage of Kubernetes and
    Go kit to cleanly separate all of these additional concerns from the Delinkcious
    domain code, but it was a lot of hard work.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体系统中实现所有这些功能本来很容易。在Delinkcious单体系统中部署、监控和调试也很简单。然而，随着Delinkcious在功能上的增长，以及用户和开发团队的增加，单体应用程序的缺点变得更加明显。这就是为什么我们选择了基于微服务的方法。然而，在这个过程中，我们不得不编写大量的代码，安装许多额外的工具，并配置许多与Delinkcious应用程序本身无关的组件。我们明智地利用了Kubernetes和Go
    kit来清晰地将所有这些额外的关注点与Delinkcious领域代码分离，但这是一项艰苦的工作。
- en: For example, if security is a high priority, you would want to authenticate
    and authorize inter-service calls in your system. We have done this in Delinkcious
    by introducing a mutual secret between the link service and the social graph service.
    We have to configure a secret, make sure it is accessible only to these two services,
    and add code to verify that each call is coming from the correct service. Maintaining
    (for example, rotating secrets) and evolving this across many services is not
    an easy task.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果安全性是高优先级，您会希望在系统中对服务间调用进行身份验证和授权。我们在Delinkcious中通过引入链接服务和社交图服务之间的共享密钥来实现这一点。我们必须配置一个密钥，确保它只能被这两个服务访问，并添加代码来验证每个调用是否来自正确的服务。在许多服务中维护（例如，轮换密钥）和演变这一点并不是一件容易的事情。
- en: Another example of this is distributed tracing. In a monolith, the entire chain
    of calls can be captured by a stack trace. In Delinkcious, you have to install
    a distributed tracing service, such as Jaeger, and modify the code to record spans.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个例子，即分布式跟踪。在单体系统中，整个调用链可以通过堆栈跟踪来捕获。在Delinkcious中，您必须安装分布式跟踪服务，例如Jaeger，并修改代码以记录跨度。
- en: Centralized logging in a monolith is trivial since the monolith is already a
    single centralized entity.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体系统中进行集中日志记录是微不足道的，因为单体系统已经是一个集中的实体。
- en: The bottom line is that microservices bring a lot of benefits, but they are
    much harder to manage and reign in.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，微服务带来了许多好处，但它们要管理和控制得多困难。
- en: Using a shared library to manage the cross-cutting concerns of microservices
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用共享库来管理微服务的横切关注点
- en: One of the most common approaches is to implement all these concerns in a library
    or a set of libraries. All the microservices include or depend on the shared library
    that takes care of all these cross-cutting aspects, such as configuration, logging,
    secret management, tracing, rate limiting, and fault tolerance. This sounds great
    in theory; let the services deal with the application domain and let a shared
    library or libraries deal with the common concerns. Hystrix from Netflix is a
    great example of a Java library that takes care of managing latency and fault
    tolerance. Finagle from Twitter is another good example of a Scala library (targeting
    the JVM). Many organizations use a collection of such libraries and often write
    their own.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的方法之一是在一个库或一组库中实现所有这些关注点。所有微服务都包含或依赖于处理所有这些横切面问题的共享库，如配置、日志记录、秘钥管理、跟踪、速率限制和容错。这在理论上听起来很不错；让服务处理应用领域，让一个共享库或一组库处理常见的关注点。Netflix的Hystrix就是一个很好的例子，它是一个处理延迟和容错的Java库。Twitter的Finagle是另一个很好的例子，它是一个针对JVM的Scala库。许多组织使用一系列这样的库，并经常编写自己的库。
- en: 'In practice, however, this approach has severe downsides. The first issue is
    that, being a programming language library, it is naturally implemented in a specific
    language (for example, Java, in the case of Hystrix). Your system may have microservices
    in multiple languages (even Delinkcious has both Go and Python services). Having
    microservices implemented in different programming languages is one of the greatest
    benefits. A shared library (or libraries) significantly hinders this aspect. This
    is because you end up with several unappealing options, as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实践中，这种方法有严重的缺点。第一个问题是，作为一个编程语言库，它自然是用特定的语言实现的（例如，在Hystrix的情况下是Java）。你的系统可能有多种语言的微服务（即使Delinkcious也有Go和Python服务）。使用不同编程语言实现的微服务是最大的好处之一。共享库（或库）显著地阻碍了这一方面。这是因为你最终会有几个不太吸引人的选项，如下所示：
- en: You restrict all your microservices to a single programming language.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将所有的微服务限制在一个编程语言中。
- en: You maintain cross-language shared libraries for each programming language you
    use that behaves the same.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你为你使用的每种编程语言维护跨语言共享库，使其行为相同。
- en: You accept that different services will interact differently with your centralized
    services (for example, different logging formats or missing tracing).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你接受不同的服务将以不同的方式与你的集中服务进行交互（例如，不同的日志格式或缺失的跟踪）。
- en: All of these options are pretty bad. But that's not the end of it; let's say
    you've picked a combination of the preceding options. This will very likely include
    a significant amount of custom code, because no off-the-shelve library will provide
    you with everything that you need. Now, you want to update your shared code library.
    Since it's shared by all or most of your services, this means you have to do an
    across-the-board upgrade of all your services. However, it's likely that you can't
    just shut down your system and upgrade all the services at once.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些选项都相当糟糕。但事情并没有就此结束；假设你选择了前面提到的一些选项的组合。这很可能会包括大量的自定义代码，因为没有现成的库能够提供你所需的一切。现在，你想要更新你的共享代码库。由于它被所有或大多数服务共享，这意味着你必须对所有服务进行全面升级。然而，很可能你不能一次性关闭系统并升级所有服务。
- en: Instead, you'll have to do it in the form of a rolling update. Even blue-green
    deployment can't be done instantly across multiple services. The problem is that,
    often, the shared code is related to how you manage mutual secrets or authentication
    between services. For example, if service A upgrades to the new version of the
    shared library and service B is still on the previous version, they might not
    be able to communicate. This results in an outage, which can cascade and impact
    many services. You can find a way to introduce changes in a backward-compatible
    way, but this is more difficult and error-prone.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，您将不得不以滚动更新的形式进行。即使是蓝绿部署也无法立即在多个服务之间完成。问题在于，通常，共享代码与您如何管理服务之间的共享秘密或身份验证有关。例如，如果服务A升级到共享库的新版本，而服务B仍在以前的版本上，它们可能无法通信。这会导致停机，可能会影响许多服务。您可以找到一种以向后兼容的方式引入更改的方法，但这更加困难且容易出错。
- en: Okay, so shared libraries across all services are useful but hard to manage.
    Let's take a look at how a service mesh can help.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以跨所有服务共享库是有用的，但很难管理。让我们看看服务网格如何帮助。
- en: Using a service mesh to manage the cross-cutting concerns of microservices
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用服务网格来管理微服务的横切关注点
- en: 'A service mesh is a set of intelligent proxies and additional control infrastructure
    components. The proxies are deployed on every node in your cluster. The proxies
    intercept all communication between the services and can do a lot of work on your
    behalf that previously had to be done by the service (or a shared library used
    by the service). Some of the responsibilities of a service mesh are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格是一组智能代理和额外的控制基础设施组件。代理部署在集群中的每个节点上。代理拦截所有服务之间的通信，并可以代表您执行许多工作，以前必须由服务（或服务使用的共享库）完成。服务网格的一些责任如下：
- en: Reliable delivery of requests between services through retries and automatic
    failovers
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过重试和自动故障转移可靠地传递请求
- en: Latency-aware load balancing
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟感知负载平衡
- en: Route requests based on flexible and dynamic routing rules (this is also known
    as traffic shaping)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据灵活和动态的路由规则路由请求（这也被称为流量整形）
- en: Circuit breaking through deadlines
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过截止日期进行断路
- en: Service-to-service authentication and authorization
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务对服务的身份验证和授权
- en: Report metrics and support for distributed tracing
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告指标和支持分布式跟踪
- en: All of these capabilities are important for many large-scale cloud-native applications.
    Offloading them from the services is a huge win. Features such as smart traffic
    shaping require building dedicated and reliable services without a service mesh.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些功能对于许多大规模云原生应用程序都很重要。从服务中卸载它们是一个巨大的胜利。诸如智能流量整形之类的功能需要构建专门的可靠服务，而无需服务网格。
- en: 'The following diagram illustrates how a service mesh is embedded into a Kubernetes
    cluster:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了服务网格嵌入到Kubernetes集群中的方式：
- en: '![](assets/3c4edd51-3de0-4ed9-bedf-806b3153a883.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3c4edd51-3de0-4ed9-bedf-806b3153a883.png)'
- en: Service meshes sound revolutionary indeed. Let's take a look at how they fit
    into Kubernetes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格听起来确实是革命性的。让我们看看它们如何适应Kubernetes。
- en: Understanding the relationship between Kubernetes and a service mesh
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Kubernetes与服务网格之间的关系
- en: At first glance, the service mesh sounds very similar to Kubernetes itself.
    Kubernetes deploys the kubelet and the kube-proxy into each node and the service
    mesh deploys its own proxy. Kubernetes has a control plane that kubelet/kube-proxy
    interacts with, and the service mesh has its own control plane that the mesh proxies
    interact with.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，服务网格听起来与Kubernetes本身非常相似。Kubernetes将kubelet和kube-proxy部署到每个节点上，而服务网格则部署自己的代理。Kubernetes有一个控制平面，kubelet/kube-proxy与之交互，而服务网格有自己的控制平面，网格代理与之交互。
- en: I like to think of a service mesh as a complement to Kubernetes. Kubernetes
    is primarily in charge of scheduling pods and providing it with the flat networking
    model and service discovery, so different pods and services can communicate with
    each other. This is where the service mesh takes over and manages this service-to-service
    communication in a much more fine-grained way. There is a thin layer of overlap
    in responsibilities around load balancing and network policies but, overall, the
    service mesh is a great complement to Kubernetes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢把服务网格看作是对Kubernetes的一个补充。Kubernetes主要负责调度pod并为其提供扁平网络模型和服务发现，以便不同的pod和服务之间可以相互通信。这就是服务网格接管并以更精细的方式管理这种服务与服务之间的通信。在负载平衡和网络策略方面有一层薄薄的重叠，但总体而言，服务网格是对Kubernetes的一个很好的补充。
- en: It's also important to realize that these two amazing technologies don't depend
    on each other. Obviously, you can run a Kubernetes cluster without a service mesh.
    Additionally, many service meshes can work with other non-Kubernetes platforms,
    such as Mesos, Nomad, Cloud Foundry, and Consul-based deployments.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是要意识到这两种令人惊叹的技术并不依赖于彼此。显然，您可以在没有服务网格的情况下运行Kubernetes集群。此外，许多服务网格可以与其他非Kubernetes平台一起工作，例如Mesos、Nomad、Cloud
    Foundry和基于Consul的部署。
- en: Now that we understand what a service mesh is, let's take a look at a specific
    example.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了什么是服务网格，让我们来看一个具体的例子。
- en: What does Istio bring to the table?
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Istio带来了什么？
- en: Istio is a service mesh that was originally developed by Google, IBM, and Lyft.
    It was introduced in mid-2017 and took off like a rocket. It brings a coherent
    model with a control and data plane, is built around the Envoy proxy, has a lot
    of momentum, and already serves as the foundation for additional projects. It
    is, of course, open source and a **Cloud Native Computing Foundation** (**CNCF**)
    project. In Kubernetes, each Envoy proxy is injected as a sidecar container to
    each pod that participates in the mesh.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Istio是一个服务网格，最初由Google、IBM和Lyft开发。它于2017年中期推出并迅速获得成功。它带来了一个统一的模型，具有控制平面和数据平面，围绕Envoy代理构建，具有很大的动力，并已经成为其他项目的基础。当然，它是开源的，是**Cloud
    Native Computing Foundation** (**CNCF**)项目。在Kubernetes中，每个Envoy代理都被注入为参与网格的每个pod的旁路容器。
- en: Let's explore the Istio architecture, and then dive into the services that it
    provides.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索Istio架构，然后深入了解它提供的服务。
- en: Getting to know the Istio architecture
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Istio架构
- en: Istio is a large framework that provides a lot of capabilities, and it has multiple
    parts that interact with each other and with Kubernetes components (mostly indirectly
    and unobtrusively). It is divided into a control plane and a data plane. The data
    plane is a set of proxies (one per pod). Their control plane is a set of components
    that are responsible for configuring the proxies and collecting telemetry of data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Istio是一个提供了许多功能的大型框架，它有多个部分相互交互，并与Kubernetes组件（主要是间接和不显眼地）交互。它分为控制平面和数据平面。数据平面是一组代理（每个pod一个）。它们的控制平面是一组负责配置代理和收集数据遥测的组件。
- en: 'The following diagram illustrates the different parts of Istio, how they are
    related to each other, and what information is exchanged between them:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了Istio的不同部分，它们之间的关系以及它们之间交换的信息：
- en: '![](assets/bcf2a6b9-cc37-4580-9cb4-28ad191e5c04.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bcf2a6b9-cc37-4580-9cb4-28ad191e5c04.png)'
- en: Let's go a little deeper into each component, starting with the Envoy proxy.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解每个组件，从Envoy代理开始。
- en: Envoy
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使者
- en: 'Envoy is a high-performance proxy that''s implemented in C++. It was developed
    by Lyft and functions as the data plane of Istio, but it is also an independent
    CNCF project and can be used on its own. For each pod in the service mesh, Istio
    injects (either automatically or through the `istioctl` CLI) an Envoy side container
    that does the heavy lifting:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy是一个用C++实现的高性能代理。它由Lyft开发，作为Istio的数据平面，但它也是一个独立的CNCF项目，可以单独使用。对于服务网格中的每个pod，Istio注入（自动或通过`istioctl`
    CLI）一个Envoy侧容器来处理繁重的工作：
- en: Proxy HTTP, HTTP/2, and gRPC traffic between pods
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理HTTP、HTTP/2和gRPC流量之间的pod
- en: Sophisticated load balancing
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的负载平衡
- en: mTLS termination
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mTLS终止
- en: HTTP/2 and gRPC proxies
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP/2和gRPC代理
- en: Providing service health
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供服务健康状况
- en: Circuit breaking for unhealthy services
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对不健康服务的断路
- en: Percent-based traffic shaping
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于百分比的流量整形
- en: Injecting faults for testing
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注入故障进行测试
- en: Detailed metrics
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细的度量
- en: The Envoy proxy controls all the incoming and outgoing communication to its
    pod. It is, by far, the most important component of Istio. The configuration of
    Envoy is not trivial, and this is a large part of what the Istio control plane
    deals with.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy代理控制其pod的所有传入和传出通信。这是Istio最重要的组件。Envoy的配置并不是微不足道的，这是Istio控制平面处理的一个很大的部分。
- en: The next component is Pilot.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个组件是Pilot。
- en: Pilot
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 飞行员
- en: Pilot is responsible for platform-agnostic service discovery, dynamic load balancing,
    and routing. It translates high-level routing rules and resiliency from its own
    rules API into an Envoy configuration. This abstraction layer allows Istio to
    run on multiple orchestration platforms. Pilot takes all the platform-specific
    information, converts it into the Envoy data plane configuration format, and propagates
    it to each Envoy proxy with the Envoy data plane API. Pilot is stateless; in Kubernetes,
    all the configuration is stored as **custom resources definitions** (**CRDs**)
    on etcd.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Pilot负责平台无关的服务发现、动态负载平衡和路由。它将高级路由规则和弹性从自己的规则API转换为Envoy配置。这种抽象层允许Istio在多个编排平台上运行。Pilot获取所有特定于平台的信息，将其转换为Envoy数据平面配置格式，并通过Envoy数据平面API传播到每个Envoy代理。Pilot是无状态的；在Kubernetes中，所有配置都存储为etcd上的**自定义资源定义**（**CRD**）。
- en: Mixer
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合器
- en: 'Mixer is responsible for abstracting the metrics collection and policies. These
    aspects are typically implemented in services by accessing APIs directly for specific
    backends. This has the benefit of offloading this burden from service developers
    and putting the control into the hands of the operators that configure Istio.
    It also allows you to switch backends easily without code changes. The types of
    backends that Mixer can work with include the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Mixer负责抽象度量收集和策略。这些方面通常通过直接访问特定后端的API来在服务中实现。这样做的好处是可以减轻服务开发人员的负担，并将控制权交给配置Istio的运营商。它还允许您在不改变代码的情况下轻松切换后端。Mixer可以与以下类型的后端一起工作：
- en: Logging
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录
- en: Authorization
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 授权
- en: Quota
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配额
- en: Telemetry
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测
- en: Billing
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计费
- en: The interaction between the Envoy proxy and Mixer is straightforward – before
    each request, the proxy calls Mixer for precondition checks, which might cause
    the request to be rejected; after each request, the proxy reports the metrics
    to Mixer. Mixer has an adapter API to facilitate extensions for arbitrary infrastructure
    backends. It is a major part of its design.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy代理与Mixer之间的交互很简单 - 在每个请求之前，代理调用Mixer进行前置条件检查，这可能导致请求被拒绝；在每个请求之后，代理向Mixer报告度量。Mixer具有适配器API，以便为任意基础设施后端进行扩展。这是其设计的一个重要部分。
- en: Citadel
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Citadel
- en: Citadel is responsible for certificate and key management in Istio. It integrates
    with various platforms and aligns with their identity mechanisms. For example,
    in Kubernetes, it uses service accounts; on AWS, it uses AWS IAM; and on GCP/GKE,
    it can use GCP IAM. The Istio PKI is based on Citadel. It uses X.509 certificates
    in SPIFEE format as a vehicle for service identity.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Citadel负责Istio中的证书和密钥管理。它与各种平台集成，并与它们的身份机制保持一致。例如，在Kubernetes中，它使用服务账户；在AWS上，它使用AWS
    IAM；在GCP/GKE上，它可以使用GCP IAM。Istio PKI基于Citadel。它使用X.509证书以SPIFEE格式作为服务身份的载体。
- en: 'Here is the workflow in Kubernetes:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Kubernetes中的工作流程：
- en: Citadel creates certificates and key pairs for existing service accounts.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Citadel为现有的服务账户创建证书和密钥对。
- en: Citadel watches the Kubernetes API server for new service accounts to provision
    with a certificate a key pair.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Citadel监视Kubernetes API服务器，以便为新的服务账户提供证书和密钥对。
- en: Citadel stores the certificates and keys as Kubernetes secrets.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Citadel将证书和密钥存储为Kubernetes秘密。
- en: Kubernetes mounts the secrets into each new pod that is associated with the
    service account (this is standard Kubernetes practice).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes将秘密挂载到与服务账户关联的每个新pod中（这是标准的Kubernetes实践）。
- en: Citadel automatically rotates the Kubernetes secrets when the certificates expire.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当证书过期时，Citadel会自动旋转Kubernetes秘密。
- en: Pilot generates secure naming information that associates a service account
    with an Istio service. Pilot then passes the secure naming information to the
    Envoy proxy.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pilot生成安全命名信息，将服务账户与Istio服务关联起来。然后Pilot将安全命名信息传递给Envoy代理。
- en: The final major component that we will cover is Galley.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要介绍的最后一个主要组件是Galley。
- en: Galley
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Galley
- en: Galley is a relatively simple component. Its job is to abstract away the user
    configuration on different platforms. It provides the ingested configuration to
    Pilot and Mixer.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Galley是一个相对简单的组件。它的工作是在不同平台上抽象用户配置。它将摄入的配置提供给Pilot和Mixer。
- en: Now that we have broken down Istio into its major components, let's take a look
    at how it accomplishes its duties as a service mesh. The number one capability
    is traffic management.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将Istio分解为其主要组件，让我们看看它如何完成作为服务网格的职责。第一能力是流量管理。
- en: Managing traffic with Istio
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio管理流量
- en: Istio operates at the network level inside the cluster between your services,
    as well as managing how you expose your services to the world. It provides many
    capabilities, such as request routing, load balancing, automatic retries, and
    fault injection. Let's review all of these, starting with routing requests.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Istio在集群内部的网络级别运行，管理服务之间的通信，以及管理如何将服务暴露给外部世界。它提供了许多功能，如请求路由、负载平衡、自动重试和故障注入。让我们从路由请求开始，回顾所有这些功能。
- en: Routing requests
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路由请求
- en: Istio introduces its own virtual services as a CRD. Istio services have a concept
    of a version that doesn't exist for Kubernetes services. The same image can be
    deployed as different versions of a virtual service. For example, you can represent
    the production or staging environment as different versions of the same service.
    Istio allows you to configure rules that determine how to route traffic to different
    versions of a service.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Istio引入了自己的虚拟服务作为CRD。Istio服务具有一个在Kubernetes服务中不存在的版本概念。同一图像可以部署为虚拟服务的不同版本。例如，您可以将生产环境或分段环境表示为同一服务的不同版本。Istio允许您配置规则，确定如何将流量路由到服务的不同版本。
- en: 'The way this works is that Pilot sends ingress and egress rules to the proxies
    that determine where requests should be handled. You then define the rules as
    a CRD in Kubernetes. Here is a simple example that defines a virtual service for
    the `link-manager` service:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的工作方式是Pilot将入口和出口规则发送到代理，以确定请求应该由哪里处理。然后在Kubernetes中将规则定义为CRD。以下是一个简单的示例，定义了`link-manager`服务的虚拟服务：
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let's take a look at how Istio does load balancing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Istio如何进行负载均衡。
- en: Load balancing
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负载均衡
- en: 'Istio has its own platform-independent service discovery with adapters for
    the underlying platform (for example, Kubernetes). It relies on the existence
    of a service registry that the underlying platform manages, and removes unhealthy
    instances in order to update its load balancing pools. There are currently three
    supported load balancing algorithms:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Istio具有自己的平台无关的服务发现，适配器适用于底层平台（例如Kubernetes）。它依赖于底层平台管理的服务注册表的存在，并删除不健康的实例以更新其负载均衡池。目前支持三种负载均衡算法：
- en: Round robin
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮询
- en: Random
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机
- en: Weighted least request
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权最少请求
- en: Envoy has a few more algorithms, such as Maglev, ring hash, and weighted round
    robin, that Istio doesn't support yet.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy还有一些其他算法，例如Maglev、环形哈希和加权轮询，Istio目前还不支持。
- en: Istio also performs periodic health checks to verify that instances in the pool
    are actually healthy, and can remove them from load balancing temporarily if they
    fail the configured health check threshold.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Istio还执行定期健康检查，以验证池中的实例实际上是健康的，并且如果它们未通过配置的健康检查阈值，可以暂时将它们从负载均衡中移除。
- en: 'You can configure load balancing through the destination rules in a separate
    `DestinationRule` CRD, as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过单独的`DestinationRule` CRD在目标规则中配置负载均衡，如下所示：
- en: '[PRE2]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can specify different algorithms by the port, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按端口指定不同的算法，如下所示：
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, let's take a look at how Istio can help us deal with failures automatically.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看Istio如何帮助我们自动处理故障。
- en: Handling failures
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理故障
- en: 'Istio provides many mechanisms to deal with failure, including the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Istio提供了许多处理故障的机制，包括以下内容：
- en: Timeouts
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超时
- en: Retries (including backoff and jitter)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试（包括退避和抖动）
- en: Rate limiting
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速率限制
- en: Health checks
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康检查
- en: Circuit breakers
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器
- en: All of these can be configured through Istio CRDs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都可以通过Istio CRD进行配置。
- en: 'For example, the following code demonstrates how to set the connection limits
    and timeout for the `link-manager` service at the TCP level (HTTP is supported
    too):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码演示了如何在TCP级别（HTTP也支持）设置`link-manager`服务的连接限制和超时：
- en: '[PRE4]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Circuit breaking is done by explicitly checking for application errors (for
    example, the 5XX HTTP status code) within a given time period. This is done in
    an `outlierDetection` section. The following example checks for 10 consecutive
    errors every 2 minutes. If the service crosses this threshold, the instance will
    be ejected from the pool for a period of 5 minutes:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器是通过在给定时间段内明确检查应用程序错误（例如，5XX HTTP状态代码）来完成的。这是在`outlierDetection`部分完成的。以下示例每2分钟检查10个连续错误。如果服务超过此阈值，实例将被从池中驱逐5分钟：
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that, as far as Kubernetes is concerned, the service may be fine because
    the container is running.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，就Kubernetes而言，服务可能没问题，因为容器正在运行。
- en: It's great that Istio provides so many ways to deal with errors and failures
    at the operational level. When testing distributed systems, it is important to
    test the behavior when certain components fail. Istio supports this use case by
    allowing you to inject faults on purpose.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Istio提供了许多处理操作级别错误和故障的方式，这很棒。在测试分布式系统时，重要的是测试某些组件失败时的行为。Istio通过允许您故意注入故障来支持这种用例。
- en: Injecting faults for testing
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注入故障进行测试
- en: 'The failure handling mechanisms of Istio don''t magically fix errors. Automatic
    retries can automatically address intermittent failures, but some failures need
    to be handled by the application or even a human operator. In fact, the misconfiguration
    of Istio failure handling can itself cause failures (for example, configuring
    timeouts that are too short). Testing how the system behaves in the presence of
    failures can be done by artificially injecting faults. There are two types of
    faults that Istio can inject: aborts and delays. You can configure fault injection
    at the virtual service level.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Istio的故障处理机制并不能神奇地修复错误。自动重试可以自动处理间歇性故障，但有些故障需要应用程序甚至人工操作员来处理。事实上，Istio故障处理的错误配置本身可能导致故障（例如，配置的超时时间太短）。可以通过人为注入故障来测试系统在故障存在的情况下的行为。Istio可以注入两种类型的故障：中止和延迟。您可以在虚拟服务级别配置故障注入。
- en: 'Here is an example of where a delay of 5 seconds is added to 10% of all requests
    to the `link-manager` service in order to simulate a heavy load on the system:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，其中将在`link-manager`服务的10%的所有请求中添加5秒的延迟，以模拟系统的重负载：
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Testing under stress and in the presence of faults is a tremendous boon, but
    all testing is incomplete. When it's time to deploy the new version, you may want
    to deploy it to a small percentage of users or have the new version handle just
    a small percentage of all requests. This is where canary deployments come in.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在压力和故障存在的情况下进行测试是一个巨大的好处，但所有测试都是不完整的。当部署新版本时，您可能希望将其部署给一小部分用户，或者让新版本处理一小部分所有请求。这就是金丝雀部署的用武之地。
- en: Doing canary deployments
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行金丝雀部署
- en: We previously discovered how to perform canary deployments in Kubernetes. If
    we want to divert 10% of requests to our canary version, we have to deploy nine
    pods of the current version and one canary pod to get the correct ratio. Kubernetes'
    load balancing is tightly coupled to deployed pods. This is suboptimal. Istio
    has a better load balancing approach since it operates at the network level. You
    can simply configure two versions of your service and decide what percentage of
    requests go to each version, regardless of how many pods run each version.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前发现了如何在Kubernetes中执行金丝雀部署。如果我们想将10%的请求转发到我们的金丝雀版本，我们必须部署当前版本的九个pod和一个金丝雀pod以获得正确的比例。Kubernetes的负载均衡与部署的pod紧密耦合。这是次优的。Istio有更好的负载均衡方法，因为它在网络级别运行。您可以简单地配置服务的两个版本，并决定百分之多少的请求发送到每个版本，而不管每个版本运行多少个pod。
- en: 'Here is an example of where Istio will split the traffic and send 95% to v1
    of the service and 5% to v2 of the service:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，Istio将分割流量并将95%发送到服务的v1，5%发送到服务的v2：
- en: '[PRE7]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The subsets named v1 and v2 are defined in a destination rule based on labels.
    In this case, the label are `version: v1` and `version: v2`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '子集v1和v2是根据标签在目标规则中定义的。在这种情况下，标签是`version: v1`和`version: v2`：'
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This was a pretty comprehensive coverage of the traffic management capabilities
    of Istio, but there is much more to discover. Let's turn our attention to security.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对Istio流量管理能力的相当全面的覆盖，但还有更多可以发现的。让我们把注意力转向安全。
- en: Securing your cluster with Istio
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio保护您的集群
- en: 'The security model of Istio revolves around three themes: identity, authentication,
    and authorization.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Istio的安全模型围绕三个主题展开：身份、认证和授权。
- en: Understanding Istio identity
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Istio的身份
- en: Istio manages its own identity model, which can represent human users, services,
    or groups of services. In Kubernetes, Istio uses Kubernetes' service account to
    represent identity. Istio uses its PKI (through Citadel) to create a strong cryptographic
    identity for each pod that it manages. It creates a x.509 certificate (in SPIFEE
    format) and a key pair for each service account and injects them as secrets to
    the pod. Pilot manages a map between the DNS service names and the identities
    that are allowed to run them. When clients call into services, they can verify
    that the services are indeed run by allowed identities and can detect rogue services.
    With a strong identity in place, let's take a look at how authentication works
    with Istio.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Istio管理自己的身份模型，可以代表人类用户、服务或服务组。在Kubernetes中，Istio使用Kubernetes的服务账户来表示身份。Istio使用其PKI（通过Citadel）为其管理的每个pod创建强大的加密身份。它为每个服务账户创建一个x.509证书（以SPIFEE格式）和一对密钥，并将它们作为秘密注入到pod中。Pilot管理了DNS服务名称和允许运行它们的身份之间的映射。当客户端调用服务时，它们可以验证服务确实是由允许的身份运行的，并且可以检测到恶意服务。有了强大的身份验证，让我们来看看Istio的身份验证是如何工作的。
- en: Authenticating users with Istio
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio对用户进行身份验证
- en: 'Istio authentication is based on policies. There are two kinds of policies:
    namespace policies and mesh policies. A namespace policy applies to a single namespace.
    A mesh policy applies to the entire cluster. There can be only one mesh policy
    with a kind of `MeshPolicy` and it must be named `default`. Here is an example
    of a mesh policy that requires all services to use mTLS:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Istio认证是基于策略的。有两种类型的策略：命名空间策略和网格策略。命名空间策略适用于单个命名空间。网格策略适用于整个集群。只能有一个网格策略，类型为`MeshPolicy`，并且必须命名为`default`。以下是一个要求所有服务使用mTLS的网格策略示例：
- en: '[PRE9]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Namespace policies have a kind of `Policy`. If you don''t specify a namespace,
    then it will apply to the default namespace. There can be only one policy per
    namespace and it must be called `default` too. The following policy uses the targets
    selector to apply only to the `api-gateway` service and port `8080` of the link
    service:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间策略的类型为`Policy`。如果不指定命名空间，则它将应用于默认命名空间。每个命名空间只能有一个策略，并且也必须被称为`default`。以下策略使用目标选择器仅适用于`api-gateway`服务和链接服务的端口`8080`：
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The idea is to avoid ambiguity; policies are resolved from a service to a namespace
    to a mesh. If a narrow policy exists, it takes precedence.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是为了避免歧义；策略是从服务到命名空间再到网格解析的。如果存在一个狭窄的策略，它将优先。
- en: Istio provides either peer authentication through mTLS or origin authentication
    through JWT.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Istio提供了通过mTLS进行对等体身份验证或通过JWT进行源身份验证。
- en: 'You can configure peer authentication through the `peers` section, as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过`peers`部分配置对等体身份验证，如下所示：
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can configure the origin through the `origins` section, as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过`origins`部分配置源身份，如下所示：
- en: '[PRE12]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, origin authentication can be configured for specific paths (through
    the include or exclude paths). In the preceding example, the `/healthcheck` path
    is exempt from authentication, which makes sense for a health check endpoint that
    often needs to be called from a load balancer or remote monitoring service.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，可以为特定路径配置源身份验证（通过包括或排除路径）。在前面的示例中，`/healthcheck`路径被豁免于身份验证，这对于经常需要从负载均衡器或远程监控服务调用的健康检查端点是有意义的。
- en: 'By default, peer authentication is used if there is a peers section. If not,
    then authentication will not be set. To force origin authentication, you can add
    the following to the policy:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，如果存在对等体部分，则使用对等体身份验证。如果没有，则不会设置身份验证。要强制进行源身份验证，可以将以下内容添加到策略中：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now that we've discovered how Istio authenticates requests, let's take a look
    at how it does authorization.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Istio如何对请求进行身份验证，让我们来看看它是如何进行授权的。
- en: Authorizing requests with Istio
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio授权请求
- en: Services usually expose multiple endpoints. Service A may be allowed to call
    only specific endpoints of service B. Service A must first authenticate against
    service B, and then the specific request must be authorized as well. Istio supports
    this by extending the** role-based access control** (**RBAC**) that Kubernetes
    uses to authorize requests to its API server.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 服务通常公开多个端点。服务A可能只允许调用服务B的特定端点。服务A必须首先对服务B进行身份验证，然后还必须对特定请求进行授权。Istio通过扩展Kubernetes用于授权对其API服务器的请求的**基于角色的访问控制**（**RBAC**）来支持这一点。
- en: 'It''s important to note that authorization is turned off by default. To turn
    it on, you can create a `ClusterRbacConfig` object. The mode controls how authorization
    is enabled, as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，授权默认处于关闭状态。要启用它，您可以创建一个`ClusterRbacConfig`对象。模式控制授权的启用方式，如下所示：
- en: '`OFF` means authorization is disabled (the default).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OFF`表示授权已禁用（默认）。'
- en: '`ON` means authorization is enabled for all the services in the entire mesh.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ON`表示授权对整个网格中的所有服务启用。'
- en: '`ON_WITH_INCLUSION` means authorization is enabled for all the included namespaces
    and services.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ON_WITH_INCLUSION`表示授权对所有包含的命名空间和服务启用。'
- en: '`ON_WITH_EXCLUSION` means authorization is enabled for all namespaces and services
    except the excluded ones.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ON_WITH_EXCLUSION`表示授权对所有命名空间和服务启用，除了被排除的。'
- en: 'Here is an example of when authorization is enabled on all the namespaces except
    `kube-system` and `development`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是授权在除了`kube-system`和`development`之外的所有命名空间上启用的示例：
- en: '[PRE14]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The actual authorization operates at the service level and is very similar to
    the RBAC model of Kubernetes. Where in Kubernetes there is `Role`, `ClusterRole`,
    `RoleBinding`, and `ClusterRoleBinding`, in Istio, there is `ServiceRole` and
    `ServiceRoleBinding`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 实际授权在服务级别操作，与Kubernetes的RBAC模型非常相似。在Kubernetes中有`Role`、`ClusterRole`、`RoleBinding`和`ClusterRoleBinding`，在Istio中有`ServiceRole`和`ServiceRoleBinding`。
- en: 'The basic level of granularity is `namespace/service/path/method`. You can
    use wildcards for grouping. For example, the following role grants GET and HEAD
    access to all the Delinkcious managers and the API gateway in the default namespace:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的细粒度是`namespace/service/path/method`。您可以使用通配符进行分组。例如，以下角色授予默认命名空间中所有Delinkcious管理者和API网关的GET和HEAD访问权限：
- en: '[PRE15]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: However, Istio offers even further control with constraints and properties.
    You can limit a rule by the source namespace or the IP, labels, request headers,
    and other attributes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，Istio还提供了通过约束和属性进行更进一步的控制。您可以通过源命名空间或IP、标签、请求标头和其他属性来限制规则。
- en: You can refer to [https://istio.io/docs/reference/config/authorization/constraints-and-properties/](https://istio.io/docs/reference/config/authorization/constraints-and-properties/)
    for more details.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考[https://istio.io/docs/reference/config/authorization/constraints-and-properties/](https://istio.io/docs/reference/config/authorization/constraints-and-properties/)获取更多详细信息。
- en: 'Once you have a `ServiceRole`, you need to associate it with a list of subjects
    (such as service accounts or human users) that will be allowed to perform the
    requested operations. Here is how you can define `ServiceRoleBinding`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了`ServiceRole`，您需要将其与允许执行请求操作的主体（例如服务账户或人类用户）的列表进行关联。以下是如何定义`ServiceRoleBinding`：
- en: '[PRE16]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You can make a role publicly available to authenticated or unauthenticated users
    by setting the subject user to `*`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将主体用户设置为`*`，可以使角色对经过身份验证或未经身份验证的用户公开可用。
- en: 'There is much to Istio authorization that we can cover here. You can read up
    on the following topics:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Istio授权有很多内容，我们无法在这里涵盖。您可以阅读以下主题：
- en: Authorization for TCP protocols
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP协议的授权
- en: Permissive mode (experimental)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宽容模式（实验性）
- en: Debugging authorization problems
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试授权问题
- en: Authorization through Envoy filters
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Envoy过滤器进行授权
- en: Once a request is authorized there, it may still be rejected if it fails to
    comply with policy checks.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦请求在那里得到授权，如果未能符合策略检查，仍可能被拒绝。
- en: Enforcing policies with Istio
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio执行策略
- en: 'Istio policy enforcement is similar to the way admission controllers work in
    Kubernetes. Mixer has a set of adapters that are invoked before and after a request
    is processed. Before we dive in further, it''s important to note that policy enforcement
    is disabled by default. If you install Istio using helm, you can enable it by
    providing the following flag:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Istio策略执行类似于Kubernetes中的准入控制器的工作方式。Mixer有一组适配器，在请求处理之前和之后被调用。在我们进一步深入之前，重要的是要注意，默认情况下策略执行是禁用的。如果您使用helm安装Istio，可以通过提供以下标志来启用它：
- en: '[PRE17]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'On GKE, it is enabled; here is how to check this:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在GKE上，它是启用的；以下是如何检查这一点：
- en: '[PRE18]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If the result is `disablePolicyChecks: false`, then it''s already enabled.
    Otherwise, enable it by editing the Istio ConfigMap and setting it to false.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '如果结果是`disablePolicyChecks: false`，那么它已经启用。否则，通过编辑Istio ConfigMap并将其设置为false来启用它。'
- en: One common type of policy is rate limiting. You can enforce rate limits by configuring
    quota objects, binding them to specific services, and defining mixer rules. A
    good example from the Istio demo application can be found at [https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml](https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的策略类型是速率限制。您可以通过配置配额对象、将它们绑定到特定服务并定义混合器规则来强制执行速率限制。在Istio演示应用程序中可以找到一个很好的例子，网址为[https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml](https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml)。
- en: 'You can also add your own policies by creating a Mixer adapter. There are three
    built-in types of adapters, as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过创建Mixer适配器来添加自己的策略。有三种内置类型的适配器，如下：
- en: Check
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查
- en: Quota
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配额
- en: Report
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告
- en: This is not trivial; you'll have to implement a gRPC service that can handle
    the data specified in a dedicated template. Now, let's take a look at the metrics
    Istio collects for us.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是微不足道的；您将不得不实现一个可以处理专用模板中指定的数据的gRPC服务。现在，让我们来看看Istio为我们收集的指标。
- en: Collecting metrics with Istio
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Istio收集指标
- en: 'Istio collects metrics after each request. The metrics are sent to Mixer. Envoy
    is the primary producer of metrics, but you can add your own metrics if you wish.
    The configuration model for metrics is based on multiple Istio concepts: attributes,
    instances, templates, handlers, rules, and Mixer adapters.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Istio在每个请求之后收集指标。指标被发送到Mixer。Envoy是主要的指标生产者，但如果愿意，您也可以添加自己的指标。指标的配置模型基于多个Istio概念：属性、实例、模板、处理程序、规则和Mixer适配器。
- en: 'Here is a sample instance that counts all the requests and reports them as
    the `request-count` metric:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个计算所有请求并将其报告为`request-count`指标的示例实例：
- en: '[PRE19]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'apiVersion: config.istio.io/v1alpha2'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：config.istio.io/v1alpha2
- en: 'kind: handler'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：处理程序
- en: 'metadata:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: request-count-handler'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：request-count-handler
- en: 'namespace: istio-system'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：istio-system
- en: 'spec:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'compiledAdapter: prometheus'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: compiledAdapter：prometheus
- en: 'params:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'metrics:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 指标：
- en: '- name: request_count # Prometheus metric name'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：request_count # Prometheus指标名称'
- en: 'instance_name: request-count.instance.istio-system # Mixer instance name (fully-qualified)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 'instance_name：request-count.instance.istio-system # Mixer实例名称（完全合格）'
- en: 'kind: COUNTER'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：计数器
- en: 'label_names:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 标签名称：
- en: '- reporter'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '- 记者'
- en: '- source'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '- 来源'
- en: '- destination'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '- 目的地'
- en: '- message'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '- 消息'
- en: '[PRE21]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'apiVersion: config.istio.io/v1alpha2'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：config.istio.io/v1alpha2
- en: 'kind: rule'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：规则
- en: 'metadata:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: prom-request-counter'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：prom-request-counter
- en: 'namespace: istio-system'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：istio-system
- en: 'spec:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'actions:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 操作：
- en: '- handler: request-count-handler'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '- 处理程序：request-count-handler'
- en: 'instances: [ request-count ]'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 实例：[request-count]
- en: '[PRE22]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: $ kubectl get secret | grep mutual
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl get secret | grep mutual
- en: link-mutual-auth             Opaque          1      9d
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: link-mutual-auth             Opaque          1      9d
- en: social-graph-mutual-auth    Opaque          1      5d19h
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: social-graph-mutual-auth    Opaque          1      5d19h
- en: '[PRE23]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'spec:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'containers:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 容器：
- en: '- name: link-manager'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：link-manager'
- en: 'image: g1g1/delinkcious-link:0.3'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图像：g1g1/delinkcious-link:0.3
- en: 'imagePullPolicy: Always'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: imagePullPolicy：Always
- en: 'ports:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 端口：
- en: '- containerPort: 8080'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '- containerPort：8080'
- en: 'envFrom:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: envFrom：
- en: '- configMapRef:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '- configMapRef：'
- en: 'name: link-manager-config'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：link-manager-config
- en: 'volumeMounts:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: volumeMounts：
- en: '- name: mutual-auth'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：mutual-auth'
- en: 'mountPath: /etc/delinkcious'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 挂载路径：/etc/delinkcious
- en: 'readOnly: true'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: readOnly：true
- en: 'volumes:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 卷：
- en: '- name: mutual-auth'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：mutual-auth'
- en: 'secret:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密：
- en: 'secretName: link-mutual-auth'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: secretName：link-mutual-auth
- en: '[PRE24]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: // encodeHTTPGenericRequest is a transport/http.EncodeRequestFunc that
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: // encodeHTTPGenericRequest is a transport/http.EncodeRequestFunc that
- en: // JSON-encodes any request to the request body. Primarily useful in a client.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: // JSON-encodes any request to the request body. Primarily useful in a client.
- en: func encodeHTTPGenericRequest(_ context.Context, r *http.Request, request interface{})
    error {
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: func encodeHTTPGenericRequest(_ context.Context, r *http.Request, request interface{})
    error {
- en: var buf bytes.Buffer
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: var buf bytes.Buffer
- en: if err := json.NewEncoder(&buf).Encode(request); err != nil {
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果err：= json.NewEncoder(&buf).Encode(request); err！= nil {
- en: return err
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: return err
- en: '}'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: r.Body = ioutil.NopCloser(&buf)
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: r.Body = ioutil.NopCloser(&buf)
- en: if os.Getenv("DELINKCIOUS_MUTUAL_AUTH") != "false" {
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果os.Getenv("DELINKCIOUS_MUTUAL_AUTH")！= "false" {
- en: token := auth_util.GetToken(SERVICE_NAME)
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: token：= auth_util.GetToken(SERVICE_NAME)
- en: r.Header["Delinkcious-Caller-Token"] = []string{token}
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: r.Header["Delinkcious-Caller-Token"] = []string{token}
- en: '}'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: return nil
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: return nil
- en: '}'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE25]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: func decodeGetFollowersRequest(_ context.Context, r *http.Request) (interface{},
    error){
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: func decodeGetFollowersRequest(_ context.Context, r *http.Request) (interface{},
    error){
- en: if os.Getenv("DELINKCIOUS_MUTUAL_AUTH") != "false" {
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果os.Getenv("DELINKCIOUS_MUTUAL_AUTH")！= "false" {
- en: token := r.Header["Delinkcious-Caller-Token"]
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: token：= r.Header["Delinkcious-Caller-Token"]
- en: if len(token) == 0 || token[0] == "" {
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果len(token) == 0 || token[0] == "" {
- en: return nil, errors.New("Missing caller token")
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: return nil, errors.New("Missing caller token")
- en: '}'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: if !auth_util.HasCaller("link-manager", token[0]) {
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 如果！auth_util.HasCaller("link-manager", token[0]) {
- en: return nil, errors.New("Unauthorized caller")
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: return nil, errors.New("Unauthorized caller")
- en: '}'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '...'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '...'
- en: '}'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE26]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'apiVersion: "rbac.istio.io/v1alpha1"'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion："rbac.istio.io/v1alpha1"
- en: 'kind: ServiceRole'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：ServiceRole
- en: 'metadata:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: get-following'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：get-following
- en: 'namespace: default'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：默认
- en: 'spec:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'rules:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 规则：
- en: '- services: ["social-graph.default.svc.cluster.local"]'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '- 服务：["social-graph.default.svc.cluster.local"]'
- en: 'paths: ["/following"]'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 路径：["/following"]
- en: 'methods: ["GET"]'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 方法：["GET"]
- en: '[PRE27]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'apiVersion: "rbac.istio.io/v1alpha1"'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion："rbac.istio.io/v1alpha1"
- en: 'kind: ServiceRoleBinding'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：ServiceRoleBinding
- en: 'metadata:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: get-following'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：get-following
- en: 'namespace: default'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：默认
- en: 'spec:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'subjects:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 主题：
- en: '- user: "cluster.local/ns/default/sa/link-manager"'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '- 用户："cluster.local/ns/default/sa/link-manager"'
- en: 'roleRef:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: roleRef：
- en: 'kind: ServiceRole'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：ServiceRole
- en: 'name: "get-following"'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 名称："get-following"
- en: '[PRE28]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: $ kubectl scale --replicas=9 deployment/green-link-manager
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl scale --replicas=9 deployment/green-link-manager
- en: deployment.extensions/green-link-manager scaled
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.extensions/green-link-manager scaled
- en: $ kubectl get po -l svc=link,app=manager
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl get po -l svc=link,app=manager
- en: NAME                                 READY  STATUS    RESTARTS   AGE
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 名称                                 READY  STATUS    RESTARTS   AGE
- en: green-link-manager-5874c6cd4f-2ldfn   1/1   Running   10         15h
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-2ldfn   1/1   Running   10         15h
- en: green-link-manager-5874c6cd4f-9csxz   1/1   Running   0          52s
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-9csxz   1/1   Running   0          52s
- en: green-link-manager-5874c6cd4f-c5rqn   1/1   Running   0          52s
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-c5rqn   1/1   Running   0          52s
- en: green-link-manager-5874c6cd4f-mvm5v   1/1   Running   10         15h
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-mvm5v   1/1   Running   10         15h
- en: green-link-manager-5874c6cd4f-qn4zj   1/1   Running   0          52s
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-qn4zj   1/1   Running   0          52s
- en: green-link-manager-5874c6cd4f-r2jxf   1/1   Running   0          52s
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: green-link-manager-5874c6cd4f-r2jxf   1/1   Running   0          52s
- en: green-link-manager-5874c6cd4f-rtwsj   1/1   Running   0          52s
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色链接管理器-5874c6cd4f-rtwsj 1/1 运行中 0 52秒
- en: green-link-manager-5874c6cd4f-sw27r   1/1   Running   0          52s
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色链接管理器-5874c6cd4f-sw27r 1/1 运行中 0 52秒
- en: green-link-manager-5874c6cd4f-vcj9s   1/1   Running   10         15h
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色链接管理器-5874c6cd4f-vcj9s 1/1 运行中 10 15小时
- en: yellow-link-manager-67847d6b85-n97b5  1/1   Running   4          6m20s
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: yellow-link-manager-67847d6b85-n97b5 1/1 运行中 4 6分钟20秒
- en: '[PRE29]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'apiVersion: networking.istio.io/v1alpha3'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: networking.istio.io/v1alpha3'
- en: 'kind: VirtualService'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：VirtualService
- en: 'metadata:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: social-graph-manager'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：social-graph-manager
- en: 'spec:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'hosts:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 主机：
- en: '- social-graph-manager'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '- social-graph-manager'
- en: 'http:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: http：
- en: '- route:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '- 路由：'
- en: '- destination:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '- 目的地：'
- en: 'host: social-graph-manager'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 主机：social-graph-manager
- en: 'subset: v0.5'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 子集：v0.5
- en: 'weight: 90'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 权重：90
- en: '- destination:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '- 目的地：'
- en: 'host: social-graph-manager'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 主机：social-graph-manager
- en: 'subset: canary'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 子集：金丝雀
- en: 'weight: 10'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 权重：10
- en: '[PRE30]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'apiVersion: nats.io/v1alpha2'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: nats.io/v1alpha2'
- en: 'kind: NatsCluster'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：NatsCluster
- en: 'metadata:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: nats-cluster'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：nats-cluster
- en: 'spec:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'pod:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: pod：
- en: Disable istio on nats pods
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 nats pods 上禁用 istio
- en: 'annotations:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：
- en: 'sidecar.istio.io/inject: "false"'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 'sidecar.istio.io/inject: "false"'
- en: 'size: 1'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 大小：1
- en: 'version: "1.4.0"'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 版本："1.4.0"
- en: '[PRE31]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: $ kubectl get crd -l k8s-app=istio -o custom-columns="NAME:.metadata.name"
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl get crd -l k8s-app=istio -o custom-columns="NAME:.metadata.name"
- en: NAME
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 名称
- en: adapters.config.istio.io
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: adapters.config.istio.io
- en: apikeys.config.istio.io
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: apikeys.config.istio.io
- en: attributemanifests.config.istio.io
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: attributemanifests.config.istio.io
- en: authorizations.config.istio.io
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: authorizations.config.istio.io
- en: bypasses.config.istio.io
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: bypasses.config.istio.io
- en: checknothings.config.istio.io
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: checknothings.config.istio.io
- en: circonuses.config.istio.io
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: circonuses.config.istio.io
- en: deniers.config.istio.io
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: deniers.config.istio.io
- en: destinationrules.networking.istio.io
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: destinationrules.networking.istio.io
- en: edges.config.istio.io
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: edges.config.istio.io
- en: envoyfilters.networking.istio.io
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: envoyfilters.networking.istio.io
- en: fluentds.config.istio.io
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: fluentds.config.istio.io
- en: gateways.networking.istio.io
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: gateways.networking.istio.io
- en: handlers.config.istio.io
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: handlers.config.istio.io
- en: httpapispecbindings.config.istio.io
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: httpapispecbindings.config.istio.io
- en: httpapispecs.config.istio.io
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: httpapispecs.config.istio.io
- en: instances.config.istio.io
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: instances.config.istio.io
- en: kubernetesenvs.config.istio.io
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: kubernetesenvs.config.istio.io
- en: kuberneteses.config.istio.io
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: kuberneteses.config.istio.io
- en: listcheckers.config.istio.io
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: listcheckers.config.istio.io
- en: listentries.config.istio.io
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: listentries.config.istio.io
- en: logentries.config.istio.io
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: logentries.config.istio.io
- en: memquotas.config.istio.io
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: memquotas.config.istio.io
- en: metrics.config.istio.io
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: metrics.config.istio.io
- en: noops.config.istio.io
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: noops.config.istio.io
- en: opas.config.istio.io
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: opas.config.istio.io
- en: prometheuses.config.istio.io
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: prometheuses.config.istio.io
- en: quotas.config.istio.io
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: quotas.config.istio.io
- en: quotaspecbindings.config.istio.io
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: quotaspecbindings.config.istio.io
- en: quotaspecs.config.istio.io
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: quotaspecs.config.istio.io
- en: rbacconfigs.rbac.istio.io
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: rbacconfigs.rbac.istio.io
- en: rbacs.config.istio.io
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: rbacs.config.istio.io
- en: redisquotas.config.istio.io
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: redisquotas.config.istio.io
- en: reportnothings.config.istio.io
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: reportnothings.config.istio.io
- en: rules.config.istio.io
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: rules.config.istio.io
- en: servicecontrolreports.config.istio.io
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: servicecontrolreports.config.istio.io
- en: servicecontrols.config.istio.io
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: servicecontrols.config.istio.io
- en: serviceentries.networking.istio.io
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: serviceentries.networking.istio.io
- en: servicerolebindings.rbac.istio.io
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: servicerolebindings.rbac.istio.io
- en: serviceroles.rbac.istio.io
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: serviceroles.rbac.istio.io
- en: signalfxs.config.istio.io
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: signalfxs.config.istio.io
- en: solarwindses.config.istio.io
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: solarwindses.config.istio.io
- en: stackdrivers.config.istio.io
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: stackdrivers.config.istio.io
- en: statsds.config.istio.io
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: statsds.config.istio.io
- en: stdios.config.istio.io
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: stdios.config.istio.io
- en: templates.config.istio.io
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: templates.config.istio.io
- en: tracespans.config.istio.io
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: tracespans.config.istio.io
- en: virtualservices.networking.istio.io
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: virtualservices.networking.istio.io
- en: '[PRE32]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: $ kubectl -n istio-system get all -o name
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl -n istio-system get all -o name
- en: pod/istio-citadel-6995f7bd9-7c7x9
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-citadel-6995f7bd9-7c7x9
- en: pod/istio-egressgateway-57b96d87bd-cnc2s
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-egressgateway-57b96d87bd-cnc2s
- en: pod/istio-galley-6d7dd498f6-b29sk
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-galley-6d7dd498f6-b29sk
- en: pod/istio-ingressgateway-ddd557db7-glwm2
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-ingressgateway-ddd557db7-glwm2
- en: pod/istio-pilot-5765d76b8c-d9hq7
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-pilot-5765d76b8c-d9hq7
- en: pod/istio-policy-5b47b88467-x7pqf
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-policy-5b47b88467-x7pqf
- en: pod/istio-sidecar-injector-6b9fbbfcf6-fhc4k
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-sidecar-injector-6b9fbbfcf6-fhc4k
- en: pod/istio-telemetry-65dcd9ff85-bkjtd
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: pod/istio-telemetry-65dcd9ff85-bkjtd
- en: pod/promsd-7b49dcb96c-wrfs8
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: pod/promsd-7b49dcb96c-wrfs8
- en: service/istio-citadel
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-citadel
- en: service/istio-egressgateway
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-egressgateway
- en: service/istio-galley
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-galley
- en: service/istio-ingressgateway
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-ingressgateway
- en: service/istio-pilot
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-pilot
- en: service/istio-policy
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-policy
- en: service/istio-sidecar-injector
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-sidecar-injector
- en: service/istio-telemetry
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: service/istio-telemetry
- en: service/promsd
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: service/promsd
- en: deployment.apps/istio-citadel
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-citadel
- en: deployment.apps/istio-egressgateway
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-egressgateway
- en: deployment.apps/istio-galley
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-galley
- en: deployment.apps/istio-ingressgateway
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-ingressgateway
- en: deployment.apps/istio-pilot
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-pilot
- en: deployment.apps/istio-policy
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-policy
- en: deployment.apps/istio-sidecar-injector
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-sidecar-injector
- en: deployment.apps/istio-telemetry
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/istio-telemetry
- en: deployment.apps/promsd
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.apps/promsd
- en: replicaset.apps/istio-citadel-6995f7bd9
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-citadel-6995f7bd9
- en: replicaset.apps/istio-egressgateway-57b96d87bd
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-egressgateway-57b96d87bd
- en: replicaset.apps/istio-galley-6d7dd498f6
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-galley-6d7dd498f6
- en: replicaset.apps/istio-ingressgateway-ddd557db7
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-ingressgateway-ddd557db7
- en: replicaset.apps/istio-pilot-5765d76b8c
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-pilot-5765d76b8c
- en: replicaset.apps/istio-policy-5b47b88467
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-policy-5b47b88467
- en: replicaset.apps/istio-sidecar-injector-6b9fbbfcf6
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-sidecar-injector-6b9fbbfcf6
- en: replicaset.apps/istio-telemetry-65dcd9ff85
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/istio-telemetry-65dcd9ff85
- en: replicaset.apps/promsd-7b49dcb96c
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: replicaset.apps/promsd-7b49dcb96c
- en: horizontalpodautoscaler.autoscaling/istio-egressgateway
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: horizontalpodautoscaler.autoscaling/istio-egressgateway
- en: horizontalpodautoscaler.autoscaling/istio-ingressgateway
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: horizontalpodautoscaler.autoscaling/istio-ingressgateway
- en: horizontalpodautoscaler.autoscaling/istio-pilot
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: horizontalpodautoscaler.autoscaling/istio-pilot
- en: horizontalpodautoscaler.autoscaling/istio-policy
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: horizontalpodautoscaler.autoscaling/istio-policy
- en: horizontalpodautoscaler.autoscaling/istio-telemetry
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: horizontalpodautoscaler.autoscaling/istio-telemetry
- en: '[PRE33]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: $ kubectl get po
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl get po
- en: NAME READY STATUS RESTARTS AGE
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: NAME READY STATUS RESTARTS AGE
- en: api-gateway-5497d95c74-zlgnm 2/2 Running 0 4d11h
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: api-gateway-5497d95c74-zlgnm 2/2 Running 0 4d11h
- en: link-db-7445d6cbf7-wdfsb 2/2 Running 0 4d22h
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: link-db-7445d6cbf7-wdfsb 2/2 Running 0 4d22h
- en: link-manager-54968ff8cf-vtpqr 2/2 Running 1 4d13h
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: link-manager-54968ff8cf-vtpqr 2/2 Running 1 4d13h
- en: nats-cluster-1 1/1 Running 0 4d20h
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: nats-cluster-1 1/1 Running 0 4d20h
- en: nats-operator-55dfdc6868-2b57q 2/2 Running 3 4d22h
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: nats-operator-55dfdc6868-2b57q 2/2 Running 3 4d22h
- en: news-manager-7f447f5c9f-n2v2v 2/2 Running 1 4d20h
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: news-manager-7f447f5c9f-n2v2v 2/2 Running 1 4d20h
- en: news-manager-redis-0 2/2 Running 0 4d22h
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: news-manager-redis-0 2/2 Running 0 4d22h
- en: social-graph-db-7d8ffb877b-nrzxh 2/2 Running 0 4d11h
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: social-graph-db-7d8ffb877b-nrzxh 2/2 Running 0 4d11h
- en: social-graph-manager-59b464456f-48lrn 2/2 Running 1 4d11h
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: social-graph-manager-59b464456f-48lrn 2/2 Running 1 4d11h
- en: trouble-64554479d-rjszv 2/2 Running 0 4d17h
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: trouble-64554479d-rjszv 2/2 Running 0 4d17h
- en: user-db-0 2/2 Running 0 4d22h
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: user-db-0 2/2 Running 0 4d22h
- en: user-manager-699458447-9h64n 2/2 Running 2 4d22h
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: user-manager-699458447-9h64n 2/2 Running 2 4d22h
- en: '```'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: If you think that Istio is too big and complicated, you may still want to enjoy
    the benefits of a service mesh by pursuing one of the alternatives.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: If you think that Istio is too big and complicated, you may still want to enjoy
    the benefits of a service mesh by pursuing one of the alternatives.
- en: Alternatives to Istio
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alternatives to Istio
- en: Istio has a lot of momentum, but it's not necessarily the best service mesh
    for you. Let's take a look at some other service meshes and consider their attributes.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: Istio has a lot of momentum, but it's not necessarily the best service mesh
    for you. Let's take a look at some other service meshes and consider their attributes.
- en: Linkerd 2.0
  id: totrans-458
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Linkerd 2.0
- en: Buoyant is the company that coined the term *Service Mesh* in 2016 and came
    out with the first service mesh – Linkerd. It was based on Twitter's Finagle and
    was implemented in Scala. Since then, Buoyant developed a new service mesh that
    focused on Kubernetes, called Conduit (which was implemented in Rust and Go),
    and later (in July 2018) renamed it to Linkerd 2.0\. It is a CNCF project like
    Istio. Linkerd 2.0 also uses sidecar containers that can be automatically or manually
    injected.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: Buoyant是在2016年创造了术语“服务网格”的公司，并推出了第一个服务网格——Linkerd。它基于Twitter的Finagle，并用Scala实现。此后，Buoyant开发了一个专注于Kubernetes的新服务网格，称为Conduit（用Rust和Go实现），后来（在2018年7月）将其改名为Linkerd
    2.0。它像Istio一样是一个CNCF项目。Linkerd 2.0还使用可以自动或手动注入的旁路容器。
- en: 'Due to its lightweight design and tighter implementation of the data plane
    proxies in Rust, Linkerd 2.0 is supposed to outperform Istio and consume far fewer
    resources in the control plane. You can refer to the following resources for more
    information:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其轻量级设计和在Rust中更紧密实现数据平面代理，Linkerd 2.0应该优于Istio，并在控制平面消耗更少的资源。您可以参考以下资源获取更多信息：
- en: '**CPU and memory**: [https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory](https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory)'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU和内存：[https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory](https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory)
- en: '**Linkerd 2.0 and Istio Performance Benchmark**: [https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb](https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb)'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linkerd 2.0和Istio性能基准测试：[https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb](https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb)
- en: '**Benchmarking Istio and Linkerd CPU**: [https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781](https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781)'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio和Linkerd CPU性能基准测试：[https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781](https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781)
- en: Buoyant is a smaller company and it seems to lag slightly behind Istio in functionality.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: Buoyant是一家较小的公司，似乎在功能上略逊于Istio。
- en: Envoy
  id: totrans-465
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Envoy
- en: The Istio data plane is Envoy, which does all the heavy lifting. You may find
    the Istio control plane too complicated and prefer to remove this layer of indirection
    and build your own control plane to interact directly with Envoy. This can be
    useful in some specialized circumstances; for example, if you want to use a load
    balancing algorithm offered by Envoy that Istio doesn't support.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: Istio的数据平面是Envoy，它完成所有繁重的工作。您可能会发现Istio的控制平面过于复杂，并希望删除这一间接层，并构建自己的控制平面直接与Envoy交互。在某些特定情况下，这可能很有用；例如，如果您想使用Istio不支持的Envoy提供的负载均衡算法。
- en: HashiCorp Consul
  id: totrans-467
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HashiCorp Consul
- en: Consul doesn't tick all the checkboxes for a service mesh, but it provides service
    discovery, service identity, and mTLS authorization. It is not Kubernetes-specific
    and isn't endorsed by the CNCF. If you already use Consul or other HashiCorp products,
    you may prefer to use it as a service mesh too.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: Consul并不完全符合服务网格的所有要求，但它提供了服务发现、服务身份验证和mTLS授权。它并不特定于Kubernetes，并且没有得到CNCF的认可。如果您已经在使用Consul或其他HashiCorp产品，您可能更喜欢将其用作服务网格。
- en: AWS App Mesh
  id: totrans-469
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS App Mesh
- en: If you run your infrastructure on AWS, you should consider the AWS App Mesh.
    It is a newer project, AWS-specific, and also uses Envoy as its data plane. It
    is safe to assume that it will integrate the best with AWS IAM networking and
    monitoring technologies. It's not clear at this point as to whether AWS App Mesh
    is going to be a better service mesh for Kubernetes or if its main purpose is
    to provide service mesh benefits for ECS – AWS' proprietary container orchestration
    solution.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在AWS上运行基础设施，您应该考虑AWS App Mesh。这是一个较新的项目，专门针对AWS，并且还使用Envoy作为其数据平面。可以肯定地假设它将与AWS
    IAM网络和监控技术最好地集成。目前尚不清楚AWS App Mesh是否将成为Kubernetes的更好的服务网格，或者其主要目的是为ECS提供服务网格的好处-
    AWS的专有容器编排解决方案。
- en: Others
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他
- en: 'There a few other service meshes out there. I will just mention them here so
    that you can pursue them further if you''re interested. Some of them have some
    form of integration with Istio. It''s not always clear what their value is since
    they are not open:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他的服务网格。我只是在这里提一下，这样你就可以进一步了解它们。其中一些与Istio有某种形式的集成。它们的价值并不总是很清楚，因为它们不是开放的：
- en: Aspen Mesh
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aspen Mesh
- en: Kong Mesh
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kong Mesh
- en: AVI Networks Universal Service Mesh
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AVI Networks通用服务网格
- en: The no mesh option
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无网格选项
- en: You can always avoid a service mesh completely and use a library such as Go
    kit, Hystrix, or Finagle. You might lose the benefits of the external service
    mesh, but if you tightly control all your microservices and they all use the same
    programming language, then the library approach may work just fine for you. It
    is conceptually and operationally simpler and it shifts the responsibility for
    managing cross-cutting concerns toward developers.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以完全避免使用服务网格，而使用诸如Go kit、Hystrix或Finagle之类的库。您可能会失去外部服务网格的好处，但如果您严格控制所有微服务，并且它们都使用相同的编程语言，那么库方法可能对您非常有效。这在概念上和操作上更简单，它将管理横切关注点的责任转移到开发人员身上。
- en: Summary
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've looked at service meshes and Istio in particular. Istio
    is a complex project; it sits on top of Kubernetes and creates a type of shadow
    cluster with its proxies. Istio has outstanding features; it can shape traffic
    at a very fine-grained level, provide sophisticated authentication and authorization,
    enforce advanced policies, collect a lot of information, and help scale your cluster.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看了服务网格，特别是Istio。Istio是一个复杂的项目；它位于Kubernetes之上，并创建了一种带有代理的影子集群。Istio具有出色的功能；它可以在非常精细的级别上塑造流量，提供复杂的身份验证和授权，执行高级策略，收集大量信息，并帮助扩展您的集群。
- en: We covered the Istio architecture, its powerful capabilities, and explored how
    Delinkcious can benefit from these capabilities.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了Istio的架构，其强大的功能，并探讨了Delinkcious如何从这些功能中受益。
- en: However, Istio is far from simple. It creates a plethora of custom resources,
    and it overlaps and extends existing Kubernetes resources in complex ways (VirtualService
    versus Service).
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Istio远非简单。它创建了大量的自定义资源，并且以复杂的方式重叠和扩展现有的Kubernetes资源（VirtualService与Service）。
- en: We also reviewed alternatives to Istio, including Linkerd 2.0, straight Envoy,
    AWS App Mesh, and Consul.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还回顾了Istio的替代方案，包括Linkerd 2.0、纯Envoy、AWS App Mesh和Consul。
- en: At this point, you should have a good understanding of the benefits of service
    meshes and what Istio can do for your projects. You may have to do some extra
    reading and experimentation to make an informed decision of whether you should
    incorporate Istio into your system right away, consider one of the alternatives,
    or just wait.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该对服务网格的好处以及Istio对您的项目能做什么有了很好的理解。您可能需要进行一些额外的阅读和实验，以便做出明智的决定，即立即将Istio纳入您的系统，考虑其中一种替代方案，或者只是等待。
- en: I believe that services meshes and Istio, in particular, will be very important
    and will become a standard best practice to incorporate into large Kubernetes
    clusters.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信服务网格和特别是Istio将非常重要，并且将成为纳入大型Kubernetes集群的标准最佳实践。
- en: In the next chapter, which is the last chapter, we will continue our discussion
    about the future of microservices, Kubernetes, and other emerging trends, such
    as serverless.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，也是最后一章，我们将继续讨论微服务、Kubernetes和其他新兴趋势的未来，比如无服务器。
- en: Further reading
  id: totrans-486
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can refer to the following resources for more information regarding what
    was covered in this chapter:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下资源，了解本章涵盖的更多信息：
- en: '**Istio**: [https://istio.io](https://istio.io)'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Istio**：[https://istio.io](https://istio.io)'
- en: '**Hystrix**:[ https://github.com/Netflix/Hystrix](https://github.com/Netflix/Hystrix)'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hystrix**：[https://github.com/Netflix/Hystrix](https://github.com/Netflix/Hystrix)'
- en: '**Finagle**:[ https://twitter.github.io/finagle/](https://twitter.github.io/finagle/)'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Finagle**：[https://twitter.github.io/finagle/](https://twitter.github.io/finagle/)'
- en: '**Envo**:[ https://www.envoyproxy.io/](https://www.envoyproxy.io/)'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Envo**：[https://www.envoyproxy.io/](https://www.envoyproxy.io/)'
- en: '**Spiffe**:[ https://spiffe.io](https://spiffe.io)'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spiffe**：[https://spiffe.io](https://spiffe.io)'
- en: '**Configuration**:[ https://istio.io/docs/reference/config/](https://istio.io/docs/reference/config/)'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Configuration**：[https://istio.io/docs/reference/config/](https://istio.io/docs/reference/config/)'
