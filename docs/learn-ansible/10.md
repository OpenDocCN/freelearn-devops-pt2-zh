# 十、高可用性云部署

继续我们的 AWS 部署，我们将开始将服务部署到我们在上一章中创建的网络中，到本章结束时，我们将剩下一个高可用性的 WordPress 安装，我们将通过在向站点发送流量时删除实例来测试它。

在我们上一章创建的角色的基础上，我们将执行以下操作:

*   启动和配置亚马逊 RDS(数据库)
*   启动和配置亚马逊 EFS(共享存储)
*   启动并创建**亚马逊机器映像** ( **AMI** )(部署 WordPress 代码)
*   启动和配置启动配置和自动缩放组(高可用性)

# 技术要求

和前一章一样，我们将使用 AWS 您将需要我们在上一章中创建的访问密钥和机密密钥来启动我们高度可用的 WordPress 安装所需的资源。请注意，我们将启动需要付费的资源。同样，您可以在随附的 GitHub 资源库的`Chapter10`文件夹中找到完整的行动手册，网址为[。](https://github.com/PacktPublishing/Learn-Ansible/tree/master/Chapter10/aws-wordpress)

# 规划部署

在我们深入研究行动手册之前，我们应该了解我们正在努力实现的目标。如前所述，我们将在 AWS VPC 的基础上增加实例和存储。我们更新后的图表如下所示:

![](../images/00088.jpeg)

在图表中，我们有以下内容:

*   3 个 EC2 实例(t2.micro)，每个可用性区域一个
*   2 个无线电数据系统实例(t2.micro)，在主/备用多 AZ 配置中
*   跨越三个可用性区域的 5gb EFS 存储

在我们讨论部署本身之前，根据这里的图表和规范，这个部署将花费我们多少钱来运行？

# 部署成本

在 EU-西一区进行这一部署的费用如下:

| **实例类型** | **#实例** | **每小时总成本** | **每日总成本** | **每月总成本** |
| EC2 实例(t2.micro) | three | $0.038 | $0.091 | $27.22 |
| 无线电数据系统实例(T2 . micro)—主服务器和备用服务器 | Two | $0.036 | $0.086 | $25.92 |
| 应用负载平衡器 | one | $0.033 | $0.80 | $23.90 |
| 5 GB EFS | one | $0.002 | £0.06 | $1.65 |
| 合计: | $0.109 | $2.62 | $78.69 |

还会有一些其他的小成本，比如带宽和存储包含我们软件栈的 AMI 的成本。我们可以通过删除一些冗余、禁用多 AZ RDS 实例以及将 EC2 实例数量减少到一个来显著降低这些成本；然而，这开始在我们的部署中引入单点故障，这是我们不想做的。

# WordPress 注意事项和高可用性

到目前为止，我们已经在一台服务器上启动了 WordPress，这很好，但是由于我们试图消除部署中尽可能多的单点故障，这意味着我们必须稍微考虑一下我们最初是如何配置和启动部署的。

首先，让我们讨论一下启动部署所需的顺序。我们需要在中启动元素的基本顺序如下:

*   **VPC、子网、互联网网关、路由和安全组**:这些都是启动我们部署所需要的
*   **应用弹性负载平衡器**:我们将使用弹性负载平衡器的公共主机名进行安装，因此这需要在我们开始安装之前启动
*   **RDS 数据库实例**:在我们启动安装之前，我们的数据库实例是可用的，这一点很重要，因为我们需要创建 WordPress 数据库并引导安装
*   **EFS 存储**:我们需要一些存储来在接下来将要启动的 EC2 实例之间共享

到目前为止，还不错；然而，这是我们必须开始考虑 WordPress 的地方。

你们中的一些人可能从经验中知道，当前版本的 WordPress 并没有真正设计成跨多个服务器分布。在这种部署中，我们可以应用大量的黑客和变通方法来让 WordPress 发挥出色；然而，这一章不是关于部署 WordPress 的细节。相反，它是关于如何使用 Ansible 来部署多层 web 应用。

正因为如此，我们将通过在 EFS 卷上部署我们的代码和内容来获得最基本的多实例 WordPress 选项。这意味着我们所要做的就是安装我们的 LEMP 栈。应该注意的是，这个选项不是性能最好的，但它将满足我们的需求。

现在回到任务列表。在启动实例时，我们需要执行以下操作:

*   启动运行 CentOS 7 的临时 EC2 实例，以便我们可以重用现有行动手册的部分内容
*   更新操作系统，安装我们安装和运行 WordPress 安装所需的软件栈、支持工具和配置
*   装载 EFS 卷，设置正确的权限，并将其配置为在启动时装载
*   将临时实例连接到我们的负载平衡器，并安装和配置 WordPress
*   从我们的临时实例创建一个 AMI
*   使用我们刚刚创建的 AMI 创建一个启动配置
*   创建自动缩放组并附加启动配置；它还应该向弹性负载平衡器注册我们的 WordPress 实例

在最初的行动手册执行过程中，当我们创建 AMI 时，会有一段短暂的停机时间；进一步的行动手册运行应该在现有实例启动并运行的情况下重复该过程，然后，一旦构建了 AMI，就应该将其部署在当前实例旁边，一旦新实例在弹性负载平衡器中注册并接收流量，该过程就会终止。这将允许我们更新我们的操作系统包和配置，而不会有任何停机时间——这也将模拟我们部署 AMIs，其中包含我们的代码库；这一章后面会有更多的介绍。

现在我们已经知道了我们想要实现的目标，让我们开始行动吧。

# 剧本

剧本将被分成几个部分。在我们开始第一个之前，让我们创建文件夹结构。根据前面的章节，我们只需要运行以下命令:

```
$ mkdir aws-wordpress aws-wordpress/group_vars aws-wordpress/roles
$ touch aws-wordpress/production aws-wordpress/site.yml aws-wordpress/group_vars/common.yml
```

现在我们已经有了基本的结构，我们可以开始创建角色，从网络开始。

# 亚马逊 VPC

创建底层网络的所有工作都在上一章中完成，这意味着我们只需将您之前剧本中的`elb`、`gateway`、`securitygroups`、`subnets`和`vpc`文件夹复制到您当前的`roles`文件夹中。

复制后，更新`site.yml`文件，使其为:

```
- name: Create and configure an Amazon VPC
  hosts: localhost
  connection: local
  gather_facts: True

  vars_files:
    - group_vars/common.yml

  roles:
    - roles/vpc
    - roles/subnets
    - roles/gateway
    - roles/securitygroups
    - roles/elb
```

另外，将以下内容添加到`group_vars/common.yml`文件中:

```
---
# the common variables

environment_name: "wordpress"
ec2_region: "eu-west-1"
```

最后，我们需要更新正在创建的子网；为此，将`roles/subnets/defaults/main.yml`中的`the_subnets`变量更新为:

```
the_subnets:
  - { use: 'ec2', az: 'a', subnet: '10.0.10.0/24' }
  - { use: 'ec2', az: 'b', subnet: '10.0.11.0/24' }
  - { use: 'ec2', az: 'c', subnet: '10.0.12.0/24' }
  - { use: 'elb', az: 'a', subnet: '10.0.20.0/24' }
  - { use: 'elb', az: 'b', subnet: '10.0.21.0/24' }
  - { use: 'elb', az: 'c', subnet: '10.0.22.0/24' }
  - { use: 'rds', az: 'a', subnet: '10.0.30.0/24' }
  - { use: 'rds', az: 'b', subnet: '10.0.31.0/24' }
  - { use: 'efs', az: 'a', subnet: '10.0.40.0/24' }
  - { use: 'efs', az: 'b', subnet: '10.0.41.0/24' }
  - { use: 'efs', az: 'c', subnet: '10.0.42.0/24' }
```

如您所见，我们正在为 EFS 卷添加一个额外的子网，使其在所有三个可用性区域中都可用。稍后详细说明原因。然而，它确实展示了我们行动手册的灵活性，我们所要做的就是在变量中添加一行来创建额外的子网。

这就完成了剧本的第一部分；我们现在可以进入一些新的领域，并启动我们的亚马逊 RDS 实例。

# 亚马逊无线电数据系统

让我们从运行以下命令来创建角色的文件结构开始:

```
$ ansible-galaxy init roles/rds
```

现在，让我们讨论一下启动 RDS 实例需要做什么。首先，我们需要定义一些默认值；将以下内容添加到`roles/rds/defaults/main.yml`文件中:

```
rds:
  db_username: "{{ environment_name }}"
  db_password: "{{ lookup('password', 'group_vars/rds_passwordfile chars=ascii_letters,digits length=30') }}"
  db_name: "{{ environment_name }}"
  app_instance_type: "db.t2.micro"
  engine: "mariadb"
  hdd_size: "5"
  no_of_backups: "7"
  multi_az: "yes"
  wait: "yes"
  wait_time: "1200"
```

有些变量是不言而喻的，比如`db_username`、`db_password`、`db_name`，虽然，如你所见，我们正在用`db_password`的内容做一些有趣的事情。我们使用的不是硬编码密码，而是查找插件；这些允许 Ansible 读取外部数据，例如文件、Redis、MongoDB 或各种 API 的内容。

在我们的例子中，我们使用 Ansible 密码查找插件用随机生成的密码填充 Ansible 控制器上的一个文件；这个文件在随后的查找中被单独留下，这意味着密码可以被重用。Ansible 将生成一个包含字母和数字的密码，长度为 30 个字符，并将其放在`group_vars/rds_passwordfile`处的一个文件中。该文件随后被添加到`.gitignore`文件中，因此我们最终不会将密码发送到版本控制。

需要注意的其他事情是，我们正在启动一个 db.t2.micro ( `app_instance_type` ) MariaDB ( `engine`)实例，在多 AZ 配置(`multi_az`)中有 5 GB ( `hdd_size`)的存储空间。我们将保留 7 天的备份(`no_of_backups`)，当实例首次启动时，我们将等待(`wait`)20 分钟(`wait_time`)让实例可用，然后进入行动手册的下一部分。

在启动 RDS 实例之前，我们需要做一件事，那就是创建一个 RDS 子网组；这就是我们如何将 RDS 实例与我们在推出 VPC 时创建的子网相关联。在`roles/rds/tasks/main.yml`中，输入以下内容:

```
- name: create RDS subnet group
  rds_subnet_group:
    region: "{{ ec2_region }}"
    state: present
    name: "{{ environment_name }}_rds_group"
    description: "RDS Group for {{ environment_name }}"
    subnets: "{{ subnet_rds_ids }}"
```

此任务使用我们在`subnets`角色中注册的两个子网的列表来创建一个名为`wordpress_rds_group`的组。当涉及到将子网组与我们的 RDS 实例相关联时，我们将使用它的名称，而不是它的唯一 ID，因此我们没有必要注册任务的输出供以后使用。角色中的下一个也是最后一个任务是启动无线电数据系统实例。进入以下`rds_subnet_group`任务:

```
- name: launch the rds instance
  rds:
    region: "{{ ec2_region }}"
    command: "create"
    instance_name: "{{ environment_name }}-rds"
    db_engine: "{{ rds.engine }}"
    size: "{{ rds.hdd_size }}"
    backup_retention: "{{ rds.no_of_backups }}"
    instance_type: "{{ rds.app_instance_type }}"
    multi_zone: "{{ rds.multi_az }}"
    subnet: "{{ environment_name }}_rds_group"
    vpc_security_groups: "{{ sg_rds.group_id }}"
    username: "{{ rds.db_username }}"
    password: "{{ rds.db_password }}"
    db_name: "{{ rds.db_name }}"
    wait: "{{ rds.wait }}"
    wait_timeout: "{{ rds.wait_time }}"
    tags:
      Name: "{{ environment_name }}-rds"
      Environment: "{{ environment_name }}"
```

除了`command`选项之外，其他所有内容都使用一个变量来填充——这意味着如果在重用角色时我们想要更改实例的任何部分，我们可以简单地通过将它们复制到我们的`group_vars/common.yml`文件来覆盖默认变量。与无线电数据系统模块交互时，您可以选择`command`选项的几个选项，它们是:

*   `create`:这将创建一个 RDS 实例。如果已经存在，模块将收集关于它的事实
*   `replicate`:这将创建您传递给它的 RDS 实例的只读副本
*   `delete`:这将删除 RDS 实例；您可以选择在删除实例之前拍摄快照
*   `facts`:收集无线电数据系统实例的信息
*   `modify`:如果您已经更改了配置的任何部分，那么这会立即或在下一个计划的维护窗口期间更新您的实例
*   `promote`:这将提升你的一个读副本成为新的主副本
*   `snapshot`:这将创建 RDS 实例的手动快照
*   `reboot`:这将重新启动命名的无线电数据系统实例
*   `restore`:这将从命名快照创建一个新的 RDS 实例

您可能需要考虑当前无线电数据系统模块的一些小问题。其中最大的是，它目前只允许您启动支持磁存储的 RDS 实例。一旦实例启动，就可以添加一个使用 AWS 命令行工具将存储迁移到通用固态硬盘的任务；然而，我们不会在这里讨论这个问题。

此外，Ansible 还不支持亚马逊极光，尽管它被列为一个选项。同样，可以创建使用 AWS 命令行工具来创建和配置极光集群的任务，但是如果您想要本机 Ansible 支持，您目前就很倒霉了。

Amazon Aurora is Amazon's own database engine, which allows you to run either your MySQL or PostgreSQL databases on top of Amazon's custom-built, SSD-based, fault-tolerant, and self-healing database storage clusters. This custom storage architecture allows you to scale your database to over 60 TB without disruption or the need to reorganize your datasets.

Ansible 社区正在进行重构 RDS 模块的工作，以支持自定义存储选项，并引入对 Aurora 的本机支持。然而，这在很大程度上是一项正在进行的工作，它还没有进入当前的 Ansible 版本(在撰写本文时是 2.5)。

这就是我们 RDS 实例所需的全部内容；我们可以继续下一个角色。

# 亚马逊 EFS

创建 EFS 卷只需要三个任务；与前面的角色一样，我们可以使用`ansible-galaxy`命令来创建文件夹和文件结构:

```
$ ansible-galaxy init roles/efs
```

在添加任务之前，我们需要添加一些默认变量和一个模板，所以在`roles/efs/defaults/main.yml`中添加以下内容:

```
efs:
  wait: "yes"
  wait_time: "1200"
```

现在，在`roles/efs/templates`中创建一个名为`targets.j2`的文件，该文件应包含:

```
---

efs_targets:
{% for item in subnet_efs_ids %}
      - subnet_id: "{{ item }}"
        security_groups: [ "{{ sg_efs.group_id }}" ]
{% endfor %}
```

如您所见，该模板正在循环遍历`subnet_efs_ids`变量，以在变量名`efs_targets`下创建子网 id 和安全组列表；我们将很快发现为什么需要这样做。

`roles/efs/tasks/main.yml`中的第一个任务使用`template`模块读取前一个文件，创建一个文件并存储在`group_vars`文件夹中，第二个任务使用`include_vars`模块加载文件的内容:

```
- name: generate the efs targets file
  template:
    src: "targets.j2"
```

```
    dest: "group_vars/generated_efs_targets.yml"

- name: load the efs targets
  include_vars: "group_vars/generated_efs_targets.yml"
```

现在我们已经填充并加载了`efs_targets`变量，我们可以添加第三个也是最后一个任务；该任务使用`efs`模块创建卷:

```
- name: create the efs volume
  efs:
    region: "{{ ec2_region }}"
    state: present
    name: "{{ environment_name }}-efs"
    tags:
        Name: "{{ environment_name }}-efs"
        Environment: "{{ environment_name }}"
    targets: "{{ efs_targets }}"
    wait: "{{ efs.wait }}"
    wait_timeout: "{{ efs.wait_time }}"
```

“那么，当你可以使用`with_items`的时候，为什么还要去努力创建一个模板，生成一个文件，然后加载内容呢？”你可能会问自己。

如果我们使用`with_items`，那么我们的任务将如下所示:

```
- name: create the efs volume
  efs:
    region: "{{ ec2_region }}"
    state: present
    name: "{{ environment_name }}-efs"
    tags:
        Name: "{{ environment_name }}-efs"
        Environment: "{{ environment_name }}"
    targets:
      - subnet_id: "{{ item }}"
        security_groups: [ "{{ sg_efs.group_id }}" ]
    wait: "{{ efs.wait }}"
    wait_timeout: "{{ efs.wait_time }}"
  with_items: "{{ subnet_efs_ids }}"
```

乍一看，这似乎应该行得通；但是，如果我们看一下`group_vars/generated_efs_targets.yml`生成后的样子，您可能会注意到一个重要的区别:

```
efs_targets:
      - subnet_id: "subnet-0ce64b6a"
        security_groups: [ "sg-695f8b14" ]
      - subnet_id: "subnet-2598747f"
        security_groups: [ "sg-695f8b14" ]
      - subnet_id: "subnet-ee3487a6"
        security_groups: [ "sg-695f8b14" ]
```

从示例中可以看到，我们有三个部分，每个部分的`subnet_id`对于一个可用性区域是唯一的。如果我们使用`with_items`，我们将只有一个部分，任务将执行三次，每次覆盖以前的目标。当然，我们可以硬编码三个目标，但是如果我们决定在一个只有两个可用性区域或一个有四个可用性区域的区域中重用这个角色呢？硬编码意味着我们将失去让 Ansible 根据目标动态适应一系列动态结果的灵活性。

现在，我们已经完成了 EFS 的角色，基本的任务也完成了。在我们开始启动 EC2 实例之前，我们可以看看测试我们的行动手册。

# 测试剧本

如上所述，现在是测试我们已经完成的角色的好时机，以确保它们按预期工作。为此，打开`site.yml`文件并添加以下内容:

```
---

- name: Create, launch and configure our basic AWS environment
  hosts: localhost
  connection: local
  gather_facts: True

  vars_files:
    - group_vars/common.yml

  roles:
    - roles/vpc
    - roles/subnets
    - roles/gateway
    - roles/securitygroups
    - roles/elb
    - roles/rds
    - roles/efs
```

在运行我们的剧本之前，我们需要设置`AWS_ACCESS_KEY`和`AWS_SECRET_KEY`环境变量；为此，运行以下命令，用我们在上一章中生成的详细信息替换每个变量的值:

```
$ export AWS_ACCESS_KEY=AKIAI5KECPOTNTTVM3EDA
$ export AWS_SECRET_KEY=Y4B7FFiSWl0Am3VIFc07lgnc/TAtK5+RpxzIGTr
```

我们会想要计时我们的剧本运行。为此，我们可以在`ansible-playbook`命令前加上`time`，这意味着我们需要运行的命令看起来像:

```
$ time ansible-playbook -i production site.yml
```

不要忘记，我们已经告诉 Ansible 在启动 RDS 实例和创建 EFS 卷之前最多等待 20 分钟，因此最初的行动手册运行可能需要一点时间。

这样做的原因是，当 RDS 实例启动时，首先创建它，然后克隆到备用服务器，最后进行初始备份。只有完成这些步骤后，RDS 实例才会被标记为就绪，我们的行动手册才会继续运行。此外，对于 EFS 卷，我们正在跨三个可用性区域创建一个由三个卷组成的集群，因此需要一些时间来配置它们:

```
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

PLAY [Create, launch and configure our basic AWS environment] ************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/vpc : ensure that the VPC is present] ***********************************************
changed: [localhost]

TASK [roles/subnets : ensure that the subnets are present] **************************************
changed: [localhost] => (item={u'subnet': u'10.0.10.0/24', u'use': u'ec2', u'az': u'a'})
changed: [localhost] => (item={u'subnet': u'10.0.11.0/24', u'use': u'ec2', u'az': u'b'})
changed: [localhost] => (item={u'subnet': u'10.0.12.0/24', u'use': u'ec2', u'az': u'c'})
changed: [localhost] => (item={u'subnet': u'10.0.20.0/24', u'use': u'elb', u'az': u'a'})
changed: [localhost] => (item={u'subnet': u'10.0.21.0/24', u'use': u'elb', u'az': u'b'})
changed: [localhost] => (item={u'subnet': u'10.0.22.0/24', u'use': u'elb', u'az': u'c'})
changed: [localhost] => (item={u'subnet': u'10.0.30.0/24', u'use': u'rds', u'az': u'a'})
changed: [localhost] => (item={u'subnet': u'10.0.31.0/24', u'use': u'rds', u'az': u'b'})
changed: [localhost] => (item={u'subnet': u'10.0.40.0/24', u'use': u'efs', u'az': u'a'})
changed: [localhost] => (item={u'subnet': u'10.0.41.0/24', u'use': u'efs', u'az': u'b'})
changed: [localhost] => (item={u'subnet': u'10.0.42.0/24', u'use': u'efs', u'az': u'c'})

TASK [roles/subnets : gather information about the ec2 subnets] *********************************
ok: [localhost]

TASK [roles/subnets : gather information about the elb subnets] *********************************
ok: [localhost]

TASK [roles/subnets : gather information about the rds subnets] *********************************
ok: [localhost]

TASK [roles/subnets : gather information about the efs subnets] *********************************
ok: [localhost]

TASK [roles/subnets : register just the IDs for each of the subnets] ****************************
ok: [localhost]

TASK [roles/gateway : ensure that there is an internet gateway] *********************************
changed: [localhost]

TASK [roles/gateway : check that we can route through internet gateway] *************************
changed: [localhost]

TASK [roles/securitygroups : provision elb security group] **************************************
changed: [localhost]

TASK [roles/securitygroups : find out your current public IP address using https://ipify.org/] *****
ok: [localhost]

TASK [roles/securitygroups : set your public ip as a fact] **************************************
ok: [localhost]

TASK [roles/securitygroups : provision ec2 security group] **************************************
changed: [localhost]

TASK [roles/securitygroups : provision rds security group] **************************************
changed: [localhost]

TASK [roles/securitygroups : provision efs security group] **************************************
changed: [localhost]

TASK [roles/elb : provision the target group] ***************************************************
changed: [localhost]

TASK [roles/elb : provision an application elastic load balancer] *******************************
changed: [localhost]

TASK [roles/rds : create RDS subnet group] ******************************************************
changed: [localhost]

TASK [roles/rds : launch the rds instance] ******************************************************
changed: [localhost]

TASK [roles/efs : generate the efs targets file] ************************************************
changed: [localhost]

TASK [roles/efs : load the efs targets] *********************************************************
ok: [localhost]

TASK [roles/efs : create the efs volume] ********************************************************
changed: [localhost]

PLAY RECAP **************************************************************************************
localhost : ok=23 changed=14 unreachable=0 failed=0
```

正如您从输出中看到的，剧本运行按预期执行。我们可以检查 AWS 控制台，确保一切都已创建，从 VPC 开始:

![](../images/00089.jpeg)

然后，检查弹性负载平衡器，它可以在 EC2 部分找到:

![](../images/00090.jpeg)

我们还可以检查我们的 RDS 实例是否已启动并运行:

![](../images/00091.jpeg)

然后，我们剧本的最后一部分是 EFS 卷:

![](../images/00092.jpeg)

当我运行剧本时，只花了 18 分钟多一点，从以下输出可以看出:

![](../images/00093.jpeg)

不出所料，大部分时间是等待无线电数据系统实例和 EFS 卷准备就绪。

既然我们知道行动手册可以无误地启动我们的基本基础架构，我们就可以继续行动手册的其余部分。或者我们可以？

# 终止资源

正如本章开头已经提到的，我们正在启动资源，这些资源在启动和运行时会产生成本。由于我们仍在编写行动手册，我们不希望资源闲置，在工作时增加成本，因此让我们创建一个支持行动手册，撤销刚刚运行的所有内容。

为此，让我们创建一个名为`remove`的角色:

```
$ ansible-galaxy init roles/remove
```

这个角色将使用 Ansible 来删除我们刚刚发布的所有内容，从而在我们开发行动手册时降低成本。首先需要给`roles/remove/defaults/main.yml`增加一些默认变量；这些是:

```
wait:
  wait: "yes"
  wait_time: "1200"

vpc_cidr_block: "10.0.0.0/16"
```

`vpc_cidr_block`变量应该匹配你的 VPC CIDR。现在，我们可以开始向`roles/remove/tasks/main.yml`添加任务，这将删除我们已经启动的所有内容。当每一个资源都以特定的顺序启动时，我们将会倒退，这意味着我们需要以相反的顺序移除它们。让我们从 EFS 卷开始:

```
- name: remove the efs shares
  efs:
    region: "{{ ec2_region }}"
    state: absent
    name: "{{ environment_name }}-efs"
    wait: "{{ wait.wait }}"
    wait_timeout: "{{ wait.wait_time }}"
```

我们这次只需要提供一些细节，因为卷已经存在；我们需要给它一个体积的名称和一个`absent`的`state`。您会注意到，我们会等待卷完全删除后再继续。在我们继续下一个任务之前，我们将在本行动手册中暂停相当多的时间，以便在 AWS 应用编程接口中完全取消资源注册。

接下来的几项任务涉及删除无线电数据系统实例和无线电数据系统子网组:

```
- name: terminate the rds instance
  rds:
    region: "{{ ec2_region }}"
    command: "delete"
    instance_name: "{{ environment_name }}-rds"
    wait: "{{ wait.wait }}"
    wait_timeout: "{{ wait.wait_time }}"

- name: wait for 2 minutes before continuing
  pause:
    minutes: 2

- name: remove RDS subnet group
  rds_subnet_group:
    region: "{{ ec2_region }}"
    state: absent
    name: "{{ environment_name }}_rds_group"
```

如您所见，使用`pause`模块，在终止无线电数据系统实例和删除无线电数据系统子网组之间有 2 分钟的暂停。如果我们删除此暂停，那么我们将面临 RDS 实例未完全取消注册的风险，这意味着我们将无法删除子网组，这将导致行动手册中出现错误。

如果在任何阶段，剧本抛出了一个错误，我们应该能够再次运行它，它应该从它停止的地方继续。虽然，当我们根本无法运行剧本时，会有一个不归点；我会让你知道这是什么时候。

现在，RDS 实例和子网组已经删除，我们可以删除弹性负载平衡器:

```
- name: terminate the application elastic load balancer
  elb_application_lb:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-elb"
    state: "absent"

- name: prompt
  pause:
    prompt: "Make sure the elastic load balancer has been terminated before proceeding"
```

你会注意到，这次虽然`pause`模块再次被使用，但我们并没有提供一段时间。相反，我们指示用户检查 AWS 控制台，然后在弹性负载平衡器被移除后按键。这是因为`elb_application_lb`模块不支持等待资源被移除。

当资源正在被移除时，如果你点击*进入*，下一个任务将立即失败，因此需要手动检查。该任务将删除 ELB 目标组:

```
- name: remove the target group
  elb_target_group:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-target-group"
    state: "absent"
```

接下来的任务将删除安全组；因为我们有引用其他组的组，所以在我们移除行中的下一组之前有 30 秒的`pause`:

```
- name: remove the efs security group
  ec2_group:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-efs"
    state: "absent"

- name: wait for 30 seconds before continuing
  pause:
    seconds: 30

- name: remove the rds security group
  ec2_group:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-rds"
    state: "absent"

- name: wait for 30 seconds before continuing
  pause:
    seconds: 30

- name: remove the ec2 security group
  ec2_group:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-ec2"
    state: "absent"

- name: wait for 30 seconds before continuing
  pause:
    seconds: 30

- name: remove the elb security group
  ec2_group:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-elb"
    state: "absent"

- name: wait for 30 seconds before continuing
  pause:
    seconds: 30
```

同样，如您所见，我们只需提供组名和`absent`的`state`。下一个任务，删除路由表，需要的不仅仅是名称:

```
- name: get some facts on the route table
  ec2_vpc_route_table_facts:
    region: "{{ ec2_region }}"
    filters:
      "tag:Name": "{{ environment_name }}_outbound"
      "tag:Environment": "{{ environment_name }}"
  register: route_table_facts

- name: remove the route table
  ec2_vpc_route_table:
    region: "{{ ec2_region }}"
```

```
    vpc_id: "{{ route_table_facts.route_tables[0].vpc_id }}"
    route_table_id: "{{ route_table_facts.route_tables[0].id }}"
    lookup: "id"
    state: "absent"
  ignore_errors: yes
```

要删除路由表，我们需要知道 VPC 标识和路由表的标识。为了找出这些信息，我们使用`ec2_vpc_route_table_facts`模块来收集基于`Name`和`Environment`标签的数据，所以我们只移除我们想要的。这些信息随后被传递到`ec2_vpc_route_table`模块，我们指示该模块使用路由表的标识进行`lookup`操作。

我们还告诉 Ansible 忽略这里产生的任何错误。原因是，如果后续任务抛出错误，并且我们需要重新运行剧本，我们将需要它在剧本运行中超过这个点，并且如果该任务已经成功运行，它将不能运行，因为将没有要删除的内容，这本身将生成错误。

接下来的两项任务是收集有关 VPC 的信息并删除互联网网关:

```
- name: get some facts on the vpc
  ec2_vpc_net_facts:
    region: "{{ ec2_region }}"
    filters:
      "tag:Name": "{{ environment_name }}"
      "tag:Environment": "{{ environment_name }}"
  register: vpc_facts

- name: ensure that there isn't an internet gateway
  ec2_vpc_igw:
    region: "{{ ec2_region }}"
    state: "absent"
    vpc_id: "{{ vpc_facts.vpcs[0].vpc_id }}"
    tags:
      "Name": "{{ environment_name }}_internet_gateway"
      "Environment": "{{ environment_name }}"
  ignore_errors: yes
```

同样，我们会忽略任何生成的错误，以便在需要执行多次的情况下，我们可以继续运行行动手册。该任务使用`ec2_vpc_subnet_facts`模块收集环境中活动子网的信息；然后我们将此信息注册为`the_subnets`:

```
- name: gather information about the subnets
  ec2_vpc_subnet_facts:
    region: "{{ ec2_region }}"
```

```
    filters:
      "tag:Environment": "{{ environment_name }}"
  register: the_subnets
```

一旦我们有了子网的信息，我们就可以使用它们的 CIDR 块并通过将`state`设置为`absent`来删除它们:

```
- name: ensure that the subnets are absent
  ec2_vpc_subnet:
    region: "{{ ec2_region }}"
    state: "absent"
    vpc_id: "{{ vpc_facts.vpcs[0].vpc_id }}"
    cidr: "{{ item.cidr_block }}"
  with_items: "{{ the_subnets.subnets }}"
```

It is at this point that the playbook would generate an error if you were to run it more than once and make it this far. If it does, you can remove the VPC manually.

最后，现在我们已经从我们的 VPC 移除了所有内容，它是空的，这意味着我们可以毫无错误地移除 VPC 本身:

```
- name: ensure that the VPC is absent
  ec2_vpc_net:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}"
    state: "absent"
    cidr_block: "{{ vpc_cidr_block }}"
```

现在我们已经完成了我们的角色，我们可以创建一个名为`remove.yml`的剧本，它包含以下内容:

```
---

- name: Terminate everything in our basic AWS environment
  hosts: localhost
  connection: local
  gather_facts: True

  vars_files:
    - group_vars/common.yml

  roles:
    - roles/remove
```

我们现在已经具备了移除 AWS 环境的所有条件；为此，请运行以下命令:

```
$ time ansible-playbook -i production remove.yml
```

Don't forget to check that the Elastic Load Balancer has been removed and press any key to continue during the playbook run. Otherwise, you will be waiting around for a while.

当我运行剧本时，只花了不到 12 分钟:

![](../images/00094.jpeg)

如果您没有跟随行动手册的输出，您可以在此处看到所有暂停和`ec2_vpc_subnet_facts`模块收集的子网信息:

```
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

PLAY [Terminate everything in our basic AWS environment] *****************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/remove : remove the efs shares] *****************************************************
changed: [localhost]

TASK [roles/remove : terminate the rds instance] ************************************************
changed: [localhost]

TASK [roles/remove : wait for 2 minutes before continuing] **************************************
Pausing for 120 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/remove : remove RDS subnet group] ***************************************************
changed: [localhost]

TASK [roles/remove : terminate the application elastic load balancer] ***************************
changed: [localhost]

TASK [roles/remove : prompt] ********************************************************************
[roles/remove : prompt]
Make sure the elastic load balancer has been terminated before proceeding:

ok: [localhost]

TASK [roles/remove : remove the target group] ***************************************************
changed: [localhost]

TASK [roles/remove : remove the efs security group] *********************************************
changed: [localhost]

TASK [roles/remove : wait for 30 seconds before continuing] *************************************
Pausing for 30 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/remove : remove the rds security group] *********************************************
changed: [localhost]

TASK [roles/remove : wait for 30 seconds before continuing] *************************************
Pausing for 30 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/remove : remove the ec2 security group] *********************************************
changed: [localhost]

TASK [roles/remove : wait for 30 seconds before continuing] *************************************
Pausing for 30 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/remove : remove the elb security group] *********************************************
changed: [localhost]

TASK [roles/remove : wait for 30 seconds before continuing] *************************************
Pausing for 30 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/remove : get some facts on the route table] *****************************************
ok: [localhost]

TASK [roles/remove : remove the route table] ****************************************************
changed: [localhost]

TASK [roles/remove : get some facts on the vpc] *************************************************
ok: [localhost]

TASK [roles/remove : ensure that there isn't an internet gateway] *******************************
changed: [localhost]

TASK [roles/remove : gather information about the subnets] **************************************
ok: [localhost]

TASK [roles/remove : ensure that the subnets are absent] ****************************************
changed: [localhost] => (item={u'availability_zone': u'eu-west-1b', u'subnet_id': u'subnet-50259618', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'rds', u'Name': u'wordpress_rds_eu-west-1b'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.31.0/24', u'available_ip_address_count': 251, u'id': u'subnet-50259618', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1a', u'subnet_id': u'subnet-80f954e6', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'elb', u'Name': u'wordpress_elb_eu-west-1a'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.20.0/24', u'available_ip_address_count': 251, u'id': u'subnet-80f954e6', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1c', u'subnet_id': u'subnet-499f7313', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'ec2', u'Name': u'wordpress_ec2_eu-west-1c'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.12.0/24', u'available_ip_address_count': 251, u'id': u'subnet-499f7313', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1a', u'subnet_id': u'subnet-74fc5112', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'ec2', u'Name': u'wordpress_ec2_eu-west-1a'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.10.0/24', u'available_ip_address_count': 251, u'id': u'subnet-74fc5112', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1b', u'subnet_id': u'subnet-9f3a89d7', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'ec2', u'Name': u'wordpress_ec2_eu-west-1b'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.11.0/24', u'available_ip_address_count': 251, u'id': u'subnet-9f3a89d7', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1c', u'subnet_id': u'subnet-8e967ad4', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'efs', u'Name': u'wordpress_efs_eu-west-1c'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.42.0/24', u'available_ip_address_count': 251, u'id': u'subnet-8e967ad4', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1a', u'subnet_id': u'subnet-d7fe53b1', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'efs', u'Name': u'wordpress_efs_eu-west-1a'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.40.0/24', u'available_ip_address_count': 251, u'id': u'subnet-d7fe53b1', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1c', u'subnet_id': u'subnet-029b7758', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'elb', u'Name': u'wordpress_elb_eu-west-1c'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.22.0/24', u'available_ip_address_count': 251, u'id': u'subnet-029b7758', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1a', u'subnet_id': u'subnet-ede5488b', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'rds', u'Name': u'wordpress_rds_eu-west-1a'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.30.0/24', u'available_ip_address_count': 251, u'id': u'subnet-ede5488b', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1b', u'subnet_id': u'subnet-ec3e8da4', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'efs', u'Name': u'wordpress_efs_eu-west-1b'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.41.0/24', u'available_ip_address_count': 251, u'id': u'subnet-ec3e8da4', u'map_public_ip_on_launch': False})
changed: [localhost] => (item={u'availability_zone': u'eu-west-1b', u'subnet_id': u'subnet-c227948a', u'assign_ipv6_address_on_creation': False, u'tags': {u'Environment': u'wordpress', u'Use': u'elb', u'Name': u'wordpress_elb_eu-west-1b'}, u'default_for_az': False, u'state': u'available', u'ipv6_cidr_block_association_set': [], u'vpc_id': u'vpc-7596f013', u'cidr_block': u'10.0.21.0/24', u'available_ip_address_count': 251, u'id': u'subnet-c227948a', u'map_public_ip_on_launch': False})

TASK [roles/remove : ensure that the VPC is absent] *********************************************
changed: [localhost]

PLAY RECAP **************************************************************************************
localhost : ok=23 changed=13 unreachable=0 failed=0
```

我建议仔细检查一下你的 AWS 控制台的资源是否用完了，因为没有人喜欢惊喜账单。现在我们已经完成并执行了我们的`remove`行动手册，这样我们就不会产生任何不必要的成本，我们可以继续构建我们高度可用的 WordPress 安装。

# EC2 实例

现在我们已经拥有了安装 WordPress 所需的所有基本服务，我们可以开始部署安装 WordPress 所需的计算资源了。这就是事情变得有趣的地方，因为我们必须在我们的行动手册中构建逻辑，以便如果我们的站点启动并运行，我们可以部署操作系统的更新并推出新的映像，而不会出现任何宕机。

但是如果这是一个新的部署，我们需要启动一个实例，将其附加到弹性负载平衡器，安装软件栈，配置 WordPress，并创建一个映像，然后我们可以在启动配置中使用，我们将需要将其附加到一个自动缩放组。

虽然这看起来很复杂，但将这种逻辑构建到行动手册中会使维护和移交给其他人管理/运行变得更加容易，因为他们不需要担心现有的部署，只需要运行行动手册。

# 实例发现

我们将简单地将这个角色称为 EC2，因此我们需要运行以下命令来创建角色结构:

```
$ ansible-galaxy init roles/ec2
```

该角色的主要目标是确保在执行结束时，我们有一个实例，无论是新的还是现有的，然后我们可以在即将到来的角色中使用它来建立 AMI。

`roles/ec2/defaults/main.yml`中的默认值定义了如果我们的角色发现这是一个新部署，我们想要使用哪个映像。对于我们的安装，我们将使用中央操作系统在 AWS 市场提供的 AWS；这意味着我们可以重用我们的 WordPress 安装手册中的大部分内容:

```
image:
  base: "CentOS Linux 7 x86_64*"
  owner: "679593333241"
  root_device: "ebs"
  architecture: "x86_64"
wait_port: "22"
ec2_instance_type: "t2.micro"
```

当我们开始使用映像时，我们将更详细地讨论为什么我们需要这些信息。现在我们已经有了默认值，我们可以继续进行`roles/ec2/tasks/main.yml`中的任务。

当我们使用自动缩放组启动实例时，它们都将被命名为`wordpress_ec2`，因此我们的 EC2 角色要做的第一件事就是找出我们是否有任何正在运行的实例。为此，我们将使用`ec2_instance_facts`模块收集任何正在运行并标有名称`wordpress_ec2`的实例的信息:

```
- name: gather facts on any already running instances
  ec2_instance_facts:
    region: "{{ ec2_region }}"
    filters:
      instance-state-name: "running"
      "tag:environment": "{{ environment_name }}"
      "tag:Name": "{{ environment_name }}-ec2"
  register: running_instances
```

虽然我们现在有了关于任何已经运行的实例的信息，但它并不是我们真正可以使用的格式，所以让我们将结果添加到名为`already_running`的主机组中:

```
- name: add any already running instances to a group
  add_host:
    name: "{{ item.public_dns_name }}"
    ansible_ssh_host: "{{ item.public_dns_name }}"
    groups: "already_running"
  with_items: "{{ running_instances.instances }}"
```

现在，我们剩下一个名为`already_running`的主机组，可能包含 0 到 3 台主机；我们现在需要计算组中的主机数量，并设置一个包含主机数量的事实:

```
- name: set the number of already running instances as a fact
  set_fact:
    number_of_running_hosts: "{{ groups['already_running'] | length | default(0) }}"
```

这里，我们使用了内置的 Ansible 变量`groups`以及我们的组名；现在我们有了一个主机列表，我们可以通过使用`length`过滤器来统计列表中的项目数量。最后，我们说如果列表是空的，那么默认值应该是`0`。

现在我们有一个包含`number_of_running_hosts`的变量，我们现在可以对下一步需要做什么做出一些决定。

首先，如果`number_of_running_hosts`是`0`，那么我们正在进行一个新的部署，我们应该运行启动一个新的 EC2 实例的任务:

```
- name: run the tasks for a new deployment 
  include_tasks: "new_deployment.yml"
  when: number_of_running_hosts|int == 0
```

或者，如果`number_of_running_hosts`大于`1`，那么我们需要选择一个已经运行的实例来使用:

```
- name: run the tasks for an existing deployment 
  include_tasks: "existing_deployment.yml"
  when: number_of_running_hosts|int >= 1
```

让我们看看这些任务，从新部署期间发生的事情开始。

# 新部署

如果我们正在进行新的部署，那么我们需要执行以下任务:

1.  在我们使用的地区找到最新的 CentOS 7 AMI
2.  上传我们的公钥副本，这样我们就可以使用它来将 SSH 引入实例
3.  使用前面的信息启动实例
4.  将新实例添加到主机组
5.  等到 SSH 可用
6.  将我们的实例添加到弹性负载平衡器中

所有这些任务都在`roles/ec2/tasks/new_deployment.yml`中定义，所以让我们从如何找到正确的 AMI 来开始这些任务。

我们不能简单地在这里提供一个急性心肌梗死的标识，因为每个地区都有不同的标识，而且每个急性心肌梗死都会定期更新，以确保它是补丁。为了解决这个问题，我们可以运行以下任务:

```
- name: search for all of the AMIs in the defined region which match our selection
  ec2_ami_facts:
    region: "{{ ec2_region }}"
    owners: "{{ image.owner }}"
    filters:
      name: "{{ image.base }}"
      architecture: "{{ image.architecture }}"
      root-device-type: "{{ image.root_device }}" 
  register: amiFind

- name: filter the list of AMIs to find the latest one with an EBS backed volume
  set_fact:
    amiSortFilter: "{{ amiFind.images | sort(attribute='creation_date') | last }}"

- name: finally grab AMI ID of the most recent result which matches our base image which is backed by an EBS volume
  set_fact:
    our_ami_id: "{{ amiSortFilter.image_id }}"
```

如您所见，我们首先在寻找 CentOS 创建的所有名称中有`CentOS Linux 7 x86_64*`并且还使用**弹性块存储** ( **EBS** )支持的存储的`x86_64` AMIs。这将为我们提供几个注册为`amiFind`的非政府组织的详细信息。

接下来，我们需要将 AMIs 列表过滤到最新的一个，所以我们设置了一个名为`amiSortFilter`的事实。这里，它正在获取映像列表`amiFind`，并根据它们的创建日期对它们进行排序。然后我们只取列表中最后一个 AMI 的信息注册为`amiSortFilter`。最后，我们通过设置一个名为`our_ami_id`的事实来减少更多的信息，这是`amiSortFilter`变量中的`image_id`，只留下我们需要的信息。

现在我们知道了 AMI ID，我们需要确保有一个可以使用的 SSH 密钥，以便在启动时可以访问实例。首先，让我们检查您在 Ansible 控制器上的用户是否有 SSH 密钥；如果我们找不到，那么就会产生一个:

```
- name: check the user {{ ansible_user_id }} has a key, if not create one
  user:
    name: "{{ ansible_user_id }}"
    generate_ssh_key: yes
    ssh_key_file: "~/.ssh/id_rsa"
```

现在我们已经确认了密钥的存在，我们需要将公共部分上传到 AWS:

```
- name: upload the users public key
  ec2_key:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-{{ ansible_user_id }}"
    key_material: "{{ item }}"
  with_file: "~/.ssh/id_rsa.pub"
```

我们现在已经准备好了启动 EC2 实例的一切；为此，我们将使用在 Ansible 2.5 中引入的`ec2_instance`模块:

```
- name: launch an instance
  ec2_instance:
    region: "{{ ec2_region }}"
    state: "present"
    instance_type: "{{ ec2_instance_type }}"
    image_id: "{{ our_ami_id }}"
    wait: yes
    key_name: "{{ environment_name }}-{{ ansible_user_id }}"
    security_groups: [ "{{ sg_ec2.group_id }}" ]
    network: 
      assign_public_ip: true
    filters:
      instance-state-name: "running"
      "tag:Name": "{{ environment_name }}-tmp"
      "tag:environment": "{{ environment_name }}"
    vpc_subnet_id: "{{ subnet_ec2_ids[0] }}"
    tags:
      Name: "{{ environment_name }}-tmp"
      environment: "{{ environment_name }}"
```

这样，我们就可以将 EC2 实例启动到其中一个 EC2 子网中，附加一个公共 IP 地址和我们的 EC2 安全组。该实例将是一个名为`wordpress-tmp`的 t2.micro CentOS 7 实例。我们给它分配标签，我们也使用过滤器，这样如果在剧本运行期间发生任何事情，我们需要重新运行它，它将使用我们已经运行的实例，而不是启动另一个。

一旦实例启动，我们需要找出它的信息，并将其添加到名为`ec2_instance`的主机组中:

```
- name: gather facts on the instance we just launched using the AWS API
  ec2_instance_facts:
    region: "{{ ec2_region }}"
    filters:
      instance-state-name: "running"
      "tag:Name": "{{ environment_name }}-tmp"
      "tag:environment": "{{ environment_name }}"
  register: singleinstance

- name: add our temporary instance to a host group for use in the next step
  add_host:
```

```
    name: "{{ item.public_dns_name }}"
    ansible_ssh_host: "{{ item.public_dns_name }}"
    groups: "ec2_instance"
  with_items: "{{ singleinstance.instances }}"
```

我们需要等待 SSH 可以访问后再继续；在这里，我们将使用`wait_for`模块:

```
- name: wait until SSH is available before moving onto the next step
  wait_for:
    host: "{{ item.public_dns_name }}"
    port: 22
    delay: 2
    timeout: 320
    state: "started"
  with_items: "{{ singleinstance.instances }}"
```

最后，SSH 可用后，我们需要向我们的弹性负载平衡器目标组注册该实例:

```
- name: add the instance to the target group
  elb_target_group:
    name: "{{ environment_name }}-target-group"
    region: "{{ ec2_region }}"
    protocol: "http"
    port: "80"
    vpc_id: "{{ vpc_info.vpc.id }}"
    state: "present"
    targets:
      - Id: "{{ item.instance_id }}"
        Port: "80"
    modify_targets: "true"
  with_items: "{{ singleinstance.instances }}"
```

这将留给我们一个名为`wordpress-tmp`的实例，它可以通过 SSH 访问，并在名为`ec2_instance`的主机组中的弹性负载平衡器后面活动。

# 现有部署

如果已经有实例在运行，则跳过前面的任务，运行`roles/ec2/existing_deployment.yml`中的单个任务。该任务只需获取一台正在运行的主机，并将其添加到名为`ec2_instance`的主机组中:

```
- name: add one of our running instances to a host group for use in the next step
  add_host:
    name: "{{ groups['already_running'][0] }}"
    ansible_ssh_host: "{{ groups['already_running'][0] }}"
    groups: "ec2_instance"
```

这使我们处于与新部署任务结束时相同的位置，一个名为`ec2_instance`的主机有一个可通过 SSH 访问的实例。

# 堆

我们要创建的下一个角色是只在主机上执行的角色——名为`stack`的`ec2_instance`组。与前面的角色一样，我们可以从`aws-wordpress`文件夹中运行以下命令来创建所需的文件:

```
$ ansible-galaxy init roles/stack
```

这个角色是三个角色中的一个。与 EC2 角色一样，我们正在构建逻辑，以便根据剧本第一次连接时找到的实例的状态来执行任务。先来看看`roles/stack/tasks/main.yml`的内容。

其中的第一个任务在新部署和现有部署上执行；它运行一个`yum update`:

```
- name: update all of the installed packages
  yum:
    name: "*"
    state: "latest"
    update_cache: "yes"
```

接下来，我们需要知道是否安装了 WordPress:

```
- name: are the wordpress files already there?
  stat:
    path: "{{ wordpress_system.home }}/index.php"
  register: wp_installed
```

接下来的两个任务包括两个额外的角色；一个安装并配置软件栈，另一个执行初始 WordPress 安装，但前提是没有找到现有安装:

```
- name: if no wordpress installed install and configure the software stack
  include_role:
    name: "stack"
    tasks_from: "deploy.yml"
  when: wp_installed.stat.exists == False

- name: if no wordpress installed, install it !!!
  include_role:
    name: "stack"
    tasks_from: "wordpress.yml"
  when: wp_installed.stat.exists == False
```

这两个角色是我们在本地安装 WordPress 时创建的角色的浓缩版本。

# 默认变量

在我们看角色之前，让我们看一下`roles/stack/defaults/main.yml`的代码，因为有一些不同:

```
wp_cli:
  download: "https://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar"
  path: "/usr/local/bin/wp"

wordpress:
  domain: "http://{{ elb_results.load_balancers[0].dns_name }}/"
  title: "WordPress installed by Ansible on AWS"
  username: "ansible"
  password: "password"
  email: "test@example.com"

efs_mount_dir: "/efs"

wordpress_system:
  user: "wordpress"
  group: "php-fpm"
  comment: "wordpress system user"
  home: "{{ efs_mount_dir }}/wordpress"
  state: "present"

php:
  ip: "127.0.0.1"
  port: "9000"
  upstream: "php"
  ini:
    - { regexp: '^;date.timezone =', replace: 'date.timezone = Europe/London' }
    - { regexp: '^expose_php = On', replace: 'expose_php = Off' }
    - { regexp: '^upload_max_filesize = 2M', replace: 'upload_max_filesize = 20M' }

selinux:
  http_permissive: true

repo_packages:
  - "epel-release"
  - "https://centos7.iuscommunity.org/ius-release.rpm"

nginx_repo:
  name: "nginx"
  description: "The mainline NGINX repo"
  baseurl: "http://nginx.org/packages/mainline/centos/7/$basearch/"
  gpgcheck: "no"
  enabled: "yes"

system_packages:
  - "MySQL-python"
  - "policycoreutils-python"
  - "nfs-utils"

stack_packages:
  - "nginx"
  - "mariadb"
  - "php72u"
  - "php72u-bcmath"
  - "php72u-cli"
  - "php72u-common"
  - "php72u-dba"
  - "php72u-fpm"
  - "php72u-fpm-nginx"
  - "php72u-gd"
  - "php72u-intl"
  - "php72u-json"
  - "php72u-mbstring"
  - "php72u-mysqlnd"
  - "php72u-process"
  - "php72u-snmp"
  - "php72u-soap"
  - "php72u-xml"
  - "php72u-xmlrpc"

extra_packages:
  - "vim-enhanced"
  - "git"
  - "unzip"
```

主要区别是:

*   `wordpress.domain` URL:这一次，我们没有硬编码域，而是有了弹性负载平衡器 URL，这是我们通过使用`elb_application_lb_facts`模块获得的。稍后会有更多。
*   `efs_mount_dir`变量:这是一个新的变量，我们将使用它来定义在实例中我们希望我们的 EFS 共享挂载到哪里。
*   `wordpress_system.home`选项:现在使用`efs_mount_dir`，所以我们的 WordPress 安装可以在所有实例间共享。
*   缺少马里亚数据库服务器:您会注意到安装和配置马里亚数据库服务器的引用已被删除；由于我们有一个 RDS 实例，我们不再需要这些。

我们使用`include_role`模块作为角色执行任务，以确保变量被正确加载。

# 部署

第一个额外的角色，称为`roles/stack/tasks/deploy.yml`，按照您的预期执行，并部署软件栈和配置。

首先是增加 EFS 的份额；首先，我们需要使用`efs_facts`模块收集一些关于 EFS 共享的信息:

```
- name: find some information on the elastic load balancer
  local_action:
    module: efs_facts
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-efs"
  become: no
```

你可能已经注意到我们对`efs_facts`模块的称呼不同；我们实际上使用的是`local_action`模块，它在我们的 Ansible 控制器上运行`efs_facts`模块，而不是 EC2 实例。这是因为我们实际上并没有给我们的 EC2 实例提供对 API 的访问，因为我们没有安装 Boto，也没有将我们的访问密钥和机密访问密钥作为变量传递。

使用`local_action`模块，我们可以返回到我们的 Ansible 控制器，收集关于我们的 EFS 的信息，然后将结果应用到我们的 EC2 实例上；我们将在以后的安装中再次使用这个模块。

我们使用`become: no`作为这个任务的一部分；否则，将尝试使用`sudo`执行。这是因为我们在`site.yml`文件的这一部分告诉所有任务使用`become: yes`和`become_method: sudo`，我们将在本章稍后更新。

下一个任务装载 EFS 共享，并将其添加到`fstab`文件，这意味着当我们将从正在创建的 AMI 启动的实例首次启动时，它将自动装载:

```
- name: ensure EFS volume is mounted.
  mount:
    name: "{{ efs_mount_dir }}"
    src: "{{ efs[0].file_system_id }}.efs.{{ ec2_region }}.amazonaws.com:/"
    fstype: nfs4
    opts: nfsvers=4.1
    state: mounted
```

`efs_mount_dir`是自动创建的，所以我们不需要担心事先创建。角色的下一部分安装和配置栈:

```
- name: install the repo packages
  yum:
    name: "{{ item }}"
    state: "installed"
  with_items: "{{ repo_packages }}"

- name: add the NGINX mainline repo
  yum_repository:
    name: "{{ nginx_repo.name }}"
    description: "{{ nginx_repo.description }}"
    baseurl: "{{ nginx_repo.baseurl }}"
    gpgcheck: "{{ nginx_repo.gpgcheck }}"
    enabled: "{{ nginx_repo.enabled }}"

- name: install the stack packages
  yum:
    name: "{{ item }}"
    state: "installed"
  with_items: "{{ system_packages + stack_packages + extra_packages }}"

- name: add the wordpress user
  user: 
    name: "{{ wordpress_system.user }}"
    group: "{{ wordpress_system.group }}"
    comment: "{{ wordpress_system.comment }}"
    home: "{{ wordpress_system.home }}"
    state: "{{ wordpress_system.state }}"

- name: copy the nginx.conf to /etc/nginx/
  template:
    src: "nginx-nginx.conf.j2"
    dest: "/etc/nginx/nginx.conf"
  notify: "restart nginx"

- name: create the global directory in /etc/nginx/
  file:
    dest: "/etc/nginx/global/"
    state: "directory"
    mode: "0644"

- name: copy the restrictions.conf to /etc/nginx/global/
  copy:
    src: "nginx-global-restrictions.conf"
    dest: "/etc/nginx/global/restrictions.conf"
  notify: "restart nginx"

- name: copy the wordpress_shared.conf to /etc/nginx/global/
  template:
    src: "nginx-global-wordpress_shared.conf.j2"
    dest: "/etc/nginx/global/wordpress_shared.conf"
  notify: "restart nginx"

- name: copy the default.conf to /etc/nginx/conf.d/
  template:
    src: "nginx-confd-default.conf.j2"
    dest: "/etc/nginx/conf.d/default.conf"
  notify: "restart nginx"

- name: copy the www.conf to /etc/php-fpm.d/
  template:
    src: "php-fpmd-www.conf.j2"
    dest: "/etc/php-fpm.d/www.conf"
  notify: "restart php-fpm"

- name: configure php.ini
  lineinfile: 
    dest: "/etc/php.ini"
    regexp: "{{ item.regexp }}"
    line: "{{ item.replace }}"
    backup: "yes"
    backrefs: "yes"
  with_items: "{{ php.ini }}"
  notify: "restart php-fpm"

- name: start php-fpm
  service:
    name: "php-fpm"
    state: "started"

- name: start nginx
  service:
    name: "nginx"
    state: "started"

- name: set the selinux allowing httpd_t to be permissive is required
  selinux_permissive:
    name: httpd_t
    permissive: true
  when: selinux.http_permissive == true
```

为此，您需要从我们在[第 5 章](05.html#2MP360-0fda9dda24fc45e094341803448da041)、*部署 WordPress* 中创建的 LEMP 剧本的`stack-config`角色中复制`files`、`handlers`和`templates`的文件。

# WordPress

你可能已经猜到了，这个可以在`roles/stack/tasks/main.yml`和`roles/stack/tasks/deploy.yml`旁边的`roles/stack/tasks/wordpress.yml`文件中找到的角色安装并配置了 WordPress。

在我们继续执行任务之前，我们需要找到关于我们的 RDS 实例的信息:

```
- name: find some information on the rds instance
  local_action:
    module: rds
    region: "{{ ec2_region }}"
    command: facts
    instance_name: "{{ environment_name }}-rds"
  become: no
  register: rds_results
```

这样我们就可以在定义数据库连接时使用这些任务；同样，我们还需要了解弹性负载平衡器:

```
- name: find some information on the elastic load balancer
  local_action:
    module: elb_application_lb_facts
    region: "{{ ec2_region }}"
    names: "{{ environment_name }}-elb"
  become: no
  register: elb_results
```

其余任务执行以下操作:

1.  安装 WP-CLI。
2.  下载 WordPress。
3.  在 WordPress 文件夹上设置正确的权限。
4.  将 WordPress 配置为使用我们在收集事实时发现的端点连接到我们的 RDS 我们正在重用我们生成的密码文件。
5.  使用弹性负载平衡器网址和默认变量的详细信息安装 WordPress:

```
- name: download wp-cli
  get_url:
    url: "{{ wp_cli.download }}"
    dest: "{{ wp_cli.path }}"

- name: update permissions of wp-cli to allow anyone to execute it
  file:
    path: "{{ wp_cli.path }}"
    mode: "0755"

- name: are the wordpress files already there?
  stat:
    path: "{{ wordpress_system.home }}/index.php"
  register: wp_installed

- name: download wordpresss
  shell: "{{ wp_cli.path }} core download"
  args:
    chdir: "{{ wordpress_system.home }}"
  become_user: "{{ wordpress_system.user }}"
  become: true
  when: wp_installed.stat.exists == False

- name: set the correct permissions on the homedir
  file:
    path: "{{ wordpress_system.home }}"
    mode: "0775"
  when: wp_installed.stat.exists == False

- name: is wordpress already configured?
  stat:
    path: "{{ wordpress_system.home }}/wp-config.php"
  register: wp_configured

- name: configure wordpress
  shell: "{{ wp_cli.path }} core config --dbhost={{ rds_results.instance.endpoint }} --dbname={{ environment_name }} --dbuser={{ environment_name }} --dbpass={{ lookup('password', 'group_vars/rds_passwordfile chars=ascii_letters,digits length=30') }}"
  args:
    chdir: "{{ wordpress_system.home }}"
  become_user: "{{ wordpress_system.user }}"
  become: true
  when: wp_configured.stat.exists == False

- name: do we need to install wordpress?
  shell: "{{ wp_cli.path }} core is-installed"
  args:
    chdir: "{{ wordpress_system.home }}"
  become_user: "{{ wordpress_system.user }}"
  become: true
  ignore_errors: yes
  register: wp_installed

- name: install wordpress if needed
  shell: "{{ wp_cli.path }} core install --url='{{ wordpress.domain }}' --title='{{ wordpress.title }}' --admin_user={{ wordpress.username }} --admin_password={{ wordpress.password }} --admin_email={{ wordpress.email }}"
  args:
    chdir: "{{ wordpress_system.home }}"
  become_user: "{{ wordpress_system.user }}"
  become: true
  when: wp_installed.rc == 1
```

为了简单起见，我们没有使用 Ansible 来管理主题或插件。

这是我们停止在以前角色中发现/启动的实例上运行任务的地方；现在是时候切换回我们的 Ansible 控制器，并使用我们的实例制作一个 AMI 了。

# 高级材料情报(Advanced Material Information)

这个角色不需要做任何选择，它只是把我们的主持人从`ec2_instances`组中带出来，给它创建一个形象。首先，让我们创建角色:

```
$ ansible-galaxy init roles/ami
```

角色由三个任务组成，其中一个是暂停。首先，在`roles/ami/tasks/main.yml`中，我们需要找出一些关于实例的信息。我们正在使用`ec2_instance_facts`模块:

```
- name: find out some facts about the instance we have been using
  ec2_instance_facts:
    region: "{{ ec2_region }}"
    filters:
      dns-name: "{{ groups['ec2_instance'][0] }}"
  register: "our_instance"
```

现在我们知道了实例，我们可以创建 AMI:

```
- name: create the AMI
  ec2_ami:
    region: "{{ ec2_region }}"
    instance_id: "{{ our_instance.instances.0.instance_id }}"
    wait: "yes"
    name: "{{ environment_name }}-{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}"
    tags:
        Name: "{{ environment_name }}-{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}"
        Environment: "{{ environment_name }}"
        Date: "{{ ansible_date_time.date }} {{ ansible_date_time.time }}"
```

可以看到，我们使用的是运行`ec2_instance_facts`模块时发现的`instance_id`；我们还使用了`ansible_date_time`变量，该变量是在调用`gather_facts`模块时定义的，以给我们的 AMI 一个唯一的名称。

如前所述，最后的任务是暂停:

```
- name: wait for 2 minutes before continuing
  pause:
    minutes: 2
```

这是必需的，因为我们新创建的 AMI 可能需要一段时间才能完全注册并在 AWS 应用编程接口中可用。

# 自动缩放

我们行动手册中的最后一个角色是创建一个启动配置，然后创建/更新一个自动扩展组来最终启动我们的实例。然后它会做一点家务。要创建角色，请运行:

```
$ ansible-galaxy init roles/autoscaling
```

首先，我们需要在`roles/autoscaling/default/main.yml`中设置几个默认变量；这些详细信息显示了我们希望一次运行多少个实例，以及在部署新 AMI 时一次替换多少个实例:

```
min_size: 2
max_size: 9
desired_capacity: 3
replace_size: 2
health_check_type: ELB
assign_public_ip: yes
ec2_instance_type: "t2.micro"
```

这些变量的意思是，我们希望有三个实例一直运行，所以如果有两个实例，那么启动更多实例，并且在任何时候都不要启动超过九个实例。部署新映像时，一次替换两个实例。

我们还定义了运行状况检查，其中，使用弹性负载平衡器检查，我们告诉实例使用公共 IP 地址启动，这意味着我们可以通过 SSH 访问它们，最后，我们定义了要使用的实例类型。

我们需要在`roles/autoscaling/tasks/main.yml`中定义的第一个任务需要找到合适的 AMI 来使用:

```
- name: search through all of our AMIs
  ec2_ami_facts:
    region: "{{ ec2_region }}"
    filters:
      name: "{{ environment_name }}-*"
  register: amiFind
```

同样，我们需要了解我们构建的最后一个 AMI 的细节:

```
- name: find the last one we built
  set_fact:
    amiSortFilter: "{{ amiFind.images | sort(attribute='creation_date') | last }}"
```

最后，我们需要获得急性心肌梗死的身份证和急性心肌梗死的名称；我们将用它来命名启动配置:

```
- name: grab AMI ID and name of the most recent result
  set_fact:
    our_ami_id: "{{ amiSortFilter.image_id }}"
    our_ami_name: "{{ amiSortFilter.name }}"
```

接下来，我们有一个任务，它使用前面的信息来创建启动配置:

```
- name: create the launch configuration
  ec2_lc:
    region: "{{ ec2_region }}"
    name: "{{ our_ami_name }}"
    state: present
    image_id: "{{ our_ami_id }}"
    security_groups: [ "{{ sg_ec2.group_id }}" ]
    assign_public_ip: "{{ assign_public_ip }}"
    instance_type: "{{ ec2_instance_type }}"
    volumes:
    - device_name: /dev/xvda
      volume_size: 10
      volume_type: gp2
      delete_on_termination: true
```

一旦创建了启动配置，我们就可以创建/更新自动缩放组来引用它。在此之前，我们需要了解目标群体的**亚马逊资源名称** ( **ARN** ):

```
- name: find out the target group ARN
  elb_target_group_facts:
    region: "{{ ec2_region }}"
    names:
      - "{{ environment_name }}-target-group"
  register: elb_target_group
```

一旦我们有了这些信息，我们就可以继续下一个任务:

```
- name: create / update the auto-scaling group using the launch configuration we just created
  ec2_asg:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-asg"
    target_group_arns: [ "{{ elb_target_group.target_groups[0].target_group_arn }}" ]
    launch_config_name: "{{ our_ami_name }}"
    min_size: "{{ min_size }}"
    max_size: "{{ max_size }}"
    desired_capacity: "{{ desired_capacity }}"
    health_check_period: 300
    health_check_type: "{{ health_check_type }}"
    replace_all_instances: yes
    replace_batch_size: "{{ replace_size }}"
    vpc_zone_identifier: "{{ subnet_ec2_ids }}"
    wait_for_instances: "yes"
    wait_timeout: "900"
    tags:
      - Name: "{{ environment_name }}-ec2"
      - environment: "{{ environment_name }}"
```

一个自动伸缩组可以确保我们一直运行我们期望数量的 EC2 实例。如果没有运行，它会启动它们，并向弹性负载平衡器的目标组注册它们。

如果有实例已经在运行，并且我们已经更新了启动配置，那么它将滚动部署我们的新配置，确保我们在删除旧实例之前不会因为启动和注册新实例而停机。

最后一个任务移除我们可能正在运行的任何`tmp`实例:

```
- name: remove any tmp instances which are running
  ec2_instance:
    region: "{{ ec2_region }}"
    state: absent
    filters:
      instance-state-name: "running"
      "tag:environment": "{{ environment_name }}"
      "tag:Name": "{{ environment_name }}-tmp"
```

这应该会让我们保持我们想要的状态，仅此而已。

# 运行剧本

我们首先需要做的是更新我们的`production`库存文件；这应该如下所示:

```
# Register all of the host groups we will be creating in the playbooks
[ec2_instance]
[already_running]

# Put all the groups into into a single group so we can easily apply one config to it for overriding things like the ssh user and key location
[aws:children]
ec2_instance
already_running

# Finally, configure some bits to allow us access to the instances before we deploy our credentials using Ansible
[aws:vars]
ansible_ssh_user=centos
ansible_ssh_private_key_file=~/.ssh/id_rsa
host_key_checking=False
```

如您所见，我们正在定义主机组，并配置 Ansible 使用`centos`用户，这是我们正在使用的原始 AMI 的默认值。

`site.yml`文件需要更新:

```
---

- name: Create, launch and configure our basic AWS environment
  hosts: localhost
  connection: local
  gather_facts: True

  vars_files:
    - group_vars/common.yml

  roles:
    - roles/vpc
    - roles/subnets
    - roles/gateway
    - roles/securitygroups
    - roles/elb
    - roles/rds
    - roles/efs
    - roles/ec2

- name: Configure / update the EC2 instance
  hosts: ec2_instance
  become: yes
  become_method: sudo
  gather_facts: True

  vars_files: 
    - group_vars/common.yml

  roles:
    - roles/stack

- name: Create, launch and configure our AMI
  hosts: localhost
  connection: local
  gather_facts: True

  vars_files:
    - group_vars/common.yml

  roles:
    - roles/ami
    - roles/autoscaling
```

如你所见，我们现在有三个部分；第一部分准备环境，正如我们已经看到的——还有`ec2`角色的添加。这一部分全部在 Ansible 控制器上执行。

在下一节中，我们将继续针对`ec2_instance`组中的主机运行角色；如前所述，我们在这台主机上使用`become: yes`和`become_method: sudo`，因为我们连接的用户`centos`没有安装软件栈所需的正确权限。这就是为什么我们在使用`local_action`模块时需要禁用`become`的原因。第三部分带我们回到我们的 Ansible 控制器，在这里我们使用 AWS API 来创建我们的 AMI 并启动它。

不要忘记设置您的访问密钥和机密访问密钥环境变量:

```
$ export AWS_ACCESS_KEY=AKIAI5KECPOTNTTVM3EDA
$ export AWS_SECRET_KEY=Y4B7FFiSWl0Am3VIFc07lgnc/TAtK5+RpxzIGTr
```

Before we run the playbook you need to make sure that you are subscribed to the CentOS 7 Amazon Machine Image in the AWS Marketplace, to do this go to the following link and hit the subscribe button, if you are not subscribed to the AMI you will receive an error when you run the playbook instructing you that you do not have access to the image: [https://aws.amazon.com/marketplace/pp/B00O7WM7QW](https://aws.amazon.com/marketplace/pp/B00O7WM7QW).

我们将安排我们的行动手册再次运行，因此，要执行行动手册，请使用以下命令:

```
$ time ansible-playbook -i production site.yml
```

由于我们已经看到一半剧本的输出在运行，我将跳过`vpc`、`subnets`、`gateway`、`securitygroups`、`elb`、`rds`和`efs`角色的输出，这意味着我们将从`ec2`一个开始:

```
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [Create, launch and configure our basic AWS environment] ************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/ec2 : gather facts on any already running instances] ********************************
ok: [localhost]

TASK [roles/ec2 : add any already running instances to a group] *********************************

TASK [roles/ec2 : set the number of already running instances as a fact] ***********************
ok: [localhost]

TASK [roles/ec2 : run the tasks for a new deployment] *******************************************
included: /Users/russ/Documents/Code/learn-ansible-fundamentals-of-ansible-2x/chapter10/aws-wordpress/roles/ec2/tasks/new_deployment.yml for localhost

TASK [roles/ec2 : search for all of the AMIs in the defined region which match our selection] ***
ok: [localhost]

TASK [roles/ec2 : filter the list of AMIs to find the latest one with an EBS backed volume] *****
ok: [localhost]

TASK [roles/ec2 : finally grab AMI ID of the most recent result which matches our base image which is backed by an EBS volume] ***************************************************************
ok: [localhost]

TASK [roles/ec2 : check the user russ has a key, if not create one] *****************************
ok: [localhost]

TASK [roles/ec2 : upload the users public key] **************************************************
ok: [localhost] => (item=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDmuoFR01i/Yf3HATl9c3sufJvghTFgYzK/Zt29JiTqWlSQhmXhNNTh6iI6nXuPVhQGQaciWbqya6buncQ3vecISx6+EwsAmY3Mwpz1a/eMiXOgO/zn6Uf79dXcMN2JwpLFoON1f9PR0/DTpEkjwqb+eNLw9ThjH0J994+Pev+m8OrqgReFW36a/kviUYKsHxkXmkgxtPJgwKU90STNab4qyfKEGhi2w/NzECgseeQYs1H3klORaHQybhpXkoCIMmgy9gnzSH7oa2mJqKilVed27xoirkXzWPaAQlfiEE1iup+2xMqWY6Jl9qb8tJHRS+l8UcxTMNaWsQkTysLTgBAZ russ@mckendrick.io)

TASK [roles/ec2 : launch an instance] ***********************************************************
changed: [localhost]

TASK [roles/ec2 : gather facts on the instance we just launched using the AWS API] **************
ok: [localhost]

TASK [roles/ec2 : add our temporary instance to a host group for use in the next step] **********
changed: [localhost] =>

TASK [roles/ec2 : wait until SSH is available before moving onto the next step] *****************
ok: [localhost] => 

TASK [roles/ec2 : add the instance to the target group] ******************************************
changed: [localhost] =>

TASK [roles/ec2 : run the tasks for an existing deployment] *************************************
skipping: [localhost]

PLAY [Configure / update the EC2 instance] ******************************************************

TASK [Gathering Facts] **************************************************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : update all of the installed packages] ***************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : are the wordpress files already there?] *************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : if no wordpress installed install and configure the software stack] *********

TASK [stack : find some information on the elastic load balancer] *******************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com -> localhost]

TASK [stack : ensure EFS volume is mounted.] ****************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : install the repo packages] *************************************************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com] => (item=[u'epel-release', u'https://centos7.iuscommunity.org/ius-release.rpm'])

TASK [stack : add the NGINX mainline repo] ******************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : install the stack packages] *******************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com] => (item=[u'MySQL-python', u'policycoreutils-python', u'nfs-utils', u'nginx', u'mariadb', u'php72u', u'php72u-bcmath', u'php72u-cli', u'php72u-common', u'php72u-dba', u'php72u-fpm', u'php72u-fpm-nginx', u'php72u-gd', u'php72u-intl', u'php72u-json', u'php72u-mbstring', u'php72u-mysqlnd', u'php72u-process', u'php72u-snmp', u'php72u-soap', u'php72u-xml', u'php72u-xmlrpc', u'vim-enhanced', u'git', u'unzip'])

TASK [stack : add the wordpress user] ***********************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : copy the nginx.conf to /etc/nginx/] ***********************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : create the global directory in /etc/nginx/] ***************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : copy the restrictions.conf to /etc/nginx/global/] *********************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : copy the wordpress_shared.conf to /etc/nginx/global/] *****************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : copy the default.conf to /etc/nginx/conf.d/] **************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : copy the www.conf to /etc/php-fpm.d/] *********************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : configure php.ini] ****************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com] => (item={u'regexp': u'^;date.timezone =', u'replace': u'date.timezone = Europe/London'})
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com] => (item={u'regexp': u'^expose_php = On', u'replace': u'expose_php = Off'})
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com] => (item={u'regexp': u'^upload_max_filesize = 2M', u'replace': u'upload_max_filesize = 20M'})

TASK [stack : start php-fpm] ********************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : start nginx] **********************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : set the selinux allowing httpd_t to be permissive is required] ********************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : if no wordpress installed, install it !!!] **********************************

TASK [stack : download wp-cli] ******************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : update permissions of wp-cli to allow anyone to execute it] ***********************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : find some information on the rds instance] ****************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com -> localhost]

TASK [stack : find some information on the elastic load balancer] *******************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com -> localhost]

TASK [stack : are the wordpress files already there?] *******************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : download wordpresss] **************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : set the correct permissions on the homedir] *****************************************************************************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : is wordpress already configured?] ***************************************************************************************************************************************
ok: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : configure wordpress] ****************************************************************************************************************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

TASK [stack : do we need to install wordpress?] ***************************************************************************************************************************************
fatal: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]: FAILED! => {"changed": true, "cmd": "/usr/local/bin/wp core is-installed", "delta": "0:00:01.547784", "end": "2018-05-06 14:19:01.301168", "msg": "non-zero return code", "rc": 1, "start": "2018-05-06 14:18:59.753384", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
...ignoring

TASK [stack : install wordpress if needed] ******************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

RUNNING HANDLER [roles/stack : restart nginx] ***************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

RUNNING HANDLER [roles/stack : restart php-fpm] *************************************************
changed: [ec2-34-244-58-38.eu-west-1.compute.amazonaws.com]

PLAY [Create, launch and configure our AMI] *****************************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/ami : find out some facts about the instance we have been using] ********************
ok: [localhost]

TASK [roles/ami : create the AMI] *************************************************************************************************
changed: [localhost]

TASK [roles/ami : wait for 2 minutes before continuing] *****************************************
Pausing for 120 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/autoscaling : search through all of our AMIs] ***************************************
ok: [localhost]

TASK [roles/autoscaling : find the last one we built] *******************************************
ok: [localhost]

TASK [roles/autoscaling : grab AMI ID and name of the most recent result] ***********************
ok: [localhost]

TASK [roles/autoscaling : create the launch configuration] **************************************
changed: [localhost]

TASK [roles/autoscaling : find out the target group ARN] ****************************************
ok: [localhost]

TASK [roles/autoscaling : create / update the auto-scaling group using the launch configuration we just created] ********************************************************************************
changed: [localhost]

TASK [roles/autoscaling : remove any tmp instances] *********************************************
changed: [localhost]

PLAY RECAP **************************************************************************************
ec2-34-244-58-38.eu-west-1.compute.amazonaws.com : ok=32 changed=24 unreachable=0 failed=0
localhost : ok=47 changed=21 unreachable=0 failed=0
```

剧本在接下来的时间里为我播放:

```
real 31m34.752s
user 2m4.008s
sys  0m39.274s
```

因此，从一个命令，在 32 分钟内，我们有一个高度可用的香草 WordPress 安装。如果您从 AWS 控制台找到弹性负载平衡器的公共网址，您应该能够看到您的站点:

![](../images/00095.jpeg)

检查 AWS 控制台中的 EC2 实例，我们可以看到有三个实例，都叫做`wordpress-ec2`，正在运行，`wordpress-tmp`实例已经终止:

![](../images/00096.jpeg)

现在，让我们看看当我们再次运行剧本时会发生什么。我们不仅应该看到它执行得更快，而且应该跳过几个角色:

```
$ time ansible-playbook -i production site.yml
```

我再次截断了输出:

```
WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [Create, launch and configure our basic AWS environment] ************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/ec2 : gather facts on any already running instances] ********************************
ok: [localhost]

TASK [roles/ec2 : add any already running instances to a group] *********************************
changed: [localhost] => 

TASK [roles/ec2 : set the number of already running instances as a fact] ************************
ok: [localhost]

TASK [roles/ec2 : run the tasks for a new deployment] *******************************************
skipping: [localhost]

TASK [roles/ec2 : run the tasks for an existing deployment] *************************************
included: /Users/russ/Documents/Code/learn-ansible-fundamentals-of-ansible-2x/chapter10/aws-wordpress/roles/ec2/tasks/existing_deployment.yml for localhost

TASK [roles/ec2 : add one of our running instances to a host group for use in the next step] ****
changed: [localhost]

PLAY [Configure / update the EC2 instance] ******************************************************

TASK [Gathering Facts] **************************************************************************
ok: [ec2-52-211-180-156.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : update all of the installed packages] ***************************************
changed: [ec2-52-211-180-156.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : are the wordpress files already there?] *************************************
ok: [ec2-52-211-180-156.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : if no wordpress installed install and configure the software stack] *********
skipping: [ec2-52-211-180-156.eu-west-1.compute.amazonaws.com]

TASK [roles/stack : if no wordpress installed, install it !!!] **********************************
skipping: [ec2-52-211-180-156.eu-west-1.compute.amazonaws.com]

PLAY [Create, launch and configure our AMI] *****************************************************

TASK [Gathering Facts] **************************************************************************
ok: [localhost]

TASK [roles/ami : find out some facts about the instance we have been using] ********************
ok: [localhost]

TASK [roles/ami : create the AMI] ***************************************************************
changed: [localhost]

TASK [roles/ami : wait for 2 minutes before continuing] *****************************************
Pausing for 120 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]

TASK [roles/autoscaling : search through all of our AMIs] ***************************************
ok: [localhost]

TASK [roles/autoscaling : find the last one we built] *******************************************
ok: [localhost]

TASK [roles/autoscaling : grab AMI ID and name of the most recent result] ***********************
ok: [localhost]

TASK [roles/autoscaling : create the launch configuration] **************************************
changed: [localhost]

TASK [roles/autoscaling : find out the target group ARN] ****************************************
ok: [localhost]

TASK [roles/autoscaling : create / update the auto-scaling group using the launch configuration we just created] ********************************************************************************
changed: [localhost]

TASK [roles/autoscaling : remove any tmp instances] *********************************************
ok: [localhost]

PLAY RECAP **************************************************************************************
ec2-52-211-180-156.eu-west-1.compute.amazonaws.com : ok=3 changed=1 unreachable=0 failed=0
localhost : ok=39 changed=5 unreachable=0 failed=0
```

这一次，我返回了以下计时:

```
real 9m18.502s
user 0m48.718s
sys  0m14.115s
```

完成后，我检查我仍然可以使用我们在剧本中设置的用户名(`ansible`)和密码(`password`)登录 WordPress，方法是转到我的弹性负载平衡器网址，并在末尾添加`/wp-admin`:

![](../images/00097.jpeg)

您可以在 AWS 控制台的自动缩放活动日志中看到发生了什么:

![](../images/00098.jpeg)

如您所见，启动了三个新实例，终止了三个实例。

# 终止所有资源

在我们完成这一章之前，我们需要看一下终止资源；我们唯一需要做的补充是删除自动缩放组和 AMIs。为此，我们要给`roles/remove/tasks/main.yml`增加四个任务；从文件顶部开始，添加以下两个任务:

```
- name: remove the auto-scaling group
  ec2_asg:
    region: "{{ ec2_region }}"
    name: "{{ environment_name }}-asg"
    state: absent
    wait_for_instances: "yes"
    wait_timeout: "900"

```

```
- name: wait for 2 minutes before continuing
  pause:
    minutes: 2
```

第一个任务是删除自动缩放组。这又会终止它已经启动的任何实例。我们还内置了一个暂停，以确保所有内容都已从 AWS 应用编程接口中正确移除。

在角色的末尾，添加以下两个任务来删除所有非盟驻苏特派团:

```
- name: search through all of our AMIs
  ec2_ami_facts:
    region: "{{ ec2_region }}"
    filters:
      name: "{{ environment_name }}-*"
  register: amiFind

- name: unregister all of our AMIs
  ec2_ami:
    image_id: "{{ item.image_id }}"
    delete_snapshot: True
    state: absent
  with_items: "{{ amiFind.images }}"
```

然后，您可以使用以下命令运行行动手册:

```
$ ansible-playbook -i production remove.yml
```

和以前一样，在继续之前，不要忘记检查弹性负载平衡器是否已被移除。行动手册运行后，我建议您登录 AWS 控制台，并再次检查所有内容是否都已正确删除。行动手册没有删除启动配置，这应该不是问题，因为没有相关的成本。但是，我建议检查未连接的 EBS 卷和快照，因为这些会产生成本。

# 摘要

在这一章中，我们通过创建和启动一个高可用性的 WordPress 安装，将我们的 AWS 提升到了一个新的水平。通过利用 AWS 提供的各种服务，我们设计出了与实例可用性和可用性区域相关的任何单点故障。

我们还在行动手册中构建了逻辑，这样我们就可以使用相同的命令启动新的部署，或者通过滚动部署包含我们更新包的新实例 AMIs 来更新现有部署上的操作系统，从而实现部署期间的零停机。

虽然 WordPress 部署可能是我们所能做到的最简单的，但是当使用更复杂的应用时，部署生产就绪映像的过程将保持相似。

在下一章中，我们将了解从公共云到私有云的转变，以及 Ansible 如何与 VMware 交互。

# 问题

1.  使用`gather_facts`选项注册的变量的名称是什么，它包含我们的行动手册执行的日期和时间？
2.  对或错:Ansible 自动计算出它需要执行哪个任务，这意味着我们不必自己定义任何逻辑。
3.  解释为什么我们必须使用`local_action`模块。
4.  我们在`ansible-playbook`命令前附加哪个命令来记录我们的命令执行了多长时间？
5.  对或错:使用自动缩放时，您必须手动启动 EC2 实例。
6.  更新行动手册，以便在行动手册运行结束时为您提供弹性负载平衡器的公共网址。

# 进一步阅读

你可以在 https://aws.amazon.com/mp/centos/的 AWS 市场上找到更多关于 CentOS AMIs 的详细信息。