- en: Chapter 10. Health Check Your Cloud with Nagios
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。使用Nagios检查云的健康状况
- en: The topic of monitoring happens to be something I hold very close to my heart.
    I spent years *watching* many organizations' websites and applications to ensure
    that their availability holds as close as possible to 99.99% uptime. This task
    was not for the meek of heart in any realm of things. The thing that got me through
    it all was having a solid method to monitoring the environments that did not require
    me to literally watch it every second of the day. In this chapter, we will step
    through some of the common approaches to checking the health of your OpenStack
    cloud manually and then leverage Ansible to set up my favorite open source monitoring
    tool, Nagios.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 监控恰好是我非常关心的一个话题。我花了很多年时间*观察*许多组织的网站和应用，以确保它们的可用性尽可能接近99.99%的正常运行时间。这项任务在任何领域都不是软弱的人可以做的。支撑我度过这一切的是有一种坚实的监控方法，不需要我每天都亲自盯着它。在本章中，我们将介绍一些常见的方法来手动检查您的OpenStack云的健康状况，然后利用Ansible来设置我最喜欢的开源监控工具Nagios。
- en: 'Since we have been experimenting with the **openstack-ansible** (**OSA**) deployment
    method throughout the book, let''s continue to leverage the built-in Ansible capabilities
    part of OSA to perform various system checks. Keep in mind that what we do here
    should not replace any third-party monitoring tool that most likely will do a
    better job keeping the tasks to be monitored in a reliable rotation. We will use
    the native capabilities part of OpenStack and Linux to provide a quick view of
    your clouds health. As well as along the way, we will review other monitoring
    tips and tricks:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在整本书中一直在使用**openstack-ansible**（**OSA**）部署方法进行实验，让我们继续利用OSA的内置Ansible功能来执行各种系统检查。请记住，我们在这里所做的事情不应该取代任何第三方监控工具，这些工具很可能会更好地保持被监控任务的可靠轮换。我们将使用OpenStack和Linux的本机功能来快速查看您的云的健康状况。同时，我们还将介绍其他监控技巧和窍门：
- en: Monitoring the cloud
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控云
- en: Infrastructure services
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施服务
- en: Core OpenStack services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心OpenStack服务
- en: Setting up Nagios and importing checks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Nagios并导入检查
- en: Collecting your metrics via SNMP
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过SNMP收集指标
- en: Coding the playbook and roles
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写操作手册和角色
- en: Reviewing playbook and role
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查操作手册和角色
- en: Monitoring the cloud
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控云
- en: 'If allowed I would like to cover some monitoring basics before getting started
    here. Hopefully, the three principles I will share here are not new to you. When
    evaluating to monitor something, there are three base principles to keep in mind:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果允许的话，我想在开始之前先介绍一些监控基础知识。希望我将在这里分享的三个原则对你来说并不新鲜。在评估监控某些内容时，有三个基本原则需要牢记：
- en: Keep it simple
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持简单
- en: Keep your monitoring close to your infrastructure
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将您的监控保持在基础设施附近
- en: Create good monitors
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建良好的监控器
- en: The first point is pretty easy to absorb, as it is rather self-explanatory.
    The worst thing you could ever do is over complicate something as important as
    monitoring. This principle not only applies to your overall approach, but it also
    applies to the tool you choose to do the monitoring. If you have to create a **Visio**
    diagram of your monitoring platform, it is too complicated.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个要点很容易理解，因为它相当不言自明。你能做的最糟糕的事情就是过于复杂化如监控这样重要的事情。这个原则不仅适用于你的整体方法，也适用于你选择用来进行监控的工具。如果你不得不创建一个你的监控平台的**Visio**图，那就太复杂了。
- en: The next point of keeping your monitoring close to your infrastructure is meant
    to express that the tool used to monitor should physically reside close to the
    infrastructure/application. The monitoring platform should not have to traverse
    VPNs or multiple firewalls just to poll the devices/applications. Centrally place
    the monitoring platform, so you can poll as many systems as possible with minimal
    path to travel. You should be able to open up one or two ports in a firewall to
    enable monitoring, and this should be turned into a standardized process part
    of standing up new devices/applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将监控保持在基础设施附近的下一个要点是，用于监控的工具应该物理上靠近基础设施/应用程序。监控平台不应该需要穿越VPN或多个防火墙才能轮询设备/应用程序。将监控平台集中放置，这样您就可以以最小的路径轮询尽可能多的系统。您应该能够在防火墙中打开一两个端口以启用监控，并且这应该成为启动新设备/应用程序的标准化流程的一部分。
- en: The last point is another rather self-explanatory concept. Creating good monitors
    is critical, and it will avoid false positive monitor alerts. Over time individuals
    will begin to ignore monitoring alerts if they mostly all turn out to be false
    alarms. Make sure that each monitoring check works as expected and is tuned to
    avoid false alarms as much as possible. Never launch a new alert monitor without
    testing it during various workloads and time of the day. Also, it should go without
    saying to make sure that the monitor adds value and is not redundant.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点是另一个相当不言自明的概念。创建良好的监控器至关重要，它将避免错误的监控警报。随着时间的推移，如果大部分警报都被证明是虚假警报，个人将开始忽略监控警报。确保每个监控检查都按预期工作，并调整以尽量避免虚假警报。在各种工作负载和一天中的不同时间测试之后，再启动新的警报监控。此外，毋庸置疑，确保监控器增加价值并且不是多余的。
- en: 'Now that we have gotten the basics out of the way, we can now focus on monitoring
    OpenStack. This would normally cover the following four areas:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了基础知识，我们现在可以专注于监控OpenStack。这通常涵盖以下四个领域：
- en: Monitoring the physical hardware (base resource consumption)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控物理硬件（基础资源消耗）
- en: Monitoring the OpenStack API endpoints
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控OpenStack API端点
- en: Monitoring the OpenStack services processes
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控OpenStack服务进程
- en: Monitoring the Compute nodes via the infrastructure nodes
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过基础设施节点监控计算节点
- en: Since the first two areas are honestly better suited for a monitoring tool to
    handle, we will not be focusing on these tools in this book. So our focus will
    be primarily on checking the health of the infrastructure services (that is, Galera,
    RabbitMQ, and so on), the core OpenStack services processes, and the Compute nodes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于前两个领域实际上更适合由监控工具处理，我们在本书中不会重点关注这些工具。因此，我们的重点将主要放在检查基础设施服务（即Galera、RabbitMQ等）、核心OpenStack服务进程和计算节点的健康状况上。
- en: Tip
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**ProTip**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**专业提示**'
- en: When monitoring the OpenStack API endpoints, make sure to include the endpoint
    response times as a metric being recorded. This allows you to identify and track
    any service-related slowdowns that eventually could cause a service failure. Capturing
    this information allows you to see performance trends over time, which could proactively
    allow you to address service related issues before failures occur. The fix could
    be something as simple as adding more containers running that particular service,
    tuning service parameters, and/or database tuning.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控OpenStack API端点时，确保包括端点响应时间作为记录的指标。这样可以帮助您识别和跟踪任何与服务相关的减速，最终可能导致服务故障。捕获这些信息可以让您随着时间查看性能趋势，这可以让您在故障发生之前主动解决服务相关问题。修复可能是简单的事情，比如增加运行特定服务的容器，调整服务参数和/或数据库调优。
- en: OpenStack service processes
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenStack服务进程
- en: Before moving to the next section, I felt it would be helpful to include some
    details on the OpenStack service processes. Here is a table outlining the OpenStack
    services and the associated process names. As anything related to OpenStack, the
    process names are subject to change on a per release basis. I hope that this will at
    least be a good starting point.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在转到下一部分之前，我觉得包括一些关于OpenStack服务进程的细节会很有帮助。这里有一张表格，列出了OpenStack服务和相关的进程名称。与OpenStack相关的任何内容，进程名称都可能因每个版本的发布而发生变化。我希望这至少是一个很好的起点。
- en: '| **Service Name** | **Code-Name** | **Process Name** |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **服务名称** | **代码名称** | **进程名称** |'
- en: '| Compute | Nova | nova-api-metadata, nova-api-os-compute, nova-cert, nova-compute,
    nova-consoleauth, nova-spicehtml5proxy, nova-api-ec2, nova-api, nova-conductor,
    nova-scheduler |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 计算 | Nova | nova-api-metadata, nova-api-os-compute, nova-cert, nova-compute,
    nova-consoleauth, nova-spicehtml5proxy, nova-api-ec2, nova-api, nova-conductor,
    nova-scheduler |'
- en: '| Object Storage | Swift | swift-proxy-server, swift-account-server, swift-account-auditor,
    swift-account-replicator, swift-account-reaper, swift-container-server, swift-container-auditor,
    swift-container-replicator, swift-container-updater, swift-object-server, swift-object-auditor,
    swift-object-replicator, swift-object-updater |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 对象存储 | Swift | swift-proxy-server, swift-account-server, swift-account-auditor,
    swift-account-replicator, swift-account-reaper, swift-container-server, swift-container-auditor,
    swift-container-replicator, swift-container-updater, swift-object-server, swift-object-auditor,
    swift-object-replicator, swift-object-updater |'
- en: '| Image | Glance | glance-api, glance-registry |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 镜像 | Glance | glance-api, glance-registry |'
- en: '| Identity | Keystone | keystone-all, apache2 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 身份 | Keystone | keystone-all, apache2 |'
- en: '| Dashboard | Horizon | apache2 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 仪表板 | Horizon | apache2 |'
- en: '| Networking | Neutron | neutron-dhcp-agent, neutron-l3-agent, neutron-linuxbridge-agent,
    neutron-metadata-agent, neutron-metering-agent, neutron-server |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | Neutron | neutron-dhcp-agent, neutron-l3-agent, neutron-linuxbridge-agent,
    neutron-metadata-agent, neutron-metering-agent, neutron-server |'
- en: '| Block Storage | Cinder | cinder-api, cinder-volume, cinder-scheduler |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 块存储 | Cinder | cinder-api, cinder-volume, cinder-scheduler |'
- en: '| Orchestration | Heat | heat-api, heat-api-cfn, heat-api-cloudwatch, heat-engine
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 编排 | Heat | heat-api, heat-api-cfn, heat-api-cloudwatch, heat-engine |'
- en: '| Telemetry | Ceilometer | ceilometer-agent-compute, ceilometer-agent-central,
    ceilometer-agent-notification, ceilometer-collector, ceilometer-alarm-evaluator,
    ceilometer-alarm-notifier, ceilometer-api |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 遥测 | Ceilometer | ceilometer-agent-compute, ceilometer-agent-central, ceilometer-agent-notification,
    ceilometer-collector, ceilometer-alarm-evaluator, ceilometer-alarm-notifier, ceilometer-api
    |'
- en: '| Database | Trove | trove-api, trove-taskmanager, trove-conductor |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 数据库 | Trove | trove-api, trove-taskmanager, trove-conductor |'
- en: Infrastructure services
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础设施服务
- en: The foundation of all the OpenStack services are called infrastructure services.
    These are the services/components needed just for OpenStack to work on any level.
    Those components are an SQL database server software, database-clustering software,
    and messaging server software. In our specific case, those components in the same
    order will be MariaDB, Galera, and RabbitMQ. Making sure that all of these components
    are healthy and working as expected in a top priority. Each of these software
    packages has native commands to report on their health, so we are covered there.
    So the challenge would then be what the best way to query for this information
    against clouds of various sizes is. Imagine that you have a 20-node control plane.
    You could execute the health check command twenty times or just execute one command
    using Ansible to get the status back.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所有OpenStack服务的基础称为基础设施服务。这些是OpenStack在任何级别上工作所需的服务/组件。这些组件是SQL数据库服务器软件、数据库集群软件和消息服务器软件。在我们的特定情况下，这些组件按照相同的顺序将是MariaDB、Galera和RabbitMQ。确保所有这些组件都健康并按预期工作是首要任务。每个软件包都有本机命令来报告它们的健康状况，所以我们在这方面已经有所准备。因此，挑战将是针对各种规模的云查询此信息的最佳方式是什么。想象一下，您有一个20节点的控制平面。您可以执行20次健康检查命令，或者只需使用Ansible执行一个命令即可获取状态。
- en: MariaDB and Galera
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MariaDB和Galera
- en: Starting with the first two components, there is a way to execute one command
    to do both, a MySQL check as well as check the health of the database cluster.
    If you remember back in [Chapter 2](ch02.html "Chapter 2. Introduction to Ansible"),
    *Introduction to Ansible*, we covered the topic of dynamic inventory and how OSA
    has prebuilt dynamic inventory scripts available that we can use to ease cloud
    management. We will use that capability here to streamline the process of checking
    on these infrastructure services.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从前两个组件开始，有一种方法可以执行一个命令来同时进行MySQL检查以及检查数据库集群的健康状况。如果您还记得[第2章](ch02.html "第2章。Ansible简介")中的内容，*Ansible简介*，我们讨论了动态清单的主题，以及OSA提供了预构建的动态清单脚本，可以用来简化云管理。我们将利用这种能力来简化检查这些基础设施服务的流程。
- en: It is useful to have a quick reminder walk through of how to use the OSA dynamic
    inventory scripts with Ansible. From the root OSA deployment (`/opt/openstack-ansible/playbooks`) directory,
    you can use the defined group names to call the containers where any of the OpenStack
    services reside. Each OpenStack service and infrastructure component has a group
    defined within the dynamic inventory. As related to the specific task we are working
    on presently, there is a group named `galera_container`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个快速提醒，介绍如何使用OSA动态清单脚本与Ansible。从根OSA部署（`/opt/openstack-ansible/playbooks`）目录中，您可以使用定义的组名来调用任何OpenStack服务所在的容器。每个OpenStack服务和基础设施组件在动态清单中都有一个定义的组。与我们目前正在处理的特定任务相关，有一个名为`galera_container`的组。
- en: 'This group contains all the containers where MySQL and Galera are installed
    for the cloud. You would then substitute this group name for any host names you
    would normally provide within the `hosts` file located inside the `root` directory
    of the playbook. Try executing the following command against your OSA cloud to
    reveal the details for your Galera containers:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该组包含安装了云端MySQL和Galera的所有容器。然后，您可以将此组名替换为您通常在playbook的`hosts`文件中提供的任何主机名。尝试针对您的OSA云执行以下命令，以显示Galera容器的详细信息：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output will look similar to this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于这样：
- en: '![MariaDB and Galera](graphics/image_10_001.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![MariaDB和Galera](graphics/image_10_001.jpg)'
- en: Note
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that the previous example was collected against an **AIO** (**All-In-One**)
    deployment of OpenStack. Normally, you should find three or more different containers
    listed under the `galera_container` group.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，前面的示例是针对OpenStack的AIO（All-In-One）部署收集的。通常情况下，您应该在`galera_container`组下找到三个或更多不同的容器。
- en: 'The area that we haven''t covered as it relates to Ansible is the ability to
    issue more basic ad hoc commands using just the Ansible runtime package. Execute
    the following command within a command prompt where Ansible is installed to see
    the details on how to use the basic Ansible program:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与Ansible相关的我们尚未涉及的领域是使用仅使用Ansible运行时包来发出更基本的临时命令的能力。在安装了Ansible的命令提示符中执行以下命令，以查看如何使用基本的Ansible程序的详细信息：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will note that the parameters are very similar to the `ansible-playbook`
    program with the main difference being that the `ansible` program is not intended
    to execute playbooks. Rather it is meant to be able to execute ad hoc tasks directly
    on the command line using all the same modules you would normally use with a playbook.
    We will use the basic Ansible program to demonstrate how to retrieve the status
    of these infrastructure services.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到参数与`ansible-playbook`程序非常相似，主要区别在于`ansible`程序不打算执行playbooks。相反，它旨在能够直接在命令行上执行临时任务，使用与playbook通常使用的相同模块。我们将使用基本的Ansible程序来演示如何检索这些基础设施服务的状态。
- en: 'Now if we put this all together, the working example of reporting on the health
    of MySQL and Galera will look like the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们把这些都放在一起，报告MySQL和Galera的健康状况的工作示例将如下所示：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding command told Ansible to use the `galera_container` group as the
    hosts to run the `shell` command against. The `shell` command will call MySQL
    and execute the `show status` query. The output of the command will look similar
    to this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令告诉Ansible使用`galera_container`组作为要运行`shell`命令的主机。`shell`命令将调用MySQL并执行`show
    status`查询。命令的输出将类似于这样：
- en: '![MariaDB and Galera](graphics/image_10_002.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![MariaDB和Galera](graphics/image_10_002.jpg)'
- en: 'Again, due to using an AIO deployment, you will note that the example shows
    a cluster size of only one. Normally, the cluster size should show three or more,
    and the status will be displayed for each container (the output will be repeated
    for each container). Key areas to look out for are: each container reports success,
    the cluster size is correct, and the cluster ID is the same across all clusters.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，由于使用AIO部署，您会注意到示例显示的集群大小只有一个。通常，集群大小应该显示为三个或更多，并且状态将显示在每个容器上（输出将对每个容器重复）。需要注意的关键领域是：每个容器报告成功，集群大小正确，并且集群ID在所有集群中都相同。
- en: RabbitMQ
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RabbitMQ
- en: 'We will use the very same principles as we did earlier for MariaDB/Galera to
    check on the status and health of the RabbitMQ cluster. The group name for the
    RabbitMQ containers is `rabbit_mq_container`, and we can see the details of the
    group by executing the following command within the OSA root deployment directory:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前对MariaDB/Galera进行状态和健康检查时相同的原则来检查RabbitMQ集群的状态和健康状况。RabbitMQ容器的组名是`rabbit_mq_container`，我们可以在OSA根部署目录中执行以下命令来查看组的详细信息：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now go ahead and test out a few commands to report on the RabbitMQ cluster
    health. The first command here will report directly on the cluster status, and
    the second command will list out all the queues that contain messages (in other
    words queues that are not empty):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以继续测试一些命令，报告RabbitMQ集群的健康状况。这里的第一个命令将直接报告集群状态，第二个命令将列出包含消息的所有队列（换句话说，非空队列）：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the commands will look similar to this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的输出将类似于这样：
- en: '![RabbitMQ](graphics/image_10_003.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![RabbitMQ](graphics/image_10_003.jpg)'
- en: Having each container report back a *success*, having the list of running nodes
    match exactly and each showing the same cluster name are the areas that matter
    the most. Do not stress too much if you find queues with messages still present.
    The idea is those messages should clear in an acceptable period of time. Use this
    metric to seek out any trends in messages getting stuck in the queue for too long.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让每个容器回报“成功”，确保运行节点列表完全匹配，并且每个节点显示相同的集群名称是最重要的。如果发现队列中仍然存在消息，请不要太担心。关键是这些消息应该在合理的时间内清除。使用这个指标来寻找消息在队列中被卡住的趋势。
- en: Core OpenStack services
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核心OpenStack服务
- en: With all the infrastructure services covered, we can move on to the core OpenStack
    services. In this section, we will cover a few principles that can be used for
    any of the OpenStack services. This approach allows you to interchange any of
    the basic approaches for any service basing it on your personal needs.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在涵盖了所有基础设施服务之后，我们可以转向核心OpenStack服务。在本节中，我们将介绍一些可以用于任何OpenStack服务的原则。这种方法允许您根据个人需求交换任何基本方法中的任何服务。
- en: 'The first three services I normally go in and check are Keystone, Nova, and
    Neutron. These services can have adverse effects on many other services within
    your cloud and need to be running properly to technically have a functioning cloud.
    While there is no distinct OpenStack command you can use to check the Keystone
    service, it will become very apparently obvious if the Keystone service is not
    operational as any/all OpenStack CLI commands will fail. I personally find the
    easiest way to test our Keystone is to either log into the Horizon dashboard or
    issue the following OpenStack CLI command:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常会检查的前三个服务是Keystone、Nova和Neutron。这些服务可能会对云中的许多其他服务产生不利影响，需要正常运行才能在技术上拥有一个正常运行的云。虽然没有明确的OpenStack命令可以用来检查Keystone服务，但如果Keystone服务不可用，任何/所有OpenStack
    CLI命令都将失败，这将变得非常明显。我个人发现测试Keystone的最简单方法是要么登录到Horizon仪表板，要么发出以下OpenStack CLI命令：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you get back the list of services using Keystone, you have just tested passing
    user credentials to Keystone for authentication and Keystone returning a proper
    token for authorization. With us taking care of testing out Keystone, the next
    step can be to issue two OpenStack CLI commands that will quickly report on the
    state of Nova and Neutron:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Keystone返回服务列表，您刚刚测试了向Keystone传递用户凭据进行身份验证，并且Keystone返回了适当的授权令牌。我们负责测试Keystone，下一步可以是发出两个OpenStack
    CLI命令，快速报告Nova和Neutron的状态：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `nova service-list` command will poll all Nova-related containers and Compute
    nodes to determine their zone, status, state, and time either the status or state
    was changed. The output of this command will look similar to this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`nova service-list`命令将轮询所有与Nova相关的容器和计算节点，以确定它们的区域、状态、状态和状态更改的时间。此命令的输出将类似于此：'
- en: '![Core OpenStack services](graphics/image_10_004.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Core OpenStack services](graphics/image_10_004.jpg)'
- en: 'Next, the `neutron agent-list` command will do the same thing as the above
    except for the Neutron-related components. You will note that in the upcoming
    example a smiley face graphic is used to determine the status of the neutron agents.
    The state of the agents will also be reported back with this command as well:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`neutron agent-list`命令将执行与上述相同的操作，只是针对与Neutron相关的组件。您将注意到在即将介绍的示例中，使用了笑脸图形来确定neutron代理的状态。代理的状态也将与此命令一起报告：
- en: '![Core OpenStack services](graphics/image_10_005.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![Core OpenStack services](graphics/image_10_005.jpg)'
- en: 'At this point, you will have to rely on checking directly on the statuses of
    the actual OpenStack service processes running within their containers to do more
    detailed monitoring. This would be similar to some of the methods published on
    the OpenStack website, http://docs.openstack.org/ops-guide/operations.html. The
    main difference is that we will use Ansible to execute the commands across all
    containers or nodes as needed. Using the basic Ansible program and the OpenStack
    service processes table mentioned previously, you will be able to check the status
    of the processes running OpenStack within your cloud. The following are a few
    examples of how this can be accomplished. It is recommended to get a complete
    output of the dynamic inventory for your cloud, so you will be aware of all the
    groups defined. Use the following command to get the complete inventory output
    (this command assumes that you are in the root OSA deployment directory):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您将不得不依靠直接检查实际运行在容器中的OpenStack服务进程的状态来进行更详细的监控。这将类似于OpenStack网站上发布的一些方法，http://docs.openstack.org/ops-guide/operations.html。主要区别在于我们将使用Ansible根据需要在所有容器或节点上执行命令。使用基本的Ansible程序和之前提到的OpenStack服务进程表，您将能够检查在您的云中运行的OpenStack进程的状态。以下是一些可以实现这一目标的示例。建议获取云的动态清单的完整输出，这样您将了解所有定义的组。使用以下命令获取完整的清单输出（此命令假定您在root
    OSA部署目录中）：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Save the JSON output at some place where you can reference it in the future.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将JSON输出保存在将来可以引用的地方。
- en: Service and process check examples
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务和进程检查示例
- en: 'The following examples show that how you can execute service and process monitor
    checks using Ansible:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例显示了如何使用Ansible执行服务和进程监视检查：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can use any of these examples to determine the health of your OpenStack
    services on a cloud of any size, big or small. Imagine that the power of being
    able to query the `nova-compute` service status across a cloud with 200 nodes
    in one command. Good stuff right? Well, of course, we have to try to take it to
    the next level by incorporating more advance monitoring tools into the mix to
    create a more robust solution.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这些示例中的任何一个来确定任何大小的云上OpenStack服务的健康状况，无论是大还是小。想象一下，能够在一个命令中查询跨200个节点的云中的`nova-compute`服务状态的能力。很棒，对吧？当然，我们必须尝试将其提升到下一个级别，通过将更多先进的监控工具整合到一起，以创建更强大的解决方案。
- en: Setting up Nagios and import checks
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Nagios并导入检查
- en: Reflecting back to the first principle mentioned previously concerning monitoring,
    keep it simple. It felt like we could not keep it any simpler than going with
    one of the leading open source monitoring platforms, Nagios Core. If you are unfamiliar
    with Nagios, take a moment to read up on it by visiting [http://www.nagios.com/products](http://www.nagios.com/products).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾之前提到的关于监控的第一个原则，保持简单。感觉我们无法比选择一种领先的开源监控平台Nagios Core更简单了。如果您对Nagios不熟悉，请花点时间阅读一下[http://www.nagios.com/products](http://www.nagios.com/products)。
- en: Yes, yes, while it may not be the flashiest dashboard visually, it is one of
    the most powerful and lightweight monitoring applications I have used. With Nagios,
    you have ultimate control on many aspects of your monitoring ecosystem. It ranges
    from being able to create custom plugins, all the way to explicitly defining execution
    windows for that host. Administration can be handled directly from the flat files,
    or you can use many of the third-party tools, such as **NConf** at [http://exchange.nagios.org/directory/Addons/Configuration/NConf/details](http://exchange.nagios.org/directory/Addons/Configuration/NConf/details).
    With the launch of the new version, XI, more and more of the features only found
    in the third-party tools are built right in. Some of the new features that stand
    out are the advanced graphs, integration into Incident management tools, and cleaner
    SLA reports.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，虽然它在视觉上可能不是最引人注目的仪表板，但它是我使用过的最强大和轻量级的监控应用之一。使用Nagios，您可以对监控生态系统的许多方面进行最终控制。它可以从能够创建自定义插件一直到明确定义执行窗口为主机。管理可以直接从平面文件中处理，或者您可以使用许多第三方工具，例如**NConf**在[http://exchange.nagios.org/directory/Addons/Configuration/NConf/details](http://exchange.nagios.org/directory/Addons/Configuration/NConf/details)。随着新版本XI的推出，越来越多的仅在第三方工具中找到的功能已经内置。一些突出的新功能包括高级图表、集成到事件管理工具以及更清晰的SLA报告。
- en: Collect your metrics via SNMP
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过SNMP收集您的指标
- en: Of course, with great capability sometimes comes great overhead. Typically,
    I have found that keeping your monitoring close to your infrastructure avoids
    limiting what you are monitoring due to firewall restrictions and so on. It is
    strongly recommend to use SNMP (UDP port `161`), rather than the NRPE agent, no
    agent installation is needed. As well as, I normally stick with Perl-written plugins
    to ease troubleshooting. Creating good'monitors is essential to minimize false
    alerts, which in time turn into ignored alerts. If you find a service check continuously
    sending off false alerts, FIX IT! Do not let it linger for days.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，伴随着强大的功能有时会带来巨大的开销。通常，我发现将监控保持在基础设施附近可以避免由于防火墙限制等原因而限制监控的内容。强烈建议使用SNMP（UDP端口`161`），而不是NRPE代理，无需安装代理。此外，我通常坚持使用Perl编写的插件来简化故障排除。创建良好的监视器对于最小化错误警报至关重要，而这些错误警报最终会变成被忽略的警报。如果发现某个服务检查持续发送错误警报，请修复它！不要让它持续几天。
- en: Because of the power behind OpenStack exposing all functionality through APIs,
    monitoring is made easy. Custom plugin scripts can be created to monitor the whole
    OpenStack stack and cross-reference any bottlenecks to physical infrastructure
    problems. This type of proactive monitoring can lead to preventing down time leading
    to outages.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OpenStack通过API公开了所有功能，因此监控变得很容易。可以创建自定义插件脚本来监视整个OpenStack堆栈，并交叉参考任何瓶颈到物理基础设施问题。这种积极的监控可以导致防止停机导致的故障。
- en: Since I have such a deep seeded love for OSA, it seemed only fitting to put
    together a series of Ansible playbooks to handle most of the Nagios and NConf
    setup. Also, because I love to pay it forward, included are OSA customized Nagios
    configs (`checkcommands`, services and a bunch of global Nagios configs) which
    can be used to monitor your OpenStack cloud within minutes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我对OSA有着深厚的热爱，因此将一系列Ansible playbooks组合起来处理大部分Nagios和NConf的设置似乎是再合适不过的了。此外，因为我喜欢回馈，还包括了OSA定制的Nagios配置（`checkcommands`、服务和一堆全局Nagios配置），可以在几分钟内用来监视您的OpenStack云。
- en: Coding the playbooks and roles
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写playbooks和roles
- en: In this section, we will now use all of that Ansible magic to create a series
    of playbooks and roles to set up Nagios to monitor your OpenStack cloud. Once
    completed, you will have a fully functioning Nagios installation that will be
    customized to monitor OpenStack with some of the monitoring checks we reviewed
    in the previous section. This time around we broken up the tasks into eight roles
    in order to keep things simple. Let's review each role in the later .
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将利用所有这些Ansible魔法来创建一系列playbooks和roles，以设置Nagios来监视您的OpenStack云。完成后，您将拥有一个完全运行的Nagios安装，该安装将被定制为使用我们在上一节中审查的一些监控检查来监视OpenStack。这一次，我们将任务分解为八个角色，以保持简单。让我们在后面审查每个角色。
- en: snmp-config
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: snmp-config
- en: 'The first role we will create will include those tasks needed to set up the
    foundation for collecting the monitoring data. The name of the file will be `main.yml`
    located within the `role` directory named `snmp-config/tasks`. The contents of
    this file will look like this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建的第一个角色将包括设置收集监控数据的基础所需的任务。该文件的名称将是`main.yml`，位于名为`snmp-config/tasks`的`role`目录中。该文件的内容将如下所示：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first four tasks are simply handling the steps needed to install and configure
    SNMP on each host you will be monitoring. This will include installing the `snmp`
    package, copying the custom config file into place, and editing the SNMP options.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前四个任务只是处理安装和配置每个要监视的主机上所需的步骤。这将包括安装`snmp`软件包，复制自定义配置文件到指定位置，并编辑SNMP选项。
- en: 'The task handling the custom `snmp.conf` will use a `template` file stored
    in the `snmp-config/templates` directory of this role. The reason for this is
    so we can leverage the variables defined in your playbook already instead of hard
    coding parameters. The contents of the file will look like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 处理自定义`snmp.conf`的任务将使用存储在此角色的`snmp-config/templates`目录中的`template`文件。这样做的原因是为了利用已在您的playbook中定义的变量，而不是硬编码参数。文件的内容将如下所示：
- en: '[PRE10]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: install-nagios
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: install-nagios
- en: 'The next role will focus on installing Nagios and its prerequisites. The file
    will be named `main.yml` located within the `role` directory named `install-nagios/tasks`.
    The contents of this file will look like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个角色将专注于安装Nagios及其先决条件。该文件将被命名为`main.yml`，位于名为`install-nagios/tasks`的`role`目录中。该文件的内容将如下所示：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This role is pretty straightforward in stepping through the tasks needed to
    perform a clean installation of Nagios. Since we will be monitoring Ubuntu systems,
    the last two tasks in this role were included for install the Ubuntu logo into
    Nagios.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个角色在执行Nagios的清洁安装所需的任务时非常直接。由于我们将监控Ubuntu系统，因此在这个角色中的最后两个任务是为了将Ubuntu标志安装到Nagios中。
- en: nagios-plugins
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: nagios-plugins
- en: 'This role will be responsible for installing our custom Nagios plugins that
    we will use to monitor our cloud. The file will be named `main.yml` within the
    `role` directory named `nagios-plugins/tasks`. Here, you will find these contents:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个角色将负责安装我们自定义的Nagios插件，我们将使用它来监视我们的云。文件将被命名为`main.yml`，位于名为`nagios-plugins/tasks`的`role`目录中。在这里，你会找到这些内容：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The preceding role copies and sets up two very important files (`nagios-plugins.tar`
    and `NagiosConfig.zip`) on the Nagios server. Without these plugins and configurations,
    you will just have a plain vanilla Nagios installation. By running this role,
    you basically are getting a preconfigured Nagios setup ready to monitor an OpenStack
    cloud deployed with OSA. With this model, you can also customize the plugins or
    specific configurations being attached to the Nagios server. If you are feeling
    curious, feel free to crack open these archives and take a look.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的角色在Nagios服务器上复制并设置了两个非常重要的文件（`nagios-plugins.tar`和`NagiosConfig.zip`）。如果没有这些插件和配置，你将只有一个普通的Nagios安装。通过运行这个角色，你基本上得到了一个预配置的Nagios设置，可以监控使用OSA部署的OpenStack云。在这个模型中，你也可以自定义附加到Nagios服务器的插件或特定配置。如果你感到好奇，可以打开这些存档文件查看一下。
- en: install-nconf
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: install-nconf
- en: 'This role could technically be considered optional, as you do not need NConf
    to run a Nagios server. I personally have found NConf to be a great compliment
    to Nagios as far as configuring your service checks and hosts. The file will be
    named `main.yml` within the `role` directory named `install-nconf/tasks`. Here
    are the contents of this file:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个角色在技术上可以被认为是可选的，因为你不需要NConf来运行Nagios服务器。我个人发现NConf在配置服务检查和主机方面是Nagios的一个很好的补充。文件将被命名为`main.yml`，位于名为`install-nconf/tasks`的`role`目录中。以下是该文件的内容：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Very similar to the role that handles installing Nagios, it covers the required
    steps to install and configure NConf. More details on how to install NConf can
    be found at [http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:documentation:start:installation](http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:documentation:start:installation).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与处理安装Nagios的角色非常相似，它涵盖了安装和配置NConf所需的步骤。有关如何安装NConf的更多详细信息，请访问[http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:documentation:start:installation](http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:documentation:start:installation)。
- en: nconf-post-install
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: nconf-post-install
- en: 'Consider this role a follow-up to the previous one as it handles the post-install
    steps for the NConf installation. It will handle the cleanup of specific files
    once the install has completed. The file will be named `main.yml` within the `role`
    directory named `nconf-post-install/tasks`. Here are the contents of this file:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个角色视为前一个角色的后续，因为它处理了NConf安装的后续步骤。它将在安装完成后处理特定文件的清理工作。文件将被命名为`main.yml`，位于名为`nconf-post-install/tasks`的`role`目录中。以下是该文件的内容：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The next two roles are intended to prepare the controller nodes to monitor the
    OpenStack processes and API's running on the local containers. You must be able
    to run the service checks remotely over SSH. The good news is that the Nagios
    plugin to do this already exists (`check_by_ssh`).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两个角色旨在准备控制节点监视本地容器上运行的OpenStack进程和API。你必须能够通过SSH远程运行服务检查。好消息是，已经存在Nagios插件来做到这一点（`check_by_ssh`）。
- en: create-nagios-user
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: create-nagios-user
- en: 'The name of this role basically explains exactly what tasks it will handle.
    It will create a user named Nagios, and this user will serve as a service account
    for the Nagios plugin. The file will be named `main.yml` within the `role` directory
    named `create-nagios-user/tasks`. Here are the contents of this file:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个角色的名称基本上解释了它将处理的任务。它将创建一个名为Nagios的用户，这个用户将作为Nagios插件的服务账户。文件将被命名为`main.yml`，位于名为`create-nagios-user/tasks`的`role`目录中。以下是该文件的内容：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: infra-plugin-config
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: infra-plugin-config
- en: 'This role will install additional SNMP package prerequisites and install local
    Nagios plugins directly on the controller node. Via SSH, Nagios will execute these
    local plugins and report the status back to Nagios to record. This is where you
    have to say that you just love technology. The file will be named `main.yml` within
    the `role` directory named `infra-plugin-config/tasks`. Here are the contents
    of this file:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个角色将安装额外的SNMP软件包前提条件，并直接在控制节点上安装本地Nagios插件。通过SSH，Nagios将执行这些本地插件，并将状态报告回Nagios进行记录。这就是你必须说你只是喜欢技术的地方。文件将被命名为`main.yml`，位于名为`infra-plugin-config/tasks`的`role`目录中。以下是该文件的内容：
- en: '[PRE16]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: nagios-post-install
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: nagios-post-install
- en: 'Last and certainly not least is the final role that makes up this series. The
    final role will complete the Nagios configuration and set up NConf to work with
    your Nagios installation. The file will be named `main.yml` within the `role`
    directory named `nagios-post-install/tasks`. Here are the contents of this file:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但肯定不是最不重要的是组成这个系列的最后一个角色。最后一个角色将完成Nagios配置，并设置NConf与你的Nagios安装一起工作。文件将被命名为`main.yml`，位于名为`nagios-post-install/tasks`的`role`目录中。以下是该文件的内容：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To support these roles, we now need to create the variable files that will go
    along with it. Since we will use three separate hosts to execute the series of
    roles against, there will be three global variable files needed. The file names
    are `hosts`, `all_containers`, and `nagios-server`; they will be saved to the
    `group_vars/` directory of the playbook.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持这些角色，我们现在需要创建与之配套的变量文件。由于我们将使用三个单独的主机来执行一系列角色，因此需要三个全局变量文件。文件名分别为`hosts`、`all_containers`和`nagios-server`；它们将保存在playbook的`group_vars/`目录中。
- en: Tip
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Keep in mind that the values defined in the variable file are intended to be
    changed before each execution for normal everyday use.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，变量文件中定义的值是为了在正常的日常使用中在每次执行前进行更改的。
- en: 'There are a bunch of new variables added in this chapter. Let''s take a moment
    to review the contents of each variable file:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中添加了许多新变量。让我们花点时间来审查每个变量文件的内容：
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s take a moment to break down the new variables. The summary is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间来分解新的变量。总结如下：
- en: '[PRE19]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since there are two global variable files that share the same variable names,
    please make sure to keep the variable value in sync if you want both reports in
    the same directory.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有两个共享相同变量名称的全局变量文件，请确保如果您希望两个报告在同一个目录中，则保持变量值同步。
- en: 'With the variable file completed, we can move on to creating the master playbook
    file. Since there will be manual configurations that need to be taken care of
    inbetween the playbooks to be run, the master playbook was broken up into multiple
    playbooks. The contents of the first playbook named `base.yml` will look like
    this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 完成变量文件后，我们可以继续创建主playbook文件。由于在运行playbook之间需要进行手动配置，主playbook被分成了多个playbook。第一个名为`base.yml`的playbook的内容如下：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The next playbook is named `base-nagios.yml`, and the contents will look like
    this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个playbook的名称为`base-nagios.yml`，内容如下：
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following playbook is named `base-nconf.yml`, and the contents will look
    like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下playbook的名称为`base-nconf.yml`，内容如下：
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The next playbook is named `post-nconf-install.yml`, and the contents will
    look like this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个playbook的名称为`post-nconf-install.yml`，内容如下：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The next playbook is named `base-infra.yml`, and the contents will look like
    this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个playbook的名称为`base-infra.yml`，内容如下：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The next playbook is named `post-nagios-install.yml`, and the contents will
    look like this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个playbook的名称为`post-nagios-install.yml`，内容如下：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The playbook and role names can be anything you choose. Specific names have
    been provided here in order to allow you to easily follow along and reference
    the completed code found in the GitHub repository. The only warning is that whatever
    you decide to name the roles must remain uniform when referenced from within the
    playbook(s).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: playbook和role的名称可以是您选择的任何内容。这里提供了具体的名称，以便您可以轻松地跟踪并引用GitHub存储库中找到的完成代码。唯一的警告是，无论您决定如何命名角色，都必须在playbook中引用时保持统一。
- en: 'Our inventory file for these playbooks and roles turns out to be a very simple
    one. Inside the inventory file, we will only have to define the address of the
    Nagios server. An example of this is shown as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的playbooks和roles的清单文件非常简单。在清单文件中，我们只需要定义Nagios服务器的地址。示例如下：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: I hope that you are happy with how it all came out. In keeping with our tradition,
    we will finish up the chapter with a quick review of the playbooks and roles just
    created with a little added extra instructions included.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您对所有的工作都感到满意。按照我们的传统，我们将以快速审查刚刚创建的playbooks和roles结束本章，并包含一些额外的指示。
- en: Reviewing playbook and role
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查playbook和role
- en: Let's jump right into examining the roles we created.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们立即开始检查我们创建的角色。
- en: 'The completed role and file named `main.yml` located in the `snmp-config/tasks`
    directory looks like this:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`snmp-config/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The completed role and file named `main.yml` located in the `install-nagios/tasks`
    directory looks like this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`install-nagios/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE28]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The completed role and file named `main.yml` located in the `nagios-plugins/tasks`
    directory looks like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`nagios-plugins/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The completed role and file named `main.yml` located in the `install-nconf/tasks`
    directory looks like this:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`install-nconf/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The completed role and file named `main.yml` located in the `nconf-post-install/tasks`
    directory looks like this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`nconf-post-install/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The completed role and file named `main.yml` located in the `create-nagios-user/tasks`
    directory looks like this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`create-nagios-user/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The completed role and file named `main.yml` located in the `infra-plugin-config/tasks`
    directory looks like this:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`infra-plugin-config/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE33]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The completed role and file named `main.yml` located in the `nagios-post-install/tasks`
    directory looks like this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 位于`nagios-post-install/tasks`目录中的完成角色和文件名为`main.yml`的文件如下：
- en: '[PRE34]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The corresponding global variable file is named `all_containers` and is saved
    to the `group_vars/` directory of the complete playbook:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的全局变量文件名为`all_containers`，保存在完整playbook的`group_vars/`目录中：
- en: '[PRE35]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The corresponding global variable file is named `hosts` and is saved to the
    `group_vars/` directory of the complete playbook:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的全局变量文件名为`hosts`，保存在完整playbook的`group_vars/`目录中：
- en: '[PRE36]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The corresponding global variable file is named `nagios-server` and is saved
    to the `group_vars/` directory of the complete playbook:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的全局变量文件名为`nagios-server`，保存在完整playbook的`group_vars/`目录中：
- en: '[PRE37]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now the master playbook file has been created and will be located in the `root`
    directory of the `playbook` directory:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在主playbook文件已经创建，并位于`playbook`目录的`root`目录中：
- en: '`base.yml`'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base.yml`'
- en: '[PRE38]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`base-nagios.yml`'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base-nagios.yml`'
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`base-nconf.yml`'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base-nconf.yml`'
- en: '[PRE40]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`post-nconf-install.yml`'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`post-nconf-install.yml`'
- en: '[PRE41]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`base-infra.yml`'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base-infra.yml`'
- en: '[PRE42]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`post-nagios-install.yml`'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`post-nagios-install.yml`'
- en: '[PRE43]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Finally, in the end, we have created the `hosts` file, which also is located
    in the `root` directory of the `playbook` directory:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建了`hosts`文件，也位于`playbook`目录的`root`目录中：
- en: '[PRE44]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The complete set of code can again be found in the following GitHub repository
    at `https://github.com/os-admin-with-ansible/os-admin-with-ansible-v2/tree/master/nagios-openstack`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码集可以在以下GitHub存储库中再次找到：`https://github.com/os-admin-with-ansible/os-admin-with-ansible-v2/tree/master/nagios-openstack`。
- en: 'Before we finish up this topic, we of course need to test out our work and
    add in some additional instructions to complete the Nagios setup. At the end of
    running these playbooks and roles, you will have a powerful monitoring machine
    for your OpenStack clouds and other applications. Assuming that you have cloned
    the GitHub repository earlier, the command to test out the playbook from the Deployment
    node will be as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成本主题之前，我们当然需要测试我们的工作，并添加一些额外的说明来完成Nagios设置。在运行这些playbooks和roles之后，您将拥有一个功能强大的监视机器，用于监视您的OpenStack云和其他应用程序。假设您之前已经克隆了GitHub存储库，从部署节点测试playbook的命令如下：
- en: Move the playbooks and roles into the OSA deployment directory.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将playbooks和roles移动到OSA部署目录中。
- en: In order to leverage the dynamic inventory capabilities that  come with OSA,
    the playbooks and roles need to be local to  the  deployment directory. Trust
    me you will like this!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用OSA提供的动态清单功能，playbooks和roles需要在部署目录中。相信我，你会喜欢这个！
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Execute the following playbook to install and configure SNMP on your OSA cloud:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下playbook来安装和配置OSA云上的SNMP：
- en: '[PRE46]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Tip
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'If the SNMP service does not start the first time, please execute the following
    commands:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果SNMP服务第一次启动失败，请执行以下命令：
- en: '[PRE47]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Execute the following playbook to install and configure Nagios onto your monitoring
    server:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下playbook来在监视服务器上安装和配置Nagios：
- en: '[PRE48]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then connect to the monitoring server via SSH to execute the following commands
    to set  the *nagiosadmin* user password (used to log in to Nagios web dashboard)
    and restart Nagios:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过SSH连接到监视服务器，执行以下命令来设置*nagiosadmin*用户密码（用于登录Nagios Web仪表板）并重新启动Nagios：
- en: '[PRE49]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Execute the following playbook to install and configure NConf onto your monitoring
    server:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下playbook来在监视服务器上安装和配置NConf：
- en: '[PRE50]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '**NConf initial configuration**: My attempt to automate this part was not successful,
    so you have to finish the NConf configuration using the NConf web console. Browse
    `http://<monitoring server IP>/nconf` and follow the prompts to complete the initial
    configuration. Here are the suggested inputs and keep the defaults for the others:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**NConf初始配置**：我尝试自动化这部分工作并不成功，所以您必须使用NConf Web控制台完成NConf配置。浏览`http://<monitoring
    server IP>/nconf`并按照提示完成初始配置。以下是建议的输入，并保留其他默认设置：'
- en: '[PRE51]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '**Execute the post NConf playbook**:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**执行后NConf playbook**：'
- en: '[PRE52]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Execute the following playbook to configure the OSA nodes to allow for monitoring
    via SSH:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下playbook来配置OSA节点以允许通过SSH进行监视：
- en: 'In order to monitor the OpenStack processes and APIs running on the local containers,
    you must run the service checks remotely over SSH. The good news is that the Nagios
    plugin to do this already exists (`check_by_ssh`):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为了监视运行在本地容器上的OpenStack进程和API，您必须通过SSH远程运行服务检查。好消息是，Nagios插件已经存在（`check_by_ssh`）：
- en: '[PRE53]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Confirm the Nagios and NConf installation: in a browser, go to the following
    URLs:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认Nagios和NConf的安装：在浏览器中，转到以下URL：
- en: '`http://<monitoring server IP>/nagios3`'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`http://<monitoring server IP>/nagios3`'
- en: '`http://<monitoring server IP>/nconf`'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`http://<monitoring server IP>/nconf`'
- en: Time to configure Nagios for monitoring OSA.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候为监视OSA配置Nagios了。
- en: Unfortunately, this part does require manual configuration as each installation
    will differ too much to automate. In the big picture, this will just help you
    sharpen your Nagios skills. Do not worry; a copy of the Nagios directory was already
    taken. This step will take some time and should not be rushed.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这部分需要手动配置，因为每个安装的差异太大，无法自动化。从宏观上看，这只会帮助您提高Nagios技能。不用担心；Nagios目录的副本已经被保存。这一步需要一些时间，不应该被匆忙完成。
- en: The first step here is to customize the Nagios configuration files located in
    the `/etc/nagios3/rpc-nagios-configs` directory on your monitoring server. All
    the configuration files are important, but the most critical ones are the `advanced_services.cfg`
    and `hosts.cfg` files.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是自定义位于监视服务器上`/etc/nagios3/rpc-nagios-configs`目录中的Nagios配置文件。所有配置文件都很重要，但最关键的是`advanced_services.cfg`和`hosts.cfg`文件。
- en: 'Within the `advanced_services.cfg` file, you will need to update each service
    check with the IP addresses of the containers within your OSA install. The fastest
    way to get that information is to execute the following command and capture the
    output on each infrastructure node: `lxc-ls --fancy`. Here is an example:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在`advanced_services.cfg`文件中，您需要更新每个服务检查的IP地址，以便与OSA安装中的容器的IP地址匹配。获取信息的最快方法是执行以下命令，并在每个基础设施节点上捕获输出：`lxc-ls
    --fancy`。这是一个例子：
- en: '[PRE54]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The same goes for the `hosts.cfg` file; please update the OSA node names and
    IP addresses:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`hosts.cfg`文件也是一样；请更新OSA节点的名称和IP地址：'
- en: '[PRE55]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Please also add the following to the bottom of the `resources.cfg` file located
    in the root of the Nagios directory (`/etc/nagios3`):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要将以下内容添加到Nagios目录根目录（`/etc/nagios3`）中的`resources.cfg`文件的底部：
- en: '[PRE56]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: If you are having trouble making the updates to the configurations using an
    editor, do not stress out as the next step will make this process a bit easier.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在使用编辑器进行配置更新时遇到问题，请不要感到紧张，因为下一步将使这个过程变得更容易。
- en: Import Nagios configuration into NConf
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Nagios配置导入NConf
- en: Next appended the contents of the configuration files in the `/etc/nagios3/rpc-nagios-configs`
    directory to the current Nagios configuration files (add to bottom). Every host,
    host group, check, service, and contact group is uniquely named so as not to conflict
    with the current Nagios setup. Then, we will step through the instructions found
    on the NConf website, [http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:how_tos:import:import_nagios](http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:how_tos:import:import_nagios).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将`/etc/nagios3/rpc-nagios-configs`目录中配置文件的内容附加到当前Nagios配置文件的底部。每个主机、主机组、检查、服务和联系组都有唯一的名称，以避免与当前Nagios设置冲突。然后，我们将按照NConf网站上的说明进行操作，[http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:how_tos:import:import_nagios](http://www.nconf.org/dokuwiki/doku.php?id=nconf:help:how_tos:import:import_nagios)。
- en: 'As the NConf tutorial suggests, first run the commands with the `-s` parameters
    to simulate the import process first. After being able to run with no errors,
    remove the `-s` parameter to do the final import. Having connected to the monitoring
    server via SSH, run the following commands:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 正如NConf教程建议的那样，首先使用`-s`参数运行命令来模拟导入过程。在能够无错误运行后，删除`-s`参数进行最终导入。通过SSH连接到监控服务器后，运行以下命令：
- en: '[PRE57]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Now you can edit all the Nagios configurationss within the NConf web console.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以在NConf Web控制台中编辑所有Nagios配置。
- en: 'Execute the post Nagios playbook:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行后续的Nagios playbook：
- en: '[PRE58]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Generate your first Nagios config
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成你的第一个Nagios配置
- en: Once you are satisfied with all of your custom Nagios configurations (trust
    me that you will do this a couple of times), click on the **Generate Nagios config**
    link on the sidebar of the NConf web console. It will note if any errors were
    encountered. From time to time, you will see warnings, and they are just warnings,
    nothing urgent.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您对所有自定义的Nagios配置感到满意（相信我，您会做几次这样的事情），请点击NConf Web控制台侧边栏上的**生成Nagios配置**链接。它会提示是否遇到任何错误。有时，您会看到警告，它们只是警告，没有什么紧急的。
- en: 'Last but not the least, from the monitoring server, execute the following command
    to deploy the Nagios configurations to Nagios (may need to use `sudo`):'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，从监控服务器执行以下命令将Nagios配置部署到Nagios（可能需要使用`sudo`）：
- en: '[PRE59]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Having a rock solid monitor platform on your side is the key to cloud success
    (actually any production  systems success). Remember that this is only a starting
    point. I expect you to improve/customize it for your specific needs. I am looking
    forward to seeing all your great work in the future. Please make sure to share
    any changes you make, remember Open Source is all about sharing. Before wrapping
    up this final chapter, let's take a moment to recap what we discussed. First we
    covered some monitoring tips and tricks. Then examined the OpenStack components
    worth monitoring. Next, we learned how to use Ansible ad hoc commands. We then
    transitioned into how to set up Nagios and import the custom plugins for the service
    checks. Finally, we developed Ansible playbooks and roles to automate the base
    installation of Nagios and NConf with customizing it to completely monitor an
    OpenStack cloud.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个坚如磐石的监控平台是云成功的关键（实际上是任何生产系统的成功）。请记住，这只是一个起点。我期待您根据自己的特定需求进行改进/定制。我期待在未来看到您的出色工作。请确保分享您所做的任何更改，记住开源就是分享。在结束这最后一章之前，让我们花点时间回顾一下我们讨论过的内容。首先，我们介绍了一些监控技巧和诀窍。然后，我们研究了值得监控的OpenStack组件。接下来，我们学习了如何使用Ansible的临时命令。然后，我们转入如何设置Nagios并导入用于服务检查的自定义插件。最后，我们开发了Ansible
    playbook和role来自动化Nagios和NConf的基本安装，并对其进行定制，以完全监控OpenStack云。
- en: Well ladies and gentleman, this has been fun and honestly a privilege to be
    allowed to share these automation examples with you for the second time around.
    Please keep up the great work and also keep an eye out for future revisions as
    both OpenStack and Ansible continues to mature. I am really looking forward to
    hearing your feedback and seeing how you took these examples to the next level.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 女士们先生们，这真的很有趣，也很荣幸能够第二次与您分享这些自动化示例。请继续保持良好的工作，并密切关注未来的修订，因为OpenStack和Ansible都在不断成熟。我真的很期待听到您的反馈，并看到您如何将这些示例提升到下一个水平。
