["```\n---\n- hosts: servers\n  become: yes\n  gather_facts: false\n  tasks:\n    - apt: update_cache=yes\n    - apt:\n       name: mc\n    - file:\n       path: /usr/local/projects\n       mode: 1777\n       state: directory\n```", "```\n---\n- name: Setup users projects workspace with a file manager\n  hosts: servers\n  become: yes\n  gather_facts: false\n  tasks:\n    - name: Update Package manager repo index\n      apt: update_cache=yes\n    - name: Install Midnight commander as a terminal file manager\n      apt:\n       name: mc\n    - name: Create the projects workspace folder with sticky bit\n      file:\n       path: /usr/local/projects\n       mode: 1777\n       state: directory\n```", "```\n- name: Copy user configuration\ncopy: src=/home/admin/setup.conf dest=/usr/local/projects/ owner=setup group=dev mode=0677 backup=yes\n```", "```\n - name: Copy user configuration\ncopy: \nsrc: /home/admin/setup.conf\ndest: /usr/local/projects/\nowner: setup\ngroup: dev\nmode: 0677\nbackup: yes\n```", "```\n   - name: Fill in sample text file\n     lineinfile:\n       path: /usr/local/projects/setup.conf\n       line: >\n            This is the configuration file for the user\n            Setup. Please do not edit make any change \n            to it if you are not and administrator.\n```", "```\n---\n- name: Organize users projects folders\n  hosts: servers\n  become: yes\n  remote_user: setup\n  gather_facts: false\n  tasks:\n    - name: create folder for user1\n      command: mkdir /usr/local/projects/user1\n       become_user: user1\n\n   - name: Create test space for setup\n      file:\n       path: /usr/local/projects/setup/test\n       mode: 1777\n       state: directory\n---\n```", "```\n/etc/ansible/hosts:\n[linuxservers:children]\nwebservers\nloadbalancers\n\n[linuxservers:vars]\nremote_user: setup\nntpserver: 0.uk.pool.ntp.org\nbecome: yes\n\n[webservers]\nnode0\nnode1\nnode2\n\n[webservers:vars]\nremote_user: devadmin\nansible_connection: ssh\n\n[loadbalancers]\nnode3\nnode4\n\n[loadbalancers:vars]\nntpserver: 0.us.pool.ntp.org\nansible_connection: docker\n```", "```\n---\n- name: Change service settings and apply it\n  hosts: servers\n  become: yes\n  remote_user: setup\n  gather_facts: false\n  tasks:\n    - name: Flush the playbook handlers\n      meta: flush_handlers\n\n    - name: Change ntp service config\n      lineinfile:\n       path: /etc/ntp.conf\n       line: \"server 0.us.pool.ntp.org\"\n\n    - name: Flush the playbook handlers\n      meta: flush_handlers\n\n  handlers:\n    - name: restart ntp service\n      service:\n       name: ntp\n       state: restarted\n```", "```\n---\n- name: usage of sensative variable\n  hosts: servers\n  include: passwords_playbook.yml\n  tasks:\n    - name: add a MySQL user\n      mysql_user:\n        name: user1\n        password: {{ mysql_user1_password }}\n        priv: '*.*:ALL'\n        state: present \n```", "```\n\nThis method is very easy to use and manage, but it is not the best in terms of security. Ansible Vault will provide better protection for sensitive information in playbooks.\n\nAnsible Vault is not the only tool that allows you to secure variables in Ansible. There are other third-party tools that allow you to secure passwords and critical information by preventing them from being typed as clear text.\n\n# Playbook version control\n\nIt is highly recommended to use a version control service, such as GitHub, SubVersion, or Mercurial,\u00a0to manage your Ansible playbooks. Besides the countless benefits of using version control for any coding, Ansible playbooks can use GitHub projects as an input to enable frameworks that allow continuous deployment and integration. By updating your code in the repository, it gets updated on all the systems it is used in.\n\n# Making Ansible roles where possible\n\nThe best way to optimize a task is to make it an Ansible role, or preferably multiple roles if it has multiple goals. A task that has been transformed into a role is\u00a0ready to be used with multiple situations, and it can be shared to be used by other users. Roles can be included in multiple playbooks to avoid writing the same lines of code twice or more. Ansible has a role-sharing platform called Galaxy, where the community shares their roles with other users. We will cover this in more detail in the next chapter.\n\n# Ansible coding best practices\n\nAfter exploring the standards that should be followed by Ansible developers, let's now have a look at what Ansible daily users recommend as best practice for good configuration management using Ansible.\n\nThese methods may suit some setups more than others. Not every method is a good option for your environment; they may cause more trouble than benefits if they are applied inappropriately. We have collected the methods that we believe are common and useful most of the time.\n\n# Using comments in playbooks\n\nEarlier in this chapter, we discussed naming plays or tasks in the playbook to provide a better description for the reader. However, when performing unusual tasks or running commands that form part of a bigger picture, having a descriptive name is not always enough information.\n\nYou can use comments either at the start of each playbook, explaining its overall role, or in the pipelines included within the playbook. You can also offer some information about the author, including contact details when the playbook gets shared within the community. Having comments in the code you write is a good idea for any coding you do, especially if you are planning to share it. It makes any script user-friendly. Even though YAML is an easy coding language, it is not always obvious when reading the work of others. This example playbook shows a way to get more detailed information about a playbook:\n\n```", "```\n\n# Playbook files and folder naming\n\nThis is a best practice that should be followed in life, not just for scripting and playbooks! Whenever you create a file in your computer, on the cloud, or within an application, always make sure to give it a name that reveals what it is. You can also organize your files into subfolders with descriptive names. Although it might take longer for a user to navigate through the folders to get to the playbook, everything will be well explained and clear.\n\n# Avoiding the use of command modules\n\nAnsible offers a few modules that allow you to run commands to be executed as they are in the remote hosts. This is handy when the Ansible modules do not cover the task that is intended to be performed, which is especially the case when there are complex tasks.\n\nThe issue with command modules is that they do not know whether the task has been properly executed\u00a0since they can execute any command running\u00a0any tool, service, and system. The return values for a command can easily be misunderstood and sometimes do not reflect what really happened after the command execution. It is recommended that you use the\u00a0`changed_when`\u00a0option in the task in the playbook, so it looks as follows:\n\n```", "```\n\nThere are multiple methods for collecting command changes; this is one of the ones that was\u00a0most recommended in the community. File and service status modules can be used to check changes in the data via tasks or handlers, but these may cause extra tasks to be sent to the remote hosts.\n\n# Avoiding ignoring module errors\n\nAnsible offers the option of ignoring some task errors when they are reported.\u00a0This is because Ansible by default halts a playbook if one of its tasks has failed. Sometimes, if a task is used to execute an optional job or to test a particular aspect of the system, the task isn't important enough to cause the entire playbook to halt. We tend to add the\u00a0`ignore_errors: yes`\u00a0option at the end of these tasks, but this\u00a0is a very bad habit that may cause damage to your hosts, especially in pipelined tasks.\n\nThe best way to deal with optional tasks or those that return an error even when they have executed what is needed is to use the `failed_when` and `changed_when` options to define when a task has failed or performed its job.\n\n# Using Ansible conditions\n\nWe can use the information collected by Ansible about the hosts it manages to personalize tasks to a specific system using Ansible conditions. Not all modules work with every OS. To make a playbook universal, we can add in some settings where some tasks test the facts of the remote host before executing the task. This also helps with reducing the number of playbook scripts by creating scripts that adapt themselves to the system that they are being executed on. As an example, let's try to install the same package with two different names in Debian and Red Hat Linux OS:\n\n```", "```\n\n# Using Ansible loops\n\nAnsible loops offer several possibilities. One of the most common uses is to reduce the amount of code when running the same module multiple times on different inputs. The idea is to define a variable or an object variable that has its own variables, then populate the list with the different entries.\n\nThe following playbook shows a good use of Ansible loops to copy several configuration files with different sources, destinations, and ACL settings:\n\n```", "```\n\nThe default\u00a0option takes cares of empty entries by replacing them with what has been entered as the default value.\n\n# Using template files\n\nIt is recommended that you use modules that edit configuration files, such as\u00a0`lineinfile` or\u00a0`blockinfile`. These can help significantly with setting up standard configurations or updating old settings.\u00a0However, when these files are automated, they cannot handle the small changes that can be identified easily when modifying manually, leading to unpredictable\u00a0changes. There is no simple way of telling whether a configuration change will go as expected, especially for a large infrastructure.\u00a0For this reason, it is recommended to use template files to act as base configuration files, scripts, or web pages. Still, we can use `lineinfile` or `blockinfile` as a backup plan. In these, the user knows exactly what to\u00a0set up, what to edit, and what to leave for each host. This method helps to control the unpredictability of tasks.\n\nUsing the `template`\u00a0module, we can generate configuration files that are specific to the hosts from a `Jinja` file. The example `.j2` template file gets filled in with predefined variables, as follows:\n\n```", "```\n\nThese variables can then be defined in the same playbook or another YAML file, included at the play level:\n\n```", "```\n\nThe `Jinja2` files offer a level of control over the variable structure. You can introduce loops and conditional statements with some predefined functions to alter the input to match the structure of the configuration file input.\n\n# Stating task status\n\nWhen creating files, setting up configuration, or managing services, an Ansible user should always state the status of the object of the task, even when the change is aimed at its default value. Even though this will add an extra line to most of your tasks, it is a good habit to have. It is one of those practices that some people think is useless, but for debugging purposes, or for anyone reading your script, seeing the status of each task provides a better view of what each task has done. Naming the task indicates what you want it to do, but it does not necessarily mean that the task has done that action. Using the\u00a0`state`\u00a0option, however, gives a much clearer indication in this respect:\n\n```", "```\n\n# Shared storage space for data tasks\n\nThe Ansible management server is doing a lot more in the background than simply sending tasks and managing remote machines. Adding the extra task of managing file transfers and running them on its interface may cause a considerable performance degradation. We always recommend using shared storage space either on an FTP server, an NFS or Samba filesystem, or on a web server to be downloaded by the remote hosts. This practice ensures that the remote hosts carry out the transfer with another dedicated and optimized server.\n\nIt is always a good practice to have all tools archived and their sample configuration files stored in a network file system. Remote hosts can easily access the drives either temporarily for a data transfer or permanently if they are in constant need.\n\nThe following playbook task shows an example of the code for this use:\n\n```", "```\n\n# Ansible roles\n\nThis is the section in which we discover Ansible roles and what we can do with them to optimize our automation scripting.\n\n# What are Ansible roles?\n\nThe ultimate configuration management scripts optimization is to convert simple playbooks into Ansible roles. This gives you the ability to make a set of configuration management tasks modular and reusable, with multiple configurations. It also means that they can be easily shared when required. Ansible roles allow several related tasks, with their variables and dependencies, to be contained in a portable framework. This framework represents the breakdown of a complex playbook into multiple simple files.\n\nAn Ansible role is composed of multiple folders, each of which contain several YAML files. By default, they have a `main.yml` file, but they can have more than one when needed. This is a standardized structure for all Ansible roles, which allows Ansible playbooks to automatically load predefined variables, tasks, handlers, templates, and default values located in separate YAML files. Each Ansible role should contain\u00a0at least\u00a0one of the following directories, if not all of them.\n\n# The tasks folder\n\nThis is the controller folder. It contains the main YAML files.\u00a0The code within those files executes the main role tasks by calling all the other defined elements of the role. Usually, it has the `main.yml`\u00a0file with some YAML files that are OS-specific that ensure certain tasks are executed when the role is run on specific systems. It may also contain other tasks to set up, configure, or ensure the existence of certain tools, services, configuration folders, or packages that failed a test run by the main script and triggered the execution of a task to fix them. The following is\u00a0a sample task code written on the `main.yml` file in the `tasks` folder:\n\n```", "```\n\n# The handlers folder\n\nThis folder usually contains the main file with multiple handler tasks that are waiting to be triggered by other tasks, either with the role or from other playbooks or roles. It is mainly used for service management to apply a configuration change performed by another task. Here is an example of a handler script:\n\n```", "```\n\n# The vars folder\n\nThis is where the role variables get stored. Usually, it is used for a permanent variable that does not require any changes between environments. Here is an example of a\u00a0variables file:\n\n```", "```\n\n# The templates folder\n\nThis folder contains the template files used by the role to create the actual configuration files. These are then deployed by the role to the remote hosts. They are `Jinja2` template engine scripts that enable loops and other features. Here is an example of a\u00a0template file:\n\n```", "```\n\n# The defaults folder\n\nThis folder contains the default values for the non-defined variables in the role when they are used. It is a way of organizing variable inputs in the role and is one of the highly recommended options when writing a playbook. It allows for a centralized management of the default values of the variable of the role. Default values are always vulnerable because they change a lot depending on the needs and policies of the user. Having this solution allows one file to change all the values.\u00a0Here is an example of a\u00a0`defaults` folder:\n\n```", "```\ndefaults/main.yml:\n---\ntimout: 2000\nID_key: \"None\"\n```", "```\n\n# The files folder\n\nThis folder holds all extra files that are required to achieve the role task. These files usually get dispatched to remote hosts as part of certain tasks. They are usually static, and they do not contain any variables to change, be copied, extracted, or compressed to the remote host.\n\n# The meta folder\n\nThis folder contains machine-readable information about the role. These folders contain the role metadata, which includes information about authors, licenses, compatibilities, and dependencies. The main use for this option is to declare dependencies, more specifically, roles. If the current role relies on another role, that gets declared in a `meta` folder. The following example shows how `meta`\u00a0folders are used:\n\n```", "```\nmeta/main.yml:\n---\ngalaxy_info:\n  author: medalibi\n  description: NTP client installn\n  company: Packt\n  license: license (GPLv3, BSD)\n  min_ansible_version: 2.4\n  platforms:\n    - name: Ubuntu\n      version:\n        - 16.04\n        - 18.04\n  galaxy_tags:\n    - networking\n    - system\n\ndependencies: []\n```", "```\n\n# The test folder\n\nThis folder contains a test environment with an inventory file and a playbook script to test the role. It is usually used by the developers to test any new changes that have happened to the role. It also serves as a sample configuration for new users to follow the running of the role. The playbook script within the `test` folder looks as follows:\n\n```", "```\ntests/test.yml:\n---\n- hosts: servers\n  remote_user: setup\n  become: yes\n  roles:\n    - ntpclient.lab.edu\n```", "```\n\n# The README folder/file\n\nThis is a folder that can be replaced by a simple markdown\u00a0`README.md`\u00a0file. It is an optional feature but it is highly recommended when you are planning to share your roles. It acts as a documentation for the role: it can contain anything that might be useful for first-time users of the role from a simple description of the task delivered by the role, to instructions and requirements to set up this role on their environment. It might also contain some best practices and information about the author and contributors if it is built by a team.\n\nAnsible roles are used for replacing the same function that the\u00a0option `include` carry out when adding extra parameters and functions to a playbook. Roles are much more organized and allow easier sharing, either on a personal GitHub project or on the Ansible Galaxy. This will be our subject for the next chapter.Make sure to use descriptive names for your roles. Like playbooks, this helps the users of your role to have an idea of what your role should do. Your description should be brief, usually just one or two words. You can always add more detail and description in the `README` file.\n\nRoles tend to be very specific: they do one job and one job only. It is not advisable to have tasks within a role that have nothing to do with the job. Let's create some example Ansible roles that deliver a few jobs to use as template roles that follow all best practices.\n\n# Creating Ansible roles\n\nLet's now create an Ansible role from scratch. This role is a Samba file server setup on either of the big families of Linux.\u00a0It serves a folder that is accessible via a shared user.\n\nFirst, let's create our role folder using the\u00a0`ansible-galaxy`\u00a0command line. Before running the command, we need to change the Terminal workspace to the location in which we would like to store our Ansible roles:\n\n```", "```\n\nWe should see the following output:\n\n```", "```\n\nWe then create a folder with the name of the role, with the following structure of subfolders and files:\n\n```", "```\n\nLet's now populate our folder and files with the appropriate code for the role. First, we are going to populate the dependencies and requirements for the role to work. For this, we will be working on the `meta`, `template`, `files`, `vars`, and `defaults`\u00a0folders, and the OS-specific scripts in the `tasks` folder.\n\nWe will start by populating the `template` folder with a `Jinga2` template file for the configuration of the SMB service:\n\n```", "```\n\nWe are then going to put a text file in the `files` folder that contains the rules and policies of using the shared folder:\n\n```", "```\n\nAfter that, we edit the main file in the `meta` folder with some role information: author, description, support, and tags. This will look as follows:\n\n```", "```\n\nOnce this is done, we move on to defining the role variables. For this role, we are going to have all the variables stored in one file, including the OS-specific variable:\n\n```", "```\n\nTo set our default values, we fill in the `defaults` main folder with the following file:\n\n```", "```\n\nWe now create the OS-specific tasks for setting up the service:\n\n```", "```\n\nLet's now finish by adding the main task and the handlers for it:\n\n```", "```\n\nWe finish by defining the handlers for service management:\n\n```", "```\n\n# Using Ansible roles\n\nFor this section, we are going to use the `test` folder to test the new role. First, we need to set up the inventory to match our test environment:\n\n```", "```\n\nThen, we edit the `test.yml`\u00a0file for the test:\n\n```", "```\n\nWhen executing the `test.yml` playbook, we need to add to the\u00a0`ansible-playbook` command line\u00a0the\u00a0`-i` option\u00a0and specify the\u00a0`tests/inventory` inventory file\u00a0we filled earlier. The\u00a0command line should look like the following:\n\n```"]