- en: Planning for Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产规划
- en: Kubernetes provides an excellent platform for developers to rapidly build highly
    flexible distributed applications. By running our applications on Kubernetes,
    we have a number of tools at our disposal to simplify their operation, and for
    making them more reliable, resilient to errors, and, ultimately, highly available.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为开发人员提供了一个极好的平台，可以快速构建高度灵活的分布式应用程序。通过在Kubernetes上运行我们的应用程序，我们可以利用各种工具来简化它们的操作，并使它们更加可靠、抗错误，并且最终高度可用。
- en: In order for us to depend on some of the guarantees and behaviors that our applications
    can inherit from Kubernetes, it is important that we understand how Kubernetes
    behaves, and some of the factors that have an impact on a production system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了依赖于我们的应用程序可以从Kubernetes继承的一些保证和行为，重要的是我们了解Kubernetes的行为方式，以及对生产系统产生影响的一些因素。
- en: It is important as a cluster administrator that you have an understanding of
    the requirements of the applications you are running, and of the users of those
    applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作为集群管理员，重要的是你要了解你正在运行的应用程序的要求，以及这些应用程序的用户。
- en: Having an awareness of the way that Kubernetes behaves in production is key,
    so it is invaluable to gain some practical experience of running your applications
    on Kubernetes before you start to serve mission-critical traffic. For example,
    when GitHub migrated their main application to Kubernetes, they started by moving
    traffic for internal users to their new Kubernetes-based infrastructure, before
    switching their main production traffic.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中了解Kubernetes的行为方式至关重要，因此在开始提供关键任务流量之前，获得在Kubernetes上运行应用程序的实际经验是非常宝贵的。例如，当GitHub将他们的主要应用程序迁移到Kubernetes时，他们首先将内部用户的流量转移到他们基于Kubernetes的新基础设施，然后再切换到他们的主要生产流量。
- en: '"The load from internal users helped us find problems, fix bugs, and start
    getting comfortable with Kubernetes in production. During this period, we worked
    to increase our confidence by simulating procedures we anticipated performing
    in the future, writing runbooks, and performing failure tests."—Jesse Newland
    ([https://githubengineering.com/kubernetes-at-github/](https://githubengineering.com/kubernetes-at-github/))'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: “来自内部用户的负载帮助我们发现问题，修复错误，并开始逐渐熟悉Kubernetes在生产中的运行。在此期间，我们努力增加自己的信心，通过模拟未来预期执行的程序，编写运行手册，并进行故障测试。”—Jesse
    Newland ([https://githubengineering.com/kubernetes-at-github/](https://githubengineering.com/kubernetes-at-github/))
- en: While I can cover some of the things that you are likely to encounter when using
    Kubernetes on AWS in production, it is important to understand that every application
    and organization is unique in surprising ways. You should think of Kubernetes
    as a toolkit that will enable you to build a powerful and flexible environment
    for your organization. Kubernetes isn't a magic bullet that removes the need for
    operational expertise; it's a tool that assists you in managing your applications.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我可以涵盖一些在AWS上使用Kubernetes进行生产时可能会遇到的事情，但重要的是要理解每个应用程序和组织在很多方面都是独特的。你应该把Kubernetes看作一个工具包，它将帮助你为你的组织构建一个强大而灵活的环境。Kubernetes并不是一个能够消除对运维专业知识需求的魔法子弹；它是一个帮助你管理应用程序的工具。
- en: The design process
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计过程
- en: 'The design process is shown as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 设计过程如下：
- en: '![](assets/f50ea2e6-83e1-4fe8-8dbb-d53c03a585c6.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f50ea2e6-83e1-4fe8-8dbb-d53c03a585c6.png)'
- en: When you think about preparing to use Kubernetes to manage your production infrastructure,
    you shouldn't think about Kubernetes as your end goal. It is a foundation for
    building a platform on which to run systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你考虑准备使用Kubernetes来管理你的生产基础设施时，你不应该把Kubernetes看作你的最终目标。它是一个构建平台的基础，用于运行系统。
- en: When you think about building a platform to meet the needs of the different
    people in your organization, it becomes much simpler to define the requirements
    you will place on Kubernetes. When trying to plan for a production environment,
    you need to understand the requirements that your organization has. Clearly, the
    technical requirements of the software you want to manage is important. But it
    is also key to understanding the operational process that your organization needs
    to support.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当你考虑构建一个满足组织中不同人员需求的平台时，定义你将对Kubernetes提出的要求变得更加简单。在尝试规划生产环境时，你需要了解你的组织的需求。显然，你想要管理的软件的技术要求很重要。但了解你的组织需要支持的运营流程也很关键。
- en: Adopting Kubernetes offers a lot of benefits to organizations that have complex
    requirements for the software that they run. Unfortunately, this complexity can
    also lead to challenges in safely adopting Kubernetes in a successful way.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 采用Kubernetes为具有复杂软件要求的组织带来了许多好处。不幸的是，这种复杂性也可能导致在安全地成功采用Kubernetes方面出现挑战。
- en: Initial planning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始规划
- en: You should consider where you will focus your efforts for your initial roll
    out. You should look for an application that will both deliver valuable results
    quickly, as well as having a lower risk profile. If we think about the example
    at GitHub, they initially focused their efforts on building an infrastructure
    for internal users to quickly test changes to their software. By focusing on a
    review or staging infrastructure, they found an application for Kubernetes that
    would both provide value quickly to developers in their organization, as well
    as an area that had low risks to their business as it was only accessed by internal
    users.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该考虑你的初始推出的重点在哪里。你应该寻找一个既能够快速提供有价值的结果，又具有较低风险的应用程序。如果我们想想GitHub的例子，他们最初把重点放在为内部用户构建基础设施，以便快速测试他们软件的更改。通过专注于审查或分期基础设施，他们找到了一个适用于Kubernetes的应用程序，既能够为他们组织的开发人员快速提供价值，又是一个对他们的业务风险较低的领域，因为它只被内部用户访问。
- en: Applications like these that have a combination of immediate usefulness and
    a lower impact of downtime are very useful. They allow your organization to gain
    valuable operational experience using Kubernetes, as well as to drive out bugs
    and other issues well before you attempt to handle production workloads.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样既具有即时有用性又对停机影响较小的应用程序非常有用。它们使你的组织能够在使用Kubernetes时获得宝贵的运营经验，并在尝试处理生产工作负载之前消除错误和其他问题。
- en: When getting started with Kubernetes, it can be tempting to choose the simplest
    application that your organization operates and start building processes and tooling
    around this. However, this can be a mistake because it might lead to you making
    assumptions about how your applications should be operated, that might make it
    much harder to later apply the same processes and configuration to more complex
    applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用Kubernetes时，选择你的组织运营的最简单的应用程序并开始围绕它构建流程和工具可能是诱人的。然而，这可能是一个错误，因为这可能会导致你对应用程序应该如何操作做出假设，这可能会使将相同的流程和配置应用到更复杂的应用程序变得更加困难。
- en: If you choose to start building your platform to support a simple application
    that doesn't require any backend services, such as a database, you might miss
    a number of things you need to consider as part of your deployment process. For
    example, applications that are backed by a database often need to run migration
    scripts to update the schema when a new version of an application is deployed.
    If you start by designing a deployment process to meet the needs of a very simple
    application, you might not surface these requirements until later. Remember, it
    will always be much simpler to deploy a simple application that only needs a subset
    of the features that your platform provides, than a more complex application that
    needs facilities you didn't consider when designing it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择开始构建支持不需要任何后端服务（如数据库）的简单应用程序的平台，您可能会错过一些需要考虑的事情作为部署过程的一部分。例如，由数据库支持的应用程序通常需要运行迁移脚本来在部署新版本的应用程序时更新架构。如果您首先设计部署流程以满足非常简单应用程序的需求，您可能要到后来才能发现这些要求。请记住，部署一个只需要平台提供的部分功能子集的简单应用程序将始终比部署一个需要您在设计时没有考虑到的更复杂的应用程序要简单得多。
- en: If you choose to focus your efforts on a single application for your initial
    adoption of Kubernetes, make sure that you choose an application that is representative
    of your organization's needs. It can be tempting to start using Kubernetes for
    a greenfield project, as you can take application development decisions with the
    platform in mind. But remember that a new application may well be significantly
    simpler than an application that has been in use for a longer time. In the example
    from GitHub, the application they chose to deploy first was their largest application
    operated by their organization providing many core services.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择将精力集中在初始采用Kubernetes的单个应用程序上，请确保选择一个代表您组织需求的应用程序。很容易会开始为一个全新的项目使用Kubernetes，因为您可以考虑平台的应用开发决策。但请记住，一个新应用程序可能会比使用时间更长的应用程序简单得多。在GitHub的例子中，他们选择首先部署的应用程序是他们组织运营的最大的应用程序，提供许多核心服务。
- en: If your organization has an application that requires a lot of operational time
    and effort every time it is deployed, it could be that this would be a good choice
    for an initial adoption of Kubernetes. Applications like these will be well known
    for their needs by your development and operational teams, and they will immediately
    be able to start to utilize Kubernetes to address the issues that previously cost
    time and effort.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的组织有一个每次部署都需要大量运营时间和精力的应用程序，那么这可能是初始采用Kubernetes的一个很好的选择。这些应用程序将因其需求而为您的开发和运营团队所熟知，并且他们将立即能够开始利用Kubernetes来解决以前花费时间和精力的问题。
- en: Planning for success
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成功的规划
- en: There are a few things that you should try to avoid in order to deliver successfully
    on a project to adopt Kubernetes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功地实施采用Kubernetes的项目，有一些事情您应该尽量避免。
- en: One trap that can be all too easy to fall into is to change too much too quickly.
    If you are taking the decision to adopt containerization and Kubernetes, it can
    be very tempting to adopt a lot of new processes and tools alongside this. This
    can slow down your progress quite significantly, because what started as a project
    to run your applications in containers can quickly grow to encompass many other
    tools and processes that your organization would like to adopt.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很容易陷入的陷阱是改变得太快太多。如果您决定采用容器化和Kubernetes，很容易会在此过程中采用许多新的流程和工具。这可能会显著减慢您的进展，因为最初是为了在容器中运行应用程序的项目很快就会扩展到包括您的组织想要采用的许多其他工具和流程。
- en: You should aim to avoid scope creep and try to change as little as possible
    in order to deliver your initial adoption of Kubernetes as quickly as possible.
    It is important to not try to deliver too many of the promises of containerization
    in one go, as they will hold your adoption back, and may indeed lead to failure
    of your whole project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该努力避免范围蔓延，并尽量改变尽可能少的内容，以便尽快交付您对Kubernetes的初始采用。重要的是不要试图一次实现太多容器化的承诺，因为这将阻碍您的采用，并可能导致整个项目的失败。
- en: Try to consider the environment you are currently deploying your applications
    to and aim to replicate its facilities at first, later adding additional functionality.
    Many of the tools and procedures that we discuss in the rest of this book might
    indeed be optional for your Kubernetes cluster, items that you can add at a later
    date to provide additional valuable services, but not to be viewed as blockers
    to adoption.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试考虑您当前部署应用程序的环境，并首先复制其功能，然后添加额外的功能。我们在本书的其余部分讨论的许多工具和流程可能确实是您的Kubernetes集群的可选项，可以在以后的日期添加，以提供额外的有价值的服务，但不应视为采用的障碍。
- en: If you have the opportunity to reduce the scope of the infrastructure your Kubernetes
    deployment provides at the time of your additional roll out, you should consider
    doing so. It reduces the scope of new tools and processes that your organization
    needs to understand. And it will give you the opportunity to focus on that topic
    in greater detail at a later time, with reference to the operational experience
    you will have gained running your applications on Kubernetes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有机会在额外的部署中减少Kubernetes部署提供的基础设施范围，您应该考虑这样做。这样可以减少组织需要理解的新工具和流程的范围。这将使您有机会在以后更详细地关注这个主题，并参考您在Kubernetes上运行应用程序时获得的运营经验。
- en: Consider log management as an example of this—if your current procedure is to
    log into servers with SSH and tail log files, you can provide the same functionality
    to operators of your Kubernetes cluster with the `kubectl logs` command. Implementing
    a solution to aggregate and search logs generated by your cluster might be desirable,
    but shouldn't necessarily be a blocker to using Kubernetes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以日志管理为例，如果您当前的流程是使用SSH登录服务器并查看日志文件，您可以使用`kubectl logs`命令为您的Kubernetes集群的操作员提供相同的功能。实施一个解决方案来聚合和搜索集群生成的日志可能是可取的，但不一定是使用Kubernetes的阻碍因素。
- en: If you currently deploy your applications onto servers running a Linux distribution
    that is readily available as a container image, you should stick with that distribution,
    rather than looking for alternatives at this stage, as your developers and operational
    staff will already be knowledgeable about how it works, and you won't have to
    invest time fixing incompatibilities. Learning to operate your applications on
    Kubernetes should be your focus, rather than learning how to configure a new operating
    system distribution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您当前将应用程序部署到运行Linux发行版的服务器上，该发行版作为容器映像readily可用，您应该坚持使用该发行版，而不是在这个阶段寻找替代方案，因为您的开发人员和运营人员已经了解它的工作原理，您不必投入时间来修复不兼容性。学习在Kubernetes上操作您的应用程序应该是您的重点，而不是学习如何配置新的操作系统发行版。
- en: Planning for a successful roll out
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划成功的部署。
- en: It can be tempting to shake up the processes and responsibilities in your organization.
    But trying to do this as part of adopting a new tool like Kubernetes can be risky.
    For example, if in your organization you have an operations team responsible for
    deploying and monitoring your applications, the point at which you adopt Kubernetes
    is not the correct time to hand this responsibility to someone else, such as your
    development team, or to attempt to automate a manual process.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 改变组织中的流程和责任可能是诱人的。但在采用像Kubernetes这样的新工具时，尝试这样做可能是有风险的。例如，如果在您的组织中有一个负责部署和监控应用程序的运维团队，那么在采用Kubernetes时并不是将这一责任交给其他人（比如开发团队）或尝试自动化手动流程的正确时机。
- en: This can be frustrating because, often, adoption of Kubernetes comes as part
    of wider plans to improve the processes and tooling that your organization uses.
    You should wait to successfully establish the use and operation of Kubernetes
    first. This will put you in a much better position to introduce new tools and
    processes once you have a stable foundation to build upon. You should view the
    adoption of Kubernetes as building a foundation that will be flexible enough to
    implement whatever changes to tools and processes you want to make in the future.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能令人沮丧，因为通常采用Kubernetes是作为改进组织使用的流程和工具的更广泛计划的一部分。您应该等到成功建立Kubernetes的使用和操作后再进行。这将使您在有一个稳定的基础之后更好地引入新工具和流程。您应该将采用Kubernetes视为建立一个灵活的基础，以便在将来实施对工具和流程的任何更改。
- en: You will discover that implementing new tools, services, and processes becomes
    much simpler once your application infrastructure is running on Kubernetes. Once
    you have a Kubernetes cluster at your disposal, you will discover that the barriers
    to trying out a new tool are significantly reduced. Instead of spending lots of
    time planning and provisioning, you can quickly evaluate and try out a new tool
    just by submitting a new configuration to your cluster.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的应用基础设施在Kubernetes上运行，您会发现实施新工具、服务和流程变得更加简单。一旦您拥有了一个Kubernetes集群，您会发现尝试新工具的障碍大大降低。您可以通过向集群提交新配置来快速评估和尝试新工具，而不是花费大量时间进行规划和配置。
- en: Discovering requirements
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现需求
- en: 'The designing requirements are shown in the following diagram:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 设计需求如下图所示：
- en: '![](assets/5a21d4ce-edfe-4d5e-9fa1-f901d1f353fc.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5a21d4ce-edfe-4d5e-9fa1-f901d1f353fc.png)'
- en: '**Availability**, **capacity**, and **performance** are key properties that
    we should consider when preparing for production. When gathering the functional
    requirements for your cluster, it can help to categorize which requirements imply
    some consideration of these properties.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备生产时，**可用性**、**容量**和**性能**是我们应该考虑的关键属性。在收集集群的功能需求时，可以帮助将需求归类为涉及这些属性的需求。
- en: It is important to understand that it might not be possible to optimize for
    all three properties without making some trade-offs. For example, for applications
    that depend on very high network performance, AWS provides a tool called a cluster
    placement group. This ensures that the best network performance is available by
    provisioning the EC2 VMs in such a way that fast network interconnections are
    available between them (presumably by locating them in close proximity within
    an AWS data center). By provisioning instances this way, the highest network throughputs
    (above 5 GB) and lowest latencies can be achieved between machines within the
    cluster placement group. For some applications that require these levels of performance,
    this might be a worthwhile optimization.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要明白，可能无法在不做出一些权衡的情况下优化所有三个属性。例如，对于依赖非常高网络性能的应用程序，AWS提供了一个称为集群放置组的工具。这确保了通过在AWS数据中心内以某种方式配置EC2
    VM来提供最佳网络性能，从而在它们之间提供快速的网络互连（可能是通过将它们放置在AWS数据中心内的相近位置）。通过这种方式配置实例，可以在集群放置组内的机器之间实现最高的网络吞吐量（超过5
    GB）和最低的延迟。对于一些需要这些性能水平的应用程序来说，这可能是一种值得的优化。
- en: However, since EC2 instances within a cluster placement group cannot span multiple
    availability zones, reliability of such a setup might be lower, since underlying
    power or connectivity issues could conceivably affect all the instances in a particular
    zone, especially if they are deployed in order to maximize interconnect speed.
    If your application doesn't have a requirement on such high-performance networking,
    it would indeed be unwise to trade reliability for greater performance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于集群放置组内的EC2实例不能跨多个可用区，因此这种设置的可靠性可能较低，因为潜在的电源或连接问题可能会影响特定区域内的所有实例，特别是如果它们被部署以最大化互连速度。如果您的应用程序对这种高性能网络没有要求，将可靠性换取更高性能的做法确实是不明智的。
- en: Overarching these properties is a very important property for a production system—**observability**.
    Observability really describes the ability for cluster operators to understand
    what is happening to your applications. Without being able to understand if your
    applications are performing and behaving as they should, you cannot evaluate,
    improve, and evolve the design of the system. When designing your cluster, this
    is the important feedback loop that allows you to maintain and improve your cluster
    based on operational experience. If you don't consider observability when planning
    your cluster, it can be much harder to debug issues with the cluster itself and
    with your applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些属性的最重要的属性是生产系统的一个非常重要的属性——**可观察性**。可观察性实际上描述了集群操作员了解应用程序发生了什么的能力。如果无法了解应用程序是否按照预期执行和行为，就无法评估、改进和演变系统的设计。在设计集群时，这是一个重要的反馈循环，它使您能够根据运营经验维护和改进集群。如果在规划集群时不考虑可观察性，要调试集群本身和应用程序的问题就会更加困难。
- en: When we are discussing application requirements at a planning stage, it can
    be hard to understand what the requirements of your applications will be. Having
    good observability into the performance of your cluster, the underlying hardware,
    and the applications running on top of it, lets you make pragmatic decisions and
    be flexible enough to make changes to support your applications as you discover
    more about how they behave under production workloads and as their functionality
    is developed over time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划阶段讨论应用程序需求时，很难理解应用程序的需求会是什么。对集群性能、底层硬件以及运行在其上的应用程序有良好的可观察性，可以让您做出务实的决策，并且足够灵活，以便在发现更多关于它们在生产工作负载下的行为以及随着功能随时间的开发而发生变化时，支持应用程序所做出的更改。
- en: Finally, perhaps the most important property to consider is security. Leaving
    the security of your cluster to the end of the planning process is a mistake.
    Remember that although security alone won't lead to the success of your project,
    failure to secure your cluster could lead to catastrophic consequences.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，也许最重要的属性要考虑的是安全性。将集群的安全性留到规划过程的最后是一个错误。请记住，尽管单靠安全性本身不会导致项目的成功，但未能确保集群的安全性可能会导致灾难性后果。
- en: Recent studies and disclosures have shown that unsecured Kubernetes clusters
    have already become an attractive target to those who would exploit your computing
    power for the likes of cryptocurrency mining and other nefarious purposes, not
    to mention the potential of access to your cluster being used to access sensitive
    data held within your organization.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究和披露显示，未加密的Kubernetes集群已经成为那些想要利用您的计算能力进行加密货币挖矿和其他不良目的的人的有吸引力的目标，更不用说访问您的集群可能被用来访问您组织内保存的敏感数据的潜力。
- en: Security should be considered and monitored throughout the life cycle of your
    cluster; indeed, you should try and understand the security implications of each
    and every other requirement. You will need to consider how members of your organization
    need to interact with Kubernetes, as well as having a plan to ensure that you
    secure the configuration and software of your cluster and the applications that
    you run on it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性应该在集群的整个生命周期中得到考虑和监控；事实上，您应该尝试并了解每一个其他要求的安全性影响。您需要考虑您的组织成员如何与Kubernetes进行交互，同时制定计划确保您的集群和在其上运行的应用程序的配置和软件的安全。
- en: In the following sections of this chapter, we will introduce some ideas to help
    you understand the considerations that you might need to take with regard to these
    properties. Hopefully, this chapter should give you enough understanding to discover
    what your requirements are, and to begin planning your cluster for production.
    For the specific knowledge you will need to implement your plan, keep reading;
    the second half of this book is almost entirely focused on the practical knowledge
    you will need to implement your plans.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后续部分，我们将介绍一些想法，帮助您了解在这些属性方面可能需要考虑的事项。希望本章能够让您充分了解自己的需求，并开始规划生产集群。关于实施计划所需的具体知识，请继续阅读；本书的后半部分几乎完全专注于您实施计划所需的实用知识。
- en: Availability
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可用性
- en: 'The availability is shown in the following diagram:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性如下图所示：
- en: '![](assets/ace2923e-7d64-418e-90af-66ec4b2d60bd.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ace2923e-7d64-418e-90af-66ec4b2d60bd.png)'
- en: One of the most important things to think about when planning a production system
    is availability. It is almost always the case that we run software in order to
    provide our users with a service. If, for whatever reason, our software is not
    available to meet the requests our users put on it, then, often, we fail to meet
    their expectations. Depending on the service that your organization provides,
    unavailability could cause your users to be unhappy, inconvenienced, or even suffer
    losses or harm. Part of making an adequate plan for any production system is understanding
    how downtime or errors might affect your users.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划生产系统时，考虑到可用性是最重要的事情之一。几乎总是我们运行软件来为用户提供服务。如果由于任何原因我们的软件无法满足用户的请求，那么通常我们就无法满足他们的期望。根据您的组织提供的服务，不可用可能会导致用户不满意、不便或甚至遭受损失或伤害。制定任何生产系统的充分计划的一部分是了解停机时间或错误可能如何影响您的用户。
- en: Your definition of availability can depend on the sorts of workload that your
    cluster is running and your business requirements. A key part in planning a Kubernetes
    cluster is to understand the requirements that the users have for the services
    you are running.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性的定义取决于您的集群正在运行的工作负载类型和您的业务需求。规划Kubernetes集群的关键部分是了解用户对您正在运行的服务的需求。
- en: Consider, for example, a batch job that emails a business report to your users
    once a day. So long as you can ensure that it runs at least once a day, at roughly
    the correct time, you can consider it 100% available, whereas a web server that
    can be accessed by your users at any time of the day or night needs to be available
    and error-free whenever your users need to access it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个每天给用户发送业务报告的批处理作业。只要您能确保它每天至少运行一次，大致在正确的时间，您就可以认为它的可用性达到100％，而可以在白天或晚上任何时间访问的Web服务器需要在用户需要访问时可用且无错误。
- en: 'The CEO of your organization will be happy when they arrive at work at 9 a.m.
    with a report in their inbox ready to read. They won''t care that the task failed
    to run at midnight and was retried a few minutes later successfully. However,
    if the application server hosting the web mail application that they use to read
    email is unavailable even for a moment during the day, they may be interrupted
    and inconvenienced:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当CEO在早上9点到达工作时，收件箱中已经准备好阅读的报告时，他们会很高兴。他们不会在意任务在午夜时分未能成功运行，并在几分钟后成功重试。然而，如果托管他们用来阅读电子邮件的Web邮件应用程序的应用服务器在一天中的任何时候甚至短暂不可用，他们可能会受到打扰和不便：
- en: '![](assets/c9aafa0a-5cfd-48aa-9ec5-0f6d085f4e19.png)A simple formula to calculate
    the availability of a service'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c9aafa0a-5cfd-48aa-9ec5-0f6d085f4e19.png)计算服务可用性的简单公式'
- en: Generally, systems engineers consider availability of a given service to be
    the percentage of requests that were successful out of the total requests made
    to/of the service.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，系统工程师认为给定服务的可用性是成功请求占总请求次数的百分比。
- en: We can consider a batch job that fails even several times to be available. The
    request we are making of the system (that the report is emailed to the correct
    person once a day) only requires the job to be completed successfully at least
    once. If we handle failures gracefully by retrying, there is no impact on our
    users.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以认为即使批处理作业失败了几次，也是可用的。我们对系统的要求（每天向正确的人发送报告）只需要作业至少成功完成一次。如果我们通过重试优雅地处理故障，对我们的用户没有影响。
- en: The exact number that you should plan for your systems to meet is, of course,
    largely a question of the needs of your users, and the priorities of your organization.
    It is worth bearing in mind, however, that systems designed for higher availability
    are almost invariably more complex and require more resources than a similar system
    where periods of downtime are acceptable. As a service approaches 100% availability,
    the cost and complexity of achieving the additional reliability increases exponentially.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该为系统计划的确切数字，当然，主要取决于用户的需求和组织的优先级。然而，值得记住的是，为了更高的可用性而设计的系统几乎总是比可以接受停机时间的类似系统更复杂，需要更多资源。随着服务接近100％的可用性，实现额外可靠性的成本和复杂性呈指数增长。
- en: 'If you don''t already know them, it is reasonable to initiate a discussion
    about availability requirements within your organization. You should do this in
    order to set targets and understand the best ways to run your software with Kubernetes.
    Here are some questions that you should try to answer:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还不了解它们，可以合理地开始讨论组织内的可用性要求。您应该这样做，以便设定目标并了解在Kubernetes上运行软件的最佳方法。以下是一些您应该尝试回答的问题：
- en: '*Do you know how your users are accessing your service?* For example, if your
    users are using mobile devices then connection to the internet is likely to be
    more unreliable anyway, masking the uptime (or otherwise) of your service.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你知道你的用户是如何访问你的服务的吗？* 例如，如果你的用户使用移动设备，那么连接到互联网可能本来就更不可靠，掩盖了你的服务的正常运行时间（或其他情况）。'
- en: If you are migrating your service to Kubernetes, *do you know how reliable it
    currently is?*
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在将你的服务迁移到Kubernetes，*你知道它目前的可靠性吗？*
- en: '*Are you able to put a monetary value on unavailability?* For example, e-commerce
    or ad-tech organizations will know the exact amount that will be lost for a period
    of downtime.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你能够对不可用性进行货币价值评估吗？* 例如，电子商务或广告技术组织将知道在停机期间将会损失多少金额。'
- en: '*What levels of unavailability are your users prepared to accept?* *Do you
    have competitors?*'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你的用户准备接受多少不可用性水平？* *你有竞争对手吗？*'
- en: You might have noticed that all of these questions are about your users and
    your organization; there is no solid technical answer to any of them, but you
    need to be able to answer them to understand the requirements on the system you
    are building.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，所有这些问题都是关于你的用户和你的组织；对于任何一个问题，都没有确定的技术答案，但你需要能够回答它们以了解你正在构建的系统的要求。
- en: In order to provide a highly available service accessed on a network, such as
    a web server, we need to ensure that the service is available to respond to requests
    whenever required. Since we cannot ensure that the underlying machines our service
    is running upon are 100% reliable, we need to run multiple instances of our software
    and route traffic only to those instances that are able to respond to requests.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个在网络上可以访问的高可用服务，比如一个网页服务器，我们需要确保服务能够在需要时响应请求。由于我们无法确保我们的服务运行在的底层机器是100%可靠的，我们需要运行多个实例的软件，并且只将流量路由到那些能够响应请求的实例上。
- en: The semantics of this batch job imply that (within reason) we are not too concerned
    about the amount of time the job takes to execute, whereas the time a web server
    takes to respond is quite significant. There have been many studies that show
    even sub-second delays added to the length of time a web page takes to load have
    a significant and measurable impact on users. So, even if we are able to hide
    failures (for example, by retrying failed requests), we have much lower leeway,
    and indeed we might even consider high priority requests to have failed if they
    take longer than a particular threshold.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个批处理作业的语义意味着（在合理范围内），我们并不太关心作业执行所需的时间，而网页服务器响应所需的时间则非常重要。有许多研究表明，即使是对网页加载时间增加了不到一秒的延迟，也会对用户产生显著和可测量的影响。因此，即使我们能够隐藏故障（例如通过重试失败的请求），我们的余地要小得多，甚至我们甚至可能认为高优先级的请求如果超过特定阈值的时间就已经失败了。
- en: One reason you might choose to run your applications on Kubernetes is because
    you have heard about its self-healing properties. Kubernetes will manage our applications
    and will take action when required to ensure that our applications continue to
    run in the way that we have requested of Kubernetes. This is a helpful effect
    of Kubernetes declarative approach to configuration.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能选择在Kubernetes上运行你的应用程序的一个原因是因为你听说过它的自愈特性。Kubernetes将管理我们的应用程序，并在需要时采取行动，以确保我们的应用程序继续以我们要求的方式运行。这是Kubernetes对配置的声明性方法的一个有益的效果。
- en: With Kubernetes, we would ask for a certain number of replicas of a service
    to be running on the cluster. The control plane is able to take action to ensure
    that this condition continues to be true even if something occurs to affect the
    running application, whether it is due a node failing or instances of an application
    being killed periodically due to a memory leak.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kubernetes，我们将要求集群上运行某项服务的特定数量的副本。即使发生影响运行应用程序的情况，例如节点故障或应用程序实例由于内存泄漏而定期被终止，控制平面也能够采取行动来确保这种条件继续成立。
- en: Contrast this to an imperative deployment procedure that relies on the operator
    to choose a particular underlying machine (or set of machines) to run an application
    on. If a machine fails, or even if an instance of the application misbehaves,
    then manual intervention is required. We want to provide our users with the services
    that they need without interruption.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与依赖操作员选择特定基础机器（或一组机器）运行应用程序的命令式部署程序形成对比。如果机器故障，甚至如果应用程序实例表现不佳，则需要手动干预。我们希望为用户提供所需的服务而不中断。
- en: For always on or latency sensitive applications such as webservers, Kubernetes
    provides mechanisms for us to run multiple replicas of our applications and to
    test the health of our services so that failing instances can be removed from
    the services or even restarted.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于始终开启或延迟敏感的应用程序，例如Web服务器，Kubernetes为我们提供机制来运行我们应用程序的多个副本，并测试我们服务的健康状况，以便从服务中删除失败的实例，甚至重新启动。
- en: 'For batch jobs, Kubernetes will retry failed jobs, and will reschedule them
    to other nodes if the underlying node fails. These semantics of restarting and
    rescheduling failed applications rely on the Kubernetes control plane to function.
    Once a pod is running on a particular node, it will continue to run until the
    following happens:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于批处理作业，Kubernetes将重试失败的作业，并将它们重新调度到其他节点，如果底层节点失败。这种重启和重新调度失败应用程序的语义依赖于Kubernetes控制平面的功能。一旦pod在特定节点上运行，它将继续运行，直到发生以下情况：
- en: It exits
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它退出
- en: It is killed by the kubelet for using too much memory
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它被kubelet终止，因为使用了太多内存
- en: The API server requests for it to be killed (perhaps to rebalance the cluster
    or to make way for a pod with a higher priority)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API服务器请求将其终止（可能是为了重新平衡集群或为了为具有更高优先级的pod腾出空间）
- en: This means that the control plane itself can become temporarily unavailable
    without affecting the applications running on the cluster. But no pods that have
    failed, or that were running on a node that has failed, will be rescheduled until
    the control plane is available again. Clearly, you also need the API server to
    be available in order to interact with it, so the needs of your organization to
    push a new configuration to the cluster (for example, to deploy a new version
    of an application) should also be considered.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着控制平面本身可以暂时不可用，而不会影响集群上运行的应用程序。但是，直到控制平面再次可用之前，没有失败的pod，或者在已经失败的节点上运行的pod将被重新调度。显然，您还需要API服务器可用以与其交互，因此还应考虑组织推送新配置到集群的需求（例如，部署应用程序的新版本）。
- en: We will discuss some strategies and tools that you might use to provide a highly
    available control plane in [Chapter 7](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *A
    Production-Ready Cluster*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论一些策略和工具，您可以使用它们来提供一个高可用的控制平面，详情请参阅[第7章](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml)
    *生产就绪的集群*。
- en: Capacity
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容量
- en: 'The capacity is shown in the following diagram:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 容量如下图所示：
- en: '![](assets/c53ff269-a214-41be-9afa-eeec3728a8a6.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c53ff269-a214-41be-9afa-eeec3728a8a6.png)'
- en: Running a system such as Kubernetes means that you can respond to additional
    demand for your services literally within the time it takes for your applications
    to start up. This process can even become automated with tools such as the **Horizontal
    Pod Autoscaler** (which we we will discuss in [Chapter 8](c9c63001-5c21-4240-ac1e-c2be4659d8a0.xhtml),
    *Sorry My App Ate the Cluster*).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 运行诸如Kubernetes之类的系统意味着您可以在应用程序启动的时间内对服务的额外需求做出实际回应。这个过程甚至可以通过诸如**水平Pod自动缩放器**（我们将在[第8章](c9c63001-5c21-4240-ac1e-c2be4659d8a0.xhtml)中讨论的*抱歉，我的应用程序吃掉了集群*）这样的工具自动化。
- en: 'When we couple this flexibility with the ability for us to launch new EC2 instances
    at will, capacity planning is much less involved than it might have been in the
    past. Kubernetes and AWS allow us to build applications that only consume the
    amount of resources that they need to be using at any given time. Rather than
    anticipating demand for our application and pre-committing to use resources, we
    can react to the usage requirements of our applications. Kubernetes finally allows
    us to deliver one of the promises of cloud computing: the promise that we will
    only pay for the resources that we use.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将这种灵活性与我们随意启动新的EC2实例的能力相结合时，容量规划比过去要简单得多。Kubernetes和AWS允许我们构建只在任何给定时间使用所需资源量的应用程序。我们可以对应用程序的使用要求做出反应，而不是预期对我们的应用程序的需求并预先承诺使用资源。Kubernetes最终使我们能够实现云计算的一个承诺：我们只支付我们使用的资源。
- en: There are a few considerations that you should take into account in order to
    make the most efficient use of the resources that you pay to use on AWS.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用AWS支付的资源上最有效地使用资源时，您应该考虑一些因素。
- en: EC2 instance types
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EC2实例类型
- en: When preparing to launch a Kubernetes cluster, you will probably be drawn into
    thinking about the type and size of the instances that will make up your cluster.
    The instances that you choose can have a big impact on the utilization, performance,
    and cost of operating a Kubernetes cluster.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备启动Kubernetes集群时，您可能会考虑集群中将使用的实例的类型和大小。您选择的实例可能会对Kubernetes集群的利用率、性能和成本产生重大影响。
- en: When Kubernetes schedules your pods to the worker nodes in a cluster, it considers
    the resource requests and limits that are part of a pod definition.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当Kubernetes将您的pod调度到集群中的工作节点时，它会考虑作为pod定义的一部分的资源请求和限制。
- en: Typically, your pod specification will request a number of CPUs (or fractions
    thereof) and a quantity of memory. On AWS, Kubernetes uses AWS's vCPU as its unit
    of measure. A vCPU (on most instance types) is a single CPU (hyper) thread rather
    than a CPU core. If you request a fractional number of CPUs then Kubernetes allocates
    your pod a share of a vCPU. Memory is requested in bytes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您的pod规范将请求一定数量的CPU（或其分数）和一定数量的内存。在AWS上，Kubernetes使用AWS的vCPU作为其度量单位。vCPU（在大多数实例类型上）是一个单CPU（超）线程，而不是CPU核心。如果您请求了CPU的分数，则Kubernetes会为您的pod分配一个vCPU的份额。内存以字节为单位请求。
- en: EC2 instances come in several different types that offer different ratios of
    CPU to memory.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: EC2实例有几种不同类型，提供不同的CPU到内存比例。
- en: EC2 instance types
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EC2实例类型
- en: 'The EC2 instance types is shown in the following table:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: EC2实例类型显示在以下表中：
- en: '| **Category** | **Type** | **CPU to memory ratio: vCPU:GiB** | **Notes** |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **类型** | **CPU到内存比例：vCPU:GiB** | **备注** |'
- en: '| Burstable | T3 | 1 CPU : 2 GiB | Provides 5-40% CPU baseline + burstable
    extra use. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 突发型 | T3 | 1 CPU : 2 GiB | 提供5-40%的CPU基线+可突发额外使用。 |'
- en: '| CPU optimized | C5 | 1 CPU : 2 GiB |  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| CPU优化 | C5 | 1 CPU : 2 GiB |  |'
- en: '| General purpose | M5 | 1 CPU : 4 GiB |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 通用型 | M5 | 1 CPU : 4 GiB |  |'
- en: '| Memory optimized | R5 | 1 CPU : 8 GiB |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 内存优化 | R5 | 1 CPU : 8 GiB |  |'
- en: '|  | X1 | 1 CPU : 15GiB |  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | X1 | 1 CPU : 15GiB |  |'
- en: '|  | X1e | 1 CPU : 30GiB |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | X1e | 1 CPU : 30GiB |  |'
- en: '| You should only consider the following instance types if you need the additional
    extra resources they provide (GPUs and/or local storage): |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 只有在需要它们提供的额外资源（GPU和/或本地存储）时，您才应该考虑以下实例类型： |'
- en: '| GPU | P3 | 1 CPU : 7.6GiB | 1 GPU : 8 CPU (NVIDIA Tesla V100) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPU | P3 | 1 CPU : 7.6GiB | 1 GPU : 8 CPU (NVIDIA Tesla V100) |'
- en: '|  | P2 | 1 CPU : 4GiB | i. 1 GPU : 4 CPU (NVIDIA K80) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | P2 | 1 CPU : 4GiB | i. 1 GPU : 4 CPU (NVIDIA K80) |'
- en: '| Storage | H1 | 1 CPU : 4GiB | 2TB HDD : 8 CPU |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 存储 | H1 | 1 CPU : 4GiB | 2TB HDD : 8 CPU |'
- en: '|  | D2 | 1 CPU : 7.6GiB | 3TB HDD : 2 CPU |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | D2 | 1 CPU : 7.6GiB | 3TB HDD : 2 CPU |'
- en: '|  | I3 | 1 CPU : 7.6GiB | 475GiB SSD : 2 CPU |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | I3 | 1 CPU : 7.6GiB | 475GiB SSD : 2 CPU |'
- en: When preparing a cluster, we should think about the instance types and size
    of instances that make up our cluster.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备集群时，我们应该考虑组成集群的实例类型和实例大小。
- en: When Kubernetes schedules our pods to the nodes in our cluster, it is of course
    aiming to pack as many containers as it can onto the cluster. This can be thwarted,
    however, if the ratio of CPU to memory requests in the majority of our pods is
    significantly different from the underlying nodes.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当Kubernetes将我们的pod调度到集群中的节点时，它当然是希望尽可能多地将容器放入集群中。然而，如果大多数pod的CPU到内存请求比在底层节点中显着不同，这可能会受到阻碍。
- en: For example, consider a scenario where we deploy pods that request 1 CPU and
    2 GiB of memory to our cluster. If our cluster were made up of `m5.xlarge` instances
    (4 vCPU and 16 GiB memory), each of our nodes would be able to run four pods.
    Once these four pods are running on this node, no more pods would be able to be
    scheduled to the node, but half the memory would be unused, effectively stranded.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑这样一个场景：我们在集群中部署了请求1个CPU和2GiB内存的pod。如果我们的集群由`m5.xlarge`实例（4 vCPU和16 GiB内存）组成，每个节点将能够运行四个pod。一旦这四个pod在该节点上运行，就无法再将更多的pod调度到该节点，但是一半的内存将被闲置，实际上处于被困的状态。
- en: If your workloads are quite homogeneous, of course it is quite simple to work
    out what instance type will offer the best ratio of CPU to memory to your applications.
    However, most clusters run a whole number of applications, each requiring different
    amounts of memory and CPU (and perhaps even other resources too).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的工作负载非常同质化，那么确定哪种实例类型将为您的应用程序提供最佳的CPU到内存比率当然是非常简单的。然而，大多数集群运行多个应用程序，每个应用程序需要不同数量的内存和CPU（甚至可能还需要其他资源）。
- en: In [Chapter 8](c9c63001-5c21-4240-ac1e-c2be4659d8a0.xhtml), *Sorry My App Ate
    the Cluster*, we discuss using the cluster autoscaler to automatically add and
    remove instances from AWS autoscaling groups in order to size your cluster to
    match the requirements of your cluster at any given time. We also discuss how
    you can use the cluster autoscaler to scale clusters with multiple different instance
    types, in order to combat the problem of matching the ratio of CPU to memory in
    clusters where the size and shape of the workloads that are run is quite dynamic
    and can change from time to time.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](c9c63001-5c21-4240-ac1e-c2be4659d8a0.xhtml)中，*抱歉，我的应用程序吃掉了集群*，我们讨论了如何使用集群自动缩放器自动向AWS自动缩放组添加和删除实例，以便在任何给定时间将您的集群大小调整到与集群要求相匹配。我们还讨论了如何使用集群自动缩放器来扩展具有多种不同实例类型的集群，以应对在这些集群中运行的工作负载的大小和形状相当动态，可能会不时发生变化的CPU到内存比率的问题。
- en: Breadth versus depth
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广度与深度
- en: Amazon offers many instance sizes for each family; for example, the m5 and c5
    families have six different instance sizes available, and each step up offers
    twice the resources. So, the largest instances have 48 times more resources than
    the smallest. *How should we choose what size instances to build our cluster with?*
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊为每个系列提供了许多不同的实例大小；例如，m5和c5系列都有六种不同的实例大小，每一级别提供的资源是前一级别的两倍。因此，最大的实例比最小的实例多48倍资源。*我们应该如何选择用于构建集群的实例大小？*
- en: The size of your instances limits the largest pod you can run on your cluster.
    The instance needs 10-20% larger than your largest pod to account for the overhead
    of system services, such as logging or monitoring tools, Docker, and Kubernetes
    itself.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的实例大小限制了集群上可运行的最大Pod大小。实例需要比您最大的Pod大10-20％，以考虑系统服务（如日志记录或监控工具、Docker和Kubernetes本身）的开销。
- en: Smaller instances will allow you to scale your cluster in smaller increments,
    increasing utilization.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较小的实例将允许您以较小的增量扩展您的集群，增加利用率。
- en: Fewer (larger) instances may be simpler to manage.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较少（较大）的实例可能更容易管理。
- en: Larger instances may use a lower proportion of resources for cluster-level tasks,
    such as log shipping, and metrics.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较大的实例可能会使用较低比例的资源来执行集群级任务，例如日志传送和指标。
- en: If you want to use monitoring or logging tools, such as Datadog, Sysdig, NewRelic,
    and so on, where pricing is based on a per instance model, fewer larger instances
    may be more cost effective.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想使用监控或日志记录工具，例如Datadog、Sysdig、NewRelic等，其定价是基于每个实例模型的，较少的较大实例可能更具成本效益。
- en: Larger instances can provide more disk and networking bandwidth, but if you
    are running more processes per instance this may not offer any advantage.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较大的实例可以提供更多的磁盘和网络带宽，但如果您在每个实例上运行更多的进程，这可能不会带来任何优势。
- en: Larger instance sizes are less likely to suffer from noisy neighbor issues at
    the hypervisor level.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较大的实例大小在超级管理程序级别更不太可能受到嘈杂邻居问题的影响。
- en: Larger instances often imply more colocation of your pods. This is usually advantageous
    when the aim is to increase utilization, but can sometimes cause unexpected patterns
    of resource limitations.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较大的实例通常意味着更多的Pod共存。当旨在增加利用率时，这通常是有利的，但有时可能会导致意外的资源限制模式。
- en: Performance
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能
- en: 'The key components of your cluster that impact performance are shown in the
    following diagram:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 影响性能的集群的关键组件如下图所示：
- en: '![](assets/7d5d9899-71d1-4f75-b644-c548bd23330a.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7d5d9899-71d1-4f75-b644-c548bd23330a.png)'
- en: Disk performance
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 磁盘性能
- en: If some of your applications depend on disk performance, understanding the performance
    characteristics of EBS volumes attached to your instances can become very useful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的一些应用程序依赖于磁盘性能，了解连接到您实例的EBS卷的性能特征可能会非常有用。
- en: All of the current generation of EC2 instances relies on EBS storage. EBS storage
    is effectively a shared network attached storage, so performance can be affected
    by a number of factors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 所有当前一代的EC2实例都依赖于EBS存储。EBS存储实际上是共享的网络附加存储，因此性能可能会受到多种因素的影响。
- en: If your cluster is running on the most recent generation of EC2 instances, you
    will be using EBS optimization. This means that dedicated bandwidth is available
    for I/O operations on your EBS volumes, effectively eliminating contention between
    EBS and other network activity.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的集群正在运行在最新一代的EC2实例上，您将使用EBS优化。这意味着专用带宽可用于对EBS卷的I/O操作，有效消除了EBS和其他网络活动之间的竞争。
- en: The total maximum bandwidth available to EBS volumes is determined by the size
    of the EC2 instance. In a system where you are running multiple containers, potentially
    with one or more EBS volumes attached to each, you should have an awareness of
    this upper limit that applies to the aggregate of all volumes in use on an instance.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: EBS卷可用的总最大带宽取决于EC2实例的大小。在一个运行多个容器的系统中，可能每个容器都连接了一个或多个EBS卷，您应该意识到这个上限适用于实例上所有正在使用的卷的总和。
- en: If you are planning to run workloads that expect to do large amounts of disk
    I/O, you may need to consider the total I/O available to the instance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您计划运行期望进行大量磁盘I/O的工作负载，您可能需要考虑实例可用的总I/O。
- en: EBS provides four volume types based on two basic technologies. `gp2` and `io2`
    volumes are based on SSD, or solid-state drive, technology, while st1 and sc1
    volumes are based upon HDD, or hard disk drive technology.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: EBS基于两种基本技术提供了四种卷类型。`gp2`和`io2`卷基于固态硬盘（SSD）技术，而st1和sc1卷基于硬盘驱动器（HDD）技术。
- en: This variety of disks is useful to us because, broadly, we can divide the workloads
    that your applications might deliver into two groups. Firstly, those that will
    need to make rapid random reads and/or writes to the filesystem. Workloads that
    fall into this category include databases, web servers, and boot volumes. With
    these workloads, the limiting factor for performance is usually **I/O operations
    per second** (**IOPS**). Secondly, there are workloads that need to make sequential
    reads from the disk as fast as possible. This includes applications such as Map
    Reduce, Log Management, and datastores, such as Kafka or Casandra, that have been
    specifically optimized to make sequential reads and writes as much as possible.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这种多样性的磁盘对我们很有用，因为广义上，我们可以将您的应用程序可能提供的工作负载分为两组。首先，那些需要对文件系统进行快速随机读取和/或写入的工作负载。属于这一类别的工作负载包括数据库、Web服务器和引导卷。对于这些工作负载，性能的限制通常是每秒I/O操作（IOPS）。其次，有一些工作负载需要尽可能快地从磁盘进行顺序读取。这包括Map
    Reduce、日志管理和数据存储，如Kafka或Casandra，这些应用程序已经专门优化，尽可能地进行顺序读取和写入。
- en: There are hard upper limits at the instance level to the maximum performance
    you can achieve with EBS volumes. The maximum IOPS available to all EBS volumes
    attached to a single instance is 64,000 on the largest instance size available
    on c5 and m5 instances. The smallest c5 and m5 instances only provide 1,600 IOPS.
    It is worth bearing these limits in mind, either if you want to run workloads
    requiring the higher levels of disk performance on smaller EC2 instance types
    or are using multiple EBS volumes on the larger instance types.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在实例级别存在硬性上限，限制了您可以通过EBS卷实现的最大性能。附加到单个实例的所有EBS卷的最大IOPS在c5和m5实例上可达到64,000。最小的c5和m5实例只提供1,600
    IOPS。需要牢记这些限制，无论是如果您想在较小的EC2实例类型上运行需要更高磁盘性能的工作负载，还是在较大的实例类型上使用多个EBS卷。
- en: gp2
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: gp2
- en: '`gp2` EBS volumes should be your first port of call for most general-purpose
    applications. They provide **solid-state drive **(**SSD**) performance at a modest
    price point. Performance on `gp2` volumes is based on a credit system. The volumes
    provide a baseline performance, and also accrue credits over time that allow performance
    bust up to 3,000 IOPS when required until the accrued credits are exhausted.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`gp2` EBS卷应该是大多数通用应用的首选。它们以适中的价格提供固态硬盘（SSD）性能。`gp2`卷的性能基于一个信用系统。这些卷提供基准性能，并随着时间累积信用，允许在需要时性能突发到3,000
    IOPS，直到累积的信用用尽。'
- en: When a `gp2` volume is created, it automatically receives a credit balance that
    allows it to burst up to 3,000 IOPS for 30 minutes. This is very useful when a
    volume is used as a boot volume or can provide better performance where data needs
    to be copied rapidly to the volume as part of a bootstrapping procedure.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个`gp2`卷时，它会自动获得一个信用余额，允许它在30分钟内突发到3,000 IOPS。当卷被用作引导卷或需要快速复制数据到卷作为引导过程的一部分时，这非常有用。
- en: The rate at which burst credits accrue and the baseline performance of a `gp2`
    volume is proportional to the volume size. Volumes smaller than 33 GiB will always
    have a minimum baseline performance of 100 IOPS. Volumes larger than 1 TB have
    a baseline performance greater than 3,000 IOPS, so you won't need to consider
    burst credits. The maximum performance available to a single `gp2` volume is 10,000
    IOPS for volumes of 3.3 TB (and larger).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 突发积分的积累速度和`gp2`卷的基准性能与卷的大小成正比。小于33 GiB的卷始终具有100 IOPS的最低基准性能。大于1 TB的卷的基准性能大于3,000
    IOPS，因此您不需要考虑突发积分。单个`gp2`卷可用的最大性能为3.3 TB（及更大）的卷的10,000 IOPS。
- en: If you have a workload that requires more performance from a `gp2` volume, a
    quick fix can be to use a larger volume (even if your application does not require
    the storage it provides).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的工作负载需要从`gp2`卷中获得更高的性能，一个快速的解决方法是使用更大的卷（即使您的应用程序不需要它提供的存储空间）。
- en: You can calculate what the maximum throughput volume will support by multiplying
    the IOPS by the block size (256 KiB). However, `gp2` volumes limit the total throughput
    to 160 MiB/s so volumes larger than 214 GiB will only provide 160 MiB/s.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将IOPS乘以块大小（256 KiB）来计算卷支持的最大吞吐量。但是，`gp2`卷将总吞吐量限制为160 MiB/s，因此大于214 GiB的卷将仅提供160
    MiB/s。
- en: Having the facility to monitor metrics as they relate to disk usage can be invaluable
    for understanding how disk performance is affecting your applications, and to
    identify if and where you are hitting performance limits.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 监视与磁盘使用相关的指标的能力对于了解磁盘性能如何影响您的应用程序，并确定您何时以及在哪里达到性能限制非常宝贵。
- en: io2
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: io2
- en: For applications where reliable performance is mission critical and `gp2` volumes
    simply cannot provide enough IOPS, `io2` volumes (otherwise known as provisioned
    IOPS volumes) are available. Where the instance they are attached to can support
    them, `io2` volumes can be provisioned to provide a maximum of 32,000 IOPS. When
    an `io2` instance is created, the IOPS required are specified upfront (we will
    discuss how to do this with Kubernetes in [Chapter 9](c2a3f846-f6cc-4fd1-af93-d325afeeffb6.xhtml),
    *Storing State*). The maximum IOPS that can be provisioned for a single volume
    are dependent on the size of the volume, with the ratio between IOPS and GiB of
    storage being `50:1`. Thus, in order to provision the maximum IOPS, you need to
    request a volume of at least 640 GiB.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可靠性能至关重要且`gp2`卷无法提供足够IOPS的应用程序，可以使用`io2`卷（也称为预留IOPS卷）。如果它们所附加的实例支持它们，`io2`卷可以被配置为提供最多32,000
    IOPS。创建`io2`实例时，需要预先指定所需的IOPS（我们将在[第9章](c2a3f846-f6cc-4fd1-af93-d325afeeffb6.xhtml)中讨论如何在Kubernetes中执行此操作，*存储状态*）。可以为单个卷配置的最大IOPS取决于卷的大小，IOPS和存储的GiB之间的比率为`50:1`。因此，为了配置最大IOPS，您需要请求至少640
    GiB的卷。
- en: For situations where the required number of IOPS is less than `gp2` volumes
    will support (10,000) and where the required throughput is less that 160 MiB/s,
    `gp2` volumes supporting similar performance characteristics will typically be
    less than half the price of an `io2` volume. Unless you know you have a need for
    the enhanced performance characteristics of `io2` volumes, it makes sense to stick
    to `gp2` volumes for most general-purpose use.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所需IOPS数量小于`gp2`卷支持的IOPS（10,000）且所需吞吐量小于160 MiB/s的情况，支持类似性能特征的`gp2`卷通常会比`io2`卷的价格低一半。除非您知道自己需要`io2`卷的增强性能特征，否则大多数通用用途都应坚持使用`gp2`卷。
- en: st1
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: st1
- en: For applications that have be optimized for sequential reads, where the primary
    performance metric to be concerned about is throughput, it might be surprising
    given the current dominance of SSDs to note that the best performance is still
    provided by spinning magnetic disks.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经针对顺序读取进行了优化的应用程序，其中主要的性能指标是吞吐量，也许令人惊讶的是，尽管SSD目前占据主导地位，但最佳性能仍然由旋转磁盘提供。
- en: '**st1** (and **sc1**) volumes are the newest types of EBS volumes available
    on AWS. They have been designed to offer high throughput for workloads, such as
    Map Reduce, log processing, data warehousing, and streaming workloads, such as
    Kafka. st1 volumes offer throughputs of up to 500 MiB/s at less than half the
    cost of gp2 instances. The downside is that they support much lower IOPS and so
    offer much worse performance for random or small writes. The IOPS calculations
    that you might make for SSD are slightly different because the block size is much
    larger (1 MB versus 256 KB). So, making a small write will take just as long as
    writing a full 1 MB block (if written sequentially).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**st1**（和**sc1**）卷是AWS上可用的最新类型的EBS卷。它们旨在为诸如Map Reduce、日志处理、数据仓库和流式工作负载（如Kafka）等工作负载提供高吞吐量。st1卷以不到gp2实例成本的一半提供高达500
    MiB/s的吞吐量。缺点是它们支持的IOPS要低得多，因此对于随机或小写入来说性能要差得多。您可能会对SSD进行的IOPS计算略有不同，因为块大小要大得多（1
    MB对比256 KB）。因此，进行小写入将花费与顺序写入完整1 MB块一样长的时间。'
- en: Where your workload is correctly optimized to take advantage of the performance
    characteristics of st1 volumes, it is well worth considering their use because
    the cost is roughly half that of gp2 volumes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的工作负载已经正确优化以利用st1卷的性能特性，那么考虑使用它们是非常值得的，因为成本大约是gp2卷的一半。
- en: Just like gp2 volumes, st1 uses a bust bucket model for performance. However,
    the accumulated credits allow the throughput to burst above the baseline performance.
    The baseline performance and rate at which credits accumulate are proportional
    to volume size. With the maximum burst performance being 500 MiB/s for volumes
    larger than 2 TiB and the maximum baseline performance being 500 MiB/s for volumes
    larger than 12.5 TiB, for volumes this size (or larger) there is no need to consider
    burst characteristics since performance is constant.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 就像gp2卷一样，st1使用了性能突发模型。然而，积累的信用额允许吞吐量突破基准性能。基准性能和信用额积累速度与卷大小成正比。对于大于2 TiB的卷，最大突发性能为500
    MiB/s，对于大于12.5 TiB的卷，最大基准性能为500 MiB/s，对于这样大小（或更大）的卷，无需考虑突发特性，因为性能是恒定的。
- en: sc1
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: sc1
- en: '`sc1` volumes offer the lowest cost block storage available on AWS. They provide
    a similar performance profile to `st1` volumes, but roughly half as fast, and
    for half the cost. You might consider them for applications where you need to
    store and retrieve data from the filesystem, but access is more infrequent, or
    performance is not so important to you.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`sc1`卷提供了AWS上最低成本的块存储。它们提供了与`st1`卷类似的性能配置文件，但大约只有一半的速度，成本也只有一半。您可以考虑将它们用于需要从文件系统存储和检索数据，但访问不太频繁或性能对您来说不那么重要的应用程序。'
- en: '`sc1` volumes could be considered as an alternative to archival or blob storage
    systems, such as `s3`, as the cost is broadly similar, but with the advantage
    that no special libraries or tools are needed to read and write data from them
    and, of course, with much lower latencies before the data can be read and used.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`sc1`卷可以被视为归档或blob存储系统（如`s3`）的替代方案，因为其成本大致相似，但具有无需使用特殊库或工具即可读写数据的优势，并且在数据可以被读取和使用之前具有更低的延迟。'
- en: In use cases like Kafka, or log management, you might consider using `sc1` volumes
    for older data that you still need to keep in online storage, so it is available
    for immediate use, but where it is accessed less often so you want to optimize
    the cost of storage.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kafka 或日志管理等用例中，你可能会考虑使用 `sc1` 卷来存储旧数据，这样可以保持在线存储，以便立即使用，但访问频率较低，因此你希望优化存储成本。
- en: Networking
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络
- en: When running distributed systems, network performance can be a key factor on
    the overall observable performance of an application.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行分布式系统时，网络性能可能是应用程序整体可观察性能的关键因素。
- en: Architectural patterns that encourage building applications where communication
    between different components is primarily through the network (for example, SOA
    and microservices) lead to applications where intra-cluster networking can be
    a performance bottleneck. Clustered datastores also can place high demands on
    intra-cluster networking, especially during write operations and when rebalancing
    a cluster during scaling or maintenance operations.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励构建应用程序的架构模式，其中不同组件之间的通信主要通过网络进行（例如，SOA 和微服务），会导致应用程序中的集群内部网络成为性能瓶颈。集群数据存储在进行写操作以及在扩展或维护操作期间重新平衡集群时，也可能对集群内部网络提出高要求。
- en: Of course, network performance is also a factor to consider when running services
    that are exposed to the internet or other wide-area networks.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行暴露给互联网或其他广域网的服务时，网络性能当然也是需要考虑的因素。
- en: The latest generation of EC2 instance types benefit from a networking interface
    that AWS describes as enhanced networking. To benefit from this, you need to be
    running a relatively recent instance type (M5, C5, or R4) and have a special network
    driver installed for Amazon's Elastic Network Adapter. Luckily, if you are using
    an official AMI of any of the main Linux distributions, this should already be
    done for you.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最新一代的 EC2 实例类型受益于 AWS 描述为增强网络的网络接口。要从中受益，你需要运行相对较新的实例类型（M5、C5 或 R4），并安装亚马逊的弹性网络适配器的特殊网络驱动程序。幸运的是，如果你使用主要
    Linux 发行版的官方 AMI，这些都应该已经为你完成。
- en: 'You can check that you have the correct drivers installed with the `modinfo`
    command:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `modinfo` 命令检查是否安装了正确的驱动程序：
- en: '[PRE0]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If the drivers for the **Elastic Network Interface** are not installed, you
    will see something like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未安装 **弹性网络接口** 的驱动程序，你将看到类似以下的内容：
- en: '[PRE1]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The performance boost from enhanced networking doesn't cost anything extra to
    use, so it is something you should check is configured correctly whenever preparing
    for production. The only instances in common use that do not support enhanced
    networking are the t2 burstable instance types.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 增强网络带来的性能提升并不需要额外费用，因此在准备生产时，你应该检查是否正确配置了增强网络。常见使用中唯一不支持增强网络的实例类型是 t2 可突发性能实例。
- en: The network performance of EC2 instances is proportional to the instance size,
    with only the largest instance sizes of each instance types capable of the headline
    network throughputs of 10 or 20 GBps. Even when using the largest EC2 instance
    sizes, the headline network throughputs are only achievable when communicating
    to other instances within a cluster placement group.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: EC2 实例的网络性能与实例大小成正比，每种实例类型中最大的实例大小才能达到 10 或 20 GBps 的网络吞吐量。即使使用最大的 EC2 实例大小，只有在与集群放置组中的其他实例进行通信时，才能实现网络吞吐量的最大值。
- en: 'A cluster placement group can be used to request that Amazon starts each of
    the instances you require together in a particular area in their data centers
    so the fastest speeds (and lowest latency) are available. To improve network performance,
    we can adjust two variables:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 集群放置组可用于请求亚马逊在其数据中心的特定区域同时启动您需要的每个实例，以便获得最快的速度（和最低的延迟）。为了提高网络性能，我们可以调整两个变量：
- en: '**Increasing instance size**: This makes faster networking available to the
    instance, and also increases collocation so making localhost network calls between
    services more likely.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加实例大小**：这样可以使实例获得更快的网络，并增加共存，从而更有可能在服务之间进行本地主机网络调用。'
- en: '**Adding your instance to a cluster placement group**: This ensures that your
    instances are hosted physically nearby, improving network performance.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将您的实例添加到集群放置组**：这可以确保您的实例在物理上靠近，从而提高网络性能。'
- en: Before taking decisions like this, you need to know that the network is really
    your performance bottleneck, because all of these choices make your cluster more
    at risk from underlying failures in AWS's infrastructure. So, unless you already
    know that your particular application will make particular demands on cluster
    networking, you shouldn't try to optimize for greater performance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在做出这样的决定之前，你需要知道网络是否真的是你的性能瓶颈，因为所有这些选择会使你的集群更容易受到AWS基础设施中潜在故障的影响。因此，除非你已经知道你的特定应用程序会对集群网络提出特定要求，否则不应该试图优化以获得更高的性能。
- en: Security
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全
- en: 'Some of the key areas that impact security are show in this diagram:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了一些影响安全性的关键领域：
- en: '![](assets/989337d6-4468-42f6-9a96-069308556c62.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/989337d6-4468-42f6-9a96-069308556c62.png)'
- en: Securing the configuration and software that forms the infrastructure of your
    cluster is of vital importance, especially if you plan to expose the services
    you run on it to the internet.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 保护集群基础设施的配置和软件的安全性至关重要，特别是如果您计划将其上运行的服务暴露到互联网上。
- en: You should consider that if you expose services to the public internet that
    have well known software vulnerabilities or configuration errors, it may only
    be a matter of hours before your services are detected by automated tools being
    used to scan for vulnerable systems.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该考虑，如果你将服务暴露到公共互联网上，而这些服务有众所周知的软件漏洞或配置错误，可能只是几个小时之内，你的服务就会被用于扫描易受攻击系统的自动化工具所发现。
- en: It is important that you treat the security of your cluster as a moving target.
    This means that you, or a tool that you use, need to be aware of new software
    vulnerabilities and configuration vulnerabilities.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，你要将集群的安全性视为一个不断变化的目标。这意味着你或者你使用的工具需要意识到新的软件漏洞和配置漏洞。
- en: Vulnerabilities with the Kubernetes software, and with the underlying operating
    system software of your hosts, will be updated and patched by the Kubernetes community
    and your operating system vendor, simply requiring the operator to have a procedure
    to apply updates as they become available.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes软件和主机的基础操作系统软件的漏洞将由Kubernetes社区和您的操作系统供应商进行更新和修补，只需要操作员有一个应用更新的程序即可。
- en: More critical is the configuration of your environment, as the responsibility
    for validating its security and correctness falls on your shoulders alone. As
    well as taking the time to validate and test the configuration, you should treat
    the security of your configuration as a moving target. You should ensure that
    you take the time to review changes and advice in the Kubernetes change log as
    you make updates.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 环境配置更为关键，因为验证其安全性和正确性的责任完全落在你的肩上。除了花时间验证和测试配置外，你还应该将配置的安全性视为一个不断变化的目标。在更新时，你应该确保花时间审查Kubernetes变更日志中的更改和建议。
- en: Always be updating
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 始终进行更新
- en: 'A new minor version of Kubernetes is released approximately every three months.
    And the project can release patch-level updates to each released minor versions
    as often as once a week. The patch level updates will typically include fixes
    for more major bugs, and fixes for security issues. The Kubernetes community currently
    supports three minor versions at any one time, ending regular patch-level updates
    of the oldest supported version as each new minor version is released. This means
    that when you plan and build a cluster, you need to plan for two kinds of maintenance
    to the Kubernetes software:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的新次要版本大约每三个月发布一次。该项目可以对每个发布的次要版本发布补丁级更新，频率最多每周一次。补丁级更新通常包括修复更重大的错误和安全问题的修复。Kubernetes社区目前同时支持三个次要版本，随着每个新的次要版本发布，最旧的受支持版本的常规补丁级更新将结束。这意味着在计划和构建集群时，您需要计划对Kubernetes软件进行两种维护：
- en: '**Patch-level updates**: Up to several times a month:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**补丁级更新**：每个月多次：'
- en: These should maintain very close compatibility and mostly be trivial to perform.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些应该保持非常紧密的兼容性，大多数情况下应该是微不足道的。
- en: They should be simple to perform with very little (or no) downtime.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们应该简单易行，几乎没有（或没有）停机时间。
- en: '**Minor version upgrades**: Every 3 to 9 months:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**次要版本升级**：每3到9个月：'
- en: You might need to make minor changes to the configuration of your cluster, when
    upgrading between minor versions.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在次要版本之间升级时，您可能需要对集群的配置进行微小更改。
- en: Kubernetes does maintain good backwards compatibility, and has a strategy of
    deprecating config options before they are removed or changed. Just remember to
    take note of deprecation warnings in the change log and log output.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes确实保持良好的向后兼容性，并且有一种在删除或更改配置选项之前废弃配置选项的策略。只需记住在更改日志和日志输出中注意废弃警告。
- en: If you are using third-party applications (or have written your own tools) that
    depend on beta or alpha APIs, you might need to update those tools before upgrading
    the cluster. Tools that only use the stable APIs should continue to work between
    minor version updates.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您正在使用第三方应用程序（或编写了自己的工具），这些应用程序依赖于测试版或alpha API，则可能需要在升级集群之前更新这些工具。只使用稳定API的工具应该在次要版本更新之间继续工作。
- en: 'You might need to think about the following:'
  id: totrans-177
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可能需要考虑以下事项：
- en: A testing environment where you can apply updates to the Kubernetes software
    to validate any changes before you release them to your production environment.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个测试环境，您可以在其中应用Kubernetes软件的更新，以验证任何更改，然后再将其发布到生产环境。
- en: Procedures or tools that will allow you to roll back any version upgrades, if
    you detect any errors.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您检测到任何错误，可以通过程序或工具回滚任何版本升级。
- en: Monitoring that allows you to determine that your cluster is functioning as
    expected.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控可以让您确定您的集群是否按预期运行。
- en: The procedures that you use to update the software on the machines that make
    up your cluster really depend on the tools that you are using.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您用于更新组成集群的机器上的软件的程序确实取决于您使用的工具。
- en: There are two main strategies that you might take—upgrading in place, and an
    immutable image-based update strategy.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能采取两种主要策略——就地升级和基于不可变镜像的更新策略。
- en: In-place updates
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 就地更新
- en: There are several tools that allow you to upgrade the underlying operating system
    on the nodes of your cluster. Tools such as `unattended-upgrades` for Debian-based
    systems or `yum-cron` for Red Hat-based systems allow you to install updated packages
    on your nodes without any operator input.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种工具可以让您升级集群节点的底层操作系统。例如，对于基于Debian的系统，可以使用`unattended-upgrades`工具，对于基于Red
    Hat的系统，可以使用`yum-cron`工具，这些工具可以在没有任何操作员输入的情况下在节点上安装更新的软件包。
- en: This, of course, can be somewhat risky in a production environment if a particular
    update causes the system to fail.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在生产环境中，如果特定更新导致系统失败，这可能有一定风险。
- en: Typically, if you are managing a system with automatic updates, you would use
    the package manager to pin essential components, such as Kubernetes and **etcd**,
    to a particular version, and then handle upgrading these components in a more
    controlled way, perhaps with a configuration management tool, such as Puppet,
    Chef, or Ansible.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，如果您正在管理具有自动更新的系统，您将使用软件包管理器将基本组件（如Kubernetes和etcd）固定到特定版本，然后以更受控制的方式升级这些组件，可能使用配置管理工具，如Puppet、Chef或Ansible。
- en: When upgrading packages like this in an automated way, a reboot of the system
    is required when certain components are updated. Tools such as the **KUbernetes
    REboot Daemon** (**Kured**), ([https://github.com/weaveworks/kured](https://github.com/weaveworks/kured))
    can watch for a signal that a particular node requires a reboot and orchestrate
    rebooting nodes across the cluster in order to maintain uptime of the services
    running on the cluster. This is achieved by first signaling the Kubernetes Scheduler
    to re-schedule workloads to other nodes and then triggering a reboot.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种自动化方式升级软件包时，当更新某些组件时，系统需要重新启动。诸如KUbernetes REboot Daemon（Kured）（[https://github.com/weaveworks/kured](https://github.com/weaveworks/kured)）之类的工具可以监视特定节点需要重新启动的信号，并编排重新启动集群中的节点，以维护集群上运行的服务的正常运行时间。首先通过发出信号通知Kubernetes
    Scheduler重新调度工作负载到其他节点，然后触发重新启动。
- en: There is also a new breed of operating systems, such as CoreOS' Container Linux
    or Google's Container-Optimized OS, that take a slightly different approach to
    updates. These new container-optimized Linux distributions don't provide a traditional
    package manager at all, instead requiring you to run everything not in the base
    system (like Kubernetes) as a container.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种新型操作系统，例如CoreOS的Container Linux或Google的Container-Optimized OS，对更新采取了略有不同的方法。这些新的面向容器的Linux发行版根本不提供传统的软件包管理器，而是要求您将不在基本系统中运行的所有内容（如Kubernetes）作为容器运行。
- en: These systems handle updates of the base operating system much more like the
    firmware update systems found in consumer electronics. The base root filesystem
    in these operating systems is read-only and mounted from one of two special partitions.
    This allows the system to download a new operating system image to the unused
    partition in the background. When the system is ready to be upgraded, it is rebooted
    and the new image from the second partition is mounted as the root filesystem.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统处理基本操作系统的更新方式更像是在消费类电子产品中找到的固件更新系统。这些操作系统中的基本根文件系统是只读的，并且从两个特殊分区中挂载。这允许系统在后台下载新的操作系统镜像到未使用的分区。当系统准备好升级时，它将被重新启动，并且来自第二分区的新镜像将被挂载为根文件系统。
- en: This has the advantage that if an upgrade fails or causes the system to become
    unstable, it is simple to roll back to the last version; indeed, this process
    can even become automated.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的好处是，如果升级失败或导致系统变得不稳定，可以简单地回滚到上一个版本；事实上，这个过程甚至可以自动化。
- en: If you are using Container Linux, you can use the **Container Linux Update Operator**
    to orchestrate reboots due to OS updates ([https://github.com/coreos/container-linux-update-operator](https://github.com/coreos/container-linux-update-operator)).
    Using this tool, you can ensure that the workloads on your hosts are rescheduled
    before they are rebooted.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Container Linux，您可以使用Container Linux Update Operator来编排由于操作系统更新而需要重新启动的操作（[https://github.com/coreos/container-linux-update-operator](https://github.com/coreos/container-linux-update-operator)）。使用这个工具，您可以确保在重新启动之前，主机上的工作负载被重新调度。
- en: Immutable images
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不可变镜像
- en: Whilst there are tools to help manage upgrading your hosts in place, there are
    some advantages to be had from embracing a strategy using immutable images.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有工具可以帮助管理原地升级您的主机，但是采用不可变镜像的策略也有一些优势。
- en: Once you are managing the applications that run on your infrastructure with
    Kubernetes, the software that needs to be installed on your node becomes standardized.
    This means that it becomes much simpler to manage updating the configuration of
    your hosts as immutable images.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您使用Kubernetes管理运行在基础架构上的应用程序，需要安装在节点上的软件就变得标准化了。这意味着管理主机配置的更新变得更加简单，因为它们是不可变的镜像。
- en: This could be attractive, as it allows you to manage building and deploying
    your node software in a similar way to building application containers with Docker.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能很有吸引力，因为它允许您以与使用Docker构建应用程序容器类似的方式来管理构建和部署节点软件。
- en: Typically, if you take this approach, you will want to use a tool that simplifies
    building images in the AMI format and making them available for other tools to
    start new EC2 instances to replace those launched with a previous image. One such
    tool is packer.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，如果采用这种方法，您将希望使用一种工具来简化以AMI格式构建镜像并使其可用于其他工具启动新的EC2实例以替换使用先前镜像启动的实例。packer就是这样一种工具。
- en: Network security
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络安全
- en: When running Kubernetes on AWS, there are four different layers you will need
    to configure in order to correctly secure the traffic on your cluster.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上运行Kubernetes时，您需要配置四个不同的层次，以正确地保护集群上的流量。
- en: Infra-node networking
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础节点网络
- en: In order for traffic to pass between pods and services running on your cluster,
    you will need to configure the AWS group(s) applied to your nodes to allow this
    traffic. If you are using an overlay network, this typically means allowing traffic
    on a particular port, as all communication is encapsulated to pass over a single
    port (typically as UDP packets). For example, the flannel overlay network is typically
    configured to communicate through UPD on port `7890`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使Pod和服务之间的流量在集群上传递，您需要配置应用于节点的AWS组以允许此流量。如果您使用覆盖网络，这通常意味着允许特定端口上的流量，因为所有通信都是封装在单个端口上传递的（通常作为UDP数据包）。例如，flannel覆盖网络通常配置为通过端口7890上的UDP进行通信。
- en: When using a native VPC networking solution, such as `amazon-vpc-cni-k8s`, it
    is typically necessary to allow all traffic to pass between the nodes. The `amazon-vpc-cni-k8s`
    plugin associates multiple pod IP addresses with a single Elastic Network Interface,
    so it is not typically possible to manage infra-node networking in a more granular
    way using security groups.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用原生VPC网络解决方案，比如`amazon-vpc-cni-k8s`时，通常需要允许所有流量在节点之间传递。`amazon-vpc-cni-k8s`插件将多个Pod
    IP地址与单个弹性网络接口关联起来，因此通常无法使用安全组以更精细的方式管理基础架构节点网络。
- en: Node-master networking
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点-主节点网络
- en: In normal operations, the kubelet running on your nodes needs to connect to
    the Kubernetes API to discover the definitions of the pods it is expected to be
    running.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常操作中，运行在您的节点上的kubelet需要连接到Kubernetes API以发现它预期运行的Pod的定义。
- en: Typically, this means allowing TCP connections to be made on port `443` from
    your worker nodes to your control plane security group.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这意味着允许工作节点向控制平面安全组的443端口进行TCP连接。
- en: The control plane connects to the kubelet on an API exposed on port `10250`. 
    This is needed for the `logs` and `exec` functionality.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面连接到暴露在端口10250上的API上的kubelet。这对于`logs`和`exec`功能是必需的。
- en: External networking
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 外部网络
- en: Correctly understanding what traffic from outside your cluster is allowed to
    access your nodes is a critical part of keeping your cluster secure.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 正确理解外部集群允许访问节点的流量是保持集群安全的关键部分。
- en: Recently, several researchers have discovered a significant number of otherwise
    secured clusters that allow unlimited access to the Kubernetes dashboard, and
    thus the cluster itself, to anyone accessing them on the internet.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一些研究人员发现了大量本来受到保护的集群，允许任何人在互联网上访问Kubernetes仪表板，从而访问集群本身。
- en: Typically, in these cases, the cluster administrator had failed to properly
    configure the dashboard to authenticate users. But had they thought carefully
    about the services that were exposed to the wider internet, these breaches may
    have been avoided. Only exposing sensitive services like this to specific IP addresses
    or to users accessing your VPC through a VPN would have provided an additional
    layer of security.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在这些情况下，集群管理员未能正确配置仪表板以对用户进行身份验证。但是，如果他们仔细考虑了向更广泛的互联网公开的服务，可能会避免这些违规行为。仅将这样的敏感服务暴露给特定IP地址或通过VPN访问您的VPC的用户，将提供额外的安全层。
- en: When you do want to expose a service (or an ingress controller) to the wider
    internet, the Kubernetes Load Balancer service type will configure appropriate
    security groups for you (as well as provisioning an **Elastic Load Balancer**
    (**ELB**)).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要将服务（或入口控制器）暴露给更广泛的互联网时，Kubernetes负载均衡器服务类型将为您配置适当的安全组（以及提供**弹性负载均衡器**（**ELB**））。
- en: Kubernetes infra-pod networking
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes基础设施- pod网络
- en: Out of the box, Kubernetes doesn't provide any facilities for controlling the
    network access between pods running on your cluster. Any pod running on the cluster
    can connect to any other pod or service.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes默认情况下不提供控制集群上运行的pod之间的网络访问的任何设施。集群上运行的任何pod都可以连接到任何其他pod或服务。
- en: This might be reasonable for smaller deployments of fully-trusted applications.
    If you want to provide policies to restrict the connectivity between different
    applications running on your cluster, you will need to deploy a network plugin
    that will enforce Kubernetes networking policies, such as Calico, Romana, or WeaveNet.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完全受信任的应用程序的较小部署来说，这可能是合理的。如果您想要提供策略来限制集群上运行的不同应用程序之间的连接，则需要部署一个网络插件，该插件将执行Kubernetes网络策略，例如Calico、Romana或WeaveNet。
- en: 'Whist there is a large choice of network plugins that can be used to support
    the enforcement of the Kubernetes Network policy, if you have chosen to make use
    of AWS-supported native VPC networking, it is recommended to use Calico, as this
    configuration is supported by AWS. AWS provide example configuration to deploy
    Calico alongside the `amazon-vpc-cni-k8s` plugin in their GitHub repository: [https://github.com/aws/amazon-vpc-cni-k8s](https://github.com/aws/amazon-vpc-cni-k8s).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有很多网络插件可用于支持Kubernetes网络策略的执行，但如果您选择使用AWS支持的原生VPC网络，建议使用Calico，因为AWS支持此配置。AWS提供了示例配置，以在其GitHub存储库中部署Calico与`amazon-vpc-cni-k8s`插件：[https://github.com/aws/amazon-vpc-cni-k8s](https://github.com/aws/amazon-vpc-cni-k8s)。
- en: The Kubernetes API provides the `NetworkPolicy` resource to provide policies
    to control the ingress and egress of traffic from pods. Each `NetworkPolicy` targets
    the pods that it will affect with a label selector and namespace. As the default
    is for pods to have no networking isolation, it can be useful if you wish to be
    strict to provide a default `NetworkPolicy` that will block traffic for pods that
    haven't yet been provided with a specific network policy.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes API提供了`NetworkPolicy`资源，以提供控制流量从pod进入和流出的策略。每个`NetworkPolicy`都以标签选择器和命名空间为目标，影响它将影响的pod。由于默认情况下pod没有网络隔离，如果您希望严格提供默认的`NetworkPolicy`以阻止尚未提供特定网络策略的pod的流量，这可能是有用的。
- en: Check the Kubernetes documentation for some examples of default network policies
    to allow and deny all traffic by default at [https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-policies).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看Kubernetes文档，了解一些默认网络策略的示例，以便默认情况下允许或拒绝所有流量：[https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-policies)。
- en: IAM roles
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IAM角色
- en: Kubernetes ships with some deep integrations with AWS. This means that Kubernetes
    can perform such tasks as provisioning EBS volumes and attaching them to the EC2
    instances in your cluster, setting up ELB, and configuring security groups on
    your behalf.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes与AWS有一些深度集成。这意味着Kubernetes可以执行诸如提供EBS卷并将其附加到集群中的EC2实例、设置ELB以及为您配置安全组等任务。
- en: In order for the Kubernetes to have the access it requires to perform these
    actions, you need to provide IAM credentials to allow the control plane and the
    nodes the required amount of access.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使Kubernetes具有执行这些操作所需的访问权限，您需要提供IAM凭据，以允许控制平面和节点获得所需的访问权限。
- en: 'Typically, the most convenient way to do this is to attach an instance profile
    associated with a relevant IAM role to grant the Kubernetes processes running
    on the instance the required permissions. You saw an example of this in [Chapter
    3](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml), *Reach for the Cloud*, when we
    launched a small cluster using `kubeadm`. When planning for a production cluster,
    there are a few more considerations you should plan for:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，最方便的方法是将与相关IAM角色关联的实例配置文件附加到实例上，以授予实例上运行的Kubernetes进程所需的权限。在[第3章](4e7f067a-f87f-4a36-be63-eb3bde02ba81.xhtml)中，*云端之手*中，我们使用`kubeadm`启动了一个小集群的示例。在规划生产集群时，您还应该考虑一些其他因素：
- en: '*Are you running multiple clusters?* *Do you need cluster resources to be isolated?*'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*您是否运行多个集群？* *您是否需要隔离集群资源？*'
- en: '*Do the applications running on your cluster also need to access resources
    within AWS that require authentication?*'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的集群上运行的应用程序是否还需要访问需要身份验证的AWS内部资源？
- en: '*Do the nodes in your cluster need to authenticate with the Kubernetes API
    using the AWS IAM Authenticator?* This will also apply if you are using Amazon
    EKS.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的集群中的节点是否需要使用AWS IAM Authenticator对Kubernetes API进行身份验证？如果您正在使用Amazon EKS，这也适用。
- en: If you are running multiple clusters in your AWS account (for example, for production
    and staging or development environments), it is worth thinking about how you can
    tailor your IAM roles to prevent clusters from interfering with one another's
    resources.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在AWS账户中运行多个集群（例如，用于生产和暂存或开发环境），值得考虑如何定制IAM角色，以防止集群干扰彼此的资源。
- en: In theory, a cluster shouldn't interfere with the resources created by another,
    but you might value the extra security that separate IAM roles for each environment
    can provide. Not sharing IAM roles between production and development or staging
    environments is good practice and can prevent configuration errors (or even bugs
    in Kubernetes) in one environment causing harm to resources associated with another
    cluster. Most resources that Kubernetes interacts with are tagged with a `kubernetes.io/cluster/<cluster
    name>` tag. With some of these resources, IAM offers the ability to restrict certain
    actions to resources matching that tag. Restricting delete actions in this way
    is one way to reduce the potential for harm.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，一个集群不应该干扰另一个集群创建的资源，但您可能会重视每个环境单独提供的IAM角色所提供的额外安全性。在生产和开发或分段环境之间不共享IAM角色是一个良好的做法，可以防止一个环境中的配置错误（甚至是Kubernetes中的错误）对与另一个集群关联的资源造成伤害。Kubernetes交互的大多数资源都带有`kubernetes.io/cluster/<cluster
    name>`标签。对于其中一些资源，IAM提供了将某些操作限制为与该标签匹配的资源的能力。以这种方式限制删除操作是减少潜在危害的一种方式。
- en: When the applications running on your cluster need to access AWS resources,
    there are a number of ways to provide credentials to the AWS client libraries
    in order to authenticate correctly. You could supply credentials to your applications
    with secrets mounted as config files or as environment variables. But one of the
    most convenient ways to provide IAM credentials is to associate IAM roles to your
    pods using the same mechanism as instance profiles.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 当集群上运行的应用程序需要访问AWS资源时，有多种方法可以向AWS客户端库提供凭据，以便正确进行身份验证。您可以将凭据作为配置文件或环境变量挂载为秘密，然后提供给您的应用程序。但提供IAM凭据的最便捷的方法之一是使用与实例配置文件相同的机制将IAM角色与您的pod关联起来。
- en: Tools such as `kube2iam` or `kiam` intercept calls made by the AWS client library
    to the metadata service and provide tokens depending on an annotation set on the
    pod. This allows IAM roles to be assigned as part of your normal deployment process.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如`kube2iam`或`kiam`之类的工具拦截AWS客户端库对元数据服务的调用，并根据pod上设置的注释提供令牌。这允许IAM角色作为您正常部署过程的一部分进行分配。
- en: '**kiam** ([https://github.com/uswitch/kiam](https://github.com/uswitch/kiam))
    and **kube2iam** ([https://github.com/jtblin/kube2iam](https://github.com/jtblin/kube2iam))
    are two similar projects designed to provide IAM credentials to Kubernetes pods.
    Both projects run as an agent on each node, adding network routes to route traffic
    destined for the AWS metadata service. kiam additionally runs a central server
    component that is responsible for requesting tokens from the AWS API and maintains
    a cache of the credentials required for all running pods. This approach is noted
    to be more reliable in production clusters and reduces IAM the permissions required
    by the node agents.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**kiam** ([https://github.com/uswitch/kiam](https://github.com/uswitch/kiam))
    和 **kube2iam** ([https://github.com/jtblin/kube2iam](https://github.com/jtblin/kube2iam))
    是两个类似的项目，旨在为Kubernetes pod提供IAM凭据。这两个项目都作为每个节点上的代理运行，添加网络路由以路由到AWS元数据服务的流量。kiam另外还运行一个负责从AWS
    API请求令牌并维护所有运行中pod所需凭据的缓存的中央服务器组件。这种方法在生产集群中被认为更可靠，并减少了节点代理所需的IAM权限。'
- en: Another advantage of using one of these tools is that it prevents the applications
    running on the cluster from using the permissions assigned to the underlying instance,
    reducing the risk that an application could errant or maliciously access resources
    providing control plane services.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些工具之一的另一个优势是，它可以防止集群上运行的应用程序使用分配给底层实例的权限，从而减少了应用程序可能错误或恶意访问资源以提供控制平面服务的风险。
- en: Validation
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证
- en: When setting up a cluster, there are many different choices you might make to
    configure your cluster. It is important that you have some way to quickly validate
    that your cluster will operate correctly.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置集群时，您可能会做出许多不同选择来配置您的集群。重要的是，您需要一种快速验证集群是否能够正确运行的方法。
- en: This is a problem that the Kubernetes community has solved in order to certify
    that different Kubernetes distributions are *conformant*. To gain a seal of approval
    that a particular Kubernetes distribution is conformant, it is necessary for a
    set of integration tests to be run against a cluster. These tests are useful for
    a vendor supplying a pre-packaged installation of Kubernetes to prove that their
    distribution functions correctly. It is also very useful for cluster operators
    to use to quickly validate that configuration changes of software updates leave
    your cluster in an operable state.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Kubernetes社区为了证明不同的Kubernetes发行版是“一致的”而解决的问题。为了获得特定Kubernetes发行版的一致性认证，需要对集群运行一组集成测试。这些测试对于供应预打包的Kubernetes安装的供应商来证明其发行版是否正确运行非常有用。对于集群操作员来说，它也非常有用，可以快速验证软件更新或配置更改是否使集群处于可操作状态。
- en: Kubernetes conformance testing is based on a number of specially automated tests
    from the Kubernetes code base. These tests are run against testing clusters as
    part of the end-to-end validation of the Kubernetes code base, and must pass before
    every change to the code base is merged in.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes一致性测试基于Kubernetes代码库中的一些特殊自动化测试。这些测试作为Kubernetes代码库端到端验证的一部分运行在测试集群上，并且在每次对代码库的更改合并之前必须通过。
- en: It certainly is possible to download the Kubernetes code base (and set up a
    Golang development environment) and configure it to run the conformance test directly.
    However, there is a tool called **Sonobuoy** that can automate this process for
    you.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以下载Kubernetes代码库（并设置Golang开发环境）并配置它直接运行一致性测试。但是，有一个名为**Sonobuoy**的工具可以为您自动化这个过程。
- en: Sonobuoy makes it simple to run a set of Kubernetes conformance tests on your
    clusters in a simple and standardized manner. The simplest way to get started
    with Sonobuoy is to use the hosted browser-based service at [https://scanner.heptio.com/](https://scanner.heptio.com/).
    This service gives you a manifest to submit to your cluster and then displays
    the test results once the tests have finished running. If you want to run everything
    on your own cluster, you can install a command-line tool that will let you run
    tests and collect the results yourself by following the instructions at [https://github.com/heptio/sonobuoy](https://github.com/heptio/sonobuoy).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Sonobuoy可以简化在集群上以简单和标准化的方式运行一组Kubernetes一致性测试。使用Sonobuoy的最简单方法是使用托管的基于浏览器的服务[https://scanner.heptio.com/](https://scanner.heptio.com/)。该服务会提供一个清单供您提交到您的集群，然后在测试完成后显示测试结果。如果您想在自己的集群上运行所有内容，可以安装一个命令行工具，按照[https://github.com/heptio/sonobuoy](https://github.com/heptio/sonobuoy)上的说明运行测试并收集结果。
- en: Kubernetes conformance testing is important because it exercises a wide range
    of Kubernetes features, giving you early warning of any misconfiguration before
    you have even deployed applications to your cluster that might exercise those
    features. It can be very helpful when making changes to the configuration of your
    cluster to have a warning if your changes might affect the functionality of the
    cluster.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes一致性测试很重要，因为它涵盖了各种Kubernetes功能，可以在部署应用程序之前提前警告您是否存在任何配置错误。当您更改集群配置时，如果更改可能影响集群功能，这些测试会非常有帮助。
- en: Whilst Kubernetes conformance tests focus on testing the functionality of your
    cluster, security benchmarking checks your cluster's configuration against known
    unsafe configuration settings, ensuring that your cluster is configured to meet
    current security best practices.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Kubernetes一致性测试侧重于测试集群的功能，安全基准测试会检查集群的配置是否符合已知的不安全配置设置，确保集群配置符合当前的安全最佳实践。
- en: The **Centre for Internet Security** publishes step-by-step checklists that
    you can manually follow to test your cluster against security best practices.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**互联网安全中心**发布了逐步检查清单，您可以手动按照这些清单来测试集群是否符合安全最佳实践。'
- en: You can download a copy of these benchmarks for free at [https://www.cisecurity.org/benchmark/kubernetes/](https://www.cisecurity.org/benchmark/kubernetes/).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以免费下载这些基准测试的副本：[https://www.cisecurity.org/benchmark/kubernetes/](https://www.cisecurity.org/benchmark/kubernetes/)。
- en: It can be useful to read and follow the advice in these checklists whist building
    your cluster, as it will help you to understand the reasons for a particular configuration
    value.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建集群时阅读并遵循这些清单中的建议可能会很有用，因为它将帮助您理解特定配置值的原因。
- en: Once you have set up your cluster it can be useful to automatically validate
    your configuration as you update and make changes, to avoid your configuration
    accidentally drifting away from a secure configuration.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您设置好了集群，自动验证配置可能会很有用，以便在更新和更改时避免配置意外偏离安全配置。
- en: '`kube-bench` is a tool that provides an automated way to run the CIS benchmarks
    against your cluster: [https://github.com/aquasecurity/kube-bench](https://github.com/aquasecurity/kube-bench).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-bench`是一个工具，它提供了一种自动运行CIS基准测试的方式：[https://github.com/aquasecurity/kube-bench](https://github.com/aquasecurity/kube-bench)。'
- en: You might find it useful to also write your own integration tests that check
    that you can successfully deploy and operate some of your own applications. Tests
    like these can act as an important sanity check when rapidly developing the configuration
    for your cluster.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会发现编写自己的集成测试也很有用，这些测试可以检查您是否能成功部署和操作自己的一些应用程序。在快速开发集群配置时，这些测试可以作为一个重要的健全性检查。
- en: There are many tools that could be used to perform tests like these. I would
    recommend whatever test automation tool that the engineers in your organization
    are already comfortable with. You could use a tool specially designed for running
    automated tests, such as cucumber, but a simple shell script that deploys an application
    to your cluster and then checks that it is accessible is a great start too.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多工具可以用来执行这样的测试。我建议使用您组织中的工程师已经熟悉的任何测试自动化工具。您可以使用专门设计用于运行自动化测试的工具，比如cucumber，但是一个简单的shell脚本，部署一个应用程序到您的集群，然后检查它是否可访问，也是一个很好的开始。
- en: Observability
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观测性
- en: 'Observability is shown in the following diagram:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性显示在以下图表中：
- en: '![](assets/e1f09642-520c-4579-809e-3ac616965ea2.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e1f09642-520c-4579-809e-3ac616965ea2.png)'
- en: Being able to monitor and debug a cluster is one of the most important points
    to bear in mind when designing a cluster for production. Luckily, there are a
    number of solutions for managing logs and metrics that have very good support
    for Kubernetes.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 能够监视和调试集群是设计生产集群时最重要的要点之一。幸运的是，有许多解决方案可以很好地支持Kubernetes的日志和指标管理。
- en: Logging
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: Whenever you want to know what your applications are doing, the first thing
    most operators will think to do is to look at the logs generated by the application.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 每当您想要了解您的应用程序在做什么时，大多数运维人员首先想到的是查看应用程序生成的日志。
- en: Logs are simple to understand, and they don't require any special tools to produce,
    as your application probably already supports some sort of the logging already.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 日志很容易理解，而且不需要任何特殊工具来生成，因为您的应用程序可能已经支持某种形式的日志记录。
- en: Out of the box, Kubernetes allows you to view and tail the logs that your application
    is writing to standard out and standard errors. Using the `kubectl logs` command
    should be familiar to you if you have used the `docker logs` command on your own
    machine or on a server.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，您可以直接查看和追踪应用程序写入标准输出和标准错误的日志。如果您在自己的计算机或服务器上使用过`docker logs`命令，那么使用`kubectl
    logs`命令应该对您来说很熟悉。
- en: It is more convenient than logging into each node to view the logs generated
    by a particular container. As well as viewing the logs from a particular pod,
    `kubectl logs` can show the logs from all the pods matching a particular label
    expression.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这比登录每个节点查看特定容器生成的日志更方便。除了查看特定pod的日志外，`kubectl logs`还可以显示与特定标签表达式匹配的所有pod的日志。
- en: If you need to search the logs generated by your application for a particular
    event, or if you need to see the logs generated at a particular time in the past,
    then you need to consider deploying a solution to aggregate and manage your logs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要搜索应用程序生成的日志以查找特定事件，或者如果您需要查看过去特定时间生成的日志，那么您需要考虑部署一个解决方案来聚合和管理您的日志。
- en: The most widely used tool to implement this function is **Fluentd**. Fluentd
    is a very flexible tool that can be used to collect logs from a wide variety of
    sources and then push them to one or more destinations. If your organization already
    maintains or uses a third-party tool to aggregate application logs, you will almost
    certainly find a way to configure Fluentd to store the application logs from applications
    running on Kubernetes in your chosen tool. Members of the Fluentd team, and the
    wider community, maintain over 800 different plugins that support many different
    inputs, outputs, and filtering options.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 实现此功能的最常用工具是**Fluentd**。Fluentd是一个非常灵活的工具，可以用于从各种来源收集日志，然后将其推送到一个或多个目的地。如果您的组织已经维护或使用第三方工具来聚合应用程序日志，您几乎肯定会找到一种方法来配置Fluentd以将运行在Kubernetes上的应用程序的应用程序日志存储在您选择的工具中。Fluentd团队和更广泛的社区维护着超过800个不同的插件，支持许多不同的输入、输出和过滤选项。
- en: 'As Fluentd is built upon the Ruby programming language, its plugins are distributed
    using the Rubygems package system. By convention, all Fluentd plugins have a name
    beginning with **fluent-plugin**, and all currently available plugins are listed
    here: [https://www.fluentd.org/plugins/all](https://www.fluentd.org/plugins/all). Because
    some of these plugins are maintained by the wider community, it is worth making
    some initial tests of a plugin you plan to use. The quality of plugins can be
    variable, depending on the stage of development a particular plugin is in and
    how often it is maintained. You can install and manage Fluentd plugins using the
    `gem install` command or control the exact versions of Fluentd plugins using the
    **bundler** tool. You can read more about installing plugins in your Fluentd installation
    here: [https://docs.fluentd.org/v1.0/articles/plugin-management](https://docs.fluentd.org/v1.0/articles/plugin-management).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Fluentd是基于Ruby编程语言构建的，它的插件使用Rubygems软件包系统进行分发。按照惯例，所有Fluentd插件的名称都以**fluent-plugin**开头，并且当前所有可用的插件都在此处列出：[https://www.fluentd.org/plugins/all](https://www.fluentd.org/plugins/all)。由于其中一些插件是由更广泛的社区维护的，因此值得对您计划使用的插件进行一些初始测试。插件的质量可能有所不同，这取决于特定插件所处的开发阶段以及维护频率。您可以使用`gem
    install`命令安装和管理Fluentd插件，或者使用**bundler**工具控制Fluentd插件的确切版本。您可以在此处阅读有关在Fluentd安装中安装插件的更多信息：[https://docs.fluentd.org/v1.0/articles/plugin-management](https://docs.fluentd.org/v1.0/articles/plugin-management)。
- en: Monitoring
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: Looking at the log output of your application can be useful if you know there
    is an issue with an application and want to debug the cause. But it is much harder
    if you don't know where in your system a problem is occurring, or if you simply
    want to assess the health of a system.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 查看应用程序的日志输出可能是有用的，如果您知道应用程序存在问题并希望调试原因。但是，如果您不知道系统中出现问题的位置，或者只是想评估系统的健康状况，那么这将变得更加困难。
- en: Your logs are very flexible because your applications can write any information
    in an unstructured way to a logging endpoint. This in a large system can become
    quite overwhelming, and the amount of effort required to filter and analyze this
    output can become complex.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 您的日志非常灵活，因为您的应用程序可以以非结构化的方式向日志端点写入任何信息。在大型系统中，这可能会变得非常压倒，以及需要过滤和分析此输出的工作量可能会变得复杂。
- en: Monitoring or metrics collection takes a different approach. By defining measurements
    that reflect the performance and operation of your system, of Kubernetes, and
    your infrastructure, you can much more quickly answer questions about the health
    and performance of your system.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 监控或指标收集采取了不同的方法。通过定义反映系统、Kubernetes和基础设施的性能和运行情况的测量，您可以更快地回答有关系统健康和性能的问题。
- en: Collected metrics are also one of the most useful sources for automated alerting
    systems. They can warn members of your organization about abnormal behavior in
    your applications or infrastructure.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 收集的指标也是自动警报系统中最有用的信息源之一。它们可以警告您的组织成员有关应用程序或基础设施异常行为。
- en: There are a number of commercial and open source tools that can be used to collect
    metrics and create alerts. The decision you take will most likely be influenced
    by your organization and the requirements you have.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多商业和开源工具可用于收集指标并创建警报。您所做的决定很可能会受到您的组织和您的要求的影响。
- en: As I have already said, trying to introduce too many new tools or processes
    to your organization at once can risk your success. In many cases, many monitoring
    tools already support integration with Kubernetes. If this is the case, it may
    be prudent to consider continuing to use the existing tools your organization
    is used to.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我已经说过的，试图一次向您的组织引入太多新工具或流程可能会冒险。在许多情况下，许多监控工具已经支持与Kubernetes集成。如果是这种情况，考虑继续使用您的组织习惯使用的现有工具可能是明智的。
- en: Whichever tools you choose to record metrics from your applications and from
    the cluster and the underlying infrastructure, you should think carefully about
    how to make it simple for members of your organization who are responsible for
    developing and deploying applications to surface their metrics. As part of planning
    your cluster, try writing the documentation for the procedure to expose metrics
    that should be followed by a developer deploying a new application to your cluster.
    You should aim to keep this process as simple as possible. If you need to automate
    steps of the process and provide default configuration values, you should do so
    in order to make the process simple. If the process of exporting new metrics from
    your applications is complex or requires lots of manual steps, then it becomes
    less likely that your organization's applications will expose them.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪些工具来记录应用程序、集群和基础设施的指标，您都应该仔细考虑如何使负责开发和部署应用程序的组织成员能够轻松地展示他们的指标。作为规划集群的一部分，尝试编写公开指标的流程文档，该文档应该由部署新应用程序到您的集群的开发人员遵循。您应该尽量使这个过程尽可能简单。如果需要自动化流程的步骤并提供默认配置值，您应该这样做以使流程简单化。如果从应用程序中导出新指标的过程复杂或需要大量手动步骤，那么您的组织的应用程序暴露它们的可能性就会降低。
- en: 'If the process is simple and friction-free, it becomes much simpler to instill
    a culture of monitoring by default. If, for example, you choose to use Prometheus,
    you might document the process like this:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流程简单且无摩擦，那么通过默认监控文化变得更加简单。例如，如果您选择使用Prometheus，您可以像这样记录流程：
- en: '`*` expose an endpoint `/metrics` on port `9102`'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '* 在端口`9102`上暴露一个端点`/metrics`'
- en: 'Add the annotation `"prometheus.io/scrape": true` to your pod'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '向您的pod添加注释`"prometheus.io/scrape": true`'
- en: In this example, by configuring Prometheus with sensible defaults, exposing
    metrics from a pod becomes quick and simple for a developer. It is possible to
    expose more complex configuration for the way that Prometheus will scrape metrics,
    but by using well-known default values, it makes the setup process simpler and
    makes it simpler to include a standard Prometheus library in the application.
    Whatever system you choose to use to collect metrics, try to follow these principles
    wherever possible.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，通过配置具有合理默认值的Prometheus，从pod中暴露指标对于开发人员来说变得快速简单。可以暴露更复杂的配置方式，以便Prometheus抓取指标，但是通过使用众所周知的默认值，可以使设置过程更简单，并且可以更容易地在应用程序中包含标准的Prometheus库。无论您选择使用哪种系统来收集指标，尽量在可能的情况下遵循这些原则。
- en: Collecting metrics directly from application pods and the infrastructure provides
    deep and rich information about how your application is behaving. This information
    is very useful when you need to know specifics about the application and can be
    very useful for pre-empting issues. For example, metrics about disk usage could
    be used to provide alerts that warn operators about a state that could lead to
    an application failure if not addressed.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 直接从应用程序pod和基础设施收集指标可以提供有关应用程序行为的深入丰富的信息。当您需要了解应用程序的具体信息时，这些信息非常有用，并且在预防问题方面非常有用。例如，关于磁盘使用情况的指标可以用于提供警报，警告操作员有可能导致应用程序失败的状态。
- en: Blackbox monitoring
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 黑匣子监控
- en: Whilst application-specific metrics provide deep insight that is useful for
    root cause analysis and pre-emptive alerting, Blackbox monitoring takes the opposite
    approach. By treating the application as a sealed entity, and exercising user-facing
    endpoints, you can surface the symptoms of a badly performing application. Blackbox
    monitoring can be implemented by using a tool such as the Prometheus Blackbox
    exporter. But another common pattern is to use a commercial service. The main
    advantage of this is that they typically allow you to probe applications from
    a number of locations, perhaps globally, truly exercising the full stack of infrastructure
    between your users and your applications.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然特定于应用程序的指标提供了有用的根本原因分析和预警洞察，但黑匣子监控采取了相反的方法。通过将应用程序视为封闭实体，并执行面向用户的端点，您可以展现性能不佳的应用程序的症状。黑匣子监控可以通过使用诸如Prometheus
    Blackbox导出器之类的工具来实现。但另一个常见的模式是使用商业服务。其主要优势在于它们通常允许您从多个位置（也许是全球范围内）探测应用程序，真正地在用户和应用程序之间的完整基础设施堆栈上进行探测。
- en: Alerting
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警报
- en: Recording metrics about the state of the systems you are running on Kubernetes
    is the first stage of making your systems simple to observe. Once you have collected
    your metrics there are several ways to make the data you collect simple to act
    upon.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 记录关于在Kubernetes上运行的系统状态的指标是使您的系统易于观察的第一阶段。收集了指标之后，有几种方法可以使您收集的数据易于采取行动。
- en: Most metrics collection tools offer some way to build graphs and dashboards
    for the metrics that are important to different members of your organization.
    For example, many users of Prometheus use Grafana to build dashboards to expose
    important metrics.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数指标收集工具都提供了一些方法来为组织中不同成员重要的指标构建图形和仪表板。例如，许多Prometheus用户使用Grafana构建仪表板来公开重要的指标。
- en: Whilst a dashboard is a good way to get an idea of how a particular system or
    business process is performing, there are aspects of your system that need a more
    proactive approach.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然仪表板是了解特定系统或业务流程的表现的好方法，但你的系统有一些方面需要更主动的方法。
- en: 'Any metrics-gathering system worth its salt will offer a way to emit alerts
    to members of your organization. However, when you gather metrics and whatever
    system you use to send alerts to your team, there are a few principles you should
    consider:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 任何值得一试的度量收集系统都会提供一种向组织成员发出警报的方式。然而，当你收集度量和使用任何系统向团队发送警报时，有一些原则你应该考虑：
- en: '**Alerts should be actionable**: When promoting a metric from a graph or gauge
    on a dashboard to an alert, make sure you only send alerts for states that need
    immediate human intervention, not merely warnings or information. Warnings or
    informational alerts belong on your dashboards, not on your pager.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报应该是可执行的**：当将仪表板上的图表或仪表上的度量提升为警报时，确保只对需要立即人工干预的状态发送警报，而不仅仅是警告或信息。警告或信息性警报应该出现在你的仪表板上，而不是在你的寻呼机上。'
- en: '**Alerts should be used sparingly**: Alerts interrupt people from whatever
    they are doing at that moment: working, resting, or, worst of all, sleeping. If
    a person receives too many alerts they can be a cause of stress, and quickly become
    less effective as alert fatigue sets in and they lose their attention-grabbing
    power. When designing an alerting mechanism, you should make provision to record
    how often members of your organization are interrupted by your alerting.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报应该节制使用**：警报会打断人们当前正在做的事情：工作、休息，甚至最糟糕的是睡觉。如果一个人收到太多的警报，它们可能会成为压力的原因，并且在警报疲劳设置并且失去吸引注意力的力量。在设计警报机制时，你应该考虑记录你的组织成员被你的警报打断的频率。'
- en: Alerts should be directed—you should think about who should be responsible for
    a particular alert and direct it appropriately. Alerts can be directed to a number
    of systems, such as bug trackers, emails, chat systems, and even pager applications.
    It is important that the person who receives the most mission-critical alerts
    from your organization is in a position to take ownership and manage a response.
    Less important alerts might be assigned to a team or group in a bug tracking tool.
    If your organization makes use of a chat system, such as Slack, HipChat, or IRC,
    you might want to direct alerts for a particular application to a channel or room
    used by the team that develops or is responsible for the operation of that application.
    Just remember to ensure that volumes are kept to an acceptable level or your alerts
    will quickly come to be ignored by the people who need to know about them.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 警报应该是有针对性的——你应该考虑谁应该对特定的警报负责并适当地指导它。警报可以指向多个系统，如bug跟踪器、电子邮件、聊天系统，甚至寻呼应用程序。重要的是，接收组织中最关键的警报的人能够承担责任并管理响应。不太重要的警报可能会分配给bug跟踪工具中的一个团队或组。如果你的组织使用聊天系统，如Slack、HipChat或IRC，你可能希望将特定应用程序的警报指向团队使用的频道或房间，该团队开发或负责该应用程序的运行。只需记住确保保持在可接受的水平，否则你的警报很快就会被需要知道它们的人忽视。
- en: Tracing
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 追踪
- en: Tracing is the youngest member of the observability family and is thus often
    the last one an organization will choose to implement. The idea of a tracing system
    is to measure the time a single request takes to pass through your applications.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 追踪是可观察性家族中最年轻的成员，因此通常是组织选择实施的最后一个。追踪系统的理念是测量单个请求通过你的应用程序所需的时间。
- en: This might not expose any more interesting information than well-configured
    metrics for a monolithic application. But for larger-scale systems with a distributed,
    or *microservices* architecture, where a single request can pass through tens
    or even hundreds of separate processes, tracing can help to pinpoint exactly when
    and where performance issues are occurring.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不会暴露比为单体应用程序配置良好的指标更有趣的信息。但对于具有分布式或*微服务*架构的大规模系统，其中单个请求可能通过数十甚至数百个独立进程，跟踪可以帮助准确定位性能问题发生的时间和地点。
- en: When implementing a system to collect tracing information from your applications,
    you have a number of options.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施从应用程序收集跟踪信息的系统时，您有多种选择。
- en: AWS's built-in solution for tracing includes X-Ray ships with support for Java,
    Go Node.js, Python, Ruby, and .NET applications. For these technologies, adding
    distributed tracing to your applications is simply a question of adding a library
    to your applications and configuring it correctly. [https://aws.amazon.com/xray/](https://aws.amazon.com/xray/).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: AWS的内置跟踪解决方案包括X-Ray，支持Java、Go、Node.js、Python、Ruby和.NET应用程序。对于这些技术，向您的应用程序添加分布式跟踪只是向应用程序添加库并正确配置的问题。[https://aws.amazon.com/xray/](https://aws.amazon.com/xray/)。
- en: Competing with AWS's solution is a number of tools that are designed to work
    together under the OpenTracing banner.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 与AWS的解决方案竞争的是一些旨在在OpenTracing旗帜下共同工作的工具。
- en: OpenTracing provides client libraries for nine languages that are compatible
    with nine different open source and commercial tools designed to collect trace
    data. Because of the open nature of OpenTracing, several application frameworks,
    and infrastructure components, are choosing to add support for its trace format.
    You can find out more about OpenTracing at [http://opentracing.io](http://opentracing.io).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTracing为九种语言提供了客户端库，这些库与九种不同的开源和商业工具兼容，旨在收集跟踪数据。由于OpenTracing的开放性质，一些应用程序框架和基础设施组件选择添加对其跟踪格式的支持。您可以在[http://opentracing.io](http://opentracing.io)了解更多关于OpenTracing的信息。
- en: Summary
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter has, hopefully, given you an idea of the myriad different options
    and decisions you can make when deciding to run Kubernetes in a production environment.
    Don't let the depth and breadth of the options and choices to make put you off,
    as Kubernetes is remarkably easy to get started with, especially on AWS.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 本章希望能让您了解在决定在生产环境中运行Kubernetes时，您可以做出的多种不同选项和决策。不要因为选项和选择的深度和广度而却步，因为Kubernetes非常容易上手，特别是在AWS上。
- en: In the next chapter, we will move to the practical work of getting a cluster
    set up and ready for work. We won't be able to cover all of the options, let alone
    all of the add-ons and additional tools that the community around Kubernetes has
    produced, but we will provide a stable starting point from which you can begin
    to implement your own plans.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始实际工作，设置集群并准备开始工作。我们不可能涵盖所有选项，更不用说Kubernetes周围社区制作的所有附加组件和附加工具，但我们将提供一个稳定的起点，让您可以开始实施自己的计划。
- en: Hopefully, this chapter will serve as a guide for you and your team to discuss
    and plan a cluster that meets the needs of your organization. You can then start
    to implement the features and functionality that you may have identified while
    reading this chapter.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 希望本章能为您和您的团队提供一个指南，讨论和规划满足您组织需求的集群。然后，您可以开始实施在阅读本章时可能确定的功能和功能。
- en: 'If there is one single thing to remember when launching your own cluster: keep
    it simple, silly. Kubernetes makes it simple to add new tools to your arsenal
    whenever you need, so don''t over-complicate or over-engineer too fast. Start
    with the simplest setup that can possibly work, even if you think you need to
    add complexity later; often, you will discover that the simple solution works
    just fine.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在启动自己的集群时有一件事要记住：保持简单，傻瓜。 Kubernetes使您能够在需要时轻松向您的工具库中添加新工具，因此不要过于复杂或过快地过度设计。从可能起作用的最简单设置开始，即使您认为需要稍后添加复杂性；通常，您会发现简单的解决方案完全有效。
- en: Take advantage of the fact that Kubernetes itself will allow you to rapidly
    evolve your infrastructure, and start small and add features and tools to your
    system when you need them, and not before!
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 利用Kubernetes本身的优势，它将允许您快速发展基础设施，从小处开始，需要时再添加功能和工具到系统中，而不是提前添加！
