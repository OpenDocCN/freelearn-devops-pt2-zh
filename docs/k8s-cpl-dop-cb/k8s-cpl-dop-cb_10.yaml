- en: Logging with Kubernetes
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kubernetes记录日志
- en: In this chapter, we will discuss cluster logging for Kubernetes clusters. We
    will talk about setting up a cluster to ingest logs, as well as how to view them
    using both self-managed and hosted solutions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论Kubernetes集群的集群日志记录。我们将讨论如何设置集群以摄取日志，以及如何使用自管理和托管解决方案查看日志。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下配方：
- en: Accessing Kubernetes logs locally
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地访问Kubernetes日志
- en: Accessing application-specific logs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问特定应用程序的日志
- en: Building centralized logging in Kubernetes using the EFK stack
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes中使用EFK堆栈构建集中式日志记录
- en: Logging with Kubernetes using Google Stackdriver
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Stackdriver在Kubernetes中记录日志
- en: Using a managed Kubernetes logging service
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用托管的Kubernetes日志记录服务
- en: Logging for your Jenkins CI/CD environment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的Jenkins CI/CD环境记录日志
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The recipes in this chapter expect you to have a functional Kubernetes cluster
    deployed by following one of the recommended methods described in [Chapter 1](a8580410-3e1c-4e28-8d18-aaf9d38d011f.xhtml),
    *Building Production-Ready Kubernetes Clusters*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的配方期望您已通过遵循[第1章](a8580410-3e1c-4e28-8d18-aaf9d38d011f.xhtml)中描述的建议方法之一部署了功能齐全的Kubernetes集群，*构建生产就绪的Kubernetes集群*。
- en: The *Logging for your Jenkins CI/CD environment* recipe in this chapter expects
    you to have a functional Jenkins server with an existing CI pipeline created by
    following one of the recommended methods described in [Chapter 3](811c24c7-debf-4487-91e9-81db1520c0aa.xhtml),
    *Building CI/CD Pipelines.*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的*为您的Jenkins CI/CD环境记录日志*配方期望您已通过遵循[第3章](811c24c7-debf-4487-91e9-81db1520c0aa.xhtml)中描述的建议方法之一创建了具有现有CI流水线的功能齐全的Jenkins服务器，*构建CI/CD流水线*。
- en: The Kubernetes command-line tool `kubectl` will be used for the rest of the
    recipes in this chapter since it's the main command-line interface for running
    commands against Kubernetes clusters. We will also use `helm` where Helm charts
    are available in order to deploy solutions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的本章配方将使用Kubernetes命令行工具`kubectl`，因为它是针对Kubernetes集群运行命令的主要命令行界面。我们还将使用`helm`，在部署解决方案时提供Helm图表。
- en: Accessing Kubernetes logs locally
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地访问Kubernetes日志
- en: In Kubernetes, logs can be used for debugging and monitoring activities to a
    certain level. Basic logging can be used to detect configuration problems, but
    for cluster-level logging, an external backend is required to store and query
    logs. Cluster-level logging will be covered in the *Building centralized logging
    in Kubernetes using the EFK stack* and *Logging Kubernetes using Google Stackdriver*
    recipes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，日志可用于调试和监视活动到一定程度。基本日志记录可用于检测配置问题，但对于集群级别的日志记录，需要外部后端来存储和查询日志。集群级别的日志记录将在*使用EFK堆栈构建Kubernetes中的集中式日志记录*和*使用Google
    Stackdriver记录Kubernetes*配方中进行介绍。
- en: In this section, we will learn how to access basic logs based on the options
    that are available in Kubernetes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何根据Kubernetes中可用的选项访问基本日志。
- en: Getting ready
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Clone the `k8sdevopscookbook/src` repository to your workstation to use the
    manifest files in the `chapter10` directory, as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将`k8sdevopscookbook/src`存储库克隆到您的工作站，以便在`chapter10`目录中使用清单文件，方法如下：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Make sure you have a Kubernetes cluster ready and `kubectl` and `helm` configured
    to manage the cluster resources.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已准备好Kubernetes集群，并配置了`kubectl`和`helm`来管理集群资源。
- en: How to do it…
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'This section is further divided into the following subsections to make this
    process easier:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本节进一步分为以下子节，以使此过程更加简单：
- en: Accessing logs through Kubernetes
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Kubernetes访问日志
- en: Debugging services locally using Telepresence
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Telepresence在本地调试服务
- en: Accessing logs through Kubernetes
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过Kubernetes访问日志
- en: This recipe will take you through how to access Kubernetes logs and debug services
    locally.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个步骤将带你了解如何访问Kubernetes日志并在本地调试服务。
- en: 'Let''s perform the following steps to view logs by using the various options
    that are available in Kubernetes:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用Kubernetes中提供的各种选项来执行以下步骤来查看日志：
- en: 'Get the list of pods running in the `kube-system` namespace. The pods running
    in this namespace, especially `kube-apiserver`, `kube-controller-manager`, `kube-dns`,
    and `kube-scheduler`, play a critical role in the Kubernetes control plane:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取在`kube-system`命名空间中运行的pod列表。在这个命名空间中运行的pod，特别是`kube-apiserver`、`kube-controller-manager`、`kube-dns`和`kube-scheduler`，在Kubernetes控制平面中扮演着关键的角色。
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'View the logs from a pod with a single container in the `kube-system` namespace.
    In this example, this pod is `kube-apiserver`. Replace the pod''s name and repeat
    this for the other pods as needed:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在`kube-system`命名空间中具有单个容器的pod的日志。在这个例子中，这个pod是`kube-apiserver`。替换pod的名称，并根据需要重复这个步骤。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As shown in the preceding output, you can find the time, source, and a short
    explanation of the event in the logs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，你可以在日志中找到事件的时间、来源和简短的解释。
- en: The output of the logs can become long, though most of the time all you need
    is the last few events in the logs. If you don't want to get all the logs since
    you only need the last few events in the log, you can add `-tail` to the end of
    the command, along with the number of lines you want to look at. For example, `kubectl
    logs <podname> -n <namespace> -tail 10` would return the last 10 lines. Change
    the number as needed to limit the output.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 日志的输出可能会变得很长，尽管大多数情况下你只需要查看日志中的最后几个事件。如果你不想获取所有的日志，而只需要查看日志中的最后几个事件，你可以在命令的末尾添加`-tail`，并指定你想要查看的行数。例如，`kubectl
    logs <podname> -n <namespace> -tail 10`将返回最后10行。根据需要更改数字以限制输出。
- en: 'Pods can contain multiple containers. When you list the pods, the numbers under
    the `Ready` column show the number of containers inside the pod. Let''s view a
    specific container log from a pod with multiple containers in the `kube-system`
    namespace. Here, the pod we''re looking at is called `kube-dns`. Replace the pod''s
    name and repeat this for any other pods with multiple containers:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pods可以包含多个容器。当你列出pod时，`Ready`列下的数字显示了pod内的容器数量。让我们从`kube-system`命名空间中的一个包含多个容器的pod中查看特定容器的日志。在这里，我们要查看的pod叫做`kube-dns`。替换pod的名称，并根据需要重复这个步骤。
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To view the logs after a specific time, use the `--since-time` parameter with
    a date, similar to what can be seen in the following code. You can either use
    an absolute time or request a duration. Only the logs after the specified time
    or within the duration will be displayed:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看特定时间之后的日志，请使用`--since-time`参数加上一个日期，类似于下面的代码中所示。你可以使用绝对时间或请求一个持续时间。只有在指定时间之后或在持续时间内的日志才会被显示。
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Instead of pod names, you can also view logs by label. Here, we''re listing
    pods using the `k8s-app=kube-dns` label. Since the pod contains multiple containers,
    we can use the `-c kubedns` parameter to set the target container:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了pod名称，你还可以按标签查看日志。在这里，我们使用`k8s-app=kube-dns`标签列出pod。由于pod包含多个容器，我们可以使用`-c
    kubedns`参数来设置目标容器。
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If the container has crashed or restarted, we can use the `-p` flag to retrieve
    logs from a previous instantiation of a container, as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果容器崩溃或重新启动，我们可以使用`-p`标志来从容器的先前实例中检索日志，如下所示：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now you know how to access pod logs through Kubernetes.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何通过Kubernetes访问pod日志了。
- en: Debugging services locally using Telepresence
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Telepresence在本地调试服务
- en: When a build fails in your CI pipeline or a service running in a staging cluster
    contains a bug, you may need to run the service locally to troubleshoot it properly.
    However, applications depend on other applications and services on the cluster;
    for example, a database. Telepresence helps you run your code locally, as a normal
    local process, and then forwards requests to the Kubernetes cluster. This recipe
    will show you how to debug services locally while running a local Kubernetes cluster.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当CI流水线中的构建失败或在暂存集群中运行的服务包含错误时，您可能需要在本地运行服务以正确排除故障。但是，应用程序依赖于集群中的其他应用程序和服务；例如，数据库。Telepresence帮助您在本地运行代码，作为正常的本地进程，然后将请求转发到Kubernetes集群。本教程将向您展示如何在本地运行本地Kubernetes集群时调试服务。
- en: 'Let''s perform the following steps to view logs through the various options
    that are available in Kubernetes:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤，通过Kubernetes中可用的各种选项查看日志：
- en: 'On **OSX**, install the Telepresence binary using the following command:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**OSX**上，使用以下命令安装Telepresence二进制文件：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'On **Windows**, use Ubuntu on the **Windows Subsystem for Linux** (**WSL**).
    Then, on **Ubuntu**, download and install the Telepresence binary using the following
    command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Windows**上，使用**Windows子系统Linux**（**WSL**）上的Ubuntu。然后，在**Ubuntu**上，使用以下命令下载并安装Telepresence二进制文件：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, create a deployment of your application. Here, we''re using a `hello-world`
    example:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建您的应用程序的部署。在这里，我们使用一个`hello-world`示例：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Expose the service using an external `LoadBalancer` and get the service IP:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用外部`LoadBalancer`公开服务并获取服务IP：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To be able to query the address, store the address in a variable using the
    following command:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要能够查询地址，请使用以下命令将地址存储在变量中：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Send a query to the service. This will return a `Hello, world!` message similar
    to the following:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向服务发送查询。这将返回类似于以下内容的`Hello, world!`消息：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we will create a local web service and replace the Kubernetes service
    `hello-world` message with the local web server service. First, create a directory
    and a file to be shared using the HTTP server:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个本地Web服务，并将Kubernetes服务`hello-world`的消息替换为本地Web服务器服务。首先，创建一个目录和一个文件，以便使用HTTP服务器共享：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a web server and expose the service through port `8000` using the following
    command:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Web服务器，并使用以下命令通过端口`8000`公开服务：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding command will start a proxy using the `vpn-tcp` method. Other methods
    can be found in the *Full list of Telepresence methods* link in the *See also*
    section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将使用`vpn-tcp`方法启动代理。其他方法可以在*参见*部分的*Telepresence方法完整列表*链接中找到。
- en: When a service is exposed over the network, remember that your computer is exposed
    to all the risks of running a web server. When you expose a web service using
    the commands described here, make sure that you don't have any important files
    in the `/tmp/local-test` directory that you don't want to expose externally.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务通过网络公开时，请记住您的计算机面临运行Web服务器的所有风险。当您使用此处描述的命令公开Web服务时，请确保您的`/tmp/local-test`目录中没有任何重要文件不希望外部公开。
- en: 'Send a query to the service. You will see that queries to the `hello-world`
    Service will be forwarded to your local web server:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向服务发送查询。您将看到对`hello-world`服务的查询将被转发到您的本地Web服务器：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: To end the local service, use the `fg` command to bring the background Telepresence
    job in the current shell environment into the foreground. Then, use the *Ctrl*
    + *C* keys to exit it.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要结束本地服务，请使用`fg`命令将当前shell环境中的后台Telepresence作业移到前台。然后，使用*Ctrl* + *C*键退出它。
- en: How it works...
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, you learned how to access logs and debug service problems locally.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，您学会了如何在本地访问日志并调试服务问题。
- en: In the *Debugging services locally using Telepresence* recipe, in *Step 7*, we
    ran the `telepresence --swap-deployment` command to replace the service with a
    local web service.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用Telepresence在本地调试服务*食谱中，在*步骤7*中，我们运行了`telepresence --swap-deployment`命令，用本地web服务替换了服务。
- en: Telepresence functions by building a two-way network proxy. The `--swap-deployment`
    flag is used to define the pod that will be replaced with a proxy pod on the cluster.
    Telepresence starts a `vpn-tcp` process to send all requests to the locally exposed
    port, that is, `8000`. The `--run python3 -m http.server 8000 &` flag tells Telepresence
    to run an `http.server` using Python 3 in the background via port `8000`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Telepresence通过构建双向网络代理来工作。`--swap-deployment`标志用于定义将在集群上用代理pod替换的pod。Telepresence启动`vpn-tcp`进程将所有请求发送到本地公开的端口，即`8000`。`--run
    python3 -m http.server 8000 &`标志告诉Telepresence在后台通过端口`8000`运行Python 3中的`http.server`。
- en: In the same recipe, in *Step 9*, the `fg` command is used to move the background
    service to the foreground. When you exit the service, the old pod will be restored.
    You can learn about how Telepresence functions by looking at the *How Telepresence
    works* link in the *See also* section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一食谱中，在*步骤9*中，使用`fg`命令将后台服务移至前台。当您退出服务时，旧的pod将被恢复。您可以通过查看*查看*部分中的*Telepresence工作原理*链接来了解Telepresence的功能。
- en: See also
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '`kubectl` log commands: [https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`日志命令：[https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)'
- en: Telepresence source code repository: [https://github.com/telepresenceio/telepresence](https://github.com/telepresenceio/telepresence)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程呈现源代码存储库：[https://github.com/telepresenceio/telepresence](https://github.com/telepresenceio/telepresence)
- en: 'Full list of Telepresence methods: [https://telepresence.io/reference/methods.html](https://telepresence.io/reference/methods.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Telepresence方法的完整列表：[https://telepresence.io/reference/methods.html](https://telepresence.io/reference/methods.html)
- en: 'How Telepresence works: [https://www.telepresence.io/discussion/how-it-works](https://www.telepresence.io/discussion/how-it-works)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Telepresence的工作原理：[https://www.telepresence.io/discussion/how-it-works](https://www.telepresence.io/discussion/how-it-works)
- en: 'How to use volume access support with Telepresence: [https://telepresence.io/howto/volumes.html](https://telepresence.io/howto/volumes.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用Telepresence支持卷访问：[https://telepresence.io/howto/volumes.html](https://telepresence.io/howto/volumes.html)
- en: Accessing application-specific logs
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问特定应用程序的日志
- en: In Kubernetes, pod and deployment logs that are related to how pods and containers
    are scheduled can be accessed through the `kubectl logs` command, but not all
    application logs and commands are exposed through Kubernetes APIs. Getting access
    to these logs and shell commands inside a container may be required.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，与调度pod和容器相关的日志可以通过`kubectl logs`命令访问，但并非所有应用程序日志和命令都通过Kubernetes
    API公开。可能需要访问容器内部的这些日志和shell命令。
- en: In this section, we will learn how to access a container shell, extract logs,
    and update binaries for troubleshooting.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何访问容器shell，提取日志和更新二进制文件以进行故障排除。
- en: Getting ready
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Clone the `k8sdevopscookbook/src` repository to your workstation to use the
    manifest files under the `chapter10` directory, as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将`k8sdevopscookbook/src`存储库克隆到您的工作站，以便在`chapter10`目录下使用清单文件，如下所示：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Make sure you have a Kubernetes cluster ready and `kubectl` configured to manage
    the cluster resources.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已准备好Kubernetes集群，并配置了`kubectl`以管理集群资源。
- en: How to do it…
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤…
- en: 'This section is further divided into the following subsections to make this
    process easier:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本节进一步分为以下小节，以使此过程更加简单：
- en: Getting shell access in a container
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在容器中获取shell访问权限
- en: Accessing PostgreSQL logs inside a container
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在容器内访问PostgreSQL日志
- en: Getting shell access in a container
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在容器中获取shell访问权限
- en: 'Let''s perform the following steps to create a deployment with multiple containers
    and get a shell into running containers:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来创建一个具有多个容器的部署，并进入正在运行的容器的shell：
- en: 'In this recipe, we will deploy PostgreSQL on OpenEBS persistent volumes to
    demonstrate shell access. Change the directory to the example files directory
    in `src/chapter10/postgres`, which is where all the YAML manifest for this recipe
    are stored. Create a `ConfigMap` with a database name and credentials similar
    to the following or review them and use the `cm-postgres.yaml` file:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本教程中，我们将在OpenEBS持久卷上部署PostgreSQL，以演示shell访问。将目录更改为`src/chapter10/postgres`中的示例文件目录，其中存储了此教程的所有YAML清单。创建一个`ConfigMap`，其中包含与以下类似的数据库名称和凭据，或者查看它们并使用`cm-postgres.yaml`文件：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create the service for `postgres`:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`postgres`创建服务：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Review the `postgres.yaml` file and apply it to create the PostgreSQL StatefulSet.
    We can use this to deploy the pods and to auto-create the PV/PVC:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`postgres.yaml`文件并应用它以创建PostgreSQL StatefulSet。我们可以使用它来部署pod并自动创建PV/PVC：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Get the pods with the `postgres` label:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取具有`postgres`标签的pod：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Get a shell into the `postgres-0` container:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入`postgres-0`容器的shell：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The preceding command will get you shell access to the running container.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将使您可以访问正在运行的容器的shell。
- en: Accessing PostgreSQL logs inside a container
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在容器内访问PostgreSQL日志
- en: 'Let''s perform the following steps to get the logs from the application running
    inside a container:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来从容器内运行的应用程序获取日志：
- en: 'While you are in a shell, connect to the PostgreSQL database named `postgresdb`
    using the username `testuser`. You will see the PostgreSQL prompt, as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您在shell中时，使用用户名`testuser`连接到名为`postgresdb`的PostgreSQL数据库。您将看到以下内容的PostgreSQL提示：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'While on the PostgreSQL prompt, use the following command to create a table
    and add some data to it:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在PostgreSQL提示符上，使用以下命令创建一个表并向其中添加一些数据：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Get the log''s configuration details from`postgresql.conf`. You will see that
    the logs are stored in the `/var/log/postgresql` directory:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`postgresql.conf`获取日志配置详细信息。您将看到日志存储在`/var/log/postgresql`目录中：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'List and access the logs in the `/var/log/postgresql` directory:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出并访问`/var/log/postgresql`目录中的日志：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Optionally, while you''re inside the container, you can create a backup of
    our example `postgresdb` database in the `tmp` directory using the following command:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在容器内部，您可以选择在`tmp`目录中创建我们示例的`postgresdb`数据库的备份，使用以下命令：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: With that, you have learned how to get shell access into a container and how
    to access the locally stored logs and files inside the container.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，您已经学会了如何在容器中获取shell访问权限以及如何访问容器内部的本地存储的日志和文件。
- en: Building centralized logging in Kubernetes using the EFK stack
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用EFK堆栈在Kubernetes中构建集中式日志记录
- en: As described in the the *Accessing Kubernetes logs locally* section, basic logging
    can be used to detect configuration problems, but for cluster-level logging, an
    external backend is required to store and query logs. A cluster-level logging
    stack can help you quickly sort through and analyze the high volume of production
    log data that's produced by your application in the Kubernetes cluster. One of
    the most popular centralized logging solutions in the Kubernetes ecosystem is
    the **Elasticsearch, Logstash, and Kibana** (**ELK**) stack.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如*在本地访问Kubernetes日志*部分所述，基本日志记录可用于检测配置问题，但对于集群级别的日志记录，需要外部后端来存储和查询日志。集群级别的日志记录堆栈可以帮助您快速整理和分析Kubernetes集群中应用程序产生的大量生产日志数据。Kubernetes生态系统中最受欢迎的集中式日志记录解决方案之一是**Elasticsearch，Logstash和Kibana**（**ELK**）堆栈。
- en: In the ELK stack, Logstash is used as the log collector. Logstash uses slightly
    more memory than Fluent Bit, which is a low-footprint version of Fluentd. Therefore,
    in this recipe, we will use the **Elasticsearch, Fluent-bit, and Kibana** (**EFK**)
    stack. If you have an application that has Logstash dependencies, you can always
    replace Fluentd/Fluent Bit with Logstash.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在ELK堆栈中，Logstash用作日志收集器。Logstash使用的内存略多于Fluent Bit，后者是Fluentd的低内存版本。因此，在本教程中，我们将使用Elasticsearch、Fluent-bit和Kibana
    (EFK)堆栈。如果您的应用程序具有Logstash依赖项，您可以随时用Logstash替换Fluentd/Fluent Bit。
- en: In this section, we will learn how to build a cluster-level logging system using
    the EFK stack to manage Kubernetes logs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用EFK堆栈构建集群级别的日志系统来管理Kubernetes日志。
- en: Getting ready
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Clone the `k8sdevopscookbook/src` repository to your workstation to use the
    manifest files in the `chapter10` directory, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 将k8sdevopscookbook/src存储库克隆到您的工作站，以便在chapter10目录中使用清单文件：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Make sure you have a Kubernetes cluster ready and `kubectl` and `helm` configured
    to manage the cluster resources.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已准备好一个Kubernetes集群，并配置了kubectl和helm来管理集群资源。
- en: How to do it…
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤…
- en: 'This section will show you how to configure an EFK stack on your Kubernetes
    cluster. This section is further divided into the following subsections to make
    this process easier:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将向您展示如何在Kubernetes集群上配置EFK堆栈。本节进一步分为以下子节，以使此过程更加简单：
- en: Deploying Elasticsearch Operator
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Elasticsearch Operator
- en: Requesting an Elasticsearch endpoint
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求Elasticsearch端点
- en: Deploying Kibana
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Kibana
- en: Aggregating logs with Fluent Bit
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Fluent Bit聚合日志
- en: Accessing Kubernetes logs on Kibana
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问Kibana上的Kubernetes日志
- en: Deploying Elasticsearch Operator
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署Elasticsearch Operator
- en: Elasticsearch is a highly scalable open source full-text search and analytics
    engine. Elasticsearch allows you to store, search, and analyze big volumes of
    data quickly. In this recipe, we will use it to store Kubernetes logs.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。Elasticsearch允许您快速存储、搜索和分析大量数据。在本教程中，我们将使用它来存储Kubernetes日志。
- en: 'Let''s perform the following steps to get **Elastic Cloud on Kubernetes** (**ECK**) deployed:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来部署Elastic Cloud on Kubernetes (ECK)：
- en: 'Deploy Elasticsearch Operator and its CRDs using the following command:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用以下命令部署Elasticsearch Operator及其CRD： '
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Elasticsearch Operator will create its own **CustomResourceDefinition** (**CRD**).
    We will use this CRD later to deploy and manage Elasticsearch instances on Kubernetes.
    List the new CRDs using the following command:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Elasticsearch Operator将创建自己的CustomResourceDefinition (CRD)。我们将在后面使用此CRD来在Kubernetes上部署和管理Elasticsearch实例。使用以下命令列出新的CRD：
- en: '[PRE29]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create a new namespace called `logging`:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为logging的新命名空间：
- en: '[PRE30]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Create Elasticsearch using the default parameters in the `logging` namespace
    using the following command:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在logging命名空间中使用默认参数创建Elasticsearch：
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Get the status of the Elasticsearch nodes:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取Elasticsearch节点的状态：
- en: '[PRE32]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can also confirm the pod''s status in the logging namespace using the following
    command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您还可以使用以下命令确认logging命名空间中pod的状态：
- en: '[PRE33]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'A three-node Elasticsearch cluster will be created. By default, the nodes we
    created here are all of the following types: master-eligible, data, and ingest.
    As your Elasticsearch cluster grows, it is recommended to create dedicated master-eligible,
    data, and ingest nodes.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将创建一个三节点的Elasticsearch集群。默认情况下，我们在这里创建的节点都是以下类型：可选主节点、数据节点和摄取节点。随着Elasticsearch集群的增长，建议创建专用的可选主节点、数据节点和摄取节点。
- en: Requesting the Elasticsearch endpoint
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 请求Elasticsearch端点
- en: When an Elasticsearch cluster is created, a default user password is generated
    and stored in a Kubernetes secret. You will need the full credentials to request
    the Elasticsearch endpoint.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Elasticsearch集群时，将生成并存储默认用户密码在Kubernetes秘密中。您需要完整的凭据来请求Elasticsearch端点。
- en: 'Let''s perform the following steps to request Elasticsearch access:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来请求Elasticsearch访问：
- en: 'Get the password that was generated for the default `elastic` user:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取为默认`elastic`用户生成的密码：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Request the Elasticsearch endpoint address:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求Elasticsearch端点地址：
- en: '[PRE35]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'If you are accessing the Kubernetes cluster remotely, you can create a port-forwarding
    service and use localhost, similar to what can be seen in the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您远程访问Kubernetes集群，可以创建一个端口转发服务，并使用localhost，类似于以下代码中所示：
- en: '[PRE36]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now, we have access to our three-node small Elasticsearch cluster that we deployed
    on Kubernetes. Next, we need to deploy Kibana to complete the stack.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以访问我们在Kubernetes上部署的三节点小型Elasticsearch集群。接下来，我们需要部署Kibana以完成堆栈。
- en: Deploying Kibana
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署Kibana
- en: Kibana is an open source data visualization dashboard that lets you visualize
    your Elasticsearch data.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana是一个开源的数据可视化仪表板，可以让您可视化您的Elasticsearch数据。
- en: 'Let''s perform the following steps to get Kibana deployed:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来部署Kibana：
- en: 'Create a Kibana instance associated with the Elasticsearch cluster we created
    previously:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个与我们之前创建的Elasticsearch集群相关联的Kibana实例：
- en: '[PRE37]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Get the status of the Kibana node:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取Kibana节点的状态：
- en: '[PRE38]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You can also confirm the pod''s status in the logging namespace using the following
    command:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您还可以使用以下命令确认logging命名空间中pod的状态：
- en: '[PRE39]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: With that, you have both Elasticsearch and Kibana nodes deployed. Next, we will
    deploy fluent-bit to forward container logs to our Elasticsearch deployment.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，您已经部署了Elasticsearch和Kibana节点。接下来，我们将部署fluent-bit以将容器日志转发到我们的Elasticsearch部署。
- en: Aggregating logs with Fluent Bit
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Fluent Bit聚合日志
- en: 'Let''s perform the following steps to get fluent-bit deployed:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来部署fluent-bit：
- en: 'Get the password for the default `elastic` user:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取默认`elastic`用户的密码：
- en: '[PRE40]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Copy the output of *Step 1* and edit the `fluent-bit-values.yaml` file in the
    `/src/chapter10/efk` directory. Replace the `http_passwd` value with the output
    of *Step 1* and save the file:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制*步骤1*的输出，并编辑`fluent-bit-values.yaml`文件在`/src/chapter10/efk`目录中。用*步骤1*的输出替换`http_passwd`的值，并保存文件：
- en: '[PRE41]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Deploy fluent-bit using the Helm chart:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Helm图表部署fluent-bit：
- en: '[PRE42]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Confirm the pod''s status in the `logging` namespace using the following command:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令确认`logging`命名空间中pod的状态：
- en: '[PRE43]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: With that, you have deployed all the components of the EFK stack. Next, we will
    connect to the Kibana dashboard.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，您已经部署了EFK堆栈的所有组件。接下来，我们将连接到Kibana仪表板。
- en: Accessing Kubernetes logs on Kibana
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Kibana上访问Kubernetes日志
- en: 'Let''s perform the following steps to connect to the Kibana dashboard:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤来连接到Kibana仪表板：
- en: 'Confirm that the Kibana service has been created. By default, a `ClusterIP`
    service will be created:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认Kibana服务已创建。默认情况下，将创建一个`ClusterIP`服务：
- en: '[PRE44]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Before we connect to the dashboard, get the password for the default `elastic`
    user:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在连接到仪表板之前，获取默认`elastic`用户的密码：
- en: '[PRE45]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Create a port-forwarding service to access the Kibana dashboard from your workstation:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个端口转发服务，以从您的工作站访问Kibana仪表板：
- en: '[PRE46]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Open the Kibana dashboard at `https://localhost:5601` in your browser. Enter
    `elastic` as the username and the password from the output of *Step 2*:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在浏览器中打开`https://localhost:5601`的Kibana仪表板。输入`elastic`作为用户名和*步骤2*的输出中的密码：
- en: '![](assets/57f5d206-05cf-4c26-866b-4a4abc8d4224.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/57f5d206-05cf-4c26-866b-4a4abc8d4224.png)'
- en: 'On the home page, click on the Connect to your Elasticsarch index button, as
    shown in the following screenshot:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主页上，点击“连接到您的Elasticsarch索引”按钮，如下截图所示：
- en: '![](assets/246576ee-7aed-4c0b-9407-9432daf2f360.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/246576ee-7aed-4c0b-9407-9432daf2f360.png)'
- en: 'Kibana will search for Elasticsearch index patterns. Define the index pattern
    that matches your results. In our example, we used `kubernetes_cluster-*`. Click
    on Next step to continue:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kibana将搜索Elasticsearch索引模式。定义与您的结果匹配的索引模式。在我们的示例中，我们使用了`kubernetes_cluster-*`。点击“下一步”继续：
- en: '![](assets/20aad22d-5877-49be-ac1f-732f0ac2ffcb.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/20aad22d-5877-49be-ac1f-732f0ac2ffcb.png)'
- en: 'Specify Time Filter field name as `@timestamp` and click on the Create index
    pattern button, as shown in the following screenshot:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将时间过滤器字段名称指定为`@timestamp`，然后点击“创建索引模式”按钮，如下面的屏幕截图所示：
- en: '![](assets/a15e4da8-853a-4994-a92e-1cf0dd55d416.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a15e4da8-853a-4994-a92e-1cf0dd55d416.png)'
- en: 'Click on the Discover menu. It is the first icon from the top:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“发现”菜单。这是从顶部开始的第一个图标：
- en: '![](assets/f3b5d8a6-33bc-433a-a1e8-66c4faae9bb8.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f3b5d8a6-33bc-433a-a1e8-66c4faae9bb8.png)'
- en: 'On the Discover page, use the search field to look for keywords and filters:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“发现”页面上，使用搜索字段查找关键字和过滤器：
- en: '![](assets/f24da1c3-a9e2-4ee4-8fdc-19a587f8b051.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f24da1c3-a9e2-4ee4-8fdc-19a587f8b051.png)'
- en: 'If the keyword you are looking for can''t be found in the current time frame,
    you need to change the date range by clicking on the calendar icon next to the
    search field and clicking on the Apply button after the new range has been selected:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您要查找的关键字在当前时间范围内找不到，您需要通过点击搜索字段旁边的日历图标并在选择新范围后点击“应用”按钮来更改日期范围：
- en: '![](assets/841f63e3-cc1f-4751-994d-07a55189c6ac.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/841f63e3-cc1f-4751-994d-07a55189c6ac.png)'
- en: With that, you've learned how to configure an EFK stack on your Kubernetes cluster
    in order to manage and visualize cluster-wide logs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，您已经学会了如何在Kubernetes集群上配置EFK堆栈，以便管理和可视化整个集群的日志。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '**Elastic Cloud on Kubernetes** (**ECK**): [https://github.com/elastic/cloud-on-k8s](https://github.com/elastic/cloud-on-k8s)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes上的Elastic Cloud**（**ECK**）：[https://github.com/elastic/cloud-on-k8s](https://github.com/elastic/cloud-on-k8s)'
- en: Deployment instructions on Red Hat OpenShift: [https://www.elastic.co/guide/en/cloud-on-k8s/0.9/k8s-openshift.html](https://www.elastic.co/guide/en/cloud-on-k8s/0.9/k8s-openshift.html)
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Red Hat OpenShift上的部署说明：[https://www.elastic.co/guide/en/cloud-on-k8s/0.9/k8s-openshift.html](https://www.elastic.co/guide/en/cloud-on-k8s/0.9/k8s-openshift.html)
- en: Elasticsearch Service documentation: [https://www.elastic.co/guide/en/cloud/current/index.html](https://www.elastic.co/guide/en/cloud/current/index.html)
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch服务文档：[https://www.elastic.co/guide/en/cloud/current/index.html](https://www.elastic.co/guide/en/cloud/current/index.html)
- en: 'Introduction to Kibana: [https://www.elastic.co/guide/en/kibana/7.4/introduction.html#introduction](https://www.elastic.co/guide/en/kibana/7.4/introduction.html#introduction)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kibana简介：[https://www.elastic.co/guide/en/kibana/7.4/introduction.html#introduction](https://www.elastic.co/guide/en/kibana/7.4/introduction.html#introduction)
- en: Fluentd documentation: [https://docs.fluentd.org/](https://docs.fluentd.org/)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd文档：[https://docs.fluentd.org/](https://docs.fluentd.org/)
- en: Fluent Bit documentation: [https://docs.fluentbit.io/manual/](https://docs.fluentbit.io/manual/)
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluent Bit文档：[https://docs.fluentbit.io/manual/](https://docs.fluentbit.io/manual/)
- en: Rancher Elastic Stack Kubernetes Helm Charts: [https://github.com/rancher/charts/tree/master/charts/efk/v7.3.0](https://github.com/rancher/charts/tree/master/charts/efk/v7.3.0)
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rancher弹性堆栈Kubernetes Helm图表：[https://github.com/rancher/charts/tree/master/charts/efk/v7.3.0](https://github.com/rancher/charts/tree/master/charts/efk/v7.3.0)
- en: Kudo Elastic Operator: [https://github.com/kudobuilder/operators/tree/master/repository/elastic](https://github.com/kudobuilder/operators/tree/master/repository/elastic)
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kudo弹性运算符：[https://github.com/kudobuilder/operators/tree/master/repository/elastic](https://github.com/kudobuilder/operators/tree/master/repository/elastic)
- en: Logging Kubernetes using Google Stackdriver
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google Stackdriver记录Kubernetes
- en: In this section, we will use Google Stackdriver Kubernetes Engine Monitoring
    to monitor, isolate, and diagnose our containerized applications and microservices
    environments. You will learn how to use Stackdriver Kubernetes Engine Monitoring
    to aggregate logs, events, and metrics from your Kubernetes environment on GKE
    to help you understand your application's behavior in production.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用Google Stackdriver Kubernetes Engine监控来监视，隔离和诊断我们的容器化应用程序和微服务环境。您将学习如何使用Stackdriver
    Kubernetes Engine监控来聚合来自GKE上Kubernetes环境的日志，事件和指标，以帮助您了解您的应用在生产环境中的行为。
- en: Getting ready
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Make sure you have a **Google Kubernetes Engine** (**GKE**) cluster ready and `kubectl` configured
    to manage the cluster resources. If you don't have one, you can follow the instructions
    in [Chapter 1](a8580410-3e1c-4e28-8d18-aaf9d38d011f.xhtml),* Building Production-Ready
    Kubernetes Clusters*, in the *Configuring a Kubernetes cluster on Google Cloud
    Platform* recipe.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您有一个准备好的**Google Kubernetes Engine**（**GKE**）集群，并且已经配置了`kubectl`来管理集群资源。如果没有，您可以按照第1章中的说明，*构建生产就绪的Kubernetes集群*，在*在Google云平台上配置Kubernetes集群*教程中进行操作。
- en: How to do it…
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'This section is further divided into the following subsections to make this
    process easier:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分进一步分为以下小节，以使这个过程更容易：
- en: Installing Stackdriver Kubernetes Engine Monitoring support for GKE
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为GKE安装Stackdriver Kubernetes Engine监控支持
- en: Configuring a workspace on Stackdriver
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Stackdriver上配置工作空间
- en: Viewing GKE logs using Stackdriver
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Stackdriver查看GKE日志
- en: Installing Stackdriver Kubernetes Engine Monitoring support for GKE
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为GKE安装Stackdriver Kubernetes Engine监控支持
- en: 'Installing Stackdriver Monitoring support allows you to easily monitor GKE
    clusters, debug logs, and analyze your cluster''s performance using advanced profiling
    and tracing capabilities. In this recipe, we will enable Stackdriver Kubernetes
    Engine Monitoring support to collect cluster metrics from our GKE cluster. Follow
    these steps:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 启用Stackdriver监控支持可以轻松监控GKE集群，调试日志，并使用高级分析和跟踪功能分析集群的性能。在这个教程中，我们将启用Stackdriver
    Kubernetes Engine监控支持，以从我们的GKE集群收集集群指标。按照以下步骤进行：
- en: 'Open the Google Kubernetes Engine Console at [https://console.cloud.google.com/kubernetes](https://console.cloud.google.com/kubernetes).
    On this console, you will see a list of your GKE clusters. Here, we have one cluster
    called `k8s-devops-cookbook-1`:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Google Kubernetes Engine控制台上打开[https://console.cloud.google.com/kubernetes](https://console.cloud.google.com/kubernetes)。在这个控制台上，您将看到您的GKE集群列表。在这里，我们有一个名为`k8s-devops-cookbook-1`的集群：
- en: '![](assets/372750bc-333a-4cdd-ab51-d170f9ffa7db.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/372750bc-333a-4cdd-ab51-d170f9ffa7db.png)'
- en: 'Click on the little pen-shaped Edit icon next to your cluster:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击集群旁边的小铅笔形状的编辑图标：
- en: '![](assets/90e9bfc2-5ff1-40c6-9b78-c64ef32d9a0f.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/90e9bfc2-5ff1-40c6-9b78-c64ef32d9a0f.png)'
- en: 'On the cluster configuration page, make sure that Legacy Stackdriver Logging and Legacy
    Stackdriver Monitoring are Disabled and that the Stackdriver Kubernetes Engine
    Monitoring option is set to Enabled:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集群配置页面上，确保*Legacy Stackdriver Logging*和*Legacy Stackdriver Monitoring*都为*Disabled*，并且*Stackdriver
    Kubernetes Engine Monitoring*选项设置为*Enabled*：
- en: '![](assets/da27f3de-426d-42ce-b046-90f0487cef2d.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/da27f3de-426d-42ce-b046-90f0487cef2d.png)'
- en: Click on the Save button to apply these changes to your cluster.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击*保存*按钮以将这些更改应用到您的集群上。
- en: Viewing GKE logs using Stackdriver
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Stackdriver查看GKE日志
- en: 'Enabling Stackdriver Monitoring support allows you to easily monitor GKE clusters,
    debug logs, and analyze your cluster performance using advanced profiling and
    tracing capabilities. In this recipe, we will learn how to access the logs of
    our Kubernetes cluster on GKE. Follow these steps:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 启用Stackdriver监控支持可以轻松监控GKE集群，调试日志，并使用高级分析和跟踪功能分析集群性能。在这个教程中，我们将学习如何访问我们在GKE上的Kubernetes集群的日志。按照以下步骤进行：
- en: 'From the Google Cloud Console, open the Stackdriver Logs Viewer by going to [https://console.cloud.google.com/logs/viewer](https://console.cloud.google.com/logs/viewer):'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Google Cloud控制台，通过访问[https://console.cloud.google.com/logs/viewer](https://console.cloud.google.com/logs/viewer)来打开Stackdriver日志查看器：
- en: '![](assets/6dc72aad-e31c-44e4-9f40-34c59a534cf0.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6dc72aad-e31c-44e4-9f40-34c59a534cf0.png)'
- en: 'From the Resources menu, click on the Kubernetes Container option:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从“资源”菜单中，点击“Kubernetes容器”选项：
- en: '![](assets/9c8467a1-d497-49a0-85c7-15ef1ba13ebc.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9c8467a1-d497-49a0-85c7-15ef1ba13ebc.png)'
- en: 'The Stackdriver Logging view will show a list of logs for your container in
    the selected GKE cluster. Here, you can see the container logs for the last 7
    days being displayed:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Stackdriver日志视图将显示所选GKE集群中容器的日志列表。在这里，您可以看到最近7天的容器日志被显示：
- en: '![](assets/fee97f63-b1f8-4adc-8f7a-e3d9da08d347.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/fee97f63-b1f8-4adc-8f7a-e3d9da08d347.png)'
- en: 'Filter the log level to Critical and set the time frame to the Last 24 hours
    to view the most recent critical container logs. An example result can be seen
    in the following screenshot:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将日志级别筛选为关键，并将时间范围设置为“最近24小时”，以查看最近的关键容器日志。可以在以下截图中看到一个示例结果：
- en: '![](assets/79df75ae-3657-4cf5-8fa1-0e75f9f33564.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/79df75ae-3657-4cf5-8fa1-0e75f9f33564.png)'
- en: With that, you know how to use Stackdriver to view logs for GKE clusters and
    resources, such as containers that have been deployed on the GKE clusters.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，您就知道如何使用Stackdriver查看GKE集群和资源的日志，比如部署在GKE集群上的容器。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Google Stackdriver Logging documentation: [https://cloud.google.com/logging/docs](https://cloud.google.com/logging/docs)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Stackdriver日志记录文档：[https://cloud.google.com/logging/docs](https://cloud.google.com/logging/docs)
- en: Basic query example for Stackdriver: [https://cloud.google.com/logging/docs/view/basic-queries](https://cloud.google.com/logging/docs/view/basic-queries)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stackdriver的基本查询示例：[https://cloud.google.com/logging/docs/view/basic-queries](https://cloud.google.com/logging/docs/view/basic-queries)
- en: QuickStart using logging tools: [https://cloud.google.com/logging/docs/quickstart-sdk](https://cloud.google.com/logging/docs/quickstart-sdk)
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用日志记录工具的快速入门：[https://cloud.google.com/logging/docs/quickstart-sdk](https://cloud.google.com/logging/docs/quickstart-sdk)
- en: Stackdriver Logs Router Overview: [https://cloud.google.com/logging/docs/routing/overview](https://cloud.google.com/logging/docs/routing/overview)
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stackdriver日志路由器概述：[https://cloud.google.com/logging/docs/routing/overview](https://cloud.google.com/logging/docs/routing/overview)
- en: Using a managed Kubernetes logging service
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用托管的Kubernetes日志记录服务
- en: Running an EFK stack to store and maintain Kubernetes logs in your cluster is
    useful until something goes wrong with your cluster. It is recommended that you
    keep your log management system and production cluster separate so that you have
    access in case of cluster failure.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群中运行EFK堆栈以存储和维护Kubernetes日志在您的集群中是有用的，直到集群出现问题。建议您将日志管理系统和生产集群分开，以便在集群故障时可以访问。
- en: In this section, we will learn how to use some of the freely available SaaS
    solutions to keep your cluster logs accessible, even if your cluster is not available.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用一些免费的SaaS解决方案，即使您的集群不可用，也可以保持集群日志的可访问性。
- en: Getting ready
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Make sure you have a Kubernetes cluster ready and `kubectl` configured to manage
    the cluster resources.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您有一个准备好的Kubernetes集群，并配置了`kubectl`来管理集群资源。
- en: How to do it…
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'This section is further divided into the following subsections to make this
    process easier:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本节进一步分为以下子节，以使这个过程更容易：
- en: Adding clusters to Director Online
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将集群添加到Director Online
- en: Accessing logs using Director Online
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Director Online访问日志
- en: Connecting clusters to Director Online
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将集群连接到Director Online
- en: 'OpenEBS Director provides a freely managed EFK stack as a SaaS solution so
    that you can store and manage your Kubernetes cluster logs. In this recipe, we
    will add our Kubernetes cluster to the Director SaaS platform to store our logs
    in the cloud:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: OpenEBS Director提供了一个免费的托管EFK堆栈作为SaaS解决方案，这样您就可以存储和管理您的Kubernetes集群日志。在这个教程中，我们将把我们的Kubernetes集群添加到Director
    SaaS平台，以便在云中存储我们的日志：
- en: 'Go to [www.mayadata.io](http://www.mayadata.io) to sign in to your OpenEBS
    Enterprise Platform at [https://portal.mayadata.io/home](https://portal.mayadata.io/home):'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到[www.mayadata.io](http://www.mayadata.io)以登录到您的OpenEBS企业平台，网址为[https://portal.mayadata.io/home](https://portal.mayadata.io/home)：
- en: '![](assets/d4a3025e-de06-4cb0-ac6e-da81930d9252.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d4a3025e-de06-4cb0-ac6e-da81930d9252.png)'
- en: 'Click on the Connect your Cluster button:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击Connect your Cluster按钮：
- en: '![](assets/72a5ebef-10d5-4f86-bb29-ebd844bc5ad7.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/72a5ebef-10d5-4f86-bb29-ebd844bc5ad7.png)'
- en: From the main menu, select Clusters and click on the Connect a new Cluster button.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从主菜单中，选择Clusters并单击Connect a new Cluster按钮。
- en: 'Choose your Kubernetes cluster location and name your project. Here, we''ve
    used an AWS cluster and set `AWSCluster` as our cluster name:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您的Kubernetes集群位置并命名您的项目。在这里，我们使用了一个AWS集群，并将`AWSCluster`设置为我们的集群名称：
- en: '![](assets/7df2b508-c62b-4198-94db-4353fb45f4a5.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7df2b508-c62b-4198-94db-4353fb45f4a5.png)'
- en: 'Copy and execute the command on your first cluster:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的第一个集群上复制并执行以下命令：
- en: '![](assets/94629c7f-7025-4da4-8bb0-b395f86e0c70.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/94629c7f-7025-4da4-8bb0-b395f86e0c70.png)'
- en: Shortly after doing this, Director Online will deploy a fluentd forwarder and
    aggregator on your cluster to collect logs on its platform.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样做后不久，Director Online将在您的集群上部署一个fluentd转发器和聚合器，以便在其平台上收集日志。
- en: Accessing logs using Director Online
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Director Online访问日志
- en: 'OpenEBS Director''s free plan stores cluster logs for up to 1 week. Additional
    storage is provided with the premium plan. In this recipe, we will learn how to
    access logs using the managed EFK stack provided by Director Online:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: OpenEBS Director的免费计划可存储集群日志长达1周。额外的存储空间可通过高级计划获得。在这个教程中，我们将学习如何使用Director Online提供的托管EFK堆栈来访问日志：
- en: Go to [www.mayadata.io](http://www.mayadata.io) to sign in to your OpenEBS Enterprise
    Platform at [https://portal.mayadata.io/home](https://portal.mayadata.io/home).
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到[www.mayadata.io](http://www.mayadata.io)以登录到您的OpenEBS企业平台，网址为[https://portal.mayadata.io/home](https://portal.mayadata.io/home)。
- en: From the home menu, select Clusters and select your active cluster.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从主菜单中，选择Clusters并选择您的活动集群。
- en: 'From the left-hand menu, click on Logs:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧菜单中，单击Logs：
- en: '![](assets/3488a356-52d6-4da6-92a5-d47a83b63887.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3488a356-52d6-4da6-92a5-d47a83b63887.png)'
- en: 'A Logs view will open on the Kibana Discover dashboard. Here, you can use search
    for and filter the functionalities of Elasticsearch and Kibana to manage your
    Kubernetes logs:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kibana Discover仪表板上将打开一个日志视图。在这里，您可以使用Elasticsearch和Kibana的搜索和过滤功能来管理您的Kubernetes日志：
- en: '![](assets/5345e2ed-b058-48c4-b6ea-ef082a5d4e71.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5345e2ed-b058-48c4-b6ea-ef082a5d4e71.png)'
- en: With that, you've learned how to simply keep logs accessible using managed Kubernetes
    logging solutions. You can use Director Online on multiple clusters and manage
    logs from a single interface.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，您已经学会了如何简单地使用托管的Kubernetes日志解决方案保持日志可访问。您可以在多个集群上使用Director Online，并从单个界面管理日志。
- en: Logging for your Jenkins CI/CD environment
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为您的Jenkins CI/CD环境记录日志
- en: CI/CD pipelines can generate a great amount of metadata every day in busy build
    environments. Elasticsearch is the perfect platform for feeding this kind of data
    from Jenkins.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在繁忙的构建环境中，CI/CD流水线每天都会产生大量的元数据。Elasticsearch是从Jenkins获取这种数据的完美平台。
- en: In this section, we will learn how to enable and access the logs of our Jenkins
    instance and analyze team efficiency.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何启用和访问我们的Jenkins实例的日志，并分析团队的效率。
- en: Getting ready
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: All the operations mentioned in this recipe require a fully functional Jenkins
    deployment, as described in [Chapter 3](811c24c7-debf-4487-91e9-81db1520c0aa.xhtml),
    *Building CI/CD Pipelines*, in the *Setting up a CI/CD pipeline in Jenkins X*
    section.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中提到的所有操作都需要一个完全功能的Jenkins部署，如[第3章](811c24c7-debf-4487-91e9-81db1520c0aa.xhtml)中所述，“构建CI/CD流水线”，在“在Jenkins
    X中设置CI/CD流水线”部分。
- en: 'Clone the `k8sdevopscookbook/src` repository to your workstation to use the
    manifest files in the `chapter10` directory:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 将`k8sdevopscookbook/src`存储库克隆到您的工作站，以使用`chapter10`目录中的清单文件：
- en: '[PRE47]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Make sure you have a Kubernetes cluster, Jenkins X, and an EFK stack ready and that `kubectl` has
    been configured so that you can manage the cluster resources.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您有一个Kubernetes集群，Jenkins X和EFK堆栈已准备就绪，并且`kubectl`已配置，以便您可以管理集群资源。
- en: How to do it…
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'This section will show you how to feed Jenkins logs to Elasticsearch. This
    section is further divided into the following subsections to make this process
    easier:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将向您展示如何将Jenkins日志馈送到Elasticsearch。本节进一步分为以下子节，以使此过程更容易：
- en: Installing the Fluentd plugin
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Fluentd插件
- en: Streaming Jenkins logs to Elasticsearch using Fluentd
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Fluentd将Jenkins日志流式传输到Elasticsearch
- en: Installing the Fluentd plugin
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Fluentd插件
- en: Fluentd is part of the EFK Stack, along with Elasticsearch and Kibana. It is
    an open source data collector for building a unified logging layer. This recipe
    will show you how to install the Fluentd plugin for Jenkins, which will forward
    the Jenkins logs to your Fluentd logger.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd是EFK堆栈的一部分，与Elasticsearch和Kibana一起。它是一个用于构建统一日志层的开源数据收集器。这个教程将向您展示如何为Jenkins安装Fluentd插件，它将把Jenkins日志转发到您的Fluentd记录器。
- en: 'Let''s perform the following steps to install the Fluentd plugin on Jenkins:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤在Jenkins上安装Fluentd插件：
- en: 'Access your Jenkins service dashboard and click on the Manage Jenkins menu:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问您的Jenkins服务仪表板，然后点击“管理Jenkins”菜单：
- en: '![](assets/2357fc13-1486-437e-acc7-3b3a56faec5e.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2357fc13-1486-437e-acc7-3b3a56faec5e.png)'
- en: 'In the Manage Jenkins menu, click on the Manage Plugins button:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“管理Jenkins”菜单中，点击“管理插件”按钮：
- en: '![](assets/1685df62-9477-4eac-b329-7ac2c256b0e9.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1685df62-9477-4eac-b329-7ac2c256b0e9.png)'
- en: 'Click on the Available tab and search for `fluentd` in the Filter field. The
    result should look similar to the following. Click on the Install without restart button
    to install the Fluentd plugin:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“可用”选项卡，并在过滤字段中搜索`fluentd`。结果应该类似于以下内容。点击“无需重启安装”按钮来安装Fluentd插件：
- en: '![](assets/5ebd0c67-0d9a-4131-988c-7b6d180a3827.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5ebd0c67-0d9a-4131-988c-7b6d180a3827.png)'
- en: The Fluentd plugin will be installed without the need to restart the Jenkins
    instance.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd插件将在无需重新启动Jenkins实例的情况下安装。
- en: Streaming Jenkins logs to Elasticsearch using Fluentd
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Fluentd将Jenkins日志流式传输到Elasticsearch
- en: In this recipe, we will learn how to configure the Fluentd plugin that we installed
    on Jenkins.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将学习如何配置我们在Jenkins上安装的Fluentd插件。
- en: 'Let''s perform the following steps to feed Jenkins logs to Elasticsearch:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤将Jenkins日志馈送到Elasticsearch：
- en: In the Manage Jenkins menu, click on the Configure System button.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“管理Jenkins”菜单中，点击“配置系统”按钮。
- en: 'Scroll through the settings. Under the Logger for Fluentd settings, enter a logger
    name. The logger name is used as a prefix for Fluentd. In the Host field, enter
    the Service name of your Fluentd service and the exposed port number. In our example,
    in our Kubernetes cluster, we used the stable/fluentd Helm chart to install Fluentd.
    The service name is `fluentd`. This is exposed via port `24220`. Save the changes:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 浏览设置。在Fluentd设置日志记录器下，输入日志记录器名称。日志记录器名称用作Fluentd的前缀。在主机字段中，输入您的Fluentd服务的服务名称和暴露的端口号。在我们的示例中，在我们的Kubernetes集群中，我们使用稳定的/fluentd
    Helm图表来安装Fluentd。服务名称是`fluentd`。这通过端口`24220`暴露。保存更改：
- en: '![](assets/65b41a29-41bc-4a12-adb9-7cb3d3f85038.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/65b41a29-41bc-4a12-adb9-7cb3d3f85038.png)'
- en: Select a job under the pipeline configuration.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在管道配置下选择一个作业。
- en: Click on the Add post-build action button and select the Send to Fluentd option
    from the drop-down menu.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“添加后构建操作”按钮，并从下拉菜单中选择“发送到Fluentd”选项。
- en: Now, the Fluentd plugin will push the logs to Elasticsearch through the log
    collector.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Fluentd插件将通过日志收集器将日志推送到Elasticsearch。
- en: There's more…
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'If you are using the ELK stack instead of Fluentd in the EFK stack, then follow
    the recipes given here. This section is further divided into the following subsections
    to make this process easier:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在EFK堆栈中使用ELK堆栈而不是Fluentd，则请按照此处给出的教程。本节进一步分为以下子节，以使此过程更加简单：
- en: Installing the Logstash plugin
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Logstash插件
- en: Streaming Jenkins logs to Elasticsearch using Logstash
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Logstash将Jenkins日志流式传输到Elasticsearch
- en: Installing the Logstash plugin
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Logstash插件
- en: Logstash is part of the Elastic Stack, along with Beats, Elasticsearch, and
    Kibana. It is an open source data collection engine with real-time pipelining
    capabilities. In this recipe, you will learn how to install the Logstash plugin
    for Jenkins.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash是Elastic Stack的一部分，与Beats、Elasticsearch和Kibana一起。它是一个具有实时流水线功能的开源数据收集引擎。在这个教程中，您将学习如何为Jenkins安装Logstash插件。
- en: 'Let''s perform the following steps to install the Logstash plugin for Jenkins:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤为Jenkins安装Logstash插件：
- en: 'Access your Jenkins service dashboard and click on the Manage Jenkins menu:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问您的Jenkins服务仪表板，单击“管理Jenkins”菜单：
- en: '![](assets/2b14f321-b91e-425f-849e-3fd029c91dc6.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2b14f321-b91e-425f-849e-3fd029c91dc6.png)'
- en: 'In the Manage Jenkins menu, click on the Manage Plugins button:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“管理Jenkins”菜单中，单击“管理插件”按钮：
- en: '![](assets/1685df62-9477-4eac-b329-7ac2c256b0e9.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1685df62-9477-4eac-b329-7ac2c256b0e9.png)'
- en: 'Click on the Available tab and search for `logstash` in the Filter field. The
    result should look similar to the following. Click on the Install without restart
    button to install the Logstash plugin:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“可用”选项卡，并在“筛选”字段中搜索`logstash`。结果应该类似于以下内容。单击“安装后无需重启”按钮以安装Logstash插件：
- en: '![](assets/6f810fc9-de04-4ce3-8761-ca8ed7b175dc.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6f810fc9-de04-4ce3-8761-ca8ed7b175dc.png)'
- en: The Logstash plugin will be installed without you needing to restart your Jenkins
    instance.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash插件将安装，而无需重新启动Jenkins实例。
- en: Streaming Jenkins logs to Elasticsearch using Logstash
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Logstash将Jenkins日志流式传输到Elasticsearch
- en: In this recipe, we will show you how to configure the Logstash plugin that you
    installed on Jenkins previously.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将向您展示如何配置您之前在Jenkins上安装的Logstash插件。
- en: 'Let''s perform the following steps to feed Jenkins logs to Elasticsearch:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤将Jenkins日志馈送到Elasticsearch：
- en: In the Manage Jenkins menu, click on the Configure System button.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“管理Jenkins”菜单中，单击“配置系统”按钮。
- en: Scroll through the settings. Under the Logstash settings, check the Enable sending
    logs to an Indexer checkbox. When this setting is enabled, it will open four new
    fields.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动查看设置。在Logstash设置下，选中“启用发送日志到索引器”复选框。启用此设置后，将打开四个新字段。
- en: 'In the URI field, enter the service name, followed by the indexer name; for
    example, `http://elasticsearch-es-http:9200/logstash/jenkins`. Enter your `elastic`
    username and password and save the changes:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在URI字段中，输入服务名称，然后是索引器名称；例如，`http://elasticsearch-es-http:9200/logstash/jenkins`。输入您的`elastic`用户名和密码，保存更改：
- en: '![](assets/ce1927fe-3b98-4144-afa8-ff811fe1565e.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ce1927fe-3b98-4144-afa8-ff811fe1565e.png)'
- en: Now, the Logstash plugin will push the logs to Elasticsearch through the log
    collector.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Logstash插件将通过日志收集器将日志推送到Elasticsearch。
- en: See also
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Jenkins Logstash plugin documentation: [https://wiki.jenkins.io/display/JENKINS/Logstash+Plugin](https://wiki.jenkins.io/display/JENKINS/Logstash+Plugin)
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jenkins Logstash插件文档：[https://wiki.jenkins.io/display/JENKINS/Logstash+Plugin](https://wiki.jenkins.io/display/JENKINS/Logstash+Plugin)
- en: Jenkins FluentD plugin documentation: [https://github.com/jenkinsci/fluentd-plugin](https://github.com/jenkinsci/fluentd-plugin)
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jenkins FluentD插件文档：[https://github.com/jenkinsci/fluentd-plugin](https://github.com/jenkinsci/fluentd-plugin)
- en: Debug logging in Jenkins:[ https://wiki.jenkins.io/display/JENKINS/Logging](https://wiki.jenkins.io/display/JENKINS/Logging)
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Jenkins中进行调试日志记录：[https://wiki.jenkins.io/display/JENKINS/Logging](https://wiki.jenkins.io/display/JENKINS/Logging)
