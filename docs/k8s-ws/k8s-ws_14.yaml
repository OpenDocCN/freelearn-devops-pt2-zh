- en: 14\. Running Stateful Components in Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14\. 在Kubernetes中运行有状态的组件
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we will expand our skills to go beyond stateless applications
    and learn how to deal with stateful applications. We will learn about the various
    forms of state preservation mechanisms available to Kubernetes cluster operators
    and derive a mental model for where certain options can be invoked to run applications
    well. We will also introduce Helm, a useful tool for deploying complex applications
    with various Kubernetes objects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展我们的技能，超越无状态应用程序，学习如何处理有状态应用程序。我们将了解Kubernetes集群操作员可用的各种状态保留机制，并推导出一个心智模型，以确定在何处可以调用某些选项来有效运行应用程序。我们还将介绍Helm，这是一个用于部署具有各种Kubernetes对象的复杂应用程序的有用工具。
- en: By the end of this chapter, you will be able to use StatefulSets and PersistentVolumes
    in conjunction to run apps that require disk-based state to be retained in between
    pod interruptions. You will also be able to deploy applications using Helm charts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章的学习，您将能够同时使用StatefulSets和PersistentVolumes来运行需要在Pod中断期间保留基于磁盘的状态的应用。您还将能够使用Helm
    charts部署应用程序。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: From everything that you have learned up until this point, you know that pods
    and the containers that run in them are considered ephemeral. This means that
    they are not to be depended upon for stability as Kubernetes will intervene and
    move them around the cluster in order to comply with the desired state specified
    by the various manifests in the cluster. But there's a problem in this – what
    do we do with the parts of our applications that depend on the state being persisted
    from one interaction to the next? Without certain guarantees such as predictable
    naming for the pods and dependable storage operations, which we will learn about
    later in the chapter, such stateful components may fail if Kubernetes restarts
    the relevant pods or moves them around. However, before diving into the details
    of the aforementioned topics, let's talk briefly about stateful apps and why it's
    challenging to run them in a containerized environment.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您到目前为止学到的一切，您知道Pod和其中运行的容器被认为是短暂的。这意味着不能依赖它们的稳定性，因为Kubernetes将会干预并将它们移动到集群中的其他位置，以符合集群中各种清单指定的期望状态。但是这里存在一个问题
    - 我们该如何处理我们的应用程序的部分，这些部分依赖于从一次交互到下一次交互的状态持久化？如果没有诸如可预测的Pod命名和可靠的存储操作等特定保证（我们将在本章后面学习），这样的有状态组件可能会在Kubernetes重新启动相关Pod或将其移动时失败。然而，在深入讨论上述主题的细节之前，让我们简要谈谈有状态应用程序以及在容器化环境中运行它们的挑战。
- en: Stateful Apps
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有状态应用
- en: We briefly introduced the concept of statefulness in *Chapter 12*, *Your Application
    and HA.* Stateful components of applications are a necessity to just about all
    information technology systems in the world. They're necessary to keep account
    details, records of transactions, information on HTTP requests, and a whole host
    of other purposes. The challenging part of running these applications in a production
    environment almost always has to do with either the network or the persistence
    mechanism. Whether it's spinning metal disks, flash storage, block storage, or
    some other yet-to-be-invented tool, persistence is notoriously difficult to deal
    with in all forms. Part of why this is difficult is because all of these forms
    have a non-zero probability of failure, which can become very significant once
    you need to have hundreds or even thousands of storage devices in a production
    environment. These days, many cloud providers will give assistance to customers
    and offer managed services to account for this difficulty. In the case of AWS,
    we have tools such as S3, EBS, RDS, DynamoDB, Elasticache, and many others that
    help developers and operators run stateful applications smoothly without much
    heavy lifting (provided you are OK with vendor lock-in.)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在《第12章，您的应用程序和HA》中简要介绍了有状态性的概念。应用程序的有状态组件几乎对世界上所有的信息技术系统都是必需的。它们对于保持账户详细信息、交易记录、HTTP请求信息以及许多其他用途都是必需的。在生产环境中运行这些应用程序的挑战部分原因几乎总是与网络或持久性机制有关。无论是旋转金属盘、闪存存储、块存储还是其他尚未被发明的工具，持久性在各种形式中都是非常难以处理的。这种困难的部分原因是因为所有这些形式都存在失败的非零概率，一旦你需要在生产环境中拥有数百甚至数千个存储设备，这个概率就会变得非常显著。如今，许多云服务提供商将为客户提供帮助，并提供托管服务来解决这个困难。在AWS的情况下，我们有诸如S3、EBS、RDS、DynamoDB、Elasticache等工具，这些工具可以帮助开发人员和运营商在没有太多重复工作的情况下顺利运行有状态应用程序（前提是您可以接受供应商锁定）。
- en: Another trade-off that some companies face with running stateful applications
    and the persistence mechanisms they depend on is between either training and maintaining
    a large body of staff capable of keeping these systems of record online, healthy,
    and up to date, or attempting to develop a set of tools and programmatically enforced
    processes for common operational scenarios. These two approaches differ in the
    amount of human maintenance effort needed as the organization scales.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司在运行有状态应用和它们所依赖的持久性机制时面临的另一个权衡是，要么培训和维护一大批能够保持这些记录系统在线、健康和最新的员工，要么尝试开发一套工具和程序化强制执行的常见运营场景。这两种方法在组织规模扩大时所需的人力维护工作量上有所不同。
- en: For example, a human-centric approach to operations will allow things to move
    swiftly at first, but all operational costs scale linearly with the application
    scale, and eventually, the bureaucracy causes diminishing productivity returns
    with each new hire. Software-centric approaches are a higher upfront investment,
    but costs scale logarithmically with application scale and have a higher probability
    of cascading failures in the event of an unexpected bug.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以人为中心的运营方法一开始可以让事情迅速进行，但所有运营成本都会随着应用规模线性增长，最终，官僚主义会导致每次新员工的生产力回报递减。以软件为中心的方法需要更高的前期投资，但成本随着应用规模的对数增长，并且在出现意外错误时有更高的级联故障概率。
- en: Some examples of these operational scenarios are provisioning and configuration,
    normal operations, scaling input/output, backups, and abnormal operations. Examples
    of abnormal operations include network failures, hard drive failures, corruption
    of data on disk, security breaches, and application-specific irregularities. Examples
    of application-specific irregularities could be handling MySQL-specific collation
    concerns, handling S3 eventually consistent read failures, etcd Raft protocol
    resolution errors, and so on.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作场景的一些例子包括配置和配置、正常操作、扩展输入/输出、备份和异常操作。异常操作的例子包括网络故障、硬盘故障、磁盘数据损坏、安全漏洞和特定应用程序的不规则性。特定应用程序的不规则性的例子可能包括处理特定于MySQL的排序问题、处理S3最终一致性读取故障、etcd
    Raft协议解决错误等。
- en: Many companies find it easier to pay for vendor support, use cloud-managed product
    offerings, or re-train their staff rather than developing programmatic state management
    processes and software.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司发现，他们更容易支付供应商支持费用，使用云托管产品提供，或者重新培训员工，而不是开发编程状态管理流程和软件。
- en: One of the benefits of a Kubernetes-enabled development life cycle is on the
    workload definition side. The more effort a company puts into rigorously defining
    the smallest logical unit of compute (a pod template or PersistentVolume definition),
    the better they will be prepared for Kubernetes to intervene in irregular operations
    and appropriately orchestrate the entire application. This is largely because
    Kubernetes orchestration is a classical dynamic **constraint satisfaction problem**
    (**CSP**). The more information in the form of constraints the CSP solver has
    to work with at its disposal, the more predictable workload orchestration will
    become because the number of feasible steady-state solutions is reduced. So, using
    the end goal of predictable workload orchestration, is it then possible to run
    state-bearing components of our application in Kubernetes? The answer is an unequivocal
    yes. It is common to be hesitant to run stateful workloads in Kubernetes. We've
    said from the beginning of this book that pods are ephemeral and should not be
    depended on for stability because, in the event of a node failure, they will be
    moved and restarted. So, before you decide that it's too risky to run a database
    in Kubernetes, consider this – the world's largest search engine company runs
    databases in a very similar tool to Kubernetes. This tells us that it's not only
    possible but in reality, it's preferable to work on defining workloads well enough
    that they can be run by an orchestrator because it can likely handle application
    failures much faster than a human.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes启用的开发生命周期的一个好处在于工作负载定义方面。公司越是努力地严格定义计算的最小逻辑单元（一个pod模板或PersistentVolume定义），它们就越能为Kubernetes干预不规则操作并适当编排整个应用做好准备。这在很大程度上是因为Kubernetes编排是一个经典的动态约束满足问题（CSP）。CSP求解器可以利用的约束形式的信息越多，工作负载编排就会变得更可预测，因为可行稳态解的数量会减少。因此，以可预测的工作负载编排为最终目标，我们是否可以在Kubernetes中运行应用的状态组件？答案是毫无疑问的肯定。在Kubernetes中运行有状态的工作负载常常让人犹豫不决。我们从本书的开头就说过，pod是短暂的，不应该依赖它们的稳定性，因为在节点故障的情况下，它们将被移动和重新启动。因此，在你决定在Kubernetes中运行数据库太冒险之前，请考虑一下——世界上最大的搜索引擎公司在一个与Kubernetes非常相似的工具中运行数据库。这告诉我们，不仅可能，而且实际上更好的是努力定义工作负载，使它们可以由编排器运行，因为它可能比人类更快地处理应用程序故障。
- en: So, how do we accomplish this? The answer to that question is the use of a combination
    of two Kubernetes objects that you have learned about earlier – **PersistentVolumes**
    and **StatefulSets**. These are introduced in *Chapters 7* and *9*, so we won't
    belabor their usage here except to say that we're going to be bringing together
    all of the introductory topics into an example relevant to *our application*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何实现这一点呢？对这个问题的答案是使用你之前学过的两个Kubernetes对象的组合-**PersistentVolumes**和**StatefulSets**。这些在*第7*和*第9*章介绍过，所以我们不会在这里详细说明它们的用法，除了说我们将把所有介绍性的主题结合起来，形成一个与*我们的应用*相关的示例。
- en: 'The key to effective stateful workload orchestration is modularization and
    abstraction. These are fundamental software concepts that are taught to engineers
    so they can design well-architected software systems, and the same holds for well-architected
    infrastructure systems. Let''s consider the following diagram as an example of
    modularization when it comes to running a database in Kubernetes:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的有状态工作负载编排的关键是模块化和抽象。这些是基本的软件概念，工程师们学习它们以便设计良构架构的软件系统，同样适用于良构架构的基础设施系统。让我们考虑下面的图表，作为在Kubernetes中运行数据库时模块化的一个例子：
- en: '![Figure 14.1: Modular stateful components in Kubernetes'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.1：Kubernetes中的模块化有状态组件'
- en: '](image/B14870_14_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_01.jpg)'
- en: 'Figure 14.1: Modular stateful components in Kubernetes'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1：Kubernetes中的模块化有状态组件
- en: As you can see in the preceding diagram, and as you have learned up until now
    in this book, Kubernetes is made up of modular components. Thus, by leveraging
    the StatefulSet resource, we can compose the usage of PersistentVolumes, PersistentVolumeClaims,
    StorageClasses, pods, and some special rules around their life cycles that make
    much stronger guarantees about the condition that the persistence layers of our
    app are in.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在前面的图表中所看到的，并且在本书中学到的，Kubernetes由模块化组件组成。因此，通过利用StatefulSet资源，我们可以组合使用PersistentVolumes、PersistentVolumeClaims、StorageClasses、pods以及围绕它们的生命周期的一些特殊规则，从而更强有力地保证我们应用程序的持久性层的状态。
- en: Understanding StatefulSets
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解StatefulSets
- en: 'In *Figure 14.1*, we can see that a StatefulSet is invoked to be able to manage
    pod life cycles. A StatefulSet (in older versions of Kubernetes, this was called
    a PetSet) operates very similarly to a Deployment in that we provide a pod template
    of what we want to run and how many instances of it we want to run. What differs
    between a StatefulSet and a Deployment is the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图14.1*中，我们可以看到StatefulSet被调用来管理pod的生命周期。StatefulSet（在Kubernetes的旧版本中，这被称为PetSet）的操作方式与部署非常相似，我们提供一个pod模板，指定我们要运行的内容以及我们要运行多少个实例。StatefulSet和部署之间的区别在于以下几点：
- en: '**A clear naming scheme that can be depended upon by pods in DNS queries**:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一个可以依赖于DNS查询的清晰命名方案**：'
- en: This means that in the preceding diagram when we name a StatefulSet `mysql`,
    the first pod in that StatefulSet will always be `mysql-0`. This is unlike a traditional
    deployment where pod IDs are assigned randomly. It also means that if you had
    a pod named `mysql-2` and it crashed, it would be resurrected on the cluster using
    exactly the same name.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在前面的图中，当我们将一个StatefulSet命名为`mysql`时，该StatefulSet中的第一个pod将始终是`mysql-0`。这与传统部署不同，传统部署中pod的ID是随机分配的。这也意味着，如果你有一个名为`mysql-2`的pod，它崩溃了，它将在集群中使用完全相同的名称复活。
- en: '**A clearly ordered way in which updates must proceed**:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更新必须进行的明确有序方式**：'
- en: Depending on the update strategy in this StatefulSet, each pod will be taken
    down in a very specific order. So, if you have a well-known upgrade path (such
    as in the case of minor software revisions in MySQL), you should be able to leverage
    one of the Kubernetes-provided software update strategies.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此StatefulSet中的更新策略，每个pod将按非常特定的顺序关闭。因此，如果您有一个众所周知的升级路径（例如在MySQL的次要软件修订版本的情况下），您应该能够利用Kubernetes提供的软件更新策略之一。
- en: '**Dependable storage operations**:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠的存储操作**：'
- en: Since storage is the most critical part of a stateful solution, having deterministic
    actions taken by a StatefulSet is imperative. By default, any PersistentVolume
    provisioned for a StatefulSet will be retained, even if that StatefulSet has been
    deleted. While this behavior is meant to prevent accidental deletion of data,
    it can lead to significant charges from your cloud provider during testing, so
    you should monitor this closely.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存储是有状态解决方案中最关键的部分，因此StatefulSet采取的确定性操作至关重要。默认情况下，为StatefulSet配置的任何PersistentVolume都将被保留，即使该StatefulSet已被删除。虽然此行为旨在防止数据意外删除，但在测试期间可能会导致云提供商产生重大费用，因此您应该密切监视此行为。
- en: '**A serviceName field that must be defined in the StatefulSet**:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**必须在StatefulSet中定义的serviceName字段**：'
- en: This `serviceName` field must refer to something called a "headless" service
    that points to this group of pods. This exists to allow the pods to be individually
    addressable using the common Kubernetes DNS syntax. So for example, if my StatefulSet
    is running in the default namespace and has the name `zachstatefulset`, then the
    first pod will have the DNS entry `zachstatefulset-0.default.svc.cluster.local`.
    The same DNS entry will be used by any replacement pod if this one fails.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`serviceName`字段必须指向一个称为“无头”的服务，该服务指向这组pod。这是为了允许使用常见的Kubernetes DNS语法单独地寻址这些pod。例如，如果我的StatefulSet正在default命名空间中运行，并且名称为`zachstatefulset`，那么第一个pod将具有DNS条目`zachstatefulset-0.default.svc.cluster.local`。如果此pod失败，任何替换pod都将使用相同的DNS条目。
- en: 'More on headless services can be found at this link: [https://kubernetes.io/docs/concepts/services-networking/service/#headless-services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有关无头服务的更多信息，请访问此链接：[https://kubernetes.io/docs/concepts/services-networking/service/#headless-services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services)。
- en: Deployments versus StatefulSets
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署与StatefulSets
- en: Now that you've been introduced to StatefulSets at a slightly more granular
    level, on what basis should you choose between a StatefulSet and a Deployment
    that uses a PersistentVolumeClaim? The answer to that depends on what you're looking
    to orchestrate.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经以稍微更细粒度的方式介绍了StatefulSets，那么在选择使用PersistentVolumeClaim的StatefulSet和部署之间应该根据什么基础进行选择呢？答案取决于您希望编排的内容。
- en: In theory, you could achieve similar behavior using both types of Kubernetes
    object. Both create pods, both have update strategies, and both can use PVCs to
    create and manage PersistentVolume objects. The reason StatefulSets were designed
    was to give the guarantees laid out in the preceding bullet points. Typically,
    you would want these guarantees when orchestrating databases, file servers, and
    other forms of sensitive persistence-dependent applications.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上讲，您可以使用两种类型的Kubernetes对象实现类似的行为。两者都创建pod，都有更新策略，都可以使用PVC来创建和管理PersistentVolume对象。StatefulSets的设计目的是为了提供前面列出的保证。通常，在编排数据库、文件服务器和其他形式的敏感持久性依赖应用程序时，您会希望有这些保证。
- en: As we understand how StatefulSets are useful to predictably run the stateful
    components of our applications, let's look at a specific example that's relevant
    to us. As you'll recall from previous chapters, we have a little counter app that
    we are refactoring to leverage as many cloud-native principles as possible as
    we go along. In this chapter, we will be replacing the state persistence mechanism
    and testing out a new engine.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们了解到StatefulSets对于可预测地运行应用程序的有状态组件是有用的时，让我们看一个与我们相关的具体例子。正如您从以前的章节中回忆起，我们有一个小型计数器应用程序，我们正在重构以利用尽可能多的云原生原则。在本章中，我们将替换状态持久性机制并尝试一个新的引擎。
- en: Further Refactoring Our Application
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步重构我们的应用程序
- en: We'd like to now take our application a little further into cloud-native principles.
    Let's consider that the product manager for our counter app said that we're getting
    insane amounts of load (and you can confirm this through your observability toolset),
    and some people are not always getting a strictly increasing number; sometimes,
    they are getting duplicates of the same number. So, you confer with your colleagues
    and come to the conclusion that in order to guarantee the increasing number, you
    will need guarantees around how data is accessed and persisted in your app.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在希望将我们的应用程序进一步发展到云原生原则。让我们考虑一下，我们计数器应用程序的产品经理说我们的负载量非常大（您可以通过您的可观察性工具集来确认这一点），有些人并不总是得到一个严格递增的数字；有时，他们会得到相同数字的重复。因此，您与同事商讨后得出结论，为了保证递增的数字，您需要保证数据在应用程序中的访问和持久性。
- en: Specifically, you need a guarantee that operations against this datastore are
    atomically unique, consistent between operations, isolated from other operations,
    and durable against failure. That is, you are looking for an ACID-compliant database.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，您需要保证针对此数据存储的操作是原子唯一的，在操作之间是一致的，与其他操作是隔离的，并且在故障时是持久的。也就是说，您正在寻找一个符合ACID标准的数据库。
- en: Note
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'More on what ACID compliance is can be found at this link: [https://database.guide/what-is-acid-in-databases/](https://database.guide/what-is-acid-in-databases/).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有关ACID合规性的更多信息，请访问此链接：[https://database.guide/what-is-acid-in-databases/](https://database.guide/what-is-acid-in-databases/)。
- en: The team wants to be able to use a database, but they'd rather not pay for that
    database to be run by AWS. They would also rather not be locked into AWS if they
    find better deals on GCP or Azure later.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 团队希望能够使用数据库，但他们宁愿不支付AWS运行该数据库的费用。如果他们以后在GCP或Azure上找到更好的交易，他们也宁愿不被锁定在AWS上。
- en: So, after a brief look at Google for some options, your team settles on using
    MySQL. MySQL is one of the more popular open-source RDBMS solutions, and as such
    has a lot of documentation, support, and community suggestions for implementation
    as a database solution in Kubernetes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在谷歌上简要查看了一些选项后，您的团队决定使用MySQL。MySQL是更受欢迎的开源RDBMS解决方案之一，因此有很多关于在Kubernetes中作为数据库解决方案实施的文档、支持和社区建议。
- en: 'Now the work begins on changing your code to support incrementing the counter
    using a transaction supported by MySQL. So, to do this, we need to change a few
    things:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，开始更改您的代码以支持使用MySQL支持的事务来递增计数器。因此，为了做到这一点，我们需要改变一些事情：
- en: Change our application code to use SQL instead of Redis to access the data and
    increment the counter.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改我们的应用程序代码，以使用SQL而不是Redis来访问数据并递增计数器。
- en: Modify our Kubernetes cluster to run MySQL instead of Redis.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改我们的Kubernetes集群，以运行MySQL而不是Redis。
- en: Ensure the durability of the storage underneath the database in case of catastrophic
    failure.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在发生灾难性故障时数据库下面的存储的持久性。
- en: You may be asking yourself why a cluster operator or administrator would need
    to be able to understand and refactor code. The advent of Kubernetes accelerated
    a trend in the software industry of leveraging DevOps tooling, practices, and
    culture to begin to deliver value to customers more rapidly and more predictably.
    This means beginning to scale our operations using software and not people. We
    need robust automation to take the place of human-centric processes to be able
    to make guarantees around functionalities and delivery speed. Thus, an infrastructure
    designer or administrator having systems-level software engineering experience
    to allow them to assist in refactoring a codebase to leverage more cloud-native
    practices is a huge benefit for them in their careers, and it may soon become
    a job requirement for all DevOps engineers. So, let's take a look at how to refactor
    our application for StatefulSets using MySQL for the transactions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会问自己为什么集群操作员或管理员需要能够理解和重构代码。Kubernetes的出现加速了软件行业利用DevOps工具、实践和文化开始更快、更可预测地为客户提供价值的趋势。这意味着开始使用软件而不是人来扩展我们的操作。我们需要强大的自动化来取代以人为中心的流程，以便能够保证功能和交付速度。因此，基础架构设计师或管理员具有系统级软件工程经验，使他们能够协助重构代码库以利用更多的云原生实践，对他们的职业来说是一个巨大的好处，很快可能会成为所有DevOps工程师的工作要求。因此，让我们看看如何重构我们的应用程序以使用MySQL进行StatefulSets的事务处理。
- en: Note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are not yet comfortable programming or you are not familiar with the
    syntax of the language the authors chose (Golang in this example), you don't have
    to worry – all of the solutions have been worked out and are ready to be used.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还不熟悉编程，或者对作者选择的语言的语法（例如本例中的Golang）不熟悉，您不必担心-所有解决方案都已经被解决并准备好使用。
- en: 'First, let''s examine our code for *Exercise 12.04*, *Deploying an Application
    with State Management*:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们检查*Exercise 12.04*，*使用状态管理部署应用程序*的代码：
- en: main.go
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: main.go
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The complete code for this step can be found at [https://packt.live/3jSWTHB](https://packt.live/3jSWTHB).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的完整代码可以在[https://packt.live/3jSWTHB](https://packt.live/3jSWTHB)找到。
- en: Highlighted in the preceding code are the two instances where we are accessing
    our persistence layer. As you can see, not only are we not using a transaction,
    but we are manipulating the value in the code and therefore cannot guarantee the
    constraint that this is a strictly incrementing counter. To do this, we must change
    our strategy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中突出显示了我们访问持久层的两个实例。正如您所看到的，我们不仅没有使用事务，而且在代码中操作了值，因此无法保证这是一个严格递增的计数器。为了做到这一点，我们必须改变我们的策略。
- en: Note
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the required information for using a MySQL container at this link:
    [https://hub.docker.com/_/mysql?tab=description](https://hub.docker.com/_/mysql?tab=description).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此链接找到使用MySQL容器所需的信息：[https://hub.docker.com/_/mysql?tab=description](https://hub.docker.com/_/mysql?tab=description)。
- en: 'We have provided the refactored application that uses SQL. Let''s take a look
    at the code of the refactored application:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了使用SQL的重构应用程序。让我们来看看重构应用程序的代码：
- en: main.go
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: main.go
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The complete code for this step can be found at [https://packt.live/35ck7nX](https://packt.live/35ck7nX).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的完整代码可以在[https://packt.live/35ck7nX](https://packt.live/35ck7nX)找到。
- en: As you can see, it's roughly the same as the Redis code, except now our value
    is being set in a transaction. Unlike Redis, MySQL is not a volatile in-memory
    datastore, so operations against the database must be persisted to disk to succeed,
    and ideally, they are persisted to a disk that won't disappear when the pod is
    interrupted. Let's set up the other required components of our application in
    the following exercise.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，它与Redis代码大致相同，只是现在我们的值是在事务中设置的。与Redis不同，MySQL不是一种易失性的内存数据存储，因此对数据库的操作必须持久化到磁盘才能成功，并且理想情况下，它们应该持久化到在pod中断时不会消失的磁盘上。让我们在下一个练习中设置我们应用程序的其他必需组件。
- en: 'Exercise 14.01: Deploying a Counter App with a MySQL Backend'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习14.01：部署带有MySQL后端的计数器应用
- en: 'In this exercise, we will reconfigure our counter app to work with a MySQL
    backend instead of Redis:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将重新配置我们的计数器应用程序，使其与MySQL后端一起工作：
- en: 'To begin with, we will recreate your EKS cluster from the Terraform file in
    *Exercise 12.02*, *Creating a Cluster with EKS Using Terraform*. If you already
    have the `main.tf` file, you can work with it. Otherwise, you can run the following
    command to get it:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将从Terraform文件中重新创建您的EKS集群*练习12.02*，*使用Terraform在EKS上创建集群*。如果您已经有`main.tf`文件，可以使用它。否则，您可以运行以下命令获取它：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, use the following two commands one after the other to get your cluster
    resources up and running:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，依次使用以下两个命令来启动并运行您的集群资源：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: After performing any of the exercises, if you plan to continue to the following
    exercises after a significant amount of time, it might be a good idea to deallocate
    your cluster resources to stop AWS from billing you. You can do that using the
    `terraform destroy` command. Then, you can run this step to get everything back
    online again when you are ready to perform an exercise or an activity.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行任何练习之后，如果您计划在相当长的时间后继续进行以下练习，最好将集群资源分配给您以阻止AWS向您收费。您可以使用`terraform destroy`命令来做到这一点。然后，当您准备进行练习或活动时，可以运行此步骤将所有内容恢复在线。
- en: If any exercise or activity relies on objects created in the previous exercises,
    you will need to recreate those objects as well.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何练习或活动依赖于在先前练习中创建的对象，则您还需要重新创建这些对象。
- en: 'Run the following command to get the manifest file, `with_mysql.yaml`, which
    defines all the required objects:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令获取定义所有所需对象的清单文件`with_mysql.yaml`：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Open the file for inspection so we can examine this StatefulSet:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 打开文件进行检查，以便我们可以检查这个StatefulSet：
- en: with_mysql.yaml
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MySQL.yaml
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The complete code for this step can be found at [https://packt.live/2R2WN3x](https://packt.live/2R2WN3x).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的完整代码可以在[https://packt.live/2R2WN3x](https://packt.live/2R2WN3x)找到。
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Here, a PersistentVolumeClaim is automatically binding a 10 GiB volume from
    Amazon EBS on startup to each pod. Kubernetes will automatically provision the
    EBS volume using the IAM role that we defined in our Terraform file.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，PersistentVolumeClaim在启动时会自动将10 GiB卷从Amazon EBS绑定到每个pod。 Kubernetes将使用我们在Terraform文件中定义的IAM角色自动配置EBS卷。
- en: When the pod gets interrupted for any reason, Kubernetes will automatically
    re-bind the appropriate PersistentVolume to the pod when it restarts, even if
    it is on a different worker node, so long as it is in the same availability zone.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当pod因任何原因中断时，Kubernetes将在重新启动时自动将适当的PersistentVolume重新绑定到pod，即使它在不同的工作节点上，只要它在相同的可用区。
- en: 'Let''s apply this to our cluster by running the following command:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过运行以下命令将其应用到我们的集群：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see this response:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '![Figure 14.2: Deploying the refactored application that uses a MySQL backend'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.2：部署使用MySQL后端的重构应用程序'
- en: '](image/B14870_14_02.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_02.jpg)'
- en: 'Figure 14.2: Deploying the refactored application that uses a MySQL backend'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2：部署使用MySQL后端的重构应用程序
- en: 'Now run `kubectl proxy` in this window and let''s open up another terminal
    window:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在在这个窗口运行`kubectl proxy`，然后让我们打开另一个终端窗口：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should see this response:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到这个回应：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the other window, run the following command to access our application:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一个窗口中，运行以下命令来访问我们的应用程序：
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should see this response:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到这个回应：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You should see the app running as expected, as we have seen in the previous
    chapters. And just like that, we have a working StatefulSet with our application
    using MySQL that is persisting data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '您应该看到应用程序按预期运行，就像我们在前几章中看到的那样。就像那样，我们有一个使用MySQL持久化数据的工作StatefulSet与我们的应用程序。 '
- en: As we've said, one of the things that will cause cluster operators to not pursue
    StatefulSets as a way of being able to manage their data infrastructure is a mistaken
    belief that the information in PersistentVolumes is as ephemeral as the pods they
    are bound to. This is not true. The PersistentVolumeClaims created by a StatefulSet
    will not be deleted if a pod or even the StatefulSet is deleted. This is to protect
    the data contained in these volumes at all costs. Thus, for cleanup, we need to
    delete the PersistentVolume separately. Cluster operators also have other tools
    at their disposal to prevent this from happening, such as changing the reclamation
    policy of the PersistentVolumes (or the StorageClass it was created from) that
    you are creating.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说的，导致集群操作员不追求StatefulSets作为管理数据基础设施的一种方式的原因之一是错误地认为PersistentVolumes中的信息和它们绑定的pod一样短暂。这是不正确的。由StatefulSet创建的PersistentVolumeClaims如果删除了pod甚至StatefulSet也不会被删除。这是为了不惜一切代价保护这些卷中包含的数据。因此，对于清理，我们需要单独删除PersistentVolume。集群操作员还可以利用其他工具来防止发生这种情况，例如更改PersistentVolumes（或者创建它的StorageClass）的回收策略。
- en: 'Exercise 14.02: Testing the Resilience of StatefulSet Data in PersistentVolumes'
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习14.02：测试PersistentVolumes中StatefulSet数据的弹性
- en: 'In this exercise, we will continue from where we left off in the last exercise
    and test the resilience of the data that is in our application by deleting a resource
    and seeing how Kubernetes responds:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从上一个练习中离开的地方继续，并通过删除一个资源来测试我们应用程序中的数据的弹性，看看Kubernetes如何响应：
- en: 'Now for the fun part, let''s try to test the resilience of our persistence
    mechanism by deleting the MySQL pod:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在到了有趣的部分，让我们尝试通过删除MySQL pod来测试我们持久性机制的弹性：
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see this response:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到这个回应：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The app may crash at this point, but if you keep trying the preceding `curl`
    command again after a few seconds, it should automatically continue counting from
    the number it had before we deleted the pod. We can verify this by trying to access
    the application again:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时应用可能会崩溃，但如果在删除pod之前几秒钟后再次尝试前面的`curl`命令，它应该会自动从我们删除pod之前的数字继续计数。我们可以通过尝试再次访问应用程序来验证这一点：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see a response similar to the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的回应：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, we not only get a valid response from the application, but we
    also get the next number in the sequence (`2`), meaning that no data was lost
    when we lost our MySQL pod and Kubernetes recovered it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们不仅从应用程序获得了有效的响应，而且还获得了序列中的下一个数字（`2`），这意味着当我们丢失MySQL pod并且Kubernetes恢复它时，没有丢失数据。
- en: After you've created this StatefulSet, cleaning it up is not as simple as running
    `kubectl delete -f with_mysql.yaml`. This is because Kubernetes will not automatically
    destroy a PersistentVolume created by a StatefulSet.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了这个StatefulSet之后，清理它并不像运行`kubectl delete -f with_mysql.yaml`那样简单。这是因为Kubernetes不会自动销毁由StatefulSet创建的PersistentVolume。
- en: Note
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This also means that even if we try to delete all of our AWS resources using
    `terraform destroy`, we will still be paying for orphaned EBS volumes in AWS indefinitely
    (and we don't want that in this example).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着，即使我们尝试使用`terraform destroy`删除所有AWS资源，我们仍将无限期地支付AWS中的孤立EBS卷（在这个示例中，我们不希望这样）。
- en: 'So, to clean up, we need to find out what PersistentVolumes are bound to this
    StatefulSet. Let''s list the PersistentVolumes in the default namespace of our
    cluster:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，为了清理，我们需要找出哪些PersistentVolumes绑定到这个StatefulSet。让我们列出集群默认命名空间中的PersistentVolumes：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should see a response similar to the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于以下的响应：
- en: '![Figure 14.3: Getting the list of PersistentVolumes'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.3：获取持久卷列表'
- en: '](image/B14870_14_03.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_03.jpg)'
- en: 'Figure 14.3: Getting the list of PersistentVolumes'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3：获取持久卷列表
- en: 'It looks like we have a PersistentVolume named `data-mysql-0`, which is the
    one we want to delete. First, we need to remove the objects that created this.
    Thus, let''s first delete our application and all of its components:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看起来我们有一个名为`data-mysql-0`的PersistentVolume，这是我们想要删除的。首先，我们需要删除创建它的对象。因此，让我们首先删除我们的应用程序及其所有组件：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should see this response:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '![Figure 14.4: Deleting the PersistentVolume associated with MySQL'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.4：删除与MySQL关联的持久卷'
- en: '](image/B14870_14_04.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_04.jpg)'
- en: 'Figure 14.4: Deleting the PersistentVolume associated with MySQL'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4：删除与MySQL关联的持久卷
- en: 'Let''s check on the PersistentVolume that we were trying to remove:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查一下我们试图删除的持久卷：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should see a response similar to this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这样的响应：
- en: '![Figure 14.5: Getting the list of PersistentVolumes'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.5：获取持久卷列表'
- en: '](image/B14870_14_05.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_05.jpg)'
- en: 'Figure 14.5: Getting the list of PersistentVolumes'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5：获取持久卷列表
- en: From this image, it appears that our volume is still there.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图像中，看起来我们的卷还在那里。
- en: 'We need to remove both the PersistentVolume and the PersistentVolumeClaim that
    created it. To do this, let''s run the following command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要删除创建它的PersistentVolume和PersistentVolumeClaim。为此，让我们首先运行以下命令：
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should see this response:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Once we delete the PersistentVolumeClaim, the PersistentVolume becomes `unbound`
    and is subject to its reclaim policy, which we can see in the screenshot of the
    previous step. In this case, the policy is to delete the underlying storage volume.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们删除PersistentVolumeClaim，PersistentVolume就变为`unbound`，并且受到其回收策略的约束，我们可以在上一步的截图中看到。在这种情况下，策略是删除底层存储卷。
- en: 'To verify that the PV is deleted, let''s run the following:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证PV是否已删除，让我们运行以下命令：
- en: '[PRE20]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You should see the following response:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As is apparent in this screenshot, our PersistentVolume has now been deleted.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在这个截图中所显示的，我们的PersistentVolume现在已被删除。
- en: Note
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If the reclaim policy for your case is anything other than `Delete`, you will
    need to manually delete the PersistentVolume as well.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的情况的回收策略不是`Delete`，您还需要手动删除PersistentVolume。
- en: 'Now that we have cleaned up our PersistentVolumes and PersistentVolumeClaims,
    we can continue to clean up as we would normally by running the following command:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经清理了我们的PersistentVolumes和PersistentVolumeClaims，我们可以继续按照通常的方式进行清理，通过运行以下命令：
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should see a response that ends as in this screenshot:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到一个以此截图结束的响应：
- en: '![Figure 14.6: Cleaning up resources created by Terraform'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.6：清理Terraform创建的资源'
- en: '](image/B14870_14_06.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_06.jpg)'
- en: 'Figure 14.6: Cleaning up resources created by Terraform'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6：清理Terraform创建的资源
- en: In this exercise, we have seen how Kubernetes tries to preserve PersistentVolumes
    even when we delete the StatefulSet. We have also seen how to proceed when we
    actually want to remove a PersistentVolume.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们已经看到了Kubernetes在删除StatefulSet时尝试保留PersistentVolumes。我们还看到了当我们实际想要删除PersistentVolume时应该如何进行。
- en: Now that we have seen how to set up a StatefulSet and run a MySQL database attached
    to it, we will extend the principle of high availability further in the following
    activity. Before we do this, though, we need to address the problem of Kubernetes
    manifest sprawl, because it seems to take more and more YAML manifests to achieve
    our objective of building highly available stateful applications. In the following
    section, we will learn about a tool that will help us better organize and manage
    the manifests for our applications.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何设置StatefulSet并运行附加到其上的MySQL数据库，我们将在接下来的活动中进一步扩展高可用性的原则。不过，在我们这样做之前，我们需要解决Kubernetes清单蔓延的问题，因为似乎需要更多的YAML清单来实现构建高可用性有状态应用的目标。在接下来的部分中，我们将了解一个工具，它将帮助我们更好地组织和管理应用的清单。
- en: Helm
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Helm
- en: In this section, we are going to be taking a look at a tool that is very helpful
    in the Kubernetes ecosystem called Helm. Helm was created by Microsoft after it
    quickly became apparent that for any sizeable deployment of Kubernetes (for example,
    those involving 20 or more separate components, observability tools, services,
    and other objects), there are a lot of YAML manifests to keep track of. Couple
    that with the fact that many companies run multiple environments other than production,
    which you need to be able to keep in sync with each other, and you start to have
    an unwieldy problem on your hands.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看一下一个在Kubernetes生态系统中非常有帮助的工具，称为Helm。Helm是由微软创建的，因为很快就显而易见，对于任何规模的Kubernetes部署（例如，涉及20个或更多独立组件、可观察性工具、服务和其他对象的部署），需要跟踪大量的YAML清单。再加上许多公司运行除了生产环境之外的多个环境，您需要能够使它们彼此保持同步，这样您就开始面临一个难以控制的问题。
- en: Helm allows you to write Kubernetes manifest templates, to which you supply
    arguments that override any defaults, and then Helm creates the appropriate Kubernetes
    manifests for you. Thus, you can use Helm as a sort of package manager, where
    your entire application can be deployed using a Helm chart, and you can tweak
    a few small parameters before installing. Another way to use Helm is as a templating
    engine. It allows an experienced Kubernetes operator to write a good template
    only one time and then it can be used by people not familiar with the Kubernetes
    manifest syntax to successfully create Kubernetes resources. A Helm chart can
    be created with any number of fields set by arguments, and a base template can
    be adapted to deploy vastly different implementations of a piece of software or
    a microservice to suit different needs.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Helm允许您编写Kubernetes清单模板，您可以向其提供参数以覆盖任何默认值，然后Helm会为您创建适当的Kubernetes清单。因此，您可以将Helm用作一种软件包管理器，您可以使用Helm图表部署整个应用程序，并在安装之前调整一些小参数。使用Helm的另一种方式是作为模板引擎。它允许经验丰富的Kubernetes操作员仅编写一次良好的模板，然后可以被不熟悉Kubernetes清单语法的人成功地创建Kubernetes资源。Helm图表可以通过参数设置任意数量的字段，并且可以根据不同的需求调整基本模板以部署软件或微服务的大不相同的实现。
- en: Helm packages are called "charts" and they have a specific folder structure.
    You can either use a shared Helm chart repository from Git, an Artifactory server,
    or a local filesystem. In the upcoming exercise, we're going to look at a Helm
    chart and install it on our clusters.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Helm软件包称为“图表”，它们具有特定的文件夹结构。您可以使用来自Git的共享Helm图表存储库，Artifactory服务器或本地文件系统。在即将进行的练习中，我们将查看一个Helm图表并在我们的集群上安装它。
- en: This is a good point to be introduced to Helm in your journey of learning Kubernetes
    because if you've been following along, you've written quite a bit of YAML and
    applied it to your cluster. Also, a lot of what we've written is a repeat of things
    that we've seen before. So, leveraging Helm's templating functionality will be
    helpful for packaging up similar components and delivering them using Kubernetes.
    You don't have to leverage the templating components of Helm to use it, but it
    helps so that you can reuse the chart for multiple different permutations of the
    resulting Kubernetes object.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的机会来介绍Helm，因为如果你一直在学习Kubernetes，你已经写了相当多的YAML并将其应用到了你的集群中。此外，我们所写的很多内容都是我们以前见过的东西的重复。因此，利用Helm的模板功能将有助于打包类似的组件并使用Kubernetes进行交付。你不一定要利用Helm的模板组件来使用它，但这样做会有所帮助，因为你可以重复使用图表来生成不同排列的Kubernetes对象。
- en: Note
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'We will be using Helm 3, which has significant differences from its predecessor,
    Helm 2, and was only recently released. If you are familiar with Helm 2 and want
    to know about the differences, you can refer to the documentation at this link:
    [https://v3.helm.sh/docs/faq/#changes-since-helm-2](https://v3.helm.sh/docs/faq/#changes-since-helm-2).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Helm 3，它与其前身Helm 2有很大的不同，并且最近才发布。如果你熟悉Helm 2并想了解其中的区别，你可以参考这个链接上的文档：[https://v3.helm.sh/docs/faq/#changes-since-helm-2](https://v3.helm.sh/docs/faq/#changes-since-helm-2)。
- en: Detailed coverage of Helm is beyond the scope of this book, but the fundamentals
    covered here serve as a great starting point, and also put into perspective how
    different tools and technologies can work together to remove several hurdles of
    complex application orchestration in Kubernetes.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Helm的详细覆盖范围超出了本书的范围，但这里介绍的基本知识是一个很好的起点，也让我们明白了不同的工具和技术如何一起工作，以消除Kubernetes中复杂应用编排的几个障碍。
- en: Let's see how we can create a chart (which is the Helm term for a package) and
    apply it to a cluster. Then, we will understand how Helm generates Kubernetes
    manifest files from a Helm chart.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何创建一个图表（这是Helm术语中的一个包）并将其应用到一个集群中。然后，我们将了解Helm如何从Helm图表生成Kubernetes清单文件。
- en: 'Let''s make a new Helm chart by running the following command:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行以下命令来创建一个新的Helm图表：
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should see the following response:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到以下的回应：
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: When you create a new chart, Helm will generate a chart for NGINX as a placeholder
    application by default. This will create a new folder and skeleton chart for us
    to examine.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建一个新的图表时，Helm会默认生成一个NGINX的图表作为占位符应用。这将为我们创建一个新的文件夹和骨架图表供我们检查。
- en: Note
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For the following section, make sure that you have `tree` installed as per the
    instructions in the *Preface*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，请确保你已经按照*前言*中的说明安装了`tree`。
- en: 'Let''s use the Linux `tree` command and take a look at what Helm has made for
    us:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Linux的`tree`命令来看看Helm为我们做了什么：
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You should see a response similar to the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到类似以下的回应：
- en: '![Figure 14.7: Directory structure of a Helm chart'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.7：Helm图表的目录结构'
- en: '](image/B14870_14_07.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_07.jpg)'
- en: 'Figure 14.7: Directory structure of a Helm chart'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7：Helm图表的目录结构
- en: 'Pay attention to the `templates` folder and the `values.yaml` file. Helm works
    by using the values found in the `values.yaml` file and fills those values into
    the corresponding placeholders in the files inside the `templates` folder. Let''s
    examine a part of the `values.yaml` file:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`templates`文件夹和`values.yaml`文件。Helm通过使用`values.yaml`文件中的值，并将这些值填充到`templates`文件夹中的文件中相应的占位符中。让我们来看一下`values.yaml`文件的一部分：
- en: values.yaml
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: values.yaml
- en: '[PRE26]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The complete code for this step can be found at [https://packt.live/33ej2cO](https://packt.live/33ej2cO).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步的完整代码可以在[https://packt.live/33ej2cO](https://packt.live/33ej2cO)找到。
- en: As we can see here, this is not a Kubernetes manifest, but it looks like it
    has many of the same fields. In the preceding snippet, we have highlighted the
    entire `image` block. This has three fields (`repository`, `pullPolicy`, and `tag`),
    each with their corresponding values.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在这里所看到的，这不是一个Kubernetes清单，但它看起来有许多相同的字段。在前面的片段中，我们已经突出显示了整个`image`块。这有三个字段（`repository`，`pullPolicy`和`tag`），每个字段都有其相应的值。
- en: 'Another notable file is `Chart.yaml`. The following line from this file is
    relevant to our discussion:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的文件是`Chart.yaml`。此文件中的以下行与我们的讨论相关：
- en: '[PRE27]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the complete file at this link: [https://packt.live/2FboR2a](https://packt.live/2FboR2a).'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此链接找到完整的文件：[https://packt.live/2FboR2a](https://packt.live/2FboR2a)。
- en: 'The comment in the file is pretty descriptive of what this means: *"This is
    the version number of the application being deployed. This version number should
    be incremented each time you make changes to the application. Versions are not
    expected to follow Semantic Versioning. They should reflect the version the application
    is using."*'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 文件中的注释对这意味着的描述相当详细：*“这是部署的应用程序的版本号。每次对应用程序进行更改时，应递增此版本号。版本不应遵循语义化版本。它们应反映应用程序正在使用的版本。”*
- en: 'So, how does Helm assemble these into the traditional Kubernetes manifest format
    that we expect? To understand that, let''s inspect the corresponding section of
    the `deployment.yaml` file in the `templates` folder:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Helm是如何将这些组装成我们期望的传统Kubernetes清单格式的呢？要了解这一点，让我们检查`templates`文件夹中`deployment.yaml`文件的相应部分：
- en: deployment.yaml
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 部署.yaml
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The complete code for this step can be found at [https://packt.live/3k0OGRL](https://packt.live/3k0OGRL).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的完整代码可以在此链接找到：[https://packt.live/3k0OGRL](https://packt.live/3k0OGRL)。
- en: 'This file looks a lot more like a Kubernetes manifest with a bunch of variables
    added into it. Comparing the template placeholders from `deployment.yaml` to the
    observations from `values.yaml` and `Chart.yaml`, we can infer the following:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件看起来更像是一个Kubernetes清单，其中添加了许多变量。将`deployment.yaml`中的模板占位符与`values.yaml`和`Chart.yaml`中的观察结果进行比较，我们可以推断出以下内容：
- en: '`{{ .Values.image.repository }}` will be interpreted as `nginx`.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{{ .Values.image.repository }}`将被解释为`nginx`。'
- en: '`{{ .Values.image.tag | default .Chart.AppVersion }}` will be interpreted as
    `1.16.0`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{{ .Values.image.tag | default .Chart.AppVersion }}`将被解释为`1.16.0`。'
- en: 'Thus, we get the resultant field for our deployment spec as `image: nginx:1.16.0`.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，我们得到了我们部署规范的结果字段`image: nginx:1.16.0`。'
- en: 'This is our first glimpse into the Helm templating language. For those familiar
    with templating engines such as Jinja, Go templating, or Twig, this syntax should
    look familiar. As mentioned earlier, we will not dive into too many details about
    Helm, but you can find more on the Helm documentation at this link: [https://helm.sh/docs/chart_template_guide/](https://helm.sh/docs/chart_template_guide/).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们第一次看到Helm模板语言。对于那些熟悉模板引擎（如Jinja，Go模板或Twig）的人来说，这种语法应该看起来很熟悉。如前所述，我们不会深入了解Helm的太多细节，但您可以在此链接找到有关Helm文档的更多信息：[https://helm.sh/docs/chart_template_guide/](https://helm.sh/docs/chart_template_guide/)。
- en: 'Now, let''s install the sample chart `chart-dev` that we have generated. This
    chart will deploy an example NGINX app to our Kubernetes cluster. To install a
    Helm chart, the command would look as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们安装我们生成的示例图表`chart-dev`。这个图表将在我们的Kubernetes集群中部署一个示例NGINX应用程序。要安装Helm图表，命令如下所示：
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can use `--generate-name` to get a random name. Also, since we are already
    in the `chart-dev` directory, we can directly use `values.yaml` from the root
    of the current working directory:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`--generate-name`来获取一个随机名称。此外，由于我们已经在`chart-dev`目录中，我们可以直接使用当前工作目录根目录中的`values.yaml`：
- en: '[PRE30]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You should see the following response:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 14.8: Installing a Helm chart'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.8：安装Helm图表'
- en: '](image/B14870_14_08.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_08.jpg)'
- en: 'Figure 14.8: Installing a Helm chart'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.8：安装Helm图表
- en: Notice that in the output, you are given instructions on what to do next. These
    are customizable instructions from the `templates/NOTES.txt` file. When you make
    your own Helm chart, you can use these to guide whoever is using the chart. Now,
    let's run these commands.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在输出中，您将收到关于接下来要做什么的说明。这些是来自`templates/NOTES.txt`文件的可定制说明。当您制作自己的Helm图表时，您可以使用这些来指导使用图表的人。现在，让我们运行这些命令。
- en: Note
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The exact values in this output are customized to your particular environment,
    so you should copy the commands from your terminal output. This applies to the
    following command.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出中的确切值根据您的特定环境进行了定制，因此您应该从终端输出中复制命令。这适用于以下命令。
- en: 'The first command sets the pod name into an environment variable named `POD_NAME`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令将pod名称设置为名为`POD_NAME`的环境变量：
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We'll skip the `echo` command; it just tells you how to access your application.
    The reason this `echo` command exists is to show what the next commands are going
    to be in the terminal output.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将跳过`echo`命令；它只是告诉您如何访问您的应用程序。存在这个`echo`命令的原因是为了显示终端输出中接下来的命令是什么。
- en: 'Now before we access our application, we need to do some port forwarding. The
    next command maps port `8080` on your host to port `80` on the pod:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在访问我们的应用程序之前，我们需要进行一些端口转发。下一个命令将在您的主机上将端口`8080`映射到pod上的端口`80`：
- en: '[PRE32]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You should see this response:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '[PRE33]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now let''s try to access NGINX. In a browser, go to `localhost:8080`. You should
    be able to see the default NGINX landing page:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试访问NGINX。在浏览器中，转到`localhost:8080`。您应该能够看到默认的NGINX欢迎页面：
- en: '![Figure 14.9: Accessing our default NGINX test application'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.9：访问我们的默认NGINX测试应用程序'
- en: '](image/B14870_14_09.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_09.jpg)'
- en: 'Figure 14.9: Accessing our default NGINX test application'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9：访问我们的默认NGINX测试应用程序
- en: 'You can clean this up by deleting our resources. First, let''s get the generated
    name of this release by getting a list of all the releases installed by Helm in
    your cluster:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过删除我们的资源来清理这个。首先，让我们通过获取Helm在您的集群中安装的所有发布的列表来获得此发布的生成名称：
- en: '[PRE34]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should see a response similar to this:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这样的响应：
- en: '![Figure 14.10: Getting a list of all applications installed by Helm'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.10：获取Helm安装的所有应用程序列表'
- en: '](image/B14870_14_10.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_10.jpg)'
- en: 'Figure 14.10: Getting a list of all applications installed by Helm'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10：获取Helm安装的所有应用程序列表
- en: 'Now, we can remove the release as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以按以下方式删除发布：
- en: '[PRE35]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Use the name from the previous output. You should see this response:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面输出中的名称。您应该看到这个响应：
- en: '[PRE36]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: And just like that, we've written our first chart. So, let's proceed to the
    following exercise, where we will learn exactly how Helm can make our job easier.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 就像那样，我们已经编写了我们的第一个图表。所以，让我们继续进行下一个练习，我们将学习Helm如何确切地使我们的工作变得更容易。
- en: 'Exercise 14.03: Chart-ifying Our Redis-Based Counter Application'
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习14.03：为我们的基于Redis的计数器应用创建图表
- en: We created a generic Helm chart in the previous section, but what if we want
    to make our own chart for our software? In this exercise, we will create a Helm
    chart that will deploy our HA Redis-based solution from *Chapter 12*, *Your Application
    and HA*, using Helm.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们创建了一个通用的Helm图表，但是如果我们想为我们的软件制作自己的图表呢？在这个练习中，我们将创建一个Helm图表，该图表将使用Helm从*第12章*“您的应用程序和HA”中部署我们的HA基于Redis的解决方案。
- en: 'If you are inside the `chart-dev` directory, navigate to the parent directory:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您在`chart-dev`目录中，导航到父目录：
- en: '[PRE37]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s start by making a fresh Helm chart:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先制作一个全新的Helm图表：
- en: '[PRE38]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You should see this response:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到这个响应：
- en: '[PRE39]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now let''s remove the unnecessary files from our chart:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们从图表中删除不必要的文件：
- en: '[PRE40]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we need to navigate into the `templates` folder of our chart and copy
    in the files from our repo for the Redis-based counter application:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要进入图表的`templates`文件夹，并从我们的存储库中复制Redis计数应用程序的文件：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: You may recall from previous chapters that we had multiple Kubernetes manifests
    sharing one file, separated by the `---` YAML file separator string. Now that
    we have a tool for managing Kubernetes manifests, it's better to keep them in
    separate files so that we can manage them independently. The job of bundling will
    now be handled by Helm.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得之前的章节中，我们有多个Kubernetes清单共享一个文件，由`---` YAML文件分隔符字符串分隔。现在我们有了一个管理Kubernetes清单的工具，最好将它们保存在单独的文件中，以便我们可以独立管理它们。捆绑的工作现在将由Helm来处理。
- en: 'There should be four files in the `templates` folder. Let''s confirm that as
    follows:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`templates`文件夹中应该有四个文件。让我们确认一下：'
- en: '[PRE42]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You should see the following response:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会看到以下响应：
- en: '![Figure 14.11: Expected file structure for our application'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.11：我们应用程序的预期文件结构'
- en: '](image/B14870_14_11.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_11.jpg)'
- en: 'Figure 14.11: Expected file structure for our application'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.11：我们应用程序的预期文件结构
- en: 'ow we need to modify the `values.yaml` file. Delete all contents from that
    file and copy only the following into it:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要修改`values.yaml`文件。从该文件中删除所有内容，然后只复制以下内容：
- en: '[PRE43]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, to wire them together, we need to edit both `deployment.yaml` and `redis-deployment.yaml`.
    The one we will edit first is `deployment.yaml`. We should replace `replicas:
    3` with the template, as shown in the highlighted line in the following manifest:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，为了将它们连接在一起，我们需要编辑`deployment.yaml`和`redis-deployment.yaml`。我们首先要编辑的是`deployment.yaml`。我们应该用模板替换`replicas:
    3`，如下清单中的突出显示行所示：'
- en: '[PRE44]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, edit the `redis-deployment.yaml` file and add a similar block of templating
    language, as shown in the highlighted line in the following manifest:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，编辑`redis-deployment.yaml`文件，并添加一个类似的模板语言块，如下清单中的突出显示行所示：
- en: '[PRE45]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now let''s install our application using Helm:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用Helm安装我们的应用程序：
- en: '[PRE46]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'You should see a response similar to this:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会看到类似于这样的响应：
- en: '![Figure 14.12: Installing our Helm chart with an auto-generated name'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.12：使用自动生成的名称安装我们的Helm图表'
- en: '](image/B14870_14_12.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_12.jpg)'
- en: 'Figure 14.12: Installing our Helm chart with an auto-generated name'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.12：使用自动生成的名称安装我们的Helm图表
- en: 'To check whether our application is online, we can get the list of deployments:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查我们的应用程序是否在线，我们可以获取部署列表：
- en: '[PRE47]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You should see the following output:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会看到以下输出：
- en: '![Figure 14.13: Getting the list of deployments'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.13：获取部署列表'
- en: '](image/B14870_14_13.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_13.jpg)'
- en: 'Figure 14.13: Getting the list of deployments'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.13：获取部署列表
- en: As you can see, Helm has deployed our application deployment, as well as the
    Redis backend for it. With these skills in the bag, you are soon to be a captain
    of Helm.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Helm已部署了我们的应用程序部署，以及为其部署的Redis后端。有了这些技能，您很快就会成为Helm的船长。
- en: In the following activity, we will bring together the two things we learned
    in this chapter – refactoring our application for stateful components and then
    deploying it as a Helm chart.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的活动中，我们将结合本章学到的两件事情——重构我们的应用程序以用于有状态的组件，然后将其部署为Helm图表。
- en: 'Activity 14.01: Chart-ifying Our StatefulSet Deployment'
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动14.01：将我们的StatefulSet部署为图表
- en: Now that you have experience with MySQL, StatefulSets, and Helm for resource
    management, your activity is to take what you learned in *Exercises 14.01*, *14.02*,
    and *14.03* and combine them together.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了MySQL、StatefulSets和Helm资源管理的经验，您的任务是将*练习14.01*、*14.02*和*14.03*中学到的知识结合起来。
- en: For this activity, we will refactor our Redis-based application to use MySQL
    as the backend datastore using StatefulSets, and then deploy it using Helm.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个活动，我们将重构我们基于Redis的应用程序，使用StatefulSets来使用MySQL作为后端数据存储，并使用Helm进行部署。
- en: 'Follow these high-level guidelines to complete the activity:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循这些高级指南完成活动：
- en: Set up the required cluster infrastructure as shown in *step 1* of *Exercise
    14.01*, *Deploying a Counter App with a MySQL Backend*.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照*Exercise 14.01*的*step 1*中所示设置所需的集群基础设施，部署一个带有MySQL后端的计数器应用。
- en: Introduce a new Helm chart called `counter-mysql`.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 引入一个名为`counter-mysql`的新Helm图表。
- en: Create a template for our counter application that uses MySQL as its backend.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个使用MySQL作为后端的计数器应用的模板。
- en: Create a template for our MySQL StatefulSet.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为我们的MySQL StatefulSet创建一个模板。
- en: Wire everything together with Kubernetes Service objects wherever appropriate.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在适当的地方使用Kubernetes Service对象将所有内容连接起来。
- en: Configure the template such that the `values.yaml` file is able to change the
    version of MySQL.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置模板，使`values.yaml`文件能够更改MySQL的版本。
- en: 'Test the application. You should see a similar output to that which we''ve
    seen in previous exercises with our counter application:![Figure 14.14: Expected
    output of Activity 14.01'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试应用程序。您应该看到与我们在以前的练习中看到的计数器应用程序类似的输出：![图14.14：活动14.01的预期输出
- en: '](image/B14870_14_14.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B14870_14_14.jpg)'
- en: 'Figure 14.14: Expected output of Activity 14.01'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.14：活动14.01的预期输出
- en: Note
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The solution to this activity can be found at the following address: [https://packt.live/304PEoD](https://packt.live/304PEoD).'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在以下地址找到：[https://packt.live/304PEoD](https://packt.live/304PEoD)。
- en: Also, don't forget to clean up your cloud resources using the `terraform destroy`
    command to stop AWS from billing you after you are done with the activity.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，不要忘记使用`terraform destroy`命令清理云资源，以防止AWS在活动结束后向您收费。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Over the course of this chapter, we have applied our skills to be able to leverage
    StatefulSets in our example application. We have looked at how to think about
    running stateful portions of our software programmatically and how to refactor
    applications to leverage that change in state persistence. Finally, we learned
    how to create and run Kubernetes StatefulSets that will allow us to run stateful
    components in our cluster and make guarantees about how that workload will be
    run.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的过程中，我们已经应用了我们的技能，以便能够在我们的示例应用程序中利用StatefulSets。我们已经看到了如何以编程方式考虑运行软件的有状态部分，以及如何重构应用程序以利用状态持久性的变化。最后，我们学会了如何创建和运行Kubernetes
    StatefulSets，这将使我们能够在集群中运行有状态的组件，并对工作负载的运行方式做出保证。
- en: Being equipped with the skills needed to manage stateful components on our Kubernetes
    cluster is a major step in being able to operate effectively in many real-world
    applications that you are likely to come across.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 具备管理Kubernetes集群上有状态组件所需的技能是能够有效地在许多现实世界的应用中操作的重要一步。
- en: In the next chapter, we're going to talk more about data-driven application
    orchestration with the use of Metrics Server, HorizontalPodAutoscalers, and ClusterAutoscaler.
    We will learn how these objects help us respond to varying levels of demand on
    our application running on a Kubernetes cluster.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更多地讨论使用Metrics Server、HorizontalPodAutoscalers和ClusterAutoscaler进行数据驱动的应用编排。我们将学习这些对象如何帮助我们应对运行在Kubernetes集群上的应用的需求变化。
