["```\nimport os\n from api_gateway_service.api import app\n def main():\n     port = int(os.environ.get('PORT', 5000))\n     login_url = 'http://localhost:{}/login'.format(port)\n     print('If you run locally, browse to', login_url)\n     host = '0.0.0.0'\n     app.run(host=host, port=port)\n\n if __name__ == \"__main__\":\n     raise RuntimeError('Failing on purpose to demonstrate CrashLoopBackOff')\n     main()\n```", "```\n$ minikube addons enable metrics-server\n metrics-server was successfully enabled\n```", "```\n    resources:\n       requests:\n         cpu: 100m\n```", "```\nfunc wasteCPU() {\n     fmt.Println(\"wasteCPU() here!\")\n     go func() {\n         for {\n             if rand.Int() % 8000 == 0 {\n                 time.Sleep(50 * time.Microsecond)\n             }\n         }\n     }()\n }\n```", "```\n$ kubectl autoscale deployment social-graph-manager --cpu-percent=50 --min=1 --max=5\n```", "```\n$ kubectl get hpa\nNAME   REFERENCE  TARGETS    MINPODS   MAXPODS   REPLICAS   AGE\nsocial-graph-manager   Deployment/social-graph-manager   138%/50%   1         5         5          12h\n```", "```\n$ git clone https://github.com/kubernetes/autoscaler.git\n$ cd autoscaler/vertical-pod-autoscaler/hack/ \n$ ./vpa-up.sh\n```", "```\n$ kubectl -n kube-system get svc | grep vpa\nvpa-webhook    ClusterIP   10.103.169.18    <none>        443/TCP\n\n$ kubectl -n kube-system get po | grep vpa\nvpa-admission-controller-68c748777d-92hbg 1/1  Running   0   72s\nvpa-recommender-6fc8c67d85-shh8g          1/1  Running   0   77s\nvpa-updater-786b96955c-8mcrc              1/1  Running   0   78s\n\n$ kubectl get crd | grep vertical\nverticalpodautoscalercheckpoints.autoscaling.k8s.io  2019-05-08T04:58:24Z\nverticalpodautoscalers.autoscaling.k8s.io            2019-05-08T04:58:24Z\n```", "```\napiVersion: autoscaling.k8s.io/v1beta2\nkind: VerticalPodAutoscaler\nmetadata:\n  name: link-manager\nspec:\n  targetRef:\n    apiVersion: \"extensions/v1beta1\"\n    kind:       Deployment\n    name:       link-manager\n  updatePolicy:\n    updateMode: \"Off\"\n```", "```\n$ kubectl create -f link-manager-vpa.yaml\n verticalpodautoscaler.autoscaling.k8s.io/link-manager created\n\n$ kubectl get vpa link-manager -o jsonpath=\"{.status.recommendation.containerRecommendations[0].lowerBound}\"\n map[cpu:25m memory:262144k]\n\n$ kubectl get vpa link-manager -o jsonpath=\"{.status.recommendation.containerRecommendations[0].target}\"\n map[cpu:25m memory:262144k]\n```", "```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-manager\n  labels:\n    svc: user\n    app: manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      svc: user\n      app: manager\n  template:\n    metadata:\n      labels:\n        svc: user\n        app: manager\n    spec:\n      containers:\n      - name: user-manager\n        image: g1g1/delinkcious-user:0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 7070\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 250m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n```", "```\napiVersion: v1\nkind: List\nitems:\n- apiVersion: v1\n  kind: ResourceQuota\n  metadata:\n    name: awesome-quota\n  spec:\n    hard:\n      cpu: \"1000\"\n      memory: 200Gi\n      pods: \"100\"\n```", "```\n$ kubectl create -f resource-quota.yaml \nresourcequota/awesome-quota created\n```", "```\n$ kubectl get resourcequota awesome-quota -o yaml | grep status -A 8\nstatus:\n hard:\n cpu: 1k\n memory: 200Gi\n pods: \"100\"\n used:\n cpu: 350m\n memory: 64Mi\n pods: \"10\"\n```", "```\ntype Logger struct { ... } // Not an interface!\n\nfunc New(out io.Writer, prefix string, flag int) *Logger\n\n// flag controls date, time, \u00b5s, UTC, caller\n\n// Log\nfunc (l *Logger) Print(v ...interface{})\nfunc (l *Logger) Printf(format string, v ...interface{})\nfunc (l *Logger) Println(v ...interface{})\n\n// Log and call os.Exit(1)\nfunc (l *Logger) Fatal(v ...interface{})\nfunc (l *Logger) Fatalf(format string, v ...interface{})\nfunc (l *Logger) Fatalln(v ...interface{})\n\n// Log and panic\nfunc (l *Logger) Panic(v ...interface{})\nfunc (l *Logger) Panicf(format string, v ...interface{})\nfunc (l *Logger) Panicln(v ...interface{})\n\nfunc (l *Logger) Output(calldepth int, s string) error\n```", "```\ntype Logger interface {\n Log(keyvals ...interface{}) error\n}\n```", "```\npackage log\n\nimport (\n  kit_log \"github.com/go-kit/kit/log\"\n  std_log \"log\"\n  \"os\"\n)\n\nfunc NewLogger(service string) (logger kit_log.Logger) {\n  w := kit_log.NewSyncWriter(os.Stderr)\n  logger = kit_log.NewJSONLogger(w)\n  logger = kit_log.With(logger, \"service\", service)\n  logger = kit_log.With(logger, \"timestamp\", kit_log.DefaultTimestampUTC)\n  logger = kit_log.With(logger, \"called from\", kit_log.DefaultCaller)\n\n  return\n}\n\nfunc Fatal(v ... interface{}) {\n  std_log.Fatal(v...)\n}\n```", "```\ntype linkManagerMiddleware func(om.LinkManager) om.LinkManager\n```", "```\n// implement function to return ServiceMiddleware\nfunc newLoggingMiddleware(logger log.Logger) linkManagerMiddleware {\n  return func(next om.LinkManager) om.LinkManager {\n    return loggingMiddleware{next, logger}\n  }\n}\n```", "```\ntype loggingMiddleware struct {\n  next om.LinkManager\n  logger log.Logger\n}\n```", "```\nfunc (m loggingMiddleware) GetLinks(request om.GetLinksRequest) (result om.GetLinksResult, err error) {\n  defer func(begin time.Time) {\n    m.logger.Log(\n      \"method\", \"GetLinks\",\n      \"request\", request,\n      \"result\", result,\n      \"duration\", time.Since(begin),\n    )\n  }(time.Now())\n  result, err = m.next.GetLinks(request)\n  return\n}\n```", "```\nfunc (m loggingMiddleware) AddLink(request om.AddLinkRequest) error {\n  return m.next.AddLink(request)\n}\n\nfunc (m loggingMiddleware) UpdateLink(request om.UpdateLinkRequest) error {\n  return m.next.UpdateLink(request)\n}\n\nfunc (m loggingMiddleware) DeleteLink(username string, url string) error {\n  return m.next.DeleteLink(username, url)\n}\n```", "```\n$ kubectl logs svc/link-manager\n{\"called from\":\"link_service.go:133\",\"msg\":\"*** listening on ***\",\"port\":\"8080\",\"service\":\"link manager\",\"timestamp\":\"2019-05-13T02:44:42.588578835Z\"}\n{\"called from\":\"logging_middleware.go:25\",\"duration\":\"1.526953ms\",\"method\":\"GetLinks\",\"request\":{\"UrlRegex\":\"\",\"TitleRegex\":\"\",\"DescriptionRegex\":\"\",\"Username\":\"Gigi Sayfan\",\"Tag\":\"\",\"StartToken\":\"\"},\"result\":{\"Links\":[],\"NextPageToken\":\"\"},\"service\":\"link manager\",\"timestamp\":\"2019-05-13T02:45:05.302342532Z\"}\n{\"called from\":\"logging_middleware.go:25\",\"duration\":\"591.148\u00b5s\",\"method\":\"GetLinks\",\"request\":{\"UrlRegex\":\"\",\"TitleRegex\":\"\",\"DescriptionRegex\":\"\",\"Username\":\"Gigi Sayfan\",\"Tag\":\"\",\"StartToken\":\"\"},\"result\":{\"Links\":[{\"Url\":\"https://github.com/the-gigi\",\"Title\":\"Gigi on Github\",\"Description\":\"\",\"Status\":\"pending\",\"Tags\":null,\"CreatedAt\":\"2019-05-13T02:45:05.845411Z\",\"UpdatedAt\":\"2019-05-13T02:45:05.845411Z\"}],\"NextPageToken\":\"\"},\"service\":\"link manager\",\"timestamp\":\"2019-05-13T02:45:06.134842509Z\"}\n{\"called from\":\"logging_middleware.go:25\",\"duration\":\"911.499\u00b5s\",\"method\":\"GetLinks\",\"request\":{\"UrlRegex\":\"\",\"TitleRegex\":\"\",\"DescriptionRegex\":\"\",\"Username\":\"Gigi Sayfan\",\"Tag\":\"\",\"StartToken\":\"\"},\"result\":{\"Links\":[{\"Url\":\"https://github.com/the-gigi\",\"Title\":\"Gigi on Github\",\"Description\":\"\",\"Status\":\"pending\",\"Tags\":null,\"CreatedAt\":\"2019-05-13T02:45:05.845411Z\",\"UpdatedAt\":\"2019-05-13T02:45:05.845411Z\"}],\"NextPageToken\":\"\"},\"service\":\"link manager\",\"timestamp\":\"2019-05-13T02:45:09.438915897Z\"}\n\n```", "```\n// resource usage metrics of a node.\ntype NodeMetrics struct {\n  metav1.TypeMeta\n  metav1.ObjectMeta\n\n  // The following fields define time interval from which metrics were\n  // collected from the interval [Timestamp-Window, Timestamp].\n  Timestamp metav1.Time\n  Window metav1.Duration\n\n  // The memory usage is the memory working set.\n  Usage corev1.ResourceList\n}\n\n// NodeMetricsList is a list of NodeMetrics.\ntype NodeMetricsList struct {\n  metav1.TypeMeta\n  // Standard list metadata.\n  // More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds\n  metav1.ListMeta\n\n  // List of node metrics.\n  Items []NodeMetrics\n}\n```", "```\n// ResourceList is a set of (resource name, quantity) pairs.\ntype ResourceList map[ResourceName]resource.Quantity\n```", "```\nhelm install stable/metrics-server \\\n --name metrics-server \\\n --version 2.0.4 \\\n --namespace kube-system\n```", "```\n$ kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/nodes\" | jq .\n{\n \"kind\": \"NodeMetricsList\",\n \"apiVersion\": \"metrics.k8s.io/v1beta1\",\n \"metadata\": {\n \"selfLink\": \"/apis/metrics.k8s.io/v1beta1/nodes\"\n },\n \"items\": [\n {\n \"metadata\": {\n \"name\": \"ip-192-168-13-100.ec2.internal\",\n \"selfLink\": \"/apis/metrics.k8s.io/v1beta1/nodes/ip-192-168-13-100.ec2.internal\",\n \"creationTimestamp\": \"2019-05-17T20:05:29Z\"\n },\n \"timestamp\": \"2019-05-17T20:04:54Z\",\n \"window\": \"30s\",\n \"usage\": {\n \"cpu\": \"85887417n\",\n \"memory\": \"885828Ki\"\n }\n }\n ]\n}\n```", "```\n$ kubectl top nodes\nNAME                        CPU(cores) CPU%  MEMORY(bytes)  MEMORY%\nip-192-168-13-100.ec2.internal   85m   4%     863Mi           11%\n\n$ kubectl top pods\nNAME                                    CPU(cores)   MEMORY(bytes)\napi-gateway-795f7dcbdb-ml2tm            1m           23Mi\nlink-db-7445d6cbf7-2zs2m                1m           32Mi\nlink-manager-54968ff8cf-q94pj           0m           4Mi\nnats-cluster-1                          1m           3Mi\nnats-operator-55dfdc6868-fj5j2          2m           11Mi\nnews-manager-7f447f5c9f-c4pc4           0m           1Mi\nnews-manager-redis-0                    1m           1Mi\nsocial-graph-db-7565b59467-dmdlw        1m           31Mi\nsocial-graph-manager-64cdf589c7-4bjcn   0m           1Mi\nuser-db-0                               1m           32Mi\nuser-manager-699458447-6lwjq            1m           1Mi\n```", "```\n$ helm install --name prometheus stable/prometheus\n This will create service accounts, RBAC roles, RBAC bindings, deployments, services and even a daemon set. In addition it will print the following information to connect to different components:\n```", "```\n  export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\")\n  kubectl --namespace default port-forward $POD_NAME 9090\n```", "```\nprometheus-alertmanager.default.svc.cluster.local\n```", "```\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=alertmanager\" -o jsonpath=\"{.items[0].metadata.name}\")\n  kubectl --namespace default port-forward $POD_NAME 9093\n```", "```\n prometheus-pushgateway.default.svc.cluster.local\n```", "```\n  export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=pushgateway\" -o jsonpath=\"{.items[0].metadata.name}\")\n  kubectl --namespace default port-forward $POD_NAME 9091\n```", "```\n$ kubectl get svc -o name | grep prom\nservice/prometheus-alertmanager\nservice/prometheus-kube-state-metrics\nservice/prometheus-node-exporter\nservice/prometheus-pushgateway\nservice/prometheus-server\n```", "```\n$ export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\")\n\n$ kubectl port-forward $POD_NAME 9090\nForwarding from 127.0.0.1:9090 -> 9090\nForwarding from [::1]:9090 -> 9090\n```", "```\npackage metrics\n\nimport (\n  \"github.com/prometheus/client_golang/prometheus\"\n  \"github.com/prometheus/client_golang/prometheus/promauto\"\n)\n\nfunc NewCounter(service string, name string, help string) prometheus.Counter {\n  opts := prometheus.CounterOpts{\n    Namespace: \"\",\n    Subsystem: service,\n    Name: name,\n    Help: help,\n  }\n  counter := promauto.NewCounter(opts)\n  return counter\n}\n\nfunc NewSummary(service string, name string, help string) prometheus.Summary {\n  opts := prometheus.SummaryOpts{\n    Namespace: \"\",\n    Subsystem: service,\n    Name: name,\n    Help: help,\n  }\n\n  summary := promauto.NewSummary(opts)\n  return summary\n}\n```", "```\npackage service\n\nimport (\n  \"github.com/prometheus/client_golang/prometheus\"\n  \"github.com/the-gigi/delinkcious/pkg/metrics\"\n  om \"github.com/the-gigi/delinkcious/pkg/object_model\"\n  \"strings\"\n  \"time\"\n)\n\n// implement function to return ServiceMiddleware\nfunc newMetricsMiddleware() linkManagerMiddleware {\n  return func(next om.LinkManager) om.LinkManager {\n    m := metricsMiddleware{next,\n      map[string]prometheus.Counter{},\n      map[string]prometheus.Summary{}}\n    methodNames := []string{\"GetLinks\", \"AddLink\", \"UpdateLink\", \"DeleteLink\"}\n    for _, name := range methodNames {\n      m.requestCounter[name] = metrics.NewCounter(\"link\",\n                                                  strings.ToLower(name)+\"_count\",\n                                                  \"count # of requests\")\n      m.requestLatency[name] = metrics.NewSummary(\"link\",\n                                                  strings.ToLower(name)+\"_summary\",\n                                                  \"request summary in milliseconds\")\n\n    }\n    return m\n  }\n```", "```\ntype metricsMiddleware struct {\n  next om.LinkManager\n  requestCounter map[string]prometheus.Counter\n  requestLatency map[string]prometheus.Summary\n}\n```", "```\nfunc (m metricsMiddleware) GetLinks(request om.GetLinksRequest) (result om.GetLinksResult, err error) {\n  defer func(begin time.Time) {\n    m.recordMetrics(\"GetLinks\", begin)\n  }(time.Now())\n  result, err = m.next.GetLinks(request)\n  return\n}\n```", "```\nfunc (m metricsMiddleware) recordMetrics(name string, begin time.Time) {\n  m.requestCounter[name].Inc()\n  durationMilliseconds := float64(time.Since(begin).Nanoseconds() * 1000000)\n  m.requestLatency[name].Observe(durationMilliseconds)\n}\n```", "```\n// Hook up the metrics middleware\nsvc = newMetricsMiddleware()(svc)\n\n...\n\n// Expose the metrics endpoint\nr.Methods(\"GET\").Path(\"/metrics\").Handler(promhttp.Handler())\n```", "```\n$ http http://localhost:8080/metrics | grep 'link_get\\|add'\n\n# HELP link_addlink_count count # of requests\n# TYPE link_addlink_count counter\nlink_addlink_count 3\n# HELP link_addlink_summary request summary in milliseconds\n# TYPE link_addlink_summary summary\nlink_addlink_summary{quantile=\"0.5\"} 2.514194e+12\nlink_addlink_summary{quantile=\"0.9\"} 2.565382e+12\nlink_addlink_summary{quantile=\"0.99\"} 2.565382e+12\nlink_addlink_summary_sum 7.438251e+12\nlink_addlink_summary_count 3\n# HELP link_getlinks_count count # of requests\n# TYPE link_getlinks_count counter\nlink_getlinks_count 9\n# HELP link_getlinks_summary request summary in milliseconds\n# TYPE link_getlinks_summary summary\nlink_getlinks_summary{quantile=\"0.5\"} 5.91539e+11\nlink_getlinks_summary{quantile=\"0.9\"} 8.50423e+11\nlink_getlinks_summary{quantile=\"0.99\"} 8.50423e+11\nlink_getlinks_summary_sum 5.710272e+12\nlink_getlinks_summary_count 9\n\n```", "```\n$ kubectl get svc prometheus-alertmanager\nNAME                      TYPE     CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nprometheus-alertmanager  ClusterIP  10.100.109.90 <none>  80/TCP   24h\n```", "```\ngroups:\n- name: link-manager\n  rules:\n  - alert: SlowAddLink\n    expr: link_addlink_summary{quantile=\"0.5\"} > 5\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      description: the AddLink() method takes more than 5 seconds for more than half of the request in the last minute\n      summary: the AddLink() method takes too long\n```", "```\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing_v1_jaeger_crd.yaml\ncustomresourcedefinition.apiextensions.k8s.io/jaegers.jaegertracing.io created\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/service_account.yaml\nserviceaccount/jaeger-operator created\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/role.yaml\nclusterrole.rbac.authorization.k8s.io/jaeger-operator created\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/role_binding.yaml\nclusterrolebinding.rbac.authorization.k8s.io/jaeger-operator created\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/operator.yaml\ndeployment.apps/jaeger-operator created\n```", "```\napiVersion: jaegertracing.io/v1\nkind: Jaeger\nmetadata:\n  name: jaeger-in-memory\nspec:\n  agent:\n    strategy: DaemonSet\n```", "```\npackage service\n\nimport (\n  \"github.com/opentracing/opentracing-go\"\n  om \"github.com/the-gigi/delinkcious/pkg/object_model\"\n)\n\nfunc newTracingMiddleware(tracer opentracing.Tracer) linkManagerMiddleware {\n  return func(next om.LinkManager) om.LinkManager {\n    return tracingMiddleware{next, tracer}\n  }\n}\n\ntype tracingMiddleware struct {\n  next om.LinkManager\n  tracer opentracing.Tracer\n}\n\nfunc (m tracingMiddleware) GetLinks(request om.GetLinksRequest) (result om.GetLinksResult, err error) {\n  defer func(span opentracing.Span) {\n    span.Finish()\n  }(m.tracer.StartSpan(\"GetLinks\"))\n  result, err = m.next.GetLinks(request)\n  return\n}\n```", "```\n// createTracer returns an instance of Jaeger Tracer that samples\n// 100% of traces and logs all spans to stdout.\nfunc createTracer(service string) (opentracing.Tracer, io.Closer) {\n  cfg := &jaegerconfig.Configuration{\n    ServiceName: service,\n    Sampler: &jargerconfig.SamplerConfig{\n      Type: \"const\",\n      Param: 1,\n    },\n    Reporter: &jaegerconfig.ReporterConfig{\n      LogSpans: true,\n    },\n  }\n  logger := jaegerconfig.Logger(jaeger.StdLogger)\n  tracer, closer, err := cfg.NewTracer(logger)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: cannot create tracer: %v\\n\", err))\n  }\n  return tracer, closer\n}\n```", "```\n// Create a tracer\n tracer, closer := createTracer(\"link-manager\")\n defer closer.Close()\n\n ...\n\n // Hook up the tracing middleware\n svc = newTracingMiddleware(tracer)(svc)\n```", "```\n$ kubectl logs svc/link-manager | grep span\n2019/05/20 16:44:17 Reporting span 72bce473b1af5236:72bce473b1af5236:0:1\n2019/05/20 16:44:18 Reporting span 6e9f45ce1bb0a071:6e9f45ce1bb0a071:0:1\n2019/05/20 16:44:21 Reporting span 32dd9d1edc9e747a:32dd9d1edc9e747a:0:1\n```"]