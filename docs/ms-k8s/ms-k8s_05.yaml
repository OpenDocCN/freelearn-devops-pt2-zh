- en: Configuring Kubernetes Security, Limits, and Accounts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Kubernetes安全性、限制和账户
- en: In [Chapter 4](0b446f8f-3748-4bb4-8406-78f2af468e14.xhtml), *High Availability
    and Reliability*, we looked at reliable and highly available Kubernetes clusters,
    the basic concepts, the best practices, how to do live cluster upgrades, and the
    many design trade-offs regarding performance and cost.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](0b446f8f-3748-4bb4-8406-78f2af468e14.xhtml)中，*高可用性和可靠性*，我们讨论了可靠且高可用的Kubernetes集群，基本概念，最佳实践，如何进行实时集群升级，以及关于性能和成本的许多设计权衡。
- en: In this chapter, we will explore the important topic of security. Kubernetes
    clusters are complicated systems composed of multiple layers of interacting components.
    The isolation and compartmentalization of different layers is very important when
    running critical applications. To secure the system and ensure proper access to
    resources, capabilities, and data, we must first understand the unique challenges
    facing Kubernetes as a general-purpose orchestration platform that runs unknown
    workloads. Then, we can take advantage of various securities, isolation, and access
    control mechanisms to make sure the cluster and the applications running on it,
    and the data are all safe. We will discuss various best practices and when it
    is appropriate to use each mechanism.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨安全这一重要主题。Kubernetes集群是由多个层次的相互作用组件组成的复杂系统。在运行关键应用程序时，不同层的隔离和分隔非常重要。为了保护系统并确保对资源、能力和数据的适当访问，我们必须首先了解Kubernetes作为一个运行未知工作负载的通用编排平台所面临的独特挑战。然后，我们可以利用各种安全、隔离和访问控制机制，确保集群和运行在其上的应用程序以及数据都是安全的。我们将讨论各种最佳实践以及何时适合使用每种机制。
- en: At the end of this chapter, you will have a good understanding of the Kubernetes
    security challenges. You will gain practical knowledge of how to harden Kubernetes
    against various potential attacks, establishing defense in depth, and will even
    be able to safely run a multitenant cluster while providing different users with
    full isolation as well as full control over their part of the cluster.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的结尾，您将对Kubernetes安全挑战有很好的理解。您将获得如何加固Kubernetes以抵御各种潜在攻击的实际知识，建立深度防御，并且甚至能够安全地运行多租户集群，同时为不同用户提供完全隔离以及对他们在集群中的部分拥有完全控制的能力。
- en: Understanding Kubernetes security challenges
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes安全挑战
- en: Kubernetes is a very flexible system that manages very low-level resources in
    a generic way. Kubernetes itself can be deployed on many operating systems and
    hardware or virtual-machine solutions on-premises or in the cloud. Kubernetes
    runs workloads implemented by runtimes it interacts with through a well-defined
    runtime interface, but without understanding how they are implemented. Kubernetes
    manipulates critical resources, such as networking, DNS, and resource allocation,
    on behalf or in service of applications it knows nothing about. This means that
    Kubernetes is faced with the difficult task of providing good security mechanisms
    and capabilities in a way that application administrators can use, while protecting
    itself and the application administrators from common mistakes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个非常灵活的系统，以通用方式管理非常低级别的资源。Kubernetes本身可以部署在许多操作系统和硬件或虚拟机解决方案上，可以部署在本地或云端。Kubernetes运行由运行时实现的工作负载，通过定义良好的运行时接口与之交互，但不了解它们是如何实现的。Kubernetes操作关键资源，如网络、DNS和资源分配，代表或为了应用程序服务，而对这些应用程序一无所知。这意味着Kubernetes面临着提供良好的安全机制和能力的艰巨任务，以便应用程序管理员可以使用，同时保护自身和应用程序管理员免受常见错误的影响。
- en: 'In this section, we will discuss security challenges in several layers or components
    of a Kubernetes cluster: nodes, networks, images, pods, and containers. In-dept
    defense is an important security concept that requires systems to protect themselves
    at each level, both to mitigate attacks that penetrated other layers and to limit
    the scope and damage of a breach. Recognizing the challenges in each layer is
    the first step toward defense in depth.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论Kubernetes集群的几个层次或组件的安全挑战：节点、网络、镜像、Pod和容器。深度防御是一个重要的安全概念，要求系统在每个层面都保护自己，既要减轻渗透其他层的攻击，也要限制入侵的范围和损害。认识到每个层面的挑战是向深度防御迈出的第一步。
- en: Node challenges
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点挑战
- en: The nodes are the hosts of the runtime engines. If an attacker gets access to
    a node, this is a serious threat. It can control at least the host itself and
    all the workloads running on it. But it gets worse. The node has a kubelet running
    that talks to the API server. A sophisticated attacker can replace the kubelet
    with a modified version and effectively evade detection by communicating normally
    with the Kubernetes API server, yet running its own workloads instead of the scheduled
    workloads, collecting information about the overall cluster, and disrupting the
    API server and the rest of the cluster by sending malicious messages. The node
    will have access to shared resources and secrets that may allow it to infiltrate
    even deeper. A node breach is very serious, both because of the possible damage
    and the difficulty of detecting it after the fact.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 节点是运行时引擎的主机。如果攻击者能够访问节点，这是一个严重的威胁。它至少可以控制主机本身和运行在其上的所有工作负载。但情况会变得更糟。节点上运行着一个与API服务器通信的kubelet。一个复杂的攻击者可以用修改过的版本替换kubelet，并通过与Kubernetes
    API服务器正常通信来有效地逃避检测，而不是运行预定的工作负载，收集有关整个集群的信息，并通过发送恶意消息来破坏API服务器和集群的其余部分。节点将可以访问共享资源和秘密，这可能使其渗透得更深。节点入侵非常严重，既因为可能造成的损害，也因为事后很难检测到它。
- en: Nodes can be compromised at the physical level too. This is more relevant on
    bare-metal machines where you can tell which hardware is assigned to the Kubernetes
    cluster.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 节点也可能在物理级别上受到损害。这在裸机上更相关，您可以知道哪些硬件分配给了Kubernetes集群。
- en: Another attack vector is resource drain. Imagine that your nodes become part
    of a bot network which, unrelated to your Kubernetes cluster, just runs its own
    workloads and drains CPU and memory. The danger here is that Kubernetes and your
    infrastructure may scale automatically and allocate more resources.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个攻击向量是资源耗尽。想象一下，您的节点成为了一个与您的Kubernetes集群无关的机器人网络的一部分，它只运行自己的工作负载并耗尽CPU和内存。这里的危险在于Kubernetes和您的基础设施可能会自动扩展并分配更多资源。
- en: Another problem is the installation of debugging and troubleshooting tools or
    modifying configuration outside of automated deployment. Those are typically untested
    and, if left behind and active, they can lead to at least degraded performance,
    but can also cause more sinister problems. At the least that increase the attack
    surface.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是安装调试和故障排除工具，或者在自动部署之外修改配置。这些通常是未经测试的，如果被遗留并激活，它们至少会导致性能下降，但也可能引起更严重的问题。至少会增加攻击面。
- en: 'Where security is concerned, it''s a numbers game. You want to understand the
    attack surface of the system and where you''re vulnerable. Let''s list all the
    node challenges:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及安全性的地方，这是一个数字游戏。您希望了解系统的攻击面以及您的脆弱性。让我们列出所有的节点挑战：
- en: Attacker takes control of the host
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者控制主机
- en: Attacker replaces the kubelet
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者替换kubelet
- en: Attacker takes control over a node that runs master components (API server,
    scheduler, and controller manager)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者控制运行主要组件（API服务器、调度器和控制器管理器）的节点
- en: Attacker gets physical access to a node
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者获得对节点的物理访问权限
- en: Attacker drains resources unrelated to the Kubernetes cluster
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者耗尽与Kubernetes集群无关的资源
- en: Self-inflicted damage through installation of debugging and troubleshooting
    tools or configuration change
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过安装调试和故障排除工具或更改配置造成自我伤害
- en: Any important Kubernetes cluster spans at least one network. There are many
    challenges related to networking. You need to understand how your system components
    are connected at a very fine level. Which components are supposed to talk to each
    other? What network protocols do they use? What ports? What data do they exchange?
    How is your cluster connected to the outside world?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 任何重要的Kubernetes集群至少跨越一个网络。与网络相关的挑战很多。您需要非常详细地了解系统组件是如何连接的。哪些组件应该相互通信？它们使用什么网络协议？使用什么端口？它们交换什么数据？您的集群如何与外部世界连接？
- en: 'There is a complex chain of exposing ports and capabilities or services:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 暴露端口和服务的复杂链路：
- en: Container to host
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器到主机
- en: Host to host within the internal network
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机到内部网络中的主机
- en: Host to the world
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机到世界
- en: Using overlay networks (which will be discussed more in [Chapter 10](ce60bd21-54ec-4d19-93a5-18803927e9aa.xhtml),
    *Advanced Kubernetes Networking*) can help with defense in depth where, even if
    an attacker gains access to a Docker container, they are sandboxed and can't escape
    to the underlay network infrastructure.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用覆盖网络（将在[第10章](ce60bd21-54ec-4d19-93a5-18803927e9aa.xhtml)中更多讨论，*高级Kubernetes网络*）可以帮助进行深度防御，即使攻击者获得对Docker容器的访问权限，它们也会被隔离，无法逃脱到底层网络基础设施。
- en: Discovering components is a big challenge too. There are several options here,
    such as DNS, dedicated discovery services, and load balancers. Each comes with
    a set of pros and cons that take careful planning and insight to get right for
    your situation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 发现组件也是一个很大的挑战。这里有几个选项，比如DNS、专用发现服务和负载均衡器。每种方法都有一套利弊，需要仔细规划和洞察力才能在您的情况下得到正确的解决方案。
- en: Making sure that two containers can find each other and exchange information
    is important.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 确保两个容器能够找到彼此并交换信息非常重要。
- en: You need to decide which resources and endpoints should be publicly accessible.
    Then, you need to come up with a proper way to authenticate users and services
    and authorize them to operate on resources.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要决定哪些资源和端点应该是公开访问的。然后，您需要想出一个适当的方法来对用户和服务进行身份验证，并授权它们对资源进行操作。
- en: Sensitive data must be encrypted on the way in and out of the cluster and sometimes
    at rest, too. This means key management and safe key exchange, which is one of
    the most difficult problems to solve in security.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据必须在进入和离开集群时进行加密，有时也需要在静态状态下进行加密。这意味着密钥管理和安全密钥交换，这是安全领域中最难解决的问题之一。
- en: If your cluster shares networking infrastructure with other Kubernetes clusters
    or non-Kubernetes processes, then you have to be diligent about isolation and
    separation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的集群与其他Kubernetes集群或非Kubernetes进程共享网络基础设施，那么您必须对隔离和分离非常谨慎。
- en: 'The ingredients are network policies, firewall rules, and **software-defined
    networking** (**SDN**). The recipe is often customized. This is especially challenging
    with on-premise and bare-metal clusters. Let''s recap:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些要素包括网络策略、防火墙规则和软件定义网络（SDN）。这个方案通常是定制的。这在本地和裸机集群中尤其具有挑战性。让我们回顾一下：
- en: Come up with a connectivity plan
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定连接计划
- en: Choose components, protocols, and ports
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择组件、协议和端口
- en: Figure out dynamic discovery
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找出动态发现
- en: Public versus private access
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公共与私有访问
- en: Authentication and authorization
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份验证和授权
- en: Design firewall rules
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计防火墙规则
- en: Decide on a network policy
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定网络策略
- en: Key management and exchange
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密钥管理和交换
- en: There is constant tension between making it easy for containers, users, and
    services to find and talk to each other at the network level versus locking down
    access and preventing attacks through the network or attacks on the network itself.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络层面，容器、用户和服务之间相互找到并交流变得更加容易，与此同时，也需要限制访问并防止网络攻击或对网络本身的攻击之间保持不断的紧张关系。
- en: Many of these challenges are not Kubernetes specific. However, the fact that
    Kubernetes is a generic platform that manages key infrastructure and deals with
    low-level networking makes it necessary to think about dynamic and flexible solutions
    that can integrate system-specific requirements into Kubernetes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战中许多并非特定于Kubernetes。然而，Kubernetes是一个管理关键基础设施并处理低级网络的通用平台，这使得有必要考虑动态和灵活的解决方案，可以将系统特定要求整合到Kubernetes中。
- en: Image challenges
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像挑战
- en: 'Kubernetes runs containers that comply with one of its runtime engines. It
    has no idea what these containers are doing (except collecting metrics). You can
    put certain limits on containers via quotas. You can also limit their access to
    other parts of the network via network policies. However, in the end, containers
    do need access to host resources, other hosts in the network, distributed storage,
    and external services. The image determines the behavior of a container. There
    are two categories of problems with images:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes运行符合其运行时引擎之一的容器。它不知道这些容器在做什么（除了收集指标）。您可以通过配额对容器施加一定的限制。您还可以通过网络策略限制它们对网络其他部分的访问。然而，最终，容器确实需要访问主机资源、网络中的其他主机、分布式存储和外部服务。图像决定了容器的行为。图像存在两类问题：
- en: Malicious images
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶意图像
- en: Vulnerable images
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易受攻击的图像
- en: Malicious images are images that contain code or configuration that was designed
    by an attacker to do some harm or to collect information. Malicious code can be
    injected into your image preparation pipeline, including any image repositories
    you use. Alternatively, you may install third-party images that were attacked
    themselves and that may now contain malicious code.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意图像是包含由攻击者设计的代码或配置的图像，用于造成一些伤害或收集信息。恶意代码可以被注入到您的图像准备流水线中，包括您使用的任何图像存储库。或者，您可能安装了被攻击的第三方图像，这些图像现在可能包含恶意代码。
- en: Vulnerable images are images you designed (or third-party images you install)
    that just happen to contain some vulnerability that allows an attacker to take
    control of the running container or cause some other harm, including injecting
    their own code later.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 易受攻击的图像是您设计的图像（或您安装的第三方图像），恰好包含一些漏洞，允许攻击者控制正在运行的容器或造成其他伤害，包括以后注入他们自己的代码。
- en: It's hard to tell which category is worse. At the extreme, they are equivalent
    because they allow for seizing total control of the container. The other defenses
    are in place (remember defense in depth?), and the restrictions put on the container
    will determine how much damage it can do. Minimizing the danger of bad images
    is very challenging. Fast-moving companies using microservices may generate many
    images daily. Verifying an image is not an easy task either. Consider, for example,
    how Docker images are made up of layers. The base images that contain the operating
    system may become vulnerable any time a new vulnerability is discovered. Moreover,
    if you rely on base images prepared by someone else (very common), then malicious
    code may find its way into those base images, which you have no control over and
    you trust implicitly.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 很难说哪一类更糟。在极端情况下，它们是等价的，因为它们允许完全控制容器。其他防御措施已经就位（记得深度防御吗？），并且对容器施加的限制将决定它可以造成多大的破坏。减少恶意镜像的危险非常具有挑战性。使用微服务的快速移动公司可能每天生成许多镜像。验证镜像也不是一件容易的事。例如，考虑Docker镜像由多层组成。包含操作系统的基础镜像可能在发现新漏洞时随时变得容易受攻击。此外，如果您依赖他人准备的基础镜像（非常常见），那么恶意代码可能会进入这些您无法控制并且绝对信任的基础镜像中。
- en: 'To summarize image challenges:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总结镜像挑战：
- en: Kubernetes doesn't know what images are doing
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes不知道镜像在做什么
- en: Kubernetes must provide access to sensitive resources for the designated function
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes必须为指定功能提供对敏感资源的访问
- en: It's difficult to protect the image preparation and delivery pipeline (including
    image repositories)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护镜像准备和交付管道（包括镜像仓库）是困难的
- en: The speed of development and deployment of new images may conflict with careful
    review of changes
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速开发和部署新镜像的速度可能与仔细审查更改的冲突
- en: Base images that contain the OS can easily get out of date and become vulnerable
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含操作系统的基础镜像很容易过时并变得容易受攻击
- en: Base images are often not under your control and might be more prone to injection
    of malicious code
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础镜像通常不受您控制，更容易受到恶意代码的注入
- en: Integrating a static image analyzer such as CoreOS Clair can help a lot
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成静态镜像分析器，如CoreOS Clair，可以帮助很多。
- en: Configuration and deployment challenges
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置和部署的挑战
- en: Kubernetes clusters are administered remotely. Various manifests and policies
    determine the state of the cluster at each point in time. If an attacker gets
    access to a machine with administrative control over the cluster, they can wreak
    havoc, such as collecting information, injecting bad images, weakening security,
    and tampering with logs. As usual, bugs and mistakes can be just as harmful, affecting
    important security measures and leaving the cluster open for an attack. It is
    very common these days for employees with administrative access to the cluster
    to work remotely from home or a coffee shop and have their laptops with them,
    where they are one `kubectl` command away from opening the flood gates.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群是远程管理的。各种清单和策略确定了集群在每个时间点的状态。如果攻击者能够访问具有对集群的管理控制的机器，他们可以造成严重破坏，比如收集信息、注入恶意镜像、削弱安全性和篡改日志。通常情况下，错误和失误可能同样有害，影响重要的安全措施，并使集群容易受到攻击。如今，拥有对集群的管理访问权限的员工经常在家或咖啡店远程工作，并随身携带笔记本电脑，他们离打开防护门只有一个
    `kubectl` 命令的距离。
- en: 'Let''s reiterate the challenges:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重申挑战：
- en: Kubernetes is administered remotely
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes是远程管理的
- en: An attacker with remote administrative access can gain complete control over
    the cluster
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有远程管理访问权限的攻击者可以完全控制集群
- en: Configuration and deployment is typically more difficult to test than code
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置和部署通常比代码更难测试
- en: Remote or out-of-office employees risk extended exposure, allowing an attacker
    to gain access to their laptops or phones with administrative access
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程或外出办公的员工面临延长的暴露风险，使攻击者能够以管理员权限访问他们的笔记本电脑或手机
- en: Pod and container challenges
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pod 和容器方面的挑战
- en: In Kubernetes, pods are the unit of work and contain one or more containers.
    The pod is just a grouping and deployment construct, but in practice, containers
    that are deployed together in the same pod usually interact through direct mechanisms.
    The containers all share the same localhost network and often share mounted volumes
    from the host. This easy integration between containers in the same pod can result
    in the exposure of parts of the host to all the containers. This might allow one
    bad container (either malicious or just vulnerable) to open the way for escalated
    attacks on other containers in the pod and later the taking over of the node itself.
    Master add-ons are often collocated with master components and present that kind
    of danger, especially because many of them are experimental. The same goes for
    daemon sets that run pods on every node.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，pod 是工作单位，包含一个或多个容器。Pod 只是一个分组和部署构造，但在实践中，部署在同一个 pod 中的容器通常通过直接机制进行交互。所有容器共享相同的本地主机网络，并经常共享来自主机的挂载卷。同一
    pod 中容器之间的轻松集成可能导致主机的部分暴露给所有容器。这可能允许一个恶意或易受攻击的恶意容器打开对其他容器的升级攻击的途径，然后接管节点本身。主要附加组件通常与主要组件共同存在，并呈现出这种危险，特别是因为它们中的许多是实验性的。对于在每个节点上运行
    pod 的守护程序集也是如此。
- en: 'Multi-container pod challenges include the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 多容器 pod 的挑战包括以下内容：
- en: The same pod containers share the localhost network
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同的 pod 容器共享本地主机网络
- en: The same pod containers sometimes share a mounted volume on the host filesystem
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同的 pod 容器有时会共享主机文件系统上的挂载卷
- en: Bad containers might poison other containers in the pod
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶意容器可能会影响 pod 中的其他容器
- en: Bad containers have an easier time attacking the node if collocated with other
    containers that access crucial node resources
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果与访问关键节点资源的其他容器共同存在，恶意容器更容易攻击节点
- en: Experimental add-ons that are collocated with master components might be experimental
    and less secure
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验性的附加组件与主要组件共同存在时，可能是实验性的并且安全性较低
- en: Organizational, cultural, and process challenges
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织、文化和流程方面的挑战
- en: Security is often in contrast with productivity. This is a normal trade-off
    and nothing to worry about. Traditionally, when developers and operations were
    separate, this conflict was managed at an organizational level. Developers pushed
    for more productivity and treated security requirements as the cost of doing business.
    Operations controlled the production environment and were responsible for access
    and security procedures. The DevOps movement brought down the wall between developers
    and operations. Now, speed of development often takes a front row seat. Concepts
    such as continuous deployment-deploying multiple times a day without human intervention-were
    unheard of in most organizations. Kubernetes was designed for this new world of
    cloud-native applications. However, it was developed based on Google's experience.
    Google had a lot of time and skilled experts to develop the proper processes and
    tooling to balance rapid deployments with security. For smaller organizations,
    this balancing act might be very challenging and security could be compromised.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性通常与生产力相矛盾。这是一种正常的权衡，无需担心。传统上，当开发人员和运营是分开的时，这种冲突是在组织层面上管理的。开发人员推动更多的生产力，并将安全要求视为业务成本。运营控制生产环境，并负责访问和安全程序。DevOps运动打破了开发人员和运营之间的壁垒。现在，开发速度往往占据主导地位。诸如持续部署-在没有人为干预的情况下每天部署多次-这样的概念在大多数组织中是闻所未闻的。Kubernetes是为这种新型云原生应用程序的世界而设计的。然而，它是基于谷歌的经验开发的。谷歌有大量时间和熟练的专家来开发平衡快速部署和安全性的适当流程和工具。对于较小的组织，这种平衡可能非常具有挑战性，安全性可能会受到影响。
- en: 'The challenges facing organizations that adopt Kubernetes are as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 采用Kubernetes的组织面临的挑战如下：
- en: Developers that control the operation of Kubernetes might be less security oriented
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制Kubernetes操作的开发人员可能不太关注安全性
- en: The speed of development might be considered more important than security
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发速度可能被认为比安全性更重要
- en: Continuous deployment might make it difficult to detect certain security problems
    before they reach production
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续部署可能会使难以在达到生产之前检测到某些安全问题
- en: Smaller organizations might not have the knowledge and expertise to manage security
    properly in Kubernetes clusters
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较小的组织可能没有足够的知识和专业技能来正确管理Kubernetes集群的安全性
- en: 'In this section, we reviewed the many challenges you face when you try to build
    a secure Kubernetes cluster. Most of these challenges are not specific to Kubernetes,
    but using Kubernetes means that there is a large part of your system that is generic
    and is unaware of what the system is doing. This can pose problems when trying
    to lock down a system. The challenges are spread across different levels:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了在尝试构建安全的Kubernetes集群时所面临的许多挑战。这些挑战大多数并非特定于Kubernetes，但使用Kubernetes意味着系统的大部分是通用的，并且不知道系统正在做什么。在试图锁定系统时，这可能会带来问题。这些挑战分布在不同的层次上：
- en: Node challenges
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点挑战
- en: Network challenges
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络挑战
- en: Image challenges
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像挑战
- en: Configuration and deployment challenges
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置和部署挑战
- en: Pod and container challenges
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod和容器挑战
- en: Organizational and process challenges
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织和流程挑战
- en: In the next section, we will look at the facilities Kubernetes provides to address
    some of those challenges. Many of the challenges require solutions at the larger
    system level. It is important to realize that just using all of Kubernetes security
    features is not enough.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看一下Kubernetes提供的设施，以解决其中一些挑战。许多挑战需要在更大的系统级别上找到解决方案。重要的是要意识到仅仅使用所有Kubernetes安全功能是不够的。
- en: Hardening Kubernetes
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加固Kubernetes
- en: The previous section cataloged and listed the variety of security challenges
    facing developers and administrators deploying and maintaining Kubernetes clusters.
    In this section, we will hone in on the design aspects, mechanisms, and features
    offered by Kubernetes to address some of the challenges. You can get to a pretty
    good state of security via judicious use of capabilities, such as service accounts,
    network policies, authentication, authorization, admission control, AppArmor,
    and secrets.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节列出了开发人员和管理员在部署和维护Kubernetes集群时面临的各种安全挑战。在本节中，我们将专注于Kubernetes提供的设计方面、机制和功能，以解决其中一些挑战。通过审慎使用功能，如服务账户、网络策略、身份验证、授权、准入控制、AppArmor和秘密，您可以达到一个相当良好的安全状态。
- en: Remember that a Kubernetes cluster is one part of a bigger system that includes
    other software systems, people, and processes. Kubernetes can't solve all problems.
    You should always keep in mind general security principles, such as defense in
    depth, need-to-know basis, and the principle of least privilege. In addition,
    log everything you think may be useful in the event of an attack and set up alerts
    for early detection when the system deviates from its state. It may be just a
    bug or it may be an attack. Either way, you want to know about it and respond.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，Kubernetes集群是一个更大系统的一部分，包括其他软件系统、人员和流程。Kubernetes不能解决所有问题。您应始终牢记一般安全原则，如深度防御、需要知道的基础和最小特权原则。此外，记录您认为在攻击事件中可能有用的所有内容，并设置警报，以便在系统偏离其状态时进行早期检测。这可能只是一个错误，也可能是一次攻击。无论哪种情况，您都希望了解并做出响应。
- en: Understanding service accounts in Kubernetes
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Kubernetes中的服务账户
- en: Kubernetes has regular users managed outside the cluster for humans connecting
    to the cluster (for example, through the `kubectl` command), and it has service
    accounts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在集群外部管理常规用户，用于连接到集群的人员（例如，通过`kubectl`命令），并且它还有服务账户。
- en: Regular users are global and can access multiple namespaces in the cluster.
    Service accounts are constrained to one namespace. This is important. It ensures
    namespace isolation because whenever the API server receives a request from a
    pod, its credentials will apply only to its own namespace.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 常规用户是全局的，可以访问集群中的多个命名空间。服务账户受限于一个命名空间。这很重要。它确保了命名空间的隔离，因为每当API服务器从一个pod接收到请求时，其凭据只适用于其自己的命名空间。
- en: Kubernetes manages service accounts on behalf of the pods. Whenever Kubernetes
    instantiates a pod, it assigns the pod a service account. The service account
    identifies all the pod processes when they interact with the API server. Each
    service account has a set of credentials mounted in a secret volume. Each namespace
    has a default service account named `default`. When you create a pod, it automatically
    assigns the default service account unless you specify a different service account.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes代表pod管理服务账户。每当Kubernetes实例化一个pod时，它会为pod分配一个服务账户。当pod进程与API服务器交互时，服务账户将标识所有的pod进程。每个服务账户都有一组凭据挂载在一个秘密卷中。每个命名空间都有一个名为`default`的默认服务账户。当您创建一个pod时，它会自动分配默认服务账户，除非您指定其他服务账户。
- en: 'You can create additional service accounts. Create a file named `custom-service-account.yaml`
    with the following content:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建额外的服务账户。创建一个名为`custom-service-account.yaml`的文件，其中包含以下内容：
- en: '[PRE0]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that a secret was created automatically for your new service account.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为您的新服务账户自动创建了一个秘密。
- en: 'To get more detail, type the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更多详细信息，请输入以下内容：
- en: '[PRE1]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can see the secret itself, which includes a `ca.crt` file and a token,
    by typing the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过输入以下内容查看秘密本身，其中包括一个`ca.crt`文件和一个令牌：
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How does Kubernetes manage service accounts?
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes如何管理服务账户？
- en: The API server has a dedicated component named the service account admission
    controller. It is responsible for checking, at pod creation time, whether it has
    a custom service account and, if it does, that the custom service account exists.
    If there is no service account specified, then it assigns the default service
    account.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: API服务器有一个名为服务账户准入控制器的专用组件。它负责在pod创建时检查是否有自定义服务账户，如果有，则确保自定义服务账户存在。如果没有指定服务账户，则分配默认服务账户。
- en: It also ensures that the pod has `ImagePullSecrets`, which are necessary when
    images need to be pulled from a remote image registry. If the pod spec doesn't
    have any secrets, it uses the service account's `ImagePullSecrets`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 它还确保pod具有`ImagePullSecrets`，当需要从远程镜像注册表中拉取镜像时是必要的。如果pod规范没有任何密钥，它将使用服务账户的`ImagePullSecrets`。
- en: Finally, it adds a volume with an API token for API access and a `volumeSource`
    mounted at `/var/run/secrets/kubernetes.io/serviceaccount`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它添加了一个包含API访问令牌的卷和一个`volumeSource`挂载在`/var/run/secrets/kubernetes.io/serviceaccount`上。
- en: The API token is created and added to the secret by another component named
    the **Token Controller** whenever a service account is created. The Token Controller
    also monitors secrets and adds or removes tokens wherever secrets are added or
    removed to/from a service account.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: API令牌是由另一个名为**令牌控制器**的组件创建并添加到密钥中，每当创建服务账户时。令牌控制器还监视密钥，并在密钥被添加或从服务账户中删除时添加或删除令牌。
- en: The service account controller ensures that the default service account exists
    for every namespace.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 服务账户控制器确保每个命名空间都存在默认的服务账户。
- en: Accessing the API server
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问API服务器
- en: 'Accessing the API requires a chain of steps that include authentication, authorization,
    and admission control. At each stage, the request may be rejected. Each stage
    consists of multiple plugins that are chained together. The following diagram
    illustrates this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 访问API需要一系列步骤，包括身份验证、授权和准入控制。在每个阶段，请求可能会被拒绝。每个阶段由多个链接在一起的插件组成。以下图表说明了这一点：
- en: '![](Images/d1531a41-3d47-4fc0-8bbe-f435cc592581.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/d1531a41-3d47-4fc0-8bbe-f435cc592581.png)'
- en: Authenticating users
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户身份验证
- en: 'When you first create the cluster, a client certificate and key are created
    for you. `Kubectl` uses them to authenticate itself to the API server and vice
    versa over TLS on port `443` (an encrypted HTTPS connection). You can find your
    client key and certificate by checking your `.kube/config` file:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当您首次创建集群时，会为您创建一个客户端证书和密钥。`Kubectl`使用它们在端口`443`上通过TLS与API服务器进行身份验证，反之亦然（加密的HTTPS连接）。您可以通过检查您的`.kube/config`文件找到您的客户端密钥和证书：
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that if multiple users need to access the cluster, the creator should provide
    the client certificate and key to other users in a secure manner.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果多个用户需要访问集群，创建者应以安全的方式向其他用户提供客户端证书和密钥。
- en: This is just establishing basic trust with the Kubernetes API server itself.
    You're not authenticated yet. Various authentication modules may look at the request
    and check for various additional client certificates, passwords, bearer tokens,
    and JWT tokens (for service accounts). Most requests require an authenticated
    user (either a regular user or a service account) although there are some anonymous
    requests too. If a request fails to authenticate with all the authenticators,
    it will be rejected with a 401 HTTP status code (unauthorized, which is a bit
    of a misnomer).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是与Kubernetes API服务器本身建立基本的信任。您还没有进行身份验证。各种身份验证模块可能会查看请求并检查各种额外的客户端证书、密码、持有者令牌和JWT令牌（用于服务账户）。大多数请求需要经过身份验证的用户（常规用户或服务账户），尽管也有一些匿名请求。如果请求未能通过所有身份验证器进行身份验证，它将被拒绝，并返回401
    HTTP状态码（未经授权，这有点名不副实）。
- en: 'The cluster administrator determines what authentication strategies to use
    by providing various command-line arguments to the API server:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员通过向API服务器提供各种命令行参数来确定要使用的认证策略：
- en: '`--client-ca-file=<filename>` (for x509 client certificates specified in a
    file)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --client-ca-file=<filename>（用于文件中指定的x509客户端证书）
- en: '`--token-auth-file=<filename>` (for bearer tokens specified in a file)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --token-auth-file=<filename>（用于文件中指定的持有者令牌）
- en: '`--basic-auth-file=<filename>` (for user/password pairs specified in a file)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --basic-auth-file=<filename>（用于文件中指定的用户/密码对）
- en: '`--experimental-bootstrap-token-auth` (for bootstrap tokens used by `kubeadm`)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --experimental-bootstrap-token-auth（用于`kubeadm`使用的引导令牌）
- en: 'Service accounts use an automatically loaded authentication plugin. The administrator
    may provide two optional flags:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 服务账户使用自动加载的认证插件。管理员可以提供两个可选标志：
- en: '`--service-account-key-file=<filename>` (PEM-encoded key for signing bearer
    tokens. If unspecified, the API server''s TLS private key will be used.)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --service-account-key-file=<filename>（用于签署持有者令牌的PEM编码密钥。如果未指定，将使用API服务器的TLS私钥。）
- en: '`--service-account-lookup` (If enabled, tokens that are deleted from the API
    will be revoked.)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --service-account-lookup（如果启用，从API中删除的令牌将被撤销。）
- en: There are several other methods, such as open ID connect, web hooks, Keystone
    (the OpenStack identity service), and an authenticating proxy. The main theme
    is that the authentication stage is extensible and can support any authentication
    mechanism.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他几种方法，例如开放ID连接，Web钩子，Keystone（OpenStack身份服务）和认证代理。主题是认证阶段是可扩展的，并且可以支持任何认证机制。
- en: 'The various authentication plugins will examine the request and, based on the
    provided credentials, will associate the following attributes:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 各种认证插件将检查请求，并根据提供的凭据，将关联以下属性：
- en: '**username** (user-friendly name)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户名**（用户友好的名称）'
- en: '**uid** (unique identifier and more consistent than the username)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**uid**（唯一标识符，比用户名更一致）'
- en: '**groups** (a set of group names the user belongs to)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组**（用户所属的一组组名）'
- en: '**extra fields** (maps string keys to string values)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**额外字段**（将字符串键映射到字符串值）'
- en: The authenticator has no knowledge whatsoever of what a particular user is allowed
    to do. They just map a set of credentials to a set of identities. It is the job
    of the authorizers to figure out if the request is valid for the authenticated
    user. Authentication succeeds when any authenticator accepts the credentials.
    The order by which authenticators are run is undefined.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 认证器完全不知道特定用户被允许做什么。他们只是将一组凭据映射到一组身份。授权者的工作是弄清楚请求对经过身份验证的用户是否有效。任何认证器接受凭据时，认证成功。认证器运行的顺序是未定义的。
- en: Impersonation
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟
- en: 'It is possible for users to impersonate different users (with proper authorization).
    For example, an admin may want to troubleshoot some issue as a different user
    with less privileges. This requires passing impersonation headers to the API request.
    The headers are:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以模拟不同的用户（经过适当授权）。例如，管理员可能希望以权限较低的不同用户身份解决一些问题。这需要将模拟头传递给API请求。这些头是：
- en: '`Impersonate-User`: The username to act as.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`模拟用户`：要扮演的用户名。'
- en: '`Impersonate-Group`: This is a group name to act as and can be provided multiple
    times to set multiple groups. This is optional, and it requires `Impersonate-User`.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`模拟组`：这是要扮演的组名，可以多次提供以设置多个组。这是可选的，需要`模拟用户`。'
- en: '`Impersonate-Extra-(extra name)`: This is a dynamic header used to associate
    extra fields with the user. This is optional, and it requires `Impersonate-User`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`模拟额外-(额外名称)`：这是用于将额外字段与用户关联的动态标头。这是可选的，需要`模拟用户`。'
- en: With `kubectl`, you pass `--as` and `--as-group` parameters.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`kubectl`，您可以传递`--as`和`--as-group`参数。
- en: Authorizing requests
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权请求
- en: Once a user is authenticated, authorization commences. Kubernetes has generic
    authorization semantics. A set of authorization modules receives the request,
    which includes information such as the authenticated username and the request's
    verb (`list`, `get`, `watch`, `create`, and so on). Unlike authentication, all
    authorization plugins will get a shot at any request. If a single authorization
    plugin rejects the request or no plugin had an opinion, then it will be rejected
    with a `403` HTTP status code (forbidden). A request will be continue only if
    at least one plugin accepted and no other plugin rejected it.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户经过身份验证，授权就开始了。Kubernetes具有通用的授权语义。一组授权模块接收请求，其中包括经过身份验证的用户名和请求的动词（`list`，`get`，`watch`，`create`等）。与身份验证不同，所有授权插件都将有机会处理任何请求。如果单个授权插件拒绝请求或没有插件发表意见，则将以`403`
    HTTP状态码（禁止）拒绝请求。只有在至少有一个插件被接受且没有其他插件拒绝时，请求才会继续。
- en: The cluster administrator determines what authorization plugins to use by specifying
    the `--authorization-mode` command-line flag, which is a comma-separated list
    of plugin names.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员通过指定`--authorization-mode`命令行标志来确定要使用哪些授权插件，这是一个逗号分隔的插件名称列表。
- en: 'The following modes are supported:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 支持以下模式：
- en: '`--authorization-mode=AlwaysDeny` rejects all requests; it is useful during
    testing.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=AlwaysDeny`拒绝所有请求；在测试期间很有用。'
- en: '`-authorization-mode=AlwaysAllow` allows all requests; use if you don''t need
    authorization.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-authorization-mode=AlwaysAllow`允许所有请求；如果不需要授权，则使用。'
- en: '`--authorization-mode=ABAC` allows a simple, local file-based, and user-configured
    authorization policy. **ABAC** stands for **Attribute-Based Access Control**.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=ABAC`允许使用简单的、基于本地文件的、用户配置的授权策略。**ABAC**代表**基于属性的访问控制**。'
- en: '`--authorization-mode=RBAC` is a role-based mechanism where authorization policies
    are stored and driven by the Kubernetes API. **RBAC** stands for **Role-Based
    Access Control**.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=RBAC`是一种基于角色的机制，授权策略存储在并由Kubernetes API驱动。**RBAC**代表**基于角色的访问控制**。'
- en: '`--authorization-mode=Node` is a special mode designed to authorize API requests
    made by kubelets.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=Node`是一种特殊模式，用于授权kubelet发出的API请求。'
- en: '`--authorization-mode=Webhook` allows authorization to be driven by a remote
    service using REST.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=Webhook`允许授权由使用REST的远程服务驱动。'
- en: 'You can add your own custom authorization plugin by implementing the following
    straightforward Go interface:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过实现以下简单的Go接口来添加自定义授权插件：
- en: '[PRE4]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `Attributes` input argument is also an interface that provides all the
    information you need to make an authorization decision:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`Attributes`输入参数也是一个接口，提供了您需要做出授权决定的所有信息：'
- en: '[PRE5]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Using admission control plugins
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用准入控制插件
- en: OK. The request was authenticated and authorized, but there is one more step
    before it can be executed. The request must go through a gauntlet of admission-control
    plugins. Similar to the authorizers, if a single admission controller rejects
    a request, it is denied.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。请求已经经过身份验证和授权，但在执行之前还有一步。请求必须通过一系列的准入控制插件。与授权者类似，如果单个准入控制器拒绝请求，则请求将被拒绝。
- en: 'Admission controllers are a neat concept. The idea is that there may be global
    cluster concerns that could mean grounds for rejecting a request. Without admission
    controllers, all authorizers would have to be aware of these concerns and reject
    the request. However, with admission controllers, this logic can be performed
    once. In addition, an admission controller may modify the request. Admission controllers
    run in either validating mode or mutating mode. As usual, the cluster administrator
    decides which admission control plugins are run by providing a command-line argument
    named `admission-control`. The value is a comma-separated and ordered list of
    plugins. Here is the list of recommended plugins for Kubernetes >= 1.9 (the order
    matters):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 准入控制器是一个很好的概念。其思想是可能存在全局集群关注点，这可能是拒绝请求的理由。没有准入控制器，所有授权者都必须意识到这些问题并拒绝请求。但是，有了准入控制器，这个逻辑可以执行一次。此外，准入控制器可以修改请求。准入控制器以验证模式或变异模式运行。通常情况下，集群管理员通过提供名为`admission-control`的命令行参数来决定运行哪些准入控制插件。该值是一个逗号分隔的有序插件列表。以下是Kubernetes
    >= 1.9的推荐插件列表（顺序很重要）：
- en: '[PRE6]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s look at some of the available plugins (more are added all the time):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些可用的插件（随时添加更多）：
- en: '`AlwaysAdmit`: Passthrough (I''m not sure why it''s needed).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AlwaysAdmit`: 透传（我不确定为什么需要它）。'
- en: '`AlwaysDeny`: This rejects everything (useful for testing).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AlwaysDeny`: 这拒绝一切（用于测试很有用）。'
- en: '`AlwaysPullImages`: This sets the new pod image pull policy to Always (useful
    in multi-tenant clusters to ensure that private images are not used by pods that
    don''t have credentials to pull them).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AlwaysPullImages`: 这将新的Pod镜像拉取策略设置为Always（在多租户集群中很有用，以确保没有凭据拉取私有镜像的Pod不使用它们）。'
- en: '`DefaultStorageClass`: This add a default storage class to requests for the
    creation of a `PersistentVolumeClaim` that don''t specify a storage class.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DefaultStorageClass`: 这为未指定存储类的`PersistentVolumeClaim`创建请求添加了一个默认存储类。'
- en: '`DefaultTollerationSeconds`: This sets the default toleration of pods for taints
    (if not set already): `notready:NoExecute` and `notreachable:NoExecute`.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DefaultTollerationSeconds`: 这设置了Pod对污点的默认容忍时间（如果尚未设置）：`notready:NoExecute`
    和 `notreachable:NoExecute`。'
- en: '`DenyEscalatingExec`: This denies exec and attach commands to pods that run
    with escalated privileges and that allow host access. This includes pods that
    run as privileged, have access to the host IPC namespace, and have access to the
    host PID namespace.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DenyEscalatingExec`: 这拒绝对以提升的特权运行并允许主机访问的Pod执行和附加命令。这包括以特权运行、具有主机IPC命名空间访问权限和具有主机PID命名空间访问权限的Pod。'
- en: '`EventRateLimit`: This limits the flooding of the API server with events (new
    in Kubernetes 1.9).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EventRateLimit`: 这限制了API服务器的事件洪水（Kubernetes 1.9中的新功能）。'
- en: '`ExtendedResourceToleration`: This combines taints on nodes with special resources
    such as GPU and FPGA with toleration on pods that request those resources. The
    end result is that the node with the extra resources will be dedicated to pods
    with the proper toleration.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExtendedResourceToleration`: 这将节点上的污点与GPU和FPGA等特殊资源结合起来，与请求这些资源的Pod的容忍结合起来。最终结果是具有额外资源的节点将专门用于具有适当容忍的Pod。'
- en: '`ImagePolicyWebhook`: This complicated plugin connects to an external backend
    to decide whether a request should be rejected based on the image.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImagePolicyWebhook`: 这个复杂的插件连接到外部后端，根据镜像决定是否拒绝请求。'
- en: '`Initializers`: This sets the pending initializers by modifying the metadata
    of the resource to be created (based on `InitializerConfiguration`).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Initializers`: 这通过修改要创建的资源的元数据来设置挂起的初始化器（基于`InitializerConfiguration`）。'
- en: '`InitialResources` (experimental): This assigns compute resources and limits
    based on historical usage, if not specified.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InitialResources`（实验性的）：如果未指定，这将根据历史使用情况分配计算资源和限制。'
- en: '`LimitPodHardAntiAffinity`: This denies any pod that defines an anti-affinity
    topology key other than `kubernetes.io`/`hostname` in `requiredDuringSchedulingRequiredDuringExecution`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LimitPodHardAntiAffinity`：拒绝定义了除 `kubernetes.io`/`hostname` 之外的反亲和拓扑键的任何 Pod
    在 `requiredDuringSchedulingRequiredDuringExecution` 中。'
- en: '`LimitRanger`: This rejects requests that violate resource limits.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LimitRanger`：拒绝违反资源限制的请求。'
- en: '`MutatingAdmissionWebhook`: Calls in order, registered mutating web hooks that
    are able to modify their target object. Note that there is no guarantee that the
    change will be effective due to potential changes by other mutating web hooks.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MutatingAdmissionWebhook`：按顺序调用已注册的能够修改目标对象的变异 Webhook。请注意，由于其他变异 Webhook
    的潜在更改，不能保证更改会生效。'
- en: '`NamespaceLifecycle`: This rejects object creation requests in namespaces that
    are in the process of being terminated or don''t exist.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NamespaceLifecycle`：拒绝在正在终止或不存在的命名空间中创建对象。'
- en: '`ResourceQuota`: This rejects requests that violate the namespace''s resource
    quota.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResourceQuota`：拒绝违反命名空间资源配额的请求。'
- en: '`ServiceAccount`: This is automation for service accounts.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServiceAccount`：这是服务账户的自动化。'
- en: '`ValidatingAdmissionWebhook`: This admission controller calls any validating
    webhooks that match the request. Matching webhooks are called in parallel; if
    any of them rejects the request, the request fails.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValidatingAdmissionWebhook`：此准入控制器调用与请求匹配的任何验证 Webhook。匹配的 Webhook 会并行调用；如果其中任何一个拒绝请求，请求将失败。'
- en: As you can see, the admission control plugins have diverse functionalities.
    They support namespace-wide policies and enforce the validity of requests mostly
    from a resource management point of view. This frees the authorization plugins
    to focus on valid operations. `ImagePolicyWebHook` is the gateway to validating
    images, which is a big challenge. `Initializers` is the gateway to dynamic admission
    control where you can deploy your own admission controller without compiling it
    into Kubernetes. There are also external admission web hooks, which are suitable
    for tasks such as the semantic validation of resources (do all pods have the standard
    set of labels?).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，准入控制插件具有多样的功能。它们支持命名空间范围的策略，并主要从资源管理的角度执行请求的有效性。这使授权插件可以专注于有效的操作。`ImagePolicyWebHook`
    是验证镜像的入口，这是一个很大的挑战。`Initializers` 是动态准入控制的入口，您可以在其中部署自己的准入控制器，而无需将其编译到 Kubernetes
    中。还有外部准入 Webhook，适用于诸如资源的语义验证（所有 Pod 是否具有标准的标签集？）等任务。
- en: The division of responsibility for validating an incoming request through the
    separate stages of authentication, authorization, and admission, each with their
    own plugins, makes a complicated process much easier to understand and use.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通过身份验证、授权和准入的各个阶段分别负责验证传入请求的责任划分，每个阶段都有自己的插件，使得复杂的过程变得更容易理解和使用。
- en: Securing pods
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护 Pod
- en: Pod security is a major concern because Kubernetes schedules the pods and lets
    them run. There are several independent mechanisms in order to secure pods and
    containers. Together these mechanisms support defense in depth, where even if
    an attacker (or a mistake) bypasses one mechanism, it will get blocked by another.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 安全是一个主要关注点，因为 Kubernetes 调度 Pod 并让它们运行。为了保护 Pod 和容器，有几种独立的机制。这些机制一起支持深度防御，即使攻击者（或错误）绕过一个机制，也会被另一个机制阻止。
- en: Using a private image repository
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用私有镜像仓库
- en: This approach gives you a lot of confidence that your cluster will only pull
    images that you have previously vetted, and you can manage upgrades better. You
    can configure `$HOME/.dockercfg` or `$HOME/.docker/config.json` on each node.
    However, on many cloud providers, you can't do it because nodes are provisioned
    automatically for you.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法让您非常有信心，您的集群只会拉取您之前审查过的镜像，并且您可以更好地管理升级。您可以在每个节点上配置`$HOME/.dockercfg`或`$HOME/.docker/config.json`。但是，在许多云提供商上，您无法这样做，因为节点是自动为您配置的。
- en: ImagePullSecrets
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ImagePullSecrets
- en: This approach is recommended for clusters on cloud providers. The idea is that
    the credentials for the registry will be provided by the pod, so it doesn't matter
    what node it is scheduled to run on. This circumvents the problem with `.dockercfg`
    at the node level.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法适用于云提供商上的集群。其思想是，注册表的凭据将由pod提供，因此无论它被安排在哪个节点上运行都无所谓。这避开了节点级别的`.dockercfg`问题。
- en: 'First, you need to create a `secret` object for the credentials:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要为凭据创建一个`secret`对象：
- en: '[PRE7]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can create secrets for multiple registries (or multiple users for the same
    registry) if needed. The kubelet will combine all `ImagePullSecrets`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，您可以为多个注册表（或同一注册表的多个用户）创建secret。kubelet将合并所有`ImagePullSecrets`。
- en: However, because pods can access secrets only in their own namespace, you must
    create a secret within each namespace where you want the pod to run.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，因为pod只能在其自己的命名空间中访问secret，所以您必须在希望pod运行的每个命名空间中创建一个secret。
- en: 'Once the secret is defined, you can add it to the pod spec and run some pods
    on your cluster. The pod will use the credentials from the secret to pull images
    from the target image registry:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了secret，您可以将其添加到pod规范中，并在集群上运行一些pod。pod将使用secret中的凭据从目标镜像注册表中拉取镜像：
- en: '[PRE8]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Specifying a security context
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定安全上下文
- en: A security context is a set of operating-system-level security settings, such
    as UID, gid, capabilities, and SELinux roles. These settings are applied at the
    container level as container security content. You can specify pod security context
    that will apply to all the containers in the pod. The pod security context can
    also apply its security settings (in particular, `fsGroup` and `seLinuxOptions`)
    to volumes.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 安全上下文是一组操作系统级别的安全设置，例如UID、gid、功能和SELinux角色。这些设置应用于容器级别作为容器安全内容。您可以指定将应用于pod中所有容器的pod安全上下文。pod安全上下文还可以将其安全设置（特别是`fsGroup`和`seLinuxOptions`）应用于卷。
- en: 'Here is a sample pod security context:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例pod安全上下文：
- en: '[PRE9]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The container security context is applied to each container, and it overrides
    the pod security context. It is embedded in the containers section of the pod
    manifest. Container context settings can't be applied to volumes, which remain
    at the pod level.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 容器安全上下文应用于每个容器，并覆盖了pod安全上下文。它嵌入在pod清单的容器部分中。容器上下文设置不能应用于卷，卷保持在pod级别。
- en: 'Here is a sample container security content:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例容器安全内容：
- en: '[PRE10]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Protecting your cluster with AppArmor
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AppArmor保护您的集群
- en: '`AppArmor` is a Linux kernel security module. With `AppArmor`, you can restrict
    a process running in a container to a limited set of resources, such as network
    access, Linux capabilities, and file permissions. You configure `AppArmor` though
    profiles.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`AppArmor`是一个Linux内核安全模块。使用`AppArmor`，您可以限制在容器中运行的进程对一组有限的资源的访问，例如网络访问、Linux功能和文件权限。您可以通过配置`AppArmor`来配置配置文件。'
- en: Requirements
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要求
- en: 'AppArmor support was added as beta in Kubernetes 1.4\. It is not available
    for every operating system, so you must choose a supported OS distribution in
    order to take advantage of it. Ubuntu and SUSE Linux support AppArmor and enable
    it by default. Other distributions have optional support. To check whether AppArmor
    is enabled, type the following code:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes 1.4中，AppArmor支持作为beta版本添加。它并不适用于每个操作系统，因此您必须选择一个受支持的操作系统发行版才能利用它。Ubuntu和SUSE
    Linux支持AppArmor，并默认启用。其他发行版则具有可选的支持。要检查AppArmor是否已启用，请输入以下代码：
- en: '[PRE11]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If the result is `Y`, then it's enabled.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果结果是`Y`，则已启用。
- en: 'The profile must be loaded into the kernel. Check the following file:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件必须加载到内核中。请检查以下文件：
- en: '[PRE12]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Also, only the Docker runtime supports `AppArmor` at this time.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，只有Docker运行时支持`AppArmor`。
- en: Securing a pod with AppArmor
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AppArmor保护Pod
- en: As `AppArmor` is still in beta, you specify the metadata as annotations and
    not as `bonafide` fields; when it gets out of beta that will change.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`AppArmor`仍处于beta阶段，因此您需要将元数据指定为注释，而不是`bonafide`字段；当它退出beta阶段时，这将发生变化。
- en: 'To apply a profile to a container, add the following annotation:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要将配置文件应用于容器，请添加以下注释：
- en: '[PRE13]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The pofile reference can be either the default profile, `runtime`/`default`,
    or a profile file on the host `localhost/<profile-name>`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件引用可以是默认配置文件，`runtime`/`default`，或者主机`localhost/<profile-name>`上的配置文件。
- en: 'Here is a sample profile that prevents writing to files:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个防止写入文件的示例配置文件：
- en: '[PRE14]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: AppArmor is not a Kubernetes resource, so the format is not the YAML or JSON
    you're familiar with.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: AppArmor不是Kubernetes资源，因此其格式不是您熟悉的YAML或JSON。
- en: 'To verify that the profile was attached correctly, check the attributes of
    process `1`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证配置文件是否正确附加，请检查进程`1`的属性：
- en: '[PRE15]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Pods can be scheduled on any node in the cluster by default. This means the
    profile should be loaded into every node. This is a classic use case for DaemonSet.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Pod可以在集群中的任何节点上调度。这意味着配置文件应该加载到每个节点中。这是DaemonSet的一个经典用例。
- en: Writing AppArmor profiles
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写AppArmor配置文件
- en: 'Writing profiles for `AppArmor` by hand is important. There are some tools
    that can help: `aa-genprof` and `aa-logprof` can generate a profile for you and
    help with fine tuning it by running your application with `AppArmor` in complain
    mode. The tools keep track of your application''s activity and `AppArmor` warnings
    and create a corresponding profile. This approach works, but it feels clunky.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 手动编写`AppArmor`配置文件很重要。有一些工具可以帮助：`aa-genprof`和`aa-logprof`可以为您生成配置文件，并通过在应用程序中使用`AppArmor`的complain模式来帮助微调它。这些工具会跟踪应用程序的活动和`AppArmor`警告，并创建相应的配置文件。这种方法有效，但感觉有些笨拙。
- en: 'My favorite tool is bane ([https://github.com/jessfraz/bane](https://github.com/jessfraz/bane)),
    which generates `AppArmor` profiles from a simpler profile language based on TOML
    syntax. Bane profiles are very readable and easy to grasp. Here is a snippet from
    a bane profile:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最爱工具是bane（[https://github.com/jessfraz/bane](https://github.com/jessfraz/bane)），它可以根据TOML语法生成`AppArmor`配置文件。Bane配置文件非常易读且易于理解。以下是一个bane配置文件的片段：
- en: '[PRE16]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The generated `AppArmor` profile is pretty gnarly.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的`AppArmor`配置文件相当复杂。
- en: Pod security policies
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pod安全策略
- en: '**Pod Security Policy** (**PSP**) is available as Beta since Kubernetes 1.4\.
    It must be enabled, and you must also enable the PSP admission control to use
    them. A PSP is defined at the cluster level and defines the security context for
    pods. There are a couple of differences between using PSP and directly specifying
    a security content in the pod manifest as we did earlier:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pod安全策略**（**PSP**）自Kubernetes 1.4以来就作为Beta版本可用。必须启用它，并且还必须启用PSP准入控制来使用它们。PSP在集群级别定义，并为Pod定义安全上下文。使用PSP和直接在Pod清单中指定安全内容之间有一些区别，就像我们之前所做的那样：'
- en: Applies the same policy to multiple pods or containers
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将相同的策略应用于多个Pod或容器
- en: Lets the administrator control pod creation, so users don't create pods with
    inappropriate security contexts
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让管理员控制Pod的创建，以便用户不会创建具有不适当安全上下文的Pod
- en: Dynamically generates different security content for a pod via the admission
    controller
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过准入控制器为Pod动态生成不同的安全内容
- en: PSPs really scale the concept of security contexts. Typically, you'll have a
    relatively small number of security policies compared with the number of pods
    (or rather, pod templates). This means that many pod templates and containers
    will have the same security policy. Without PSP, you have to manage it individually
    for each pod manifest.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: PSPs真的扩展了安全上下文的概念。通常，与Pod（或者说，Pod模板）的数量相比，您将拥有相对较少的安全策略。这意味着许多Pod模板和容器将具有相同的安全策略。没有PSP，您必须为每个Pod清单单独管理它。
- en: 'Here is a sample PSP that allows everything:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个允许一切的示例PSP：
- en: '[PRE17]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Authorizing pod security policies through RBAC
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过RBAC授权Pod安全策略
- en: 'This is the recommended way to enable the use of policies. Let''s create `clusterRole`
    (`Role` works too) to grant access to use the target policies. It should look
    like this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这是启用策略使用的推荐方法。让我们创建`clusterRole`（`Role`也可以）来授予使用目标策略的访问权限。它应该是这样的：
- en: '[PRE18]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we need to bind the cluster role to the authorized users:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要将集群角色绑定到授权用户：
- en: '[PRE19]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If using a role binding instead of cluster role, then it will apply only to
    pods in the same namespace as the binding. This can be paired with system groups
    to grant access to all pods run in the namespace:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用角色绑定而不是集群角色，则它将仅适用于与绑定相同命名空间中的Pod。这可以与系统组配对，以授予对在命名空间中运行的所有Pod的访问权限：
- en: '[PRE20]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Managing network policies
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理网络策略
- en: Node, pod, and container security is imperative, but it's not enough. Network
    segmentation is critical to design secure Kubernetes clusters that allows multi-tenancy
    as well as to minimize the impact of security breaches. Defense in depth mandates
    that you compartmentalize parts of the system that don't need to talk to each
    other, and allows you to carefully manage the direction, protocols, and ports
    of traffic.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 节点、Pod和容器的安全性至关重要，但这还不够。网络分割对于设计安全的Kubernetes集群至关重要，它允许多租户使用，并且可以最小化安全漏洞的影响。深度防御要求您对不需要相互通信的系统部分进行分隔，并允许您仔细管理流量的方向、协议和端口。
- en: Network policies give you fine-grained control and proper network segmentation
    in terms of your cluster. At its core, a network policy is a set of firewall rules
    applied to a set of namespaces and pods selected by labels. This is very flexible
    because labels can define virtual network segments and can be managed as Kubernetes
    resources.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略可以让您对集群的命名空间和通过标签选择的Pod进行细粒度控制和适当的网络分割。在其核心，网络策略是一组防火墙规则，应用于一组由标签选择的命名空间和Pod。这非常灵活，因为标签可以定义虚拟网络段，并且可以作为Kubernetes资源进行管理。
- en: Choosing a supported networking solution
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择支持的网络解决方案
- en: Some networking backends don't support network policies. For example, the popular
    Flannel can't be applied to policies.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网络后端不支持网络策略。例如，流行的Flannel无法应用于策略。
- en: 'Here is a list of supported network backends:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个支持的网络后端列表：
- en: Calico
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico
- en: WeaveNet
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WeaveNet
- en: Canal
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Canal
- en: Cillium
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cillium
- en: Kube-Router
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kube-Router
- en: Romana
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romana
- en: Defining a network policy
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义网络策略
- en: You define a network policy using a standard YAML manifest.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用标准的YAML清单来定义网络策略。
- en: 'Here is a sample policy:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例策略：
- en: '[PRE21]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `spec` part has two important parts—the `podSelector` and the `ingress`.
    The `podSelector` governs which pods this network policy applies to. The ingress
    governs which namespaces and pods can access these pods and which protocols and
    ports they can use.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`spec`部分有两个重要部分——`podSelector`和`ingress`。`podSelector`管理此网络策略适用于哪些 pod。`ingress`管理哪些命名空间和
    pod 可以访问这些 pod，以及它们可以使用哪些协议和端口。'
- en: 'In the sample network policy, the `pod` selector specified the target for the
    network policy to be all the pods that are labeled `role: db`. The `ingress` section
    has a `from` subsection with a `namespace` selector and a `pod` selector. All
    the namespaces in the cluster that are labeled `project: cool-project`, and within
    these namespaces, all the pods that are labeled `role: frontend`, can access the
    target pods labeled `role: db`. The `ports` section defines a list of pairs (protocol
    and port) that further restrict what protocols and ports are allowed. In this
    case, the protocol is `tcp` and the port is `6379` (Redis standard port).'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '在示例网络策略中，`pod`选择器指定了网络策略的目标，即所有标记为`role: db`的 pod。`ingress`部分有一个`from`子部分，其中包括一个`namespace`选择器和一个`pod`选择器。集群中所有标记为`project:
    cool-project`的命名空间，以及这些命名空间中所有标记为`role: frontend`的 pod，都可以访问标记为`role: db`的目标 pod。`ports`部分定义了一对对（协议和端口），进一步限制了允许的协议和端口。在这种情况下，协议是`tcp`，端口是`6379`（Redis
    标准端口）。'
- en: 'Note that the network policy is cluster-wide, so pods from multiple namespaces
    in the cluster can access the target namespace. The current namespace is always
    included, so even if it doesn''t have the `project: cool label`, `pods` with `role:
    frontend` can still have access.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，网络策略是集群范围的，因此集群中多个命名空间的 pod 可以访问目标命名空间。当前命名空间始终包括在内，因此即使它没有`project: cool`标签，带有`role:
    frontend`的`pods`仍然可以访问。'
- en: It's important to realize that the network policy operates in a whitelist fashion.
    By default, all access is forbidden, and the network policy can open certain protocols
    and ports to certain pods that match the labels. This means that if your networking
    solution doesn't support network policies, all access will be denied.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略以白名单方式运行很重要。默认情况下，所有访问都被禁止，网络策略可以打开某些协议和端口，以匹配标签的某些 pod。这意味着，如果您的网络解决方案不支持网络策略，所有访问将被拒绝。
- en: Another implication of the whitelist nature is that if multiple network policies
    exist, the union of all the rules apply. If one policy gives access to port `1234`
    and another gives access to port `5678` for the same set of pods, then a pod may
    access either port `1234` or `5678`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 白名单性质的另一个含义是，如果存在多个网络策略，则所有规则的并集都适用。如果一个策略允许访问端口`1234`，另一个策略允许访问端口`5678`，那么一个
    pod 可能访问端口`1234`或`5678`。
- en: Limiting Egress to external networks
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制对外部网络的出口
- en: 'Kubernetes 1.8 added egress network policy support, so you can control outbound
    traffic too. Here is an example that prevents access to the external IP `1.2.3.4`.
    The `order: 999` ensures that the policy is applied before other policies:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 'Kubernetes 1.8 添加了出口网络策略支持，因此您也可以控制出站流量。以下是一个示例，阻止访问外部 IP`1.2.3.4`。`order:
    999`确保在其他策略之前应用该策略：'
- en: '[PRE22]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Cross-namespace policies
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨命名空间策略
- en: If you divide your cluster into multiple namespaces, it can come in handy sometimes
    if pods communicate across namespaces. You can specify the `ingress.namespaceSelector`
    field in your network policy to enable access from multiple namespaces. For example,
    if you have production and staging namespaces and you periodically populate your
    staging environments with snapshots of your production data.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将集群划分为多个命名空间，有时如果 pod 跨命名空间通信，这可能会很方便。您可以在网络策略中指定`ingress.namespaceSelector`字段，以允许从多个命名空间访问。例如，如果您有生产和暂存命名空间，并且定期使用生产数据的快照填充暂存环境。
- en: Using secrets
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用秘密
- en: Secrets are paramount in secure systems. They can be credentials, such as a username
    and password, access tokens, API keys, or crypto keys. Secrets are typically small.
    If you have large amounts of data you want to protect, you should encrypt that
    and keep the encryption/decryption key as secrets.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密在安全系统中至关重要。它们可以是凭据，如用户名和密码、访问令牌、API密钥或加密密钥。秘密通常很小。如果您有大量要保护的数据，您应该对其进行加密，并将加密/解密密钥保留为秘密。
- en: Storing secrets in Kubernetes
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes中存储秘密
- en: Kubernetes used to store secrets in `etcd` as plaintext by default. This meant
    that direct access to `etcd` was limited and carefully guarded. As of Kubernetes
    1.7, you can now encrypt your secrets at rest (when they're stored by `etcd`).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes默认将秘密以明文存储在`etcd`中。这意味着对`etcd`的直接访问是有限的并且受到仔细保护。从Kubernetes 1.7开始，您现在可以在休息时加密您的秘密（当它们由`etcd`存储时）。
- en: Secrets are managed at the namespace level. Pods can mount secrets either as
    files via secret volumes or as environment variables. From a security standpoint,
    this means that any user or service that can create a pod in a namespace can have
    access to any secret managed for that namespace. If you want to limit access to
    a secret, put it in a namespace accessible to a limited set of users or services.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密是在命名空间级别管理的。Pod可以通过秘密卷将秘密挂载为文件，也可以将其作为环境变量。从安全的角度来看，这意味着可以创建命名空间中的任何用户或服务都可以访问为该命名空间管理的任何秘密。如果要限制对秘密的访问，请将其放在一组有限用户或服务可访问的命名空间中。
- en: When a secret is mounted to a pod, it is never written to disk. It is stored
    in `tmpfs`. When the kubelet communicates with the API server it uses TLS normally,
    so the secret is protected in transit.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 当秘密挂载到一个pod上时，它永远不会被写入磁盘。它存储在`tmpfs`中。当kubelet与API服务器通信时，通常使用TLS，因此秘密在传输过程中受到保护。
- en: Configuring encryption at Rest
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置休息时的加密
- en: 'You need to pass this argument when you start the API server:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 启动API服务器时，您需要传递此参数：
- en: '[PRE23]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here is a sample encryption config:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个样本加密配置：
- en: '[PRE24]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Creating secrets
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建秘密
- en: Secrets must be created before you try to create a pod that requires them. The
    secret must exist; otherwise, the pod creation will fail.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试创建需要它们的pod之前，必须先创建秘密。秘密必须存在；否则，pod创建将失败。
- en: 'You can create secrets with the following command:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令创建秘密：
- en: '[PRE25]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here, I create a generic secret named `hush-hash`, which contains two keys—username
    and password:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我创建了一个名为`hush-hash`的通用秘密，其中包含两个键—用户名和密码：
- en: '[PRE26]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The resulting secret is `Opaque`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的秘密是`Opaque`：
- en: '[PRE27]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You can create secrets from files using `--from-file` instead of `--from-literal`,
    and you can also create secrets manually if you encode the secret value as `base64`.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`--from-file`而不是`--from-literal`从文件创建秘密，并且如果将秘密值编码为`base64`，还可以手动创建秘密。
- en: Key names inside a secret must follow the rules for DNS subdomains (without
    the leading dot).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密中的键名必须遵循DNS子域的规则（不包括前导点）。
- en: Decoding secrets
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码秘密
- en: 'To get the content of a secret, you can use `kubectl get secret`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取秘密的内容，可以使用`kubectl get secret`：
- en: '[PRE28]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The values are `base64`-encoded. You need to decode them yourself:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是`base64`编码的。您需要自己解码它们：
- en: '[PRE29]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Using secrets in a container
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在容器中使用秘密
- en: Containers can access secrets as files by mounting volumes from the pod. Another
    approach is to access the secrets as environment variables. Finally, a container
    (given its service account has the permission) can access the Kubernetes API directly
    or use the kubectl get secret.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以通过从pod中挂载卷来将秘密作为文件访问。另一种方法是将秘密作为环境变量访问。最后，容器（如果其服务账户具有权限）可以直接访问Kubernetes
    API或使用kubectl get secret。
- en: 'To use a secret mounted as a volume, the pod manifest should declare the volume,
    and it should be mounted in the container''s spec:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用作为卷挂载的秘密，pod清单应声明卷，并且应在容器的规范中挂载：
- en: '[PRE30]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The volume name (`secret-volume`) binds the pod volume to the mount in the container.
    Multiple containers can mount the same volume.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 卷名称（`secret-volume`）将pod卷绑定到容器中的挂载点。多个容器可以挂载相同的卷。
- en: 'When this pod is running, the username and password are available as files
    under `/etc/secret-volume`:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当此pod运行时，用户名和密码将作为文件出现在`/etc/secret-volume`下：
- en: '[PRE31]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Running a multiuser cluster
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行多用户集群
- en: In this section, we will look briefly at the option to use a single cluster
    to host systems for multiple users or multiple user communities. The idea is that
    those users are totally isolated and may not even be aware that they share the
    cluster with other users. Each user community will have its own resources, and
    there will be no communication between them (except maybe through public endpoints).
    The Kubernetes namespace concept is the ultimate expression of this idea.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论使用单个集群来托管多个用户或多个用户社区的系统的选项。这个想法是这些用户是完全隔离的，甚至可能不知道他们与其他用户共享集群。每个用户社区都将拥有自己的资源，并且它们之间不会有通信（除非通过公共端点）。Kubernetes命名空间概念是这个想法的最终表达。
- en: The case for a multiuser cluster
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多用户集群的情况
- en: 'Why should you run a single cluster for multiple isolated users or deployments?
    Isn''t it simpler to just have a dedicated cluster for each user? There are two
    main reasons: cost and operational complexity. If you have many relatively small
    deployments and you want to create a dedicated cluster for each one, then you''ll
    have a separate the master node and possibly a three-node `etcd` cluster for each
    one. That can add up. Operational complexity is very important too. Managing tens
    or hundreds or thousands of independent clusters is no picnic. Every upgrade and
    every patch needs to be applied to each cluster. Operations might fail, and you''ll
    have to manage a fleet of clusters where some of them are in slightly different
    states than the others. Meta-operations across all clusters may be more difficult.
    You''ll have to aggregate and write your tools to perform operations and collect
    data from all clusters.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要为多个隔离的用户或部署运行单个集群？每个用户都有一个专用的集群不是更简单吗？主要有两个原因：成本和运营复杂性。如果您有许多相对较小的部署，并且希望为每个部署创建一个专用的集群，那么您将需要为每个部署单独的主节点，可能还需要一个三节点的`etcd`集群。这可能会增加成本。运营复杂性也非常重要。管理数十甚至数百个独立的集群并不容易。每次升级和每次补丁都需要应用到每个集群。运营可能会失败，您将不得不管理一群集群，其中一些集群的状态可能与其他集群略有不同。跨所有集群的元操作可能更加困难。您将不得不聚合并编写您的工具来执行操作并从所有集群收集数据。
- en: 'Let''s look at some use cases and requirements for multiple isolated communities
    or deployments:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些多个隔离社区或部署的用例和要求：
- en: A platform or service provider for `<Blank>-` as a service
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为`<Blank>-`服务的平台或服务提供商
- en: Managing separate testing, staging, and production environments
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理单独的测试、暂存和生产环境
- en: Delegating responsibility to community/deployment admins
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将责任委托给社区/部署管理员
- en: Enforcing resource quotas and limits on each community
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个社区强制执行资源配额和限制
- en: Users see only resources in their community
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户只能看到他们社区中的资源
- en: Using namespaces for safe multitenancy
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用命名空间进行安全的多租户管理
- en: Kubernetes namespaces are the perfect answer to safe multi-tenant clusters.
    This is not a surprise as this was one of the design goals of namespaces.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes命名空间是安全的多租户集群的完美解决方案。这并不奇怪，因为这是命名空间的设计目标之一。
- en: 'You can easily create namespaces in addition to the built-in kube system and
    default. Here is a YAML file that will create a new namespace named `custom-namespace`.
    All it has is a metadata item named `name`. It doesn''t get any simpler:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以轻松地创建除内置kube系统和默认之外的命名空间。以下是一个将创建一个名为`custom-namespace`的新命名空间的YAML文件。它只有一个名为`name`的元数据项。没有比这更简单的了：
- en: '[PRE32]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s create the namespace:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建命名空间：
- en: '[PRE33]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The status field can be `active` or `terminating`. When you delete a namespace,
    it will get into the terminating state. When the namespace is in this state, you
    will not be able to create new resources in this namespace. This simplifies the
    cleanup of namespace resources and ensures that the namespace is really deleted.
    Without it, the replication controller might create new pods when existing pods
    are deleted.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 状态字段可以是`active`或`terminating`。当您删除一个命名空间时，它将进入terminating状态。当命名空间处于此状态时，您将无法在此命名空间中创建新资源。这简化了命名空间资源的清理，并确保命名空间真正被删除。如果没有它，当现有pod被删除时，复制控制器可能会创建新的pod。
- en: 'To work with a namespace, you add the `--namespace` argument to the `kubectl`
    commands:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用命名空间，您需要在`kubectl`命令中添加`--namespace`参数：
- en: '[PRE34]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Listing pods in the custom namespace returns only the pod we just created:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在自定义命名空间中列出pod只返回我们刚刚创建的pod：
- en: '[PRE35]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Listing pods without the namespace returns the pods in the default namespace:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在不带命名空间的情况下列出pod会返回默认命名空间中的pod：
- en: '[PRE36]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Avoiding namespace pitfalls
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免命名空间陷阱
- en: Namespaces are great, but they can add some friction. When you use just the
    default namespace, you can simply omit the namespace. When using multiple namespaces,
    you must qualify everything with the namespace. This can be a burden, but doesn't
    present any danger. However, if some users (for example, cluster administrators)
    can access multiple namespaces, then you're open to accidentally modifying or
    querying the wrong namespace. The best way to avoid this situation is to hermetically
    seal the namespace and require different users and credentials for each namespace.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间很棒，但可能会增加一些摩擦。当您只使用默认命名空间时，可以简单地省略命名空间。当使用多个命名空间时，必须使用命名空间限定所有内容。这可能是一个负担，但不会带来任何危险。但是，如果一些用户（例如，集群管理员）可以访问多个命名空间，那么您就有可能意外修改或查询错误的命名空间。避免这种情况的最佳方法是将命名空间密封起来，并要求为每个命名空间使用不同的用户和凭据。
- en: Also, tools can help make clear what namespace you're operating on (for example,
    the shell prompt if working from the command line or listing the namespace prominently
    in a web interface).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，工具可以帮助清楚地显示您正在操作的命名空间（例如，如果从命令行工作，则是shell提示，或者在Web界面中突出显示命名空间）。
- en: Make sure that users that can operate on a dedicated namespace don't have access
    to the default namespace. Otherwise, every time they forget to specify a namespace,
    they'll operate quietly on the default namespace.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 确保可以在专用命名空间上操作的用户不能访问默认命名空间。否则，每当他们忘记指定命名空间时，他们将在默认命名空间上悄悄操作。
- en: Summary
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the many security challenges facing developers and
    administrators building systems and deploying applications on Kubernetes clusters.
    But we also explored the many security features and the flexible plugin-based
    security model that provide many ways to limit, control, and manage containers,
    pods, and nodes. Kubernetes already provides versatile solutions to most security
    challenges, and it will only get better as capabilities such as AppArmor and various
    plugins move from alpha/beta status to general availability. Finally, we considered
    how to use namespaces to support multiple user communities or deployments in the
    same Kubernetes cluster.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了开发人员和管理员在Kubernetes集群上构建系统和部署应用程序时面临的许多安全挑战。但我们也探讨了许多安全功能和灵活的基于插件的安全模型，提供了许多限制、控制和管理容器、pod和节点的方法。Kubernetes已经为大多数安全挑战提供了多功能解决方案，随着诸如AppArmor和各种插件从alpha/beta状态转移到一般可用状态，它将变得更加完善。最后，我们考虑了如何使用命名空间来支持同一Kubernetes集群中的多个用户社区或部署。
- en: In the next chapter, we will look into many Kubernetes resources and concepts
    and how to use them and combine them effectively. The Kubernetes object model
    is built on top of a solid foundation of a small number of generic concepts such
    as resources, manifests, and metadata. This empowers an extensible, yet surprisingly
    consistent, object model to expose a very diverse set of capabilities for developers
    and administrators.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入研究许多Kubernetes资源和概念，以及如何有效地使用它们并将它们组合起来。Kubernetes对象模型是建立在一小部分通用概念（如资源、清单和元数据）的坚实基础之上的。这使得一个可扩展的、但令人惊讶地一致的对象模型能够为开发人员和管理员提供非常多样化的能力集。
