["```\n$ cat hosts\n\n[leaf]\n leaf01 ansible_host=172.20.1.41\n leaf02 ansible_host=172.20.1.42\n leaf03 ansible_host=172.20.1.43\n leaf04 ansible_host=172.20.1.44\n\n[spine]\n spine01 ansible_host=172.20.1.35\n spine02 ansible_host=172.20.1.36\n\n[arista:children]\n leaf\n spine\n```", "```\n$ cat ansible.cfg\n\n[defaults]\n inventory=hosts\n retry_files_enabled=False\n gathering=explicit\n host_key_checking=False\n```", "```\nansible_network_os: eos\nansible_connection: network_cli\nansible_user: ansible\nansible_ssh_pass: ansible123\n```", "```\n!\nusername Ansible privilege 15 role network-admin secret sha512\n$6$mfU4Ei0AORd6rage$5YObhOI1g0wNBK5onaKDpYJhLZ9138maJKgcOznzFdpM25Tf3rb0PWSojUSM\nRQY0Y7.cexCFj5aFLY17tuNU1\n!\n\n !\nmanagement ssh\n idle-timeout 300\n authentication mode password\n login timeout 300\n!\n```", "```\nvrf definition MGMT\n!\n ip routing vrf MGMT\n !\ninterface Management1\n vrf forwarding MGMT\n ip address *$Ansible_host$\n*   no lldp transmit\n no lldp receive\n!\n```", "```\n$ ansible arista -m ping\n\n leaf03 | SUCCESS => {\n \"changed\": false,\n \"ping\": \"pong\"\n}\nleaf04 | SUCCESS => {\n \"changed\": false,\n \"ping\": \"pong\"\n}\n <-- Output Omitted for brevity -->\n```", "```\n$ cat  group_vars/all.yml\n\nglobal:\n mgmt_vrf: MGMT\n```", "```\n $ cat pb_eos_eanble_eapi.yml\n ---\n- name: \"Enable eAPI on Arista Switches\"\n hosts: arista\n vars:\n ansible_connection: network_cli\n tasks:\n - name: \"Enable eAPI\"\n eos_eapi:\n https_port: 443\n https: yes\n state: started\n```", "```\n - name: \"Enable eAPI under VRF\"\n eos_eapi:\n state: started\n vrf: \"{{global.mgmt_vrf}}\"\n```", "```\n$ cat group_vars/arista.yml\n\nansible_network_os: eos\nansible_connection: httpapi\nansible_httpapi_use_ssl: yes\nansible_httpapi_validate_certs: no\n```", "```\n!\nmanagement api http-commands\n no shutdown\n !\n vrf MGMT\n no shutdown\n!\n```", "```\n$ ansible all -m ping -l leaf01 -vvvv \n\n<172.20.1.41> attempting to start connection\n<172.20.1.41> using connection plugin httpapi\n<172.20.1.41> loaded API plugin for network_os eos\n**<172.20.1.41> ESTABLISH HTTP(S) CONNECTFOR USER: ansible TO** https://172.20.1.41:443\n```", "```\n$ cat  group_vars/all.yml\n\n <-- Output Omitted for brevity -->\n\n global:\n dns:\n - 172.20.1.1\n - 172.20.1.15\n site: DC1\n users:\n -   password: ansible123\n privilege: 15\n role: network-admin\n username: ansible\n```", "```\n$ cat pb_arista_basic_config.yml --- - name: \"Configure Basic Configuration on Arista Fabric\"\n hosts: arista tasks: - name: \"Conifgure Basic System config\" eos_system: hostname: \" {{global.site|lower}}-{{inventory_hostname}}\" name_servers: \"{{ global.dns }}\" state: present\n```", "```\n - name: \"Configure Users\"\n eos_user:\n name: \"{{ item.username }}\"\n role: \"{{ item.role | default('network-admin') }}\"\n privilege: \"{{ item.privilege | default(15)}}\"\n configured_password: \"{{ item.password }}\"\n state: present\n loop: \"{{ global.users }}\"\n```", "```\n!\nhostname dc1-leaf01\nip name-server vrf default 172.20.1.1\nip name-server vrf default 172.20.1.15\n!\n```", "```\n$ tree roles/\nroles/\n\u2514\u2500\u2500 dc_fabric_config\n \u251c\u2500\u2500 tasks\n \u2514\u2500\u2500 templates\n```", "```\n$ cat roles/dc_fabric_config/tasks/build_config_dir.yml\n\n---\n- name: Create Config Directory\n file: path={{config_dir}}   state=directory\n run_once: yes\n- name: Create Temp Directory per Node\n file: path={{tmp_dir}}/{{inventory_hostname}}  state=directory\n- name: SET FACT >> Build Directory\n set_fact:\n build_dir: \"{{tmp_dir}}/{{inventory_hostname}}\"\n```", "```\n $ cat roles/dc_fabric_config/templates/eos/mgmt.j2\n\n!\nhostname {{global.site|lower}}-{{inventory_hostname}}\n!\n!\nspanning-tree mode none\n!\naaa authorization exec default local\n!\n{% for user in global.users%}\nusername {{user.name}} privilege {{user.privilege}} role\n{{user.role|default('network-admin')}} secret {{user.password}}\n{% endfor%}\n!\n{% for dns_server in global.dns%}\nip name-server vrf default {{ dns_server }}\n{% endfor %}\n!\n```", "```\n$ cat roles/dc_fabric_config/tasks/build_device_config.yml\n\n---\n- name: \"System Configuration\"\n template:\n src: \"{{ansible_network_os}}/mgmt.j2\"\n dest: \"{{build_dir}}/00_mgmt.cfg\"\n tags: mgmt\n```", "```\n$ cat roles/build_router_config/tasks/main.yml\n\n---\n- name: Build Required Directories\n import_tasks: build_config_dir.yml\n- name: Build Device Configuration\n import_tasks: build_device_config.yml\n\n - name: \"Remove Old Assembled Config\"\n file:\n path: \"{{config_dir}}/{{ inventory_hostname }}.cfg\"\n state: absent\n- name: Build Final Device Configuration\n assemble:\n src: \"{{ build_dir }}\"\n dest: \"{{config_dir}}/{{ inventory_hostname }}.cfg\"\n- name: Remove Build Directory\n file: path={{ tmp_dir }}  state=absent\n run_once: yes\n```", "```\n$ cat pb_arista_dc_fabric.yml\n\n---\n- name: \"Build Arista DC Fabric\"\n hosts: arista\n tasks:\n - name: Generate DC Fabric Configuration\n import_role:\n name: dc_fabric_config\n delegate_to: localhost\n```", "```\n$ tree configs/\nconfigs/\n\u251c\u2500\u2500 leaf01.cfg\n\u251c\u2500\u2500 leaf02.cfg\n\u251c\u2500\u2500 leaf03.cfg\n\u251c\u2500\u2500 leaf04.cfg\n\u251c\u2500\u2500 spine01.cfg\n\u2514\u2500\u2500 spine02.cfg\n```", "```\n!\nhostname dc1-leaf01\n!\nsnmp-server enable traps\n!\nspanning-tree mode none\n!\naaa authorization exec default local\n!\nusername ansible privilege 15 role network-admin secret ansible123\n!\nip name-server vrf default 172.20.1.1\nip name-server vrf default 172.20.1.15\n!\n```", "```\np2p_ip:\n leaf01:\n - {port: Ethernet8, ip: 172.31.1.1 , peer: spine01, pport: Ethernet1, peer_ip: 172.31.1.0}\n - {port: Ethernet9, ip: 172.31.1.11 , peer: spine02, pport: Ethernet1, peer_ip: 172.31.1.10}\n leaf02:\n < -- Output Omitted for brevity -->\n leaf03:\n < -- Output Omitted for brevity -->\n leaf04:\n < -- Output Omitted for brevity -->\n spine01:\n < -- Output Omitted for brevity -->\n spine02:\n < -- Output Omitted for brevity -->\n\nlo_ip:\n leaf01: 10.100.1.1/32\n leaf02: 10.100.1.2/32\n leaf03: 10.100.1.3/32\n leaf04: 10.100.1.4/32\n spine01: 10.100.1.254/32\n spine02: 10.100.1.253/32\n```", "```\n- name: \"Configure the Physical Interfaces\"\n eos_interface:\n name: \"{{ item.port }}\"\n enabled: true\n description: \"{{global.site}} | Rpeer:{{item.peer}} | Rport:{{item.pport}}\"\n with_items: \"{{p2p_ip[inventory_hostname]}}\"\n```", "```\n- name: \"Configure IP Addresses\"\n eos_l3_interface:\n name: \"{{ item.port }}\"\n ipv4: \"{{ item.ip }}/{{ global.p2p_prefix }}\"\n state: present\n with_items: \"{{ p2p_ip[inventory_hostname] }}\"\n```", "```\n$ cat roles/dc_fabric_config/templates/eos/intf.j2\n\n{% set node_intfs = p2p_ip[inventory_hostname] %}\n{% for p in node_intfs| sort(attribute='port') %}\n!\ninterface {{p.port}}\n description \"{{global.site}} | Rpeer: {{p.peer}} | Rport: {{p.pport}}\"\n no switchport\n ip address {{p.ip}}/{{global.p2p_prefix}}\n{% endfor %}\n!\n!\ninterface Loopback0\n ip address {{lo_ip[inventory_hostname]}}\n!\n```", "```\n$ cat roles/dc_fabric_config/tasks/build_device_config.yml\n\n<-- Output Trimmed for brevity ------>\n\n- name: \"Interface Configuration\"\n template:\n src: \"{{ansible_network_os}}/intf.j2\"\n dest: \"{{build_dir}}/01_intf.cfg\"\n tags: intf\n```", "```\n$ cat configs/leaf01.cfg\n\n< -- Output Omitted for brevity -->\n\n!\ninterface Ethernet8\n description \"DC1 | Rpeer: spine01 | Rport: Ethernet1\"\n no switchport\n ip address 172.31.1.1/31\n!\ninterface Ethernet9\n description \"DC1 | Rpeer: spine02 | Rport: Ethernet1\"\n no switchport\n ip address 172.31.1.11/31\n!\n!\ninterface Loopback0\n ip address 10.100.1.1/32\n!\n```", "```\n## Leaf01 BGP Data ###\nbgp_asn: 65001\nbgp_peers:\n - peer: spine01\n peer_ip: 172.31.1.0\n remote_as: 65100\n - peer: spine02\n peer_ip: 172.31.1.10\n remote_as: 65100\n```", "```\n$ cat roles/dc_fabric_config/templates/eos/underlay_bgp.j2 {% set bgp_grp = 'LEAF' if 'spine' in inventory_hostname else 'SPINE' %}\n!\nroute-map loopback permit 10\n match ip address prefix-list loopback\n!\n{% if 'spine' in inventory_hostname %}\n!\nip prefix-list loopback\n{% for node,ip in lo_ip.items() | sort %}\n{% if 'leaf' in node or inventory_hostname in node %}\n seq {{loop.index + 10 }} permit {{ip}}\n{% endif %}\n{% endfor %}\n!\n{% else %}\n!\nip prefix-list loopback\n seq 10 permit {{lo_ip[inventory_hostname]}}\n!\n{% endif %}\n```", "```\n$ cat roles/dc_fabric_config/templates/eos/underlay_bgp.j2\n\n!\nrouter bgp {{bgp_asn}}\n router-id {{lo_ip[inventory_hostname].split('/')[0]}}\n maximum-paths 2\n bgp bestpath tie-break router-id\n neighbor {{ bgp_grp }} peer-group\n neighbor {{ bgp_grp }} description \"Peer Group for All {{bgp_grp}} Nodes\"\n neighbor {{ bgp_grp }} graceful-restart-helper\n neighbor {{ bgp_grp }} send-community standard extended\n neighbor {{ bgp_grp }} maximum-routes 100000 warning-only\n{% for p in bgp_peers %}\n neighbor {{ p.peer_ip}} peer-group {{ bgp_grp }}\n neighbor {{ p.peer_ip}} remote-as {{p.remote_as}}\n{% endfor %}\n redistribute connected route-map loopback\n !\n address-family ipv4\n neighbor {{ bgp_grp }} activate\n neighbor {{ bgp_grp }} route-map loopback out\n!\n```", "```\n$ cat roles/dc_fabric_config/tasks/build_device_config.yml\n\n< -- Output Omitted for brevity -->\n\n- name: \"Underlay BGP Configuration\"\n template:\n src: \"{{ansible_network_os}}/underlay_bgp.j2\"\n dest: \"{{config_dir}}/{{ inventory_hostname }}/03_bgp.cfg\"\n```", "```\n$ tree host_vars\n host_vars\n \u251c\u2500\u2500 leaf01\n \u2502 \u2514\u2500\u2500 underlay_bgp.yml\n \u251c\u2500\u2500 leaf02\n \u2502 \u2514\u2500\u2500 underlay_bgp.yml\n \u251c\u2500\u2500 leaf03\n \u2502 \u2514\u2500\u2500 underlay_bgp.yml\n \u251c\u2500\u2500 leaf04\n \u2502 \u2514\u2500\u2500 underlay_bgp.yml\n \u251c\u2500\u2500 spine01\n \u2502 \u2514\u2500\u2500 underlay_bgp.yml\n \u2514\u2500\u2500 spine02\n \u2514\u2500\u2500 underlay_bgp.yml\n```", "```\n$ cat configs/leaf01/04_bgp.cfg\n\n!\nroute-map loopback permit 10\n match ip address prefix-list loopback\n!\nip prefix-list loopback\n seq 10 permit 10.100.1.1/32\n!\nrouter bgp 65001\n router-id 10.100.1.1\n maximum-paths 2\n bgp bestpath tie-break router-id\n neighbor SPINE peer-group\n neighbor SPINE description \"Peer Group for All SPINE Nodes\"\n neighbor SPINE graceful-restart-helper\n neighbor SPINE send-community standard extended\n neighbor SPINE maximum-routes 100000 warning-only\n neighbor 172.31.1.0 peer-group SPINE\n neighbor 172.31.1.0 remote-as 65100\n neighbor 172.31.1.10 peer-group SPINE\n neighbor 172.31.1.10 remote-as 65100\n redistribute connected route-map loopback\n !\n address-family ipv4\n neighbor SPINE activate\n neighbor SPINE route-map loopback out\n!\u2003\n```", "```\n$ cat roles/dc_fabric_config/templates/eos/overlay_bgp.j2\n\n{% set bgp_evpn_grp = 'LEAF_EVPN' if 'spine' in inventory_hostname else 'SPINE_EVPN' %}\n\nservice routing protocols model multi-agent\n!\nrouter bgp {{bgp_asn}}\n\n neighbor {{ bgp_evpn_grp }} peer-group\n neighbor {{ bgp_evpn_grp }} description \"Peer Group for All {{bgp_evpn_grp}} EVPN Nodes\"\n neighbor {{ bgp_evpn_grp }} graceful-restart-helper\n neighbor {{ bgp_evpn_grp }} send-community extended\n neighbor {{ bgp_evpn_grp }} maximum-routes 100000 warning-only\n neighbor {{ bgp_evpn_grp }} ebgp-multihop 2\n neighbor {{ bgp_evpn_grp }} update-source Loopback0\n{% for p in bgp_peers %}\n neighbor {{ lo_ip[p.peer].split('/')[0]}} peer-group {{ bgp_evpn_grp }}\n neighbor {{ lo_ip[p.peer].split('/')[0]}} remote-as {{p.remote_as}}\n{% endfor %}\n !\n address-family evpn\n neighbor {{ bgp_evpn_grp }} activate\n !\n address-family ipv4\n no neighbor {{ bgp_evpn_grp }} activate\n!\n```", "```\n$ cat tasks/build_config.yml\n\n< -- Output Omitted for brevity -->\n\n- name: \"Overlay BGP EVPN Configuration\"\n template:\n src: \"{{ansible_network_os}}/overlay_bgp.j2\"\n dest: \"{{config_dir}}/{{ inventory_hostname }}/04_evpn.cfg\"\n```", "```\nservice routing protocols model multi-agent\n!\nrouter bgp 65001\n\n neighbor SPINE_EVPN peer-group\n neighbor SPINE_EVPN description \"Peer Group for All SPINE_EVPN EVPN Nodes\"\n neighbor SPINE_EVPN graceful-restart-helper\n neighbor SPINE_EVPN send-community extended\n neighbor SPINE_EVPN maximum-routes 100000 warning-only\n neighbor SPINE_EVPN ebgp-multihop 2\n neighbor SPINE_EVPN update-source Loopback0\n neighbor 10.100.1.254 peer-group SPINE_EVPN\n neighbor 10.100.1.254 remote-as 65100\n neighbor 10.100.1.253 peer-group SPINE_EVPN\n neighbor 10.100.1.253 remote-as 65100\n !\n address-family evpn\n neighbor SPINE_EVPN activate\n !\n address-family ipv4\n no neighbor SPINE_EVPN activate\n!\u2003\n```", "```\n- name: \"Deploy Configuration\"\n eos_config:\n src: \"{{config_dir}}/{{ inventory_hostname }}.cfg\"\n replace: config\n save_when: changed\n tags: deploy\n```", "```\n$ cat vlan_design.yml\nvlan_data:\n leaf01:\n - id: 10\n description: DB\n ports:\n - Ethernet1\n leaf02:\n - id: 20\n description: web\n ports:\n - Ethernet1\n < -- Output Omitted for brevity -->\n```", "```\n$ tree roles/provision_vlans/\n roles/provision_vlans/\n \u251c\u2500\u2500 tasks\n \u2502 \u2514\u2500\u2500 main.yml\n \u251c\u2500\u2500 templates\n \u2514\u2500\u2500 vars\n \u2514\u2500\u2500 main.yml\n```", "```\n$ cat roles/provision_vlans/tasks/main.yml\n\n---\n- name: Deploy VLANs on DC Fabric\n eos_vlan:\n name: \"VLAN_{{vlan.id}}_{{ vlan.description }}\"\n vlan_id: \"{{ vlan.id }}\"\n state: present\n interfaces: \"{{ vlan.ports }}\"\n loop: \"{{ vlan_data[inventory_hostname] }}\"\n loop_control:\n loop_var: vlan\n tags: vlans\n```", "```\n\n $ cat pb_deploy_vlans.yml\n\n---\n- name: Provision VLANs on DC Fabric\n hosts: arista\n vars_files: vlan_design.yml\n tasks:\n - name: Deploy Vlans on DC Fabric\n import_role:\n name: provision_vlans\n when: inventory_hostname in vlan_data.keys()\n```", "```\ndc1-leaf03#sh vlan\n VLAN Name Status Ports\n ----- -------------------------------- --------- -------------------------\n 1 default active Et3, Et4, Et5, Et6, Et7\n 10 VLAN_10_DB active Et1\n 20 VLAN_20_web active Et2\n\n```", "```\n$ cat roles/provision_vlans/vars/main.yml\n ---\n config_dir: ./vxlan_configs\n```", "```\n$ cat roles/provision_vlans/templates/eos/vxlan.j2\n\n{% set vlans = vlan_data[inventory_hostname] %}\n{% set all_vlans = vlans | map(attribute='id') | list %}\n!\ninterface Vxlan1\n vxlan source-interface Loopback0\n{% for vlan in all_vlans %}\n vxlan vlan {{ vlan }} vni 10{{vlan}}\n{% endfor %}\n!\nrouter bgp {{bgp_asn}}\n!\n{% for vlan in all_vlans %}\n vlan {{ vlan }}\n rd {{lo_ip[inventory_hostname].split('/')[0]}}:10{{vlan}}\n route-target both 10{{vlan}}:10{{vlan}}\n redistribute learned\n{% endfor %}\n !\n```", "```\n- name: Create VXLAN Configs Folder\n file: path={{config_dir}} state=directory\n run_once: yes\n delegate_to: localhost\n tags: vxlan\n\n- name: \"Create VXLAN Configuration\"\n template:\n src: \"{{ansible_network_os}}/vxlan.j2\"\n dest: \"{{config_dir}}/{{ inventory_hostname }}.cfg\"\n delegate_to: localhost\n tags: vxlan\n```", "```\n- name: \"Deploy Configuration\"\n eos_config:\n src: \"{{config_dir}}/{{ inventory_hostname }}.cfg\"\n save_when: changed\n tags: vxlan\n```", "```\n$ tree vxlan_configs/\nvxlan_configs/\n\u251c\u2500\u2500 leaf01.cfg\n\u251c\u2500\u2500 leaf02.cfg\n\u251c\u2500\u2500 leaf03.cfg\n\u2514\u2500\u2500 leaf04.cfg\n```", "```\n$ cat vxlan_configs/leaf01.cfg\n\ninterface Vxlan1\n vxlan source-interface Loopback0\n vxlan udp-port 4789\n vxlan vlan 10 vni 1010\n!\nrouter bgp 65001\n!\n vlan 10\n rd 10.100.1.1:1010\n route-target both 1010:1010\n redistribute learned\n !\n```", "```\n$ cat pb_jnpr_facts.yml\n\n---\n- name: Collect and Validate Arista DC Fabric Facts\n hosts: arista\n tasks:\n - name: Collect Arista Device Facts\n eos_facts:\n```", "```\n - name: Validate all DC Fabric Interface are Operational\n assert:\n that:\n - ansible_net_interfaces[item.port].lineprotocol == 'up'\n fail_msg: \"Interface {{item.port}} is not Operational \"\n loop: \"{{ p2p_ip[inventory_hostname] }}\"\n```", "```\n- name: Validate all DC Fabric Interface are has Correct IP\n assert:\n that:\n - ansible_net_interfaces[item.port].ipv4.address == item.ip\n fail_msg: \"Interface {{item.port}} has Wrong IP Address\"\n loop: \"{{ p2p_ip[inventory_hostname] }}\"\n```", "```\n\"ansible_net_interfaces\": {\n \"Ethernet8\": {\n \"bandwidth\": 0,\n \"description\": \"DC1 | Rpeer: spine01 | Rport: Ethernet1\",\n \"duplex\": \"duplexFull\",\n \"ipv4\": {\n \"address\": \"172.31.1.1\",\n \"masklen\": 31\n },\n \"lineprotocol\": \"up\",\n \"macaddress\": \"50:00:00:03:37:66\",\n \"mtu\": 1500,\n \"operstatus\": \"connected\",\n \"type\": \"routed\"\n }\n}\n```", "```\n---\n- name: \" Play 1: Retrieve All VLANs from Arista Switches\"\n hosts: leaf\n vars_files: vlan_design.yml\n tasks:\n - name: \"Get All VLANs\"\n eos_command:\n commands: show vlan | json\n register: show_vlan\n```", "```\n - name: \"Validate VLANs are Present\"\n assert:\n that: (item.vlan | string) in show_vlan.stdout[0].vlans.keys()\n fail_msg: \"VLAN:{{ item.vlan }} is NOT configured \"\n success_msg: \"VLAN:{{ item.vlan }} is configured \"\n loop: \"{{ access_interfaces[inventory_hostname] }}\"\n delegate_to: localhost\n```", "```\nok: [leaf01] => {\n \"show_vlan\": {\n < -- Output Omitted for brevity -->\n \"stdout\": [\n {\n \"vlans\": {\n \"1\": {\n \"dynamic\": false,\n \"interfaces\": {\n < -- Output Omitted for brevity -->\n },\n \"name\": \"default\",\n \"status\": \"active\"\n },\n \"10\": {\n \"dynamic\": false,\n \"interfaces\": {\n \"Ethernet1\": {\n \"privatePromoted\": false\n },\n \"Vxlan1\": {\n \"privatePromoted\": false\n }\n },\n \"name\": \"VLAN_10\",\n \"status\": \"active\"\n }\n }\n }\n ] \n```"]