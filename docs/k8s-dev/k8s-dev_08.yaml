- en: Logging and Tracing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志和跟踪
- en: When we first started with containers and Kubernetes, we showed how we could
    get the log output from any of our individual containers using the `kubectl log` command.
    As we scale the number of containers from which we want to get information, the
    ability to easily find the relevant logs becomes increasingly difficult. In the
    previous chapter, we looked at how to aggregate and collect metrics, and in this
    chapter we extend that same concept, looking at how to aggregate logging and getting
    a better understanding of how containers work together with distributed tracing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们最初开始使用容器和Kubernetes时，我们展示了如何使用`kubectl log`命令从任何一个容器中获取日志输出。随着我们希望获取信息的容器数量增加，轻松找到相关日志的能力变得越来越困难。在上一章中，我们看了如何聚合和收集指标，在本章中，我们扩展了相同的概念，看看如何聚合日志并更好地了解容器如何与分布式跟踪一起工作。
- en: 'Topics for this chapter include:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题包括：
- en: A Kubernetes concept—DaemonSet
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Kubernetes概念- DaemonSet
- en: Installing Elasticsearch, Fluentd, and Kibana
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Elasticsearch，Fluentd和Kibana
- en: Viewing logs using Kibana
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kibana查看日志
- en: Distributed tracing with Jeager
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Jeager进行分布式跟踪
- en: An example of adding tracing to your application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将跟踪添加到您的应用程序的一个例子
- en: A Kubernetes concept – DaemonSet
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个Kubernetes概念- DaemonSet
- en: A Kubernetes resource that we have now used (through Helm) is DaemonSet. This
    resource is a wrapper around pods very similar to ReplicaSet, but with the purpose
    of running a pod on every node in a cluster. When we installed Prometheus using
    Helm, it created a DaemonSet to run node-collector on each node within the Kubernetes
    cluster.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用的一个Kubernetes资源（通过Helm）是DaemonSet。这个资源是围绕pod的一个包装，与ReplicaSet非常相似，但其目的是在集群中的每个节点上运行一个pod。当我们使用Helm安装Prometheus时，它创建了一个DaemonSet，在Kubernetes集群中的每个节点上运行node-collector。
- en: 'There are two common patterns for running software in a support role with your
    application: the first is using the side-car pattern, and the second is using
    a DaemonSet. A side-car is when you include a container within your pod whose
    sole purpose is to run alongside the primary application and provide some supporting,
    but external, role. An example of a useful side-car might be a cache, or a proxy
    service of some form. Running a side-car application obviously increases the resources
    needed for a pod, and if the number of pods is relatively low or they are sparse
    compared to the size of a cluster, this would be the most efficient way to provide
    that supporting software.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中运行支持软件有两种常见模式：第一种是使用side-car模式，第二种是使用DaemonSet。side-car是指在您的pod中包含一个容器，其唯一目的是与主要应用程序一起运行并提供一些支持，但是外部的角色。一个有用的side-car的例子可能是缓存，或某种形式的代理服务。运行side-car应用程序显然会增加pod所需的资源，如果pod的数量相对较低，或者与集群的规模相比它们是稀疏的，那么这将是提供支持软件的最有效方式。
- en: When the support software you are running will be potentially replicated many
    times on a single node, and the service it is providing is fairly generic (such
    as log aggregation or metric collection), then it can be significantly more efficient
    to run a single pod on each node in a cluster. That is exactly where DaemonSet
    comes in.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行的支持软件在单个节点上可能被复制多次，并且提供的服务相当通用（例如日志聚合或指标收集）时，在集群中的每个节点上运行一个单独的pod可能会更有效。这正是DaemonSet的用武之地。
- en: Our earlier example of using a DaemonSet was running an instance of node-collector
    on every node within the cluster. The purpose of the node-collector DaemonSet
    is to collect statistics and metrics about the operation of every node. Kubernetes
    also uses DaemonSet to run its own services, such as kube-proxy, which operate
    on every node in the cluster. If you are using an overlay network to connect your
    Kubernetes cluster, such as Weave or Flannel, it is also frequently run using
    a DaemonSet. Another common use case is the one we'll explore more in this chapter,
    collecting and forwarding logging.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前使用DaemonSet的示例是在集群中的每个节点上运行一个node-collector实例。node-collector DaemonSet的目的是收集有关每个节点操作的统计数据和指标。Kubernetes还使用DaemonSet来运行自己的服务，例如在集群中的每个节点上运行的kube-proxy。如果您正在使用覆盖网络连接您的Kubernetes集群，例如Weave或Flannel，它也经常使用DaemonSet运行。另一个常见的用例是我们将在本章中更多地探讨的用例，即收集和转发日志。
- en: The required fields for a DaemonSet specification are similar to a deployment
    or job; in addition to the `apiVersion`, `kind`, and `metadata`, the DaemonSet
    also needs a spec, which includes a template that is used to create the pods on
    each node. In addition, the template can have a `nodeSelector` to match a set
    or subset of the nodes available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet规范的必需字段与部署或作业类似；除了`apiVersion`、`kind`和`metadata`之外，DaemonSet还需要一个包含模板的spec，该模板用于在每个节点上创建pod。此外，模板可以具有`nodeSelector`来匹配一组或子集可用的节点。
- en: 'Take a look at the YAML that Helm created when it installed `prometheus`. You
    can get a sense of how the data for the DaemonSet is laid out. The following output
    is from the command:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Helm在安装`prometheus`时创建的YAML。您可以了解到DaemonSet的数据是如何布局的。以下输出来自命令：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The DaemonSet specification that Helm generated is as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Helm生成的DaemonSet规范如下：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This DaemonSet runs a single container with a pod on each node, the image `prom/node-exporter:0.15`,
    which collects metrics from the volume mount points (`/proc` and `/sys` are very
    Linux-specific), and exposes them on port `9100` for `prometheus` to scrape with
    an HTTP request.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个DaemonSet在每个节点上运行一个单一的容器，使用镜像`prom/node-exporter:0.15`，从卷挂载点（`/proc`和`/sys`非常特定于Linux）收集指标，并在端口`9100`上公开它们，以便`prometheus`通过HTTP请求进行抓取。
- en: Installing and using Elasticsearch, Fluentd, and Kibana
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和使用Elasticsearch、Fluentd和Kibana
- en: Fluentd is software that's frequently used to collect and aggregate logging.
    Hosted at [https://www.fluentd.org](https://www.fluentd.org), like prometheus
    it is open source software that is managed under the umbrella of the **Cloud Native
    Computing Foundation** (**CNCF**). When it comes to talking about aggregating
    logs, the problem has existed long before containers, and ELK was a frequent acronym
    used to represent a solution, the combination of Elasticsearch, Logstash, and
    Kibana. When using containers, the number of log sources expands, making the problem
    of collecting all the logs even larger, and Fluentd evolved to support the same
    space as Logstash, focusing on structured logging with a JSON format, routing
    it, and supporting plugins to process the logs. Fluentd was written in Ruby and
    C, intending to be faster and more efficient than LogStash, and the same pattern
    is continuing with Fluent Bit ([http://fluentbit.io](http://fluentbit.io)), which
    has an even smaller memory footprint. You may even see references to EFK, which
    stands for the combination of Elasticsearch, Fluentd, and Kibana.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd是经常用于收集和聚合日志的软件。托管在[https://www.fluentd.org](https://www.fluentd.org)，就像prometheus一样，它是由**Cloud
    Native Computing Foundation** (**CNCF**)管理的开源软件。在谈论聚合日志时，问题早在容器出现之前就存在，ELK是一个常用的缩写，代表了一个解决方案，即Elasticsearch、Logstash和Kibana的组合。在使用容器时，日志来源的数量增加，使得收集所有日志的问题变得更加复杂，Fluentd发展成为支持与Logstash相同领域的软件，专注于使用JSON格式的结构化日志，路由和支持处理日志的插件。Fluentd是用Ruby和C编写的，旨在比LogStash更快，更高效，而Fluent
    Bit ([http://fluentbit.io](http://fluentbit.io))也延续了相同的模式，具有更小的内存占用。您甚至可能会看到EFK的引用，它代表Elasticsearch、Fluentd和Kibana的组合。
- en: Within the Kubernetes community, one of the more common solutions for capturing
    and aggregating logs is Fluentd, and it is even built into recent versions of
    Minikube as one of the add-ons that you can use.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes社区中，捕获和聚合日志的常见解决方案之一是Fluentd，甚至在Minikube的最新版本中作为可以使用的插件之一内置。
- en: If you are using Minikube, you can experiment with EFK very easily by enabling
    the Minikube add-on. While Fluentd and Kibana are fairly small in terms of resource
    needs, Elasticsearch has higher resource requirements, even for a small demonstration
    instance. The default VM that Minikube uses to create a single-node Kubernetes
    cluster has 2 GB of memory allocated to it, which is insufficient for running
    EFK and any additional workloads, as ElasticSearch by itself wants to utilize
    2 GB of memory while it is initializing and starting up.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Minikube，可以通过启用Minikube插件来轻松尝试EFK。尽管Fluentd和Kibana在资源需求方面相对较小，但Elasticsearch的资源需求较高，即使是用于小型演示实例。Minikube使用的默认VM用于创建单节点Kubernetes集群，分配了2GB的内存，这对于运行EFK和任何其他工作负载是不够的，因为ElasticSearch在初始化和启动时需要使用2GB的内存。
- en: 'Fortunately, you can ask Minikube to start up and allocate more memory to the
    VM that it creates. To see how Elasticsearch, Kibana, and Fluentd work together,
    you should start Minikube with at least 5 GB of RAM allocated, which you can do
    with the following command:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，您可以要求Minikube启动并为其创建的VM分配更多内存。要了解Elasticsearch、Kibana和Fluentd如何协同工作，您应该至少为Minikube分配5GB的RAM启动，可以使用以下命令完成：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can then see what add-ons are enabled and disabled for Minikube with the
    Minikube add-ons command. For example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用Minikube add-ons命令查看Minikube启用和禁用的插件。例如：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And enabling EFK is simply done using this command:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 启用EFK只需使用以下命令即可：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`enabled` does not mean instantly running. FluentD and Kibana will start fairly
    quickly, but ElasticSearch does take significantly longer. Being an add-on implies
    that software within Kubernetes will manage the containers within the kube-system
    namespace, so getting information about the current state of these services won''t
    be as simple as `kubectl get pods`. You will need to either reference `-n kube-system`
    or use the option `--all-namespaces`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`enabled`并不意味着立即运行。FluentD和Kibana会很快启动，但ElasticSearch需要更长的时间。作为附加组件意味着Kubernetes内的软件将管理kube-system命名空间内的容器，因此获取有关这些服务当前状态的信息不会像`kubectl
    get pods`那样简单。您需要引用`-n kube-system`或使用选项`--all-namespaces`：'
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can see the Minikube add-on manager loads up EFK as three ReplicaSets,
    each running a single pod, and fronted with a service that is exposed from the
    virtual machine as a NodePort. With Minikube, you can also see the list of services
    using this command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到Minikube附加管理器将EFK作为三个ReplicaSets加载，每个运行一个单独的pod，并且使用从虚拟机暴露为NodePort的服务进行前端。使用Minikube，您还可以使用以下命令查看服务列表：
- en: '[PRE15]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Log aggregation with EFK
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用EFK进行日志聚合。
- en: Fluentd starts as the source for collecting logs from all the containers. It
    uses the same underlying sources that the command `kubectl logs` uses. Within
    the cluster, every container that is operating is generating logs that are handled
    in some fashion by the container runtime, the most common of which is Docker,
    which maintains log files for every container on each of the hosts.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd作为从所有容器收集日志的源开始。它使用与命令`kubectl logs`相同的底层来源。在集群内，每个正在运行的容器都会生成日志，这些日志以某种方式由容器运行时处理，其中最常见的是Docker，它在每个主机上为每个容器维护日志文件。
- en: The Minikube add-on that sets up Fluentd configures it with a `ConfigMap`, which
    references where to load these log files, and includes additional rules to annotate
    the log data with information from Kubernetes. As Fluentd runs, it keeps track
    of these log files, reading in the data as it is updated from each container,
    parsing the log file output into data structures in JSON format, and adding the
    Kubernetes-specific information. The same configuration also details what to do
    with the output, and in the case of the Minikube add-on, it specifies an endpoint,
    which is the `elasticsearch-logging` service, where it sends this structured JSON
    data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 设置Fluentd的Minikube附加组件使用`ConfigMap`，它引用了加载这些日志文件的位置，并包含了用于注释来自Kubernetes的信息的附加规则。当Fluentd运行时，它会跟踪这些日志文件，从每个容器中读取更新的数据，将日志文件输出解析为JSON格式的数据结构，并添加Kubernetes特定的信息。相同的配置还详细说明了输出的处理方式，在Minikube附加组件的情况下，它指定了一个端点，即`elasticsearch-logging`服务，用于发送这些结构化的JSON数据。
- en: Elasticsearch is a popular open source data and search index, with corporate
    support from [Elastic.co](https://www.elastic.co/). Although it requires quite
    a bit of resources to run, it scales up extremely well and has a very flexible
    structure for adding a variety of data sources and providing a search interface
    for that data. You can get more details about how ElasticSearch works at [https://github.com/elastic/elasticsearch](https://github.com/elastic/elasticsearch),
    the GitHub repository.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch是一个流行的开源数据和搜索索引，得到了[Elastic.co](https://www.elastic.co/)的企业支持。虽然它需要相当多的资源来运行，但它的扩展性非常好，并且对于添加各种数据源并为这些数据提供搜索界面具有非常灵活的结构。您可以在[https://github.com/elastic/elasticsearch](https://github.com/elastic/elasticsearch)的GitHub存储库中获取有关ElasticSearch工作原理的更多详细信息。
- en: Kibana is the final part of this trio, and provides the web-based user interface
    for searching the content that is stored in Elasticsearch. Also maintained by
    [Elastic.co](https://www.elastic.co/), it provides some dashboard capabilities
    and an interactive query interface for Elasticsearch. You can find more information
    on Kibana at [https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana是这个三部曲的最后一部分，为搜索存储在Elasticsearch中的内容提供了基于Web的用户界面。由[Elastic.co](https://www.elastic.co/)维护，它提供了一些仪表板功能和Elasticsearch的交互式查询界面。您可以在[https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)上找到更多关于Kibana的信息。
- en: While using Minikube, everything in your cluster is on a single node, so there
    are limits and differences to using the same kind of framework in a larger cluster.
    If you are using a remote cluster with several nodes, you may want to look at
    something like Helm to install Elasticsearch, Fluentd, and Kibana. Many service
    providers who are supporting Kubernetes also have something set up to aggregate,
    store, and provide a searchable index of your containers logs. Google Stackdriver,
    Datadog, and Azure are examples that provide a similar mechanism and service,
    specific to their hosted solutions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Minikube时，集群中的所有内容都在单个节点上，因此在较大的集群中使用相同类型的框架会有限制和差异。如果您正在使用具有多个节点的远程集群，您可能需要查看类似Helm这样的工具来安装Elasticsearch、Fluentd和Kibana。许多支持Kubernetes的服务提供商也已经设置了类似的机制和服务，用于聚合、存储和提供容器日志的可搜索索引。Google
    Stackdriver、Datadog和Azure都提供了类似的机制和服务，专门针对其托管解决方案。
- en: Viewing logs using Kibana
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kibana查看日志
- en: 'For this book, we will explore how to use Kibana, taking advantage of it as
    an add-on to Minikube. After you have enabled it, and when the pods are fully
    available and reporting as Ready, you can access Kibana with this command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将探讨如何使用Kibana，并将其作为Minikube的附加组件。启用后，当pod完全可用并报告为“就绪”时，您可以使用以下命令访问Kibana：
- en: '[PRE17]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will bring up a web page that is backed by the `kibana-logging` service.
    When it is first accessed, the web page will ask you to specify a default index,
    which is used by Elasticsearch to build its search indices:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开一个由`kibana-logging`服务支持的网页。首次访问时，网页将要求您指定一个默认索引，该索引将用于Elasticsearch构建其搜索索引：
- en: '![](assets/055a41ee-3d69-408e-8cca-7be39e12a8e6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/055a41ee-3d69-408e-8cca-7be39e12a8e6.png)'
- en: Click on Create, taking the defaults that are provided. The default index pattern
    of `logstash-*` doesn't mean it has to come from `logstash` as a source, and the
    data that has already been sent to ElasticSearch from Fluentd will all be directly
    accessible.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“创建”，采用提供的默认设置。`logstash-*`的默认索引模式并不意味着它必须来自`logstash`作为数据源，而已经从Fluentd发送到ElasticSearch的数据将直接可访问。
- en: 'One you have defined a default index, the next page that is displayed will
    show you all the fields that have been added into Elasticsearch as Fluentd has
    taken the data from the container logs and Kubernetes metadata:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您定义了默认索引，下一个显示的页面将向您展示已添加到Elasticsearch中的所有字段，因为Fluentd已经从容器日志和Kubernetes元数据中获取了数据：
- en: '![](assets/de9d0ee0-d8ed-4ce1-b285-572b2f6ee971.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/de9d0ee0-d8ed-4ce1-b285-572b2f6ee971.png)'
- en: You can browse through this list to see what is being captured by field name,
    which will give you a little sense of what is available to browse and search.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以浏览此列表，查看按字段名称捕获的内容，这将让您对可供浏览和搜索的内容有一点了解。
- en: 'To see the logs that are flowing from the system, the Discover button on the
    top left of the web page will take you to a view that is built from these indices
    we just created, and by default, will reflect all of the logs that are happening
    that Fluentd is collecting:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看从系统流出的日志，网页左上角的“发现”按钮将带您进入一个由我们刚刚创建的这些索引构建的视图，默认情况下将反映Fluentd正在收集的所有日志：
- en: '![](assets/91c5976e-53e7-4849-9fea-fc73fd985733.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/91c5976e-53e7-4849-9fea-fc73fd985733.png)'
- en: The logging that you are seeing is primarily coming from the Kubernetes infrastructure
    itself. To get a better picture of how to use the logging, spin up the earlier
    examples we created, and we will scale those up to multiple instances to see the
    output.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您看到的日志主要来自Kubernetes基础架构本身。为了更好地了解如何使用日志记录，启动我们之前创建的示例，并将它们扩展到多个实例以查看输出。
- en: 'We will grab the two-tier example app of Flask and Redis from [https://github.com/kubernetes-for-developers/kfd-flask](https://github.com/kubernetes-for-developers/kfd-flask):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从[https://github.com/kubernetes-for-developers/kfd-flask](https://github.com/kubernetes-for-developers/kfd-flask)获取Flask和Redis的两层示例应用程序。
- en: '[PRE18]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This will deploy our earlier Python and Redis examples, with a single instance
    of each. Once these pods are active, go back and refresh the browser with Kibana
    active in it, and it should update to show you the latest logging. You can set
    the time period that Kibana is summarizing at the top of the window, and set it
    to auto-refresh on a regular basis, if you desire.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将部署我们之前的Python和Redis示例，每个示例只有一个实例。一旦这些pod处于活动状态，返回并刷新带有Kibana的浏览器，它应该会更新以显示最新的日志。您可以在窗口顶部设置Kibana正在总结的时间段，并且如果需要，可以将其设置为定期自动刷新。
- en: 'Finally, let''s scale up our Flask deployment to have multiple instances, which
    will make learning how to use Kibana a bit easier:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将Flask部署扩展到多个实例，这将使学习如何使用Kibana变得更容易：
- en: '[PRE20]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Filtering by app
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按应用程序筛选
- en: The key to using Kibana effectively is to filter to just the data you are interested
    in seeing. The default discovery view is set to give you a sense of how large
    the logs are from specific sources, and we can use filtering to narrow down to
    what we want to see.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有效使用Kibana的关键是筛选出您感兴趣的数据。默认的发现视图设置为让您了解特定来源的日志有多大，我们可以使用筛选来缩小我们想要查看的范围。
- en: As you view the data, scroll down on the left side through the list of fields,
    and each of these can be used as a filter. If you tap on one, Kubernetes.labels.app
    for example, Kibana will give you a summary of what different values this field
    has collected for the timespan that you are viewing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看数据时，从左侧滚动列表中滚动下去，每个字段都可以用作筛选器。如果您点击其中一个，例如Kubernetes.labels.app，Kibana将为您总结此字段在您正在查看的时间跨度内收集了哪些不同的值。
- en: '![](assets/cc31781e-ae3c-406b-8345-61bce34cad64.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/cc31781e-ae3c-406b-8345-61bce34cad64.png)'
- en: 'In the preceding example, you can see that the two `app` labels that are within
    the timespan are `flask` and `kubernetes-dashboard`. We can limit it to the Flask
    application by clicking the magnifying glass icon with a plus in it. The result
    constrains to only log items that include those values:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您可以看到在时间跨度内的两个`app`标签是`flask`和`kubernetes-dashboard`。我们可以通过点击带有加号的放大镜图标来将其限制为仅包含这些值的日志项：
- en: '![](assets/f3188d31-ab4c-43f0-b66b-5ff37bb2e83e.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f3188d31-ab4c-43f0-b66b-5ff37bb2e83e.png)'
- en: 'The icon with a magnifying glass with a minus symbol is used to set an exclusion
    filter. Since we used the `kubectl scale` command earlier to create multiple instances,
    you can scroll down to `kubernetes.pod_name` in the list of fields and see the
    pods that are listed and reporting as matching the first filter:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 带有减号符号的放大镜图标用于设置排除筛选器。由于我们之前使用`kubectl scale`命令创建了多个实例，您可以在字段列表中向下滚动到`kubernetes.pod_name`，并查看列出的并报告与第一个筛选器匹配的pod：
- en: '![](assets/127983ae-ea49-434c-a0bd-adf3a0d47235.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/127983ae-ea49-434c-a0bd-adf3a0d47235.png)'
- en: You can now refine the filter to only include one, or exclude one of those pods,
    to see all the remaining logs. As you add filters, they will appear at the top
    of the screen, and by clicking on that reference you can remove, pin, or temporarily
    disable the filter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以将过滤器细化为仅包括其中一个，或排除其中一个pod，以查看所有剩余的日志。随着您添加过滤器，它们将出现在屏幕顶部，通过单击该引用，您可以删除、固定或暂时禁用该过滤器。
- en: Lucene query language
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lucene查询语言
- en: You can also use the Lucene query language, which is what ElasticSearch uses
    by default, to refine your searches to data within the fields, make more complex
    filters, or otherwise track down the data with more precision. The Lucene query
    language goes beyond what we will cover in this book, but you can get an excellent
    overview in the Kibana documentation at [https://www.elastic.co/guide/en/kibana/current/lucene-query.html.](https://www.elastic.co/guide/en/kibana/current/lucene-query.html)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用Lucene查询语言，这是ElasticSearch默认使用的语言，以便将搜索细化到字段内的数据，制作更复杂的过滤器，或以更精确的方式跟踪数据。Lucene查询语言超出了本书的范围，但您可以在Kibana文档中获得很好的概述。
- en: Lucene's search language is oriented around searching unstructured text data,
    so basic searching for a word is as simple as entering a word. Multiple words
    are treated as individual searches, so if you are searching for a specific phrase,
    put the phrase in quotes. The search parser will also understand explicit OR and
    AND for simple Boolean searches.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Lucene的搜索语言是围绕搜索非结构化文本数据而设计的，因此搜索单词就像输入一个单词那样简单。多个单词被视为单独的搜索，因此如果您要搜索特定短语，请将短语放在引号中。搜索解析器还将理解简单布尔搜索的显式OR和AND。
- en: 'The default on the query syntax is to search all fields, and you may specify
    a field to search. To do so, name the field, followed by a colon, and then the
    search terms. For example, to search for `error` in the field `log`, you can use
    this search query:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 查询语法的默认设置是搜索所有字段，您可以指定要搜索的字段。要这样做，命名字段，后跟冒号，然后是搜索词。例如，要在字段`log`中搜索`error`，您可以使用此搜索查询：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This search query also supports wildcard searches, using the character `?`
    to represent any single unknown character, and `*` to represent zero or more characters.
    You can also use regular expressions in your query, by wrapping your query with
    `/` characters, for example:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此搜索查询还支持通配符搜索，使用字符`?`表示任何单个未知字符，`*`表示零个或多个字符。您还可以在查询中使用正则表达式，通过用`/`字符包装查询，例如：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This will search for `error` or `errors` in the log field.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在日志字段中搜索`error`或`errors`。
- en: 'NOTE: Because Lucene breaks down the fields, regular expressions are applied
    to each word in a string, and not the string as a whole. Because of this, regular
    expressions are best used when you want to hunt for a composed word, and not a
    phrase or string that includes whitespaces.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：因为Lucene会分解字段，正则表达式会应用于字符串中的每个单词，而不是整个字符串。因此，当您想要搜索组合词而不是包含空格的短语或字符串时，最好使用正则表达式。
- en: The Lucene query language also includes some advanced search options that can
    accommodate misspellings and slight variations, which can be immensely useful.
    The syntax includes support for fuzzy searches using the `~` character as a wildcard,
    which allows for slight variations in spelling, transposition, and so on. Phrases
    also support using ~ as a variation indicator, and it is used for making proximity
    searches, a maximum distance between two words in a phrase. To get more information
    on how these specific techniques work and how to use them, dig into the [ElasticSearch
    Query DSL documentation](https://www.elastic.co/guide/en/elasticsearch/reference/6.2/query-dsl-query-string-query.html#_fuzziness).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Lucene查询语言还包括一些高级搜索选项，可以容纳拼写错误和轻微变化，这可能非常有用。语法包括使用`~`字符作为通配符进行模糊搜索，允许拼写的轻微变化，转置等。短语还支持使用~作为变体指示符，并用于进行接近搜索，即短语中两个单词之间的最大距离。要了解这些特定技术的工作原理以及如何使用它们，请查阅[ElasticSearch查询DSL文档](https://www.elastic.co/guide/en/elasticsearch/reference/6.2/query-dsl-query-string-query.html#_fuzziness)。
- en: Running Kibana in production
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在生产环境中运行Kibana
- en: Kibana has a variety of other features, including setting up dashboards, making
    data visualizations, and even using simple machine learning to hunt for anomalies
    in the log data. These features are beyond the scope of this book. You can learn
    more about them in the Kibana user's guide at [https://www.elastic.co/guide/en/kibana/current/](https://www.elastic.co/guide/en/kibana/current/).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana还有各种其他功能，包括设置仪表板，制作数据可视化，甚至使用简单的机器学习来搜索日志数据中的异常。这些功能超出了本书的范围。您可以在Kibana用户指南中了解更多信息[https://www.elastic.co/guide/en/kibana/current/](https://www.elastic.co/guide/en/kibana/current/)。
- en: Running more complex developer support tools, such as Elasticsearch, Fluentd,
    and Kibana, is a more complex task than we can cover in this book. There is some
    documentation around using Fluentd and Elasticsearch as an add-on, as you have
    seen previously with the Minikube example. EFK is its own complex application
    to be managed. There are several Helm charts that might suit your needs, or you
    may want to consider leveraging a cloud provider's solution, rather than take
    on the administration of these components yourself.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 运行更复杂的开发者支持工具，如Elasticsearch，Fluentd和Kibana，是一项比我们在本书中所涵盖的更复杂的任务。有一些关于使用Fluentd和Elasticsearch作为附加组件的文档，就像你之前在Minikube示例中看到的那样。EFK是一个需要管理的复杂应用程序。有几个Helm图表可能适合您的需求，或者您可能希望考虑利用云提供商的解决方案，而不是自己管理这些组件。
- en: Distributed tracing with Jaeger
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Jaeger进行分布式跟踪
- en: As you decompose your services into multiple containers, one of the hardest
    things to understand is the flow and path of requests, and how containers are
    interacting. As you expand and use more containers to support components within
    your system, knowing which containers are which and how they're contributing to
    the performance of a request becomes a significant challenge. For simple systems,
    you can often add logging and get a view through the log files. As you move into
    dozens, or even hundreds, of different containers making up a service, that process
    becomes far less tenable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将服务分解为多个容器时，最难理解的是请求的流动和路径，以及容器之间的交互方式。随着您扩展并使用更多容器来支持系统中的组件，了解哪些容器是哪些以及它们如何影响请求的性能将成为一个重大挑战。对于简单的系统，您通常可以添加日志记录并通过日志文件查看。当您进入由数十甚至数百个不同容器组成的服务时，这个过程变得不太可行。
- en: One solution to this problem is called Distributed Tracing, which is a means
    of tracking the path of requests between containers, much like a profiler can
    track requests within a single application. This involves using libraries or frameworks
    that support a tracing library to create and pass along the information, as well
    as a system external to your application to collect this information and present
    it in a usable form. The earliest examples of this are documented in research
    papers from a Google system called Dapper, and an early open source implementation
    inspired by Dapper was called Zipkin, made by folks working at Twitter. The same
    concept has been repeated several times, and in 2016, a group started to come
    together to collaborate on the various tracing attempts. They formed OpenTracing,
    which is now a part of the Cloud Native Compute Foundation, to specify the format
    for sharing tracing across a variety of systems and languages.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的一个解决方案被称为分布式跟踪，它是一种追踪容器之间请求路径的方法，就像性能分析器可以追踪单个应用程序内的请求一样。这涉及使用支持跟踪库的库或框架来创建和传递信息，以及一个外部系统来收集这些信息并以可用的形式呈现出来。最早的例子可以在谷歌系统Dapper的研究论文中找到，受Dapper启发的早期开源实现被称为Zipkin，由Twitter的工作人员制作。相同的概念已经重复出现多次，2016年，一群人开始合作进行各种跟踪尝试。他们成立了OpenTracing，现在是Cloud
    Native Compute Foundation的一部分，用于指定在各种系统和语言之间共享跟踪的格式。
- en: Jaeger is an implementation of the OpenTracing standards, inspired by Dapper
    and Zipkin, created by engineers working at Uber, and donated to the Cloud Native
    Compute Foundation. Full documentation for Jaeger is available at [http://jaeger.readthedocs.io/](http://jaeger.readthedocs.io/).
    Released in 2017, Jaeger is in active development and use.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger是OpenTracing标准的一个实现，受Dapper和Zipkin启发，由Uber的工程师创建，并捐赠给Cloud Native Compute
    Foundation。Jaeger的完整文档可在[http://jaeger.readthedocs.io/](http://jaeger.readthedocs.io/)上找到。Jaeger于2017年发布，目前正在积极开发和使用中。
- en: There are other tracing platforms, notably OpenZipkin ([https://zipkin.io](https://zipkin.io)),
    also available, so Jaeger isn't the only option in this space.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他跟踪平台，特别是OpenZipkin（[https://zipkin.io](https://zipkin.io)），也可用，因此Jaeger并不是这个领域的唯一选择。
- en: Spans and traces
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨度和跟踪
- en: 'When looking at distributed tracing, there are two common terms that you will
    see repeatedly: span and trace. A span is the smallest unit that is tracked in
    distributed tracing, and represents an individual process getting a request and
    returning a response. As the process makes requests to other services in order
    to do its work, it passes information along with the request so that the service
    being requested can create its own span and reference the requesting one. Each
    of these spans is collected and exported from each process, gathered up, and can
    then be analyzed. A full collection of spans that are all working together is
    called a trace.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式跟踪中，有两个常见的术语，你会反复看到：跨度和跟踪。跨度是在分布式跟踪中被追踪的最小单位，代表一个接收请求并返回响应的单个过程。当该过程向其他服务发出请求以完成其工作时，它会将信息与请求一起传递，以便被请求的服务可以创建自己的跨度并引用请求的跨度。这些跨度中的每一个都被收集并从每个过程中导出，然后可以进行分析。所有共同工作的跨度的完整集合被称为跟踪。
- en: Adding, gathering, and transferring all this additional information is additional
    overhead for each of the services. While this information is valuable, it can
    also generate a huge amount of information, and if every service interacting always
    created and published every trace, the amount of data processing needed to handle
    the tracing system would exponentially outgrow the service itself. To provide
    value to tracing, tracing systems have implemented sampling so that not every
    request gets traced, but a reasonable volume, you still have enough information
    to get a good representation of the system's overall operation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 添加、收集和传输所有这些额外信息对每个服务都是额外的开销。虽然这些信息很有价值，但它也可能产生大量信息，如果每个交互的服务都创建并发布每个跟踪，处理跟踪系统所需的数据处理量将呈指数级增长。为了为跟踪提供价值，跟踪系统已经实施了抽样，以便不是每个请求都被跟踪，但是有一个合理的数量，仍然有足够的信息来获得系统整体操作的良好表示。
- en: Different tracing systems handle this differently, and how much data and what
    data is passed between services is still very much in flux. Additionally, services
    that don't follow the request/response pattern – such as a background queue or
    fan-out processing – aren't easily represented by the current tracing systems.
    The data can still be captured, but presenting a consistent view of the processing
    can be far more complex.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的跟踪系统处理方式不同，服务之间传递的数据量和数据类型仍然在不断变化。此外，不遵循请求/响应模式的服务（如后台队列或扇出处理）并不容易被当前的跟踪系统所表示。数据仍然可以被捕获，但呈现处理的一致视图可能会更加复杂。
- en: 'When you view the details of a trace, you are often presented with a flame-graph
    style output, which shows a timeline view of how long each trace took and what
    service was processing it. For example, here is an example trace detail view from
    the Jaeger documentation:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当您查看跟踪的详细信息时，通常会看到一个火焰图样式的输出，显示了每个跟踪花费的时间以及正在处理它的服务。例如，这是Jaeger文档中的一个跟踪详细视图示例：
- en: '![](assets/f3ff52a5-e84b-4000-a533-5d4dae94754e.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f3ff52a5-e84b-4000-a533-5d4dae94754e.png)'
- en: Architecture of Jaeger distributed tracing
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jaeger分布式跟踪的架构
- en: 'Like (**Elasticsearch, Fluentd, and Kibana** (**EFK**)), Jaeger is a complex
    system that collects and processes quite a bit of information. It is shown here:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与Elasticsearch、Fluentd和Kibana（EFK）类似，Jaeger是一个收集和处理大量信息的复杂系统。它在这里展示：
- en: '![](assets/9d20266c-5139-4f29-ada1-597a40a57514.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9d20266c-5139-4f29-ada1-597a40a57514.png)'
- en: This is the architecture of how Jaeger worked at Uber as of 2017\. The configuration
    uses the side-car pattern we mentioned earlier, with each container running a
    nearby container that collects the spans from the instrumentation using UDP, and
    then forwards those spans into a storage system based on Cassandra. Setting up
    a Cassandra cluster, as well as the individual collectors and the query engine,
    is far more than can be easily created in a local development environment.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Jaeger在2017年在Uber工作的架构。配置使用了我们之前提到的side-car模式，每个容器都运行一个附近的容器，使用UDP收集来自仪器的跨度，然后将这些跨度转发到基于Cassandra的存储系统。设置Cassandra集群以及单独的收集器和查询引擎远比在本地开发环境中容易创建的要多得多。
- en: Fortunately, Jaeger also has an all-in-one option for experimenting with and
    learning how to use Jaeger and what it can do. The all-in-one option has the agent,
    collector, query engine, and UI in a single container image that doesn't store
    any information persistently.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Jaeger还有一个全包选项，可以用来尝试和学习如何使用Jaeger以及它的功能。全包选项将代理、收集器、查询引擎和UI放在一个单一的容器映像中，不会持久存储任何信息。
- en: The Jaeger project has the all-on-one option, as well as Helm charts and variations
    that utilize Elasticsearch for persistence, documented and stored on GitHub at [https://github.com/jaegertracing/jaeger-kubernetes](https://github.com/jaegertracing/jaeger-kubernetes).
    In fact, the Jaeger project tests their development of Jaeger and each of the
    components by leveraging Kubernetes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger项目有一体化选项，以及利用Elasticsearch进行持久化的Helm图表和变体，这些都在GitHub上进行了记录和存储，网址为[https://github.com/jaegertracing/jaeger-kubernetes](https://github.com/jaegertracing/jaeger-kubernetes)。事实上，Jaeger项目通过利用Kubernetes来测试他们对Jaeger和每个组件的开发。
- en: Trying out Jaeger
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试Jaeger
- en: 'You can try out the current version of Jaeger by using their all-in-one development
    setup. Since they maintain this on GitHub, you can run it directly from there
    with this command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用Jaeger的一体化开发设置来尝试当前版本。由于他们在GitHub上维护这个版本，您可以直接使用以下命令从那里运行：
- en: '[PRE23]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This will create a deployment and a number of service frontends:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个部署和一些服务前端：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'And when the `jaeger-deployment` pod is reporting ready, you can use the following
    command to access the Jaeger query interface:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当`jaeger-deployment` pod报告准备就绪时，您可以使用以下命令访问Jaeger查询界面：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The resulting web page should appear:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的网页应该如下所示：
- en: '![](assets/2aef79e3-c902-4065-bd20-776ff57c1d9a.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2aef79e3-c902-4065-bd20-776ff57c1d9a.png)'
- en: 'By default, the Jaeger system is reporting on its own operations, so as you
    use the query interface, it will also generate its own traces that you can start
    to investigate. The Find Traces panel on the left of the window should show at
    the service jaeger-query, and if you click on the Find Traces button at the bottom,
    it will search based on the default parameters:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Jaeger系统正在报告自己的操作，因此当您使用查询界面时，它也会生成自己的跟踪，您可以开始调查。窗口左侧的“查找跟踪”面板应该显示在服务jaeger-query上，如果您点击底部的“查找跟踪”按钮，它将根据默认参数进行搜索：
- en: '![](assets/aa36c7cb-5d2f-492d-b685-81d5e7875ba0.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aa36c7cb-5d2f-492d-b685-81d5e7875ba0.png)'
- en: This page shows the times of all the traces found and how long they took, allowing
    you to dig down into them by API endpoint (which is called operation in this user
    interface), limiting the time span, and providing a rough representation of how
    long the queries took to process.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此页面显示了找到的所有跟踪的时间以及它们所花费的时间，允许您通过API端点（在此用户界面中称为操作）深入挖掘它们，限制时间跨度，并提供了一个大致表示查询处理时间的粗略表示。
- en: 'These traces are all made up of a single span, so are quite simple. You can
    select one of those spans and look at the trace detail, including expanding the
    information that it captured and passed along with those traces. Looking at that
    detail fully expanded should show you something like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些跟踪都由单个span组成，因此非常简单。您可以选择其中一个span并查看跟踪详细信息，包括展开它捕获和传递的信息以及这些跟踪。查看完全展开的详细信息应该显示如下：
- en: '![](assets/be759bdd-3762-4a4e-8c90-5ce79b4eb911.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/be759bdd-3762-4a4e-8c90-5ce79b4eb911.png)'
- en: Let's look at how to add tracing to your own application.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何向您自己的应用程序添加追踪。
- en: Example – adding tracing to your application
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-向您的应用程序添加追踪
- en: 'There are several things we will need to do to enable tracing from our example
    applications:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做几件事情来启用我们示例应用程序的追踪：
- en: Add the libraries and code to generate traces
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加库和代码以生成跟踪
- en: Add a tracing collector side-car to your pod
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向您的pod添加一个追踪收集器边车
- en: Let's look at enabling the tracing side-car first, and we will use the Python
    Flask example that we have been building earlier in the book.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看如何启用追踪边车，我们将使用之前在本书中构建的Python Flask示例。
- en: 'The code for this example is online at the GitHub project at [https://github.com/kubernetes-for-developers/kfd-flask](https://github.com/kubernetes-for-developers/kfd-flask),
    and the branch for this addition is `0.6.0`. You can get the code for this project
    locally using the following commands:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子的代码在线上的GitHub项目中[https://github.com/kubernetes-for-developers/kfd-flask](https://github.com/kubernetes-for-developers/kfd-flask)，这个添加的分支是`0.6.0`。您可以使用以下命令在本地获取此项目的代码：
- en: '[PRE26]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Adding a tracing collector to your pod
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向您的pod添加跟踪收集器
- en: 'The libraries that implement open-tracing typically use a very lightweight
    network connection, in this case UDP, to send traces from our code. UDP does not
    guarantee connections, so this also means that trace information could be lost
    if the network became too congested. OpenTracing and Jaeger minimize that by taking
    advantage of one of the guarantees of Kubernetes: two containers in the same pod
    will be placed on the same node, sharing the same network space. If we run a process
    in another container in our pod that captures the UDP packets, the network connectivity
    will be all on the same node and have very little chance of interference.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 实现open-tracing的库通常使用非常轻量级的网络连接，比如UDP，来从我们的代码发送跟踪信息。UDP不能保证连接，这也意味着如果网络过于拥挤，跟踪信息可能会丢失。OpenTracing和Jaeger通过利用Kubernetes的一个保证来最小化这种情况：同一个pod中的两个容器将被放置在同一个节点上，共享相同的网络空间。如果我们在pod中的另一个容器中运行一个捕获UDP数据包的进程，网络连接将全部在同一个节点上，并且干扰的可能性非常小。
- en: 'The Jaeger project has an image that listens to a variety of ports to capture
    these traces and forward them to its storage and query system. The container `jaegertracing/jaeger-agent`
    is published to DockerHub and is maintained as a very small image size (5 MB for
    version 1.2). This small size and the benefit of being close to our application
    makes it ideal for running as a side-car: another container in our pod, supporting
    the main process.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger项目有一个镜像，它监听各种端口以捕获这些跟踪信息，并将其转发到存储和查询系统。容器`jaegertracing/jaeger-agent`发布到DockerHub，并保持非常小的镜像大小（版本1.2为5
    MB）。这个小尺寸和靠近我们应用程序的好处使它非常适合作为一个辅助容器运行：在我们的pod中支持主要进程的另一个容器。
- en: 'We can do this by adding another container to the pod defined in our flask
    deployment (`deploy/flask.yaml`):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向我们flask部署（`deploy/flask.yaml`）中定义的pod添加另一个容器来实现这一点：
- en: '[PRE27]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This example is based off the Jaeger [deployment documentation](https://jaeger.readthedocs.io/en/latest/deployment/),
    which provides an example of how to use this with Docker, but not Kubernetes directly.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子是基于Jaeger [部署文档](https://jaeger.readthedocs.io/en/latest/deployment/)，它提供了如何在Docker中使用它的示例，但不是直接在Kubernetes中使用。
- en: It is important to notice the command that we have in this container. By default,
    the container runs `/go/bin/agent-linux`, but without any options. In order to
    send data to our local installation of Jaeger, we will need to tell the collector
    where to send it. The destination is defined by the option `--collector.host-port`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意我们在这个容器中的命令。默认情况下，容器运行`/go/bin/agent-linux`，但没有任何选项。为了将数据发送到我们本地安装的Jaeger，我们需要告诉收集器要发送到哪里。目的地由选项`--collector.host-port`定义。
- en: 'In this case, we installed the Jaeger all-in-one into the default namespace,
    and it includes a service named `jaeger-collector`, so that will be directly available
    to this pod. If you have an installation of Jaeger in your cluster that''s more
    robust, you may also have it defined in a different namespace. For example, the
    Helm installation of Jaeger installs into a namespace, `jaeger-infra`, and in
    those cases the value of the `collector.host-port` option would need to change
    to reflect that: `jaeger-collector.jaeger-infra.svc:14267`.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将Jaeger all-in-one安装到默认命名空间中，并包括一个名为`jaeger-collector`的服务，因此该服务将直接可用于此pod。如果您在集群中安装了更强大的Jaeger，您可能还将其定义在不同的命名空间中。例如，Jaeger的Helm安装将安装到一个名为`jaeger-infra`的命名空间中，在这种情况下，`collector.host-port`选项的值需要更改以反映这一点：`jaeger-collector.jaeger-infra.svc:14267`。
- en: There are multiple ports used by Jaeger here as well, intentionally to allow
    the agent to collect from a number of legacy mechanisms used by alternate languages.
    We will be using UDP port `6382` for the `python jaeger-tracing` client library.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里Jaeger还使用了多个端口，故意允许代理从备用语言使用的多种传统机制中收集。我们将使用UDP端口`6382`用于`python jaeger-tracing`客户端库。
- en: Add the libraries and code to generate traces
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加生成跟踪的库和代码
- en: 'We start by adding two libraries for the tracing to our project: `jaeger-client`
    and `flask_opentracing`. `flask-opentracing` adds tracing into Flask projects
    so that you can easily have all HTTP endpoints traced automatically. The OpenTracing
    project doesn''t include any collectors, so we also need a library to collect
    and send the trace data somewhere, in this case, jaeger-client.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先为跟踪添加了两个库到我们的项目中：`jaeger-client`和`flask_opentracing`。`flask-opentracing`将跟踪添加到Flask项目中，以便您可以轻松地自动跟踪所有HTTP端点。OpenTracing项目不包括任何收集器，因此我们还需要一个库来收集和发送跟踪数据到某个地方，这里是jaeger-client。
- en: The example also adds the requests library, as in this example we will add an
    HTTP endpoint that makes a remote request, processes the responses, and returns
    the values—and add tracing to that sequence.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例还添加了requests库，因为在这个示例中，我们将添加一个进行远程请求、处理响应并返回值的HTTP端点，并对该序列进行跟踪。
- en: 'Importing the libraries and initializing the tracer is fairly straightforward:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 导入库并初始化跟踪器非常简单：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Jeager recommends you use a method to initialize the tracer indirectly, as shown
    previously. The configuration in this case sets the sampler to forward all requests;
    when you use this in production, you want to consider that carefully as a configuration
    option, as tracing every request can be overwhelming in high volume services.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Jeager建议您间接使用一种方法来初始化跟踪器，如前所示。在这种情况下，配置将采样器设置为转发所有请求；在生产中使用时，您需要仔细考虑这一配置选项，因为在高负载服务中跟踪每个请求可能会很繁重。
- en: 'The tracer is initialized right after we create the Flask application:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建Flask应用程序后立即初始化跟踪器：
- en: '[PRE29]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This works with Flask to instrument all `@app.routes` with tracing, each route
    will be labeled as an operation based on the name of the Python function. You
    can also trace only specific routes with a different configuration setup and add
    tracing annotations on the Flask routes you want to trace.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将与Flask一起使用，为所有`@app.routes`添加跟踪，每个路由将被标记为基于Python函数名称的操作。您还可以使用不同的配置设置仅跟踪特定路由，并在Flask路由上添加跟踪注释。
- en: 'Rebuilding the Flask image and deploying it will immediately start to generate
    traces, and with the jaeger-agent running in a side-car, the local `jaeger dev`
    instance will start showing traces immediately. You should see a service named
    `flask-service`, based on our application name and it should have multiple operations
    listed within it:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 重建Flask图像并部署它将立即开始生成跟踪，并且在侧车中运行jaeger-agent的情况下，本地`jaeger dev`实例将立即显示跟踪。您应该看到一个名为`flask-service`的服务，基于我们的应用程序名称，并且它应该在其中列出多个操作：
- en: '![](assets/ec715a4c-c36b-4f60-81f2-fd0e0365c833.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ec715a4c-c36b-4f60-81f2-fd0e0365c833.png)'
- en: The operations alive, ready, and metrics are the Flask routes that have been
    enabled to support the liveness and readiness probes, as well as the `prometheus`
    metrics. With this already defined on our example pod, they are getting consistent
    connections, which in turn generates the traces associated with the requests.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 活动，就绪和指标操作是启用以支持活动性和就绪性探针以及`prometheus`指标的Flask路由，这已在我们的示例pod上定义，它们正在获得一致的连接，从而生成与请求相关的跟踪。
- en: 'This alone is useful, but does not yet tell you what within the method took
    more or less time. You can add spans into a trace around methods or sections of
    code that you''re interested in instrumenting, using the `opentracing` library
    that gets installed with `flask-opentracing`. The following code snippet shows
    how to wrap the call to Redis that we use in our readiness probe with a trace
    span, so that it will show up separately:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这本身就很有用，但尚未告诉您方法中的哪个部分花费了更多或更少的时间。您可以使用`flask-opentracing`安装的`opentracing`库在您感兴趣的方法或代码段周围添加跟踪span，以下代码片段显示了如何使用跟踪span包装我们在就绪探针中使用的对Redis的调用，以便它将单独显示出来：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The keys here are getting the current tracing span that we generated for every
    request with `flask_tracer.get_span()`, and then using that in a `with` statement,
    which adds the span to a discrete bit of code that executes within that context.
    We can also use methods on the span, which is available within that block of code.
    We use the method `set_tag` to add a tag with the value of the result of the ping,
    so that it will be available in the specific trace output.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于获取我们为每个请求生成的当前跟踪span，使用`flask_tracer.get_span()`，然后在`with`语句中使用它，这将在该上下文中执行的代码块中添加span。我们还可以在span上使用方法，该方法在该代码块中可用。我们使用`set_tag`方法添加一个带有ping结果值的标签，以便在特定的跟踪输出中可用。
- en: 'We will go ahead and add a `@app.route` called `/remote` to make a remote HTTP
    request to GitHub, and add tracing around that to see it as sub spans:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续添加一个`@app.route`称为`/remote`，以进行对GitHub的远程HTTP请求，并在其周围添加跟踪以将其显示为子span：
- en: '[PRE31]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This example is similar to the readiness probe, except we''re wrapping different
    sections of code in different spans and naming them explicitly: `github-api` and
    `parse-json`.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子类似于就绪探针，只是我们在不同的代码段中包装不同的部分，并明确命名它们：`github-api` 和 `parse-json`。
- en: 'While adding code, you can use commands such as `kubectl delete` and `kubectl
    apply` to recreate the deployment with building it and pushing it to your container
    registry. For these examples, my pattern was to run the following commands from
    the project''s home directory:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加代码时，您可以使用`kubectl delete`和`kubectl apply`等命令来重新创建部署并将其构建并推送到您的容器注册表。对于这些示例，我的模式是从项目的主目录运行以下命令：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: You will want to replace the image registry reference and Docker tag with values
    from your  project.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要用项目中的值替换图像注册表引用和Docker标记。
- en: 'And then, check the status of the deployment with:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用以下命令检查部署的状态：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Once it''s fully online, you''ll see it reporting as Ready:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦它完全在线，您将看到它报告为就绪：
- en: '[PRE35]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The 2/2 shows you that two containers are running for the Flask pod, our main
    code and the jaeger-agent side-car.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 2/2显示有两个容器正在运行Flask pod，我们的主要代码和jaeger-agent side-car。
- en: 'If you are using Minikube, you can also use the service commands to make it
    easy to open these endpoints in a browser:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Minikube，还可以使用服务命令轻松在浏览器中打开这些端点：
- en: '[PRE36]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Any service with a node port setting can be easily opened locally with commands
    such as:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 任何具有节点端口设置的服务都可以通过诸如以下命令轻松在本地打开：
- en: '[PRE38]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'With this code added, built, and deployed, you can see the traces in Jaeger.
    Direct your browser to make some requests to `/remote` to generate spans from
    the requests, and in the Jaeger query browser you should see something like the
    following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 添加、构建和部署此代码后，您可以在Jaeger中看到跟踪。将浏览器定向到`/remote`发出一些请求以从请求生成跨度，并且在Jaeger查询浏览器中，您应该看到类似以下内容：
- en: '![](assets/a8091b4e-1492-4e78-8a35-e54de9554fa2.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a8091b4e-1492-4e78-8a35-e54de9554fa2.png)'
- en: 'The top of the Jaeger query window will show you dots indicating the time of
    the query and the relative duration, and you''ll see the various traces that it
    found listed below – four in our case. If you select a trace, you can get to the
    detailed view, which will include the sub-spans. Click on the spans to get more
    detail from each of them:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger查询窗口的顶部将显示表示查询时间和相对持续时间的点，您将看到它找到的各种跟踪列表-在我们的情况下有四个。如果选择一个跟踪，您可以进入详细视图，其中将包括子跨度。单击跨度以从中获取更多详细信息：
- en: '![](assets/f21aaceb-4f92-4027-bca9-3ba531a43300.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f21aaceb-4f92-4027-bca9-3ba531a43300.png)'
- en: With the span detail view, any tags you set on the span within the code will
    be viewable, and you can see that the `github-api` call took the majority of the
    time (265 of 266 ms) in responding to the request to `/remote`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通过跨度详细视图，您可以查看在代码中设置的任何标签，并且您可以看到`github-api`调用在响应`/remote`请求时花费了大部分时间（265/266毫秒）。
- en: Considerations for adding tracing
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加跟踪的考虑事项
- en: Tracing is an immensely powerful tool that also comes with a cost. Every trace
    is (although small) some overhead to process and manage. You may be excited to
    add tracing to every method in your application, or to build it into a library
    that attaches tracing and span creation to every method call. This can be done,
    and you will quickly find your infrastructure overwhelmed with trace information.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪是一个非常强大的工具，但也伴随着成本。每个跟踪都会（虽然很小）增加一些处理和管理的开销。您可能会很兴奋地将跟踪添加到应用程序中的每个方法，或者将其构建到一个库中，该库会将跟踪和跨度创建附加到每个方法调用中。这是可以做到的，但您很快会发现您的基础设施被跟踪信息所淹没。
- en: Tracing is also a tool that has the most benefit when tied directly to the responsibility
    of running the code. Be very aware that as you add tracing, you are also adding
    a lot of ancillary processing needed to capture, store, and query the data created
    by the traces.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪也是一个工具，当直接与运行代码的责任直接相关时，它具有最大的好处。请注意，随着您添加跟踪，还会添加许多辅助处理，以捕获、存储和查询跟踪生成的数据。
- en: A good way to handle the balancing act of the trade-offs is to add tracing intentionally,
    iteratively, and slowly – building to gain visibility as you need it.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 处理权衡的一个好方法是有意识地、迭代地和缓慢地添加跟踪-以获得您需要的可见性。
- en: OpenTracing as a standard is supported by a number of vendors. OpenTracing is
    also an evolving standard. While writing this book, there is a lot of conversation
    happening about how to best share and handle the span data (often called "baggage")
    that is carried along with requests between processes. Like tracing itself, adding
    data can add value, but it comes with the cost of larger requests and more processing
    needed to capture and handle the information.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTracing作为一个标准得到了许多供应商的支持。OpenTracing也是一个不断发展的标准。在撰写本书时，人们正在讨论如何最好地共享和处理跨进程请求中携带的跨度数据（通常称为“行李”）。像追踪本身一样，添加数据可以增加价值，但这也带来了更大的请求成本和更多的处理需求来捕获和处理信息。
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced logging and tracing with Fluentd and Jaeger.
    We showed how to deploy it and use it, capturing and aggregating data from your
    code when it runs at scale. We walked through how to use an Elasticsearch query
    to find data. We also looked at how to view Jaeger traces and how to add tracing
    to your code.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了使用Fluentd和Jaeger进行日志记录和跟踪。我们展示了如何部署它并使用它，在代码运行时捕获和聚合数据。我们演示了如何使用Elasticsearch查询数据。我们还看了如何查看Jaeger跟踪以及如何向代码添加跟踪。
- en: In the next chapter, we will look at ways of using Kubernetes to support and
    run integration testing, as well as using it with continuous integration.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何使用Kubernetes来支持和运行集成测试，以及如何将其与持续集成一起使用。
