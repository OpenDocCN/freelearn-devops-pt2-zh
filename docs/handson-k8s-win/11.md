# 配置应用程序以使用 Kubernetes 功能

最后一章演示了如何在 Kubernetes 中使用容器化的 Windows 应用程序——现在，我们将扩展我们的投票应用程序，以使用更高级的功能，使编排更加健壮和自动化。多年来，Kubernetes 扩展了越来越多的功能，从细粒度的**基于角色的访问控制**(**【RBAC】**)或机密管理到使用**水平吊舱自动缩放器** ( **HPA** )的自动缩放，后者是容器编排的圣杯。当然，我们无法在本书的范围内涵盖所有这些功能，但我们将包括有助于运行容器化 Windows 应用程序的最有用的功能。此外，请记住，当您运行内部 Kubernetes 集群时，某些功能不可用，例如，特定于云的存储资源调配器—我们将要介绍的所有示例都假设您运行的是 AKS Engine Kubernetes 集群。

在本章中，我们将涵盖以下主题:

*   使用命名空间隔离应用程序
*   使用活跃度和就绪性探测器进行健康监测
*   指定资源限制和配置自动缩放
*   使用配置映射和机密管理应用程序配置
*   管理 Windows 节点上的持久数据存储
*   为部署配置滚动更新
*   RBAC

# 技术要求

对于本章，您将需要以下内容:

*   安装了 Windows 10 专业版、企业版或教育版(1903 版或更高版本，64 位)
*   如果您想要编辑应用程序的源代码并进行调试，请使用 Microsoft Visual Studio 2019 社区(或任何其他版本)—Visual Studio Code 对经典版本的支持有限。NET 框架
*   蔚蓝账户
*   使用 AKS 引擎部署 Windows/Linux Kubernetes 集群，准备部署上一章中的投票应用程序

接下来，您将需要自己的 Azure 帐户来为 Kubernetes 集群创建 Azure 资源。如果您还没有创建前几章的帐户，您可以在[https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/)阅读更多关于如何获得个人使用的有限免费帐户的信息。

使用 AKS 引擎部署 Kubernetes 集群已经在[第 8 章](08.html)、*中介绍了部署混合 Azure Kubernetes 服务引擎集群*。在[第 10 章](10.html)、*部署微软 SQL Server 2019 和 ASP.NET MVC 应用*中已经介绍了向 Kubernetes 部署投票应用。

您可以从官方 GitHub 资源库下载本章的最新代码示例，网址为[https://GitHub . com/PacktPublishing/hand-Kubernetes-On-Windows/tree/master/chapter 11](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11)。

# 使用命名空间隔离应用程序

在上一章中，我们已经使用了一个命名空间(名为`dev`)来将我们应用程序的组件逻辑分组到一个现有的物理 Kubernetes 集群中的一个虚拟集群中。命名空间的一般原则是为对象名称提供资源配额和范围，给定命名空间内的名称必须是唯一的，但它们不必在不同的命名空间中是唯一的。默认情况下，Kubernetes 开箱即用地提供以下命名空间:

*   `kube-system`:库本内特系统创建的对象的命名空间，如`kube-apiserver`或`kube-proxy` Pods。
*   `kube-public`:一个所有用户都可以读取的命名空间，也没有经过身份验证——它将在由 kubeadm 引导的集群中创建，通常用于系统使用。
*   `default`:没有其他命名空间的对象的命名空间。

根据您的需求和团队的规模，您可能更愿意只使用对象标签(小团队)或在名称空间级别分离对象(大团队):

*   对于小型团队来说，如果单个开发人员能够理解整个系统(大约 10 个微服务)，并且整个开发环境可以使用本地集群来托管，例如运行在虚拟机上的 minikube 或 kubeadm 部署，则可以只使用生产服务的默认命名空间。或者，您可以为生产工作负载使用一个专用的命名空间，为开发/试运行环境使用一个单独的命名空间。
*   对于快速发展的中型团队，单个开发人员不在整个系统的范围内工作，为每个子团队提供专用的名称空间可能会更容易，尤其是在不可能在本地 Kubernetes 集群上创建整个开发环境的情况下。
*   对于大型团队来说，子团队几乎独立运作，为每个团队提供单独的生产和开发名称空间可能是个好主意。您也可以考虑使用每个名称空间的资源配额和 RBAC。
*   对于企业组织来说，单个团队甚至可能不知道其他团队，创建单独的集群可能比使用名称空间划分单个集群更容易。这使得资源和计费管理更加容易，并在出现问题时提供更好的部署边界。

创建服务对象时，名称空间会影响服务的 DNS 条目的**完全限定域名** ( **FQDN** )是什么。FQDNs 有一种形式`<service-name>.<namespace-name>.svc.cluster.local`—这意味着如果您在从 Pod 调用服务时使用`<service-name>`，调用将被限制在该 Pod 运行的命名空间内。请注意，跨名称空间调用服务是可能的，但是您需要指定 FQDN。

让我们演示如何为对象创建命名空间。

# 创建命名空间

要创建名为`prod`的命名空间，可以使用以下命令:

```
kubectl create namespace prod
```

与其他对象的情况一样，通常建议使用声明性对象配置管理并将清单文件应用于 Kubernetes 集群。下面的`namespace-prod.yaml`清单文件将创建`prod`名称空间，另外指定`ResourceQuota`对象，该对象确定该名称空间的总 CPU 和内存配额:

```
---
kind: Namespace
apiVersion: v1
metadata:
  name: prod
  labels:
    name: prod
---
apiVersion: v1
kind: ResourceQuota
metadata:
  namespace: prod
  name: default-resource-quota
spec:
  hard:
    requests.cpu: 500m
    requests.memory: 1Gi
    limits.cpu: "1"
    limits.memory: 2Gi
```

要应用清单文件，请执行以下命令:

```
kubectl apply -f .\namespace-prod.yaml
```

然后，您可以使用`kubectl describe`命令来检查在我们的名称空间中使用了多少资源:

```
PS C:\src> kubectl describe resourcequota -n prod
Name:            default-resource-quota
Namespace:       prod
Resource         Used  Hard
--------         ----  ----
limits.cpu       0     1
limits.memory    0     2Gi
requests.cpu     0     500m
requests.memory  0     1Gi
```

Resource quotas in Kubernetes are highly customizable and can be applied to different resources and scoped using sophisticated selectors. You can read more about this in the official documentation at [https://kubernetes.io/docs/concepts/policy/resource-quotas/](https://kubernetes.io/docs/concepts/policy/resource-quotas/).

现在，当您知道如何管理名称空间时，让我们看看如何使用`kubectl`命令有效地使用它们。

# kubectl 命令和名称空间

`kubectl`命令按照惯例对命名空间范围的对象进行操作，使用`--namespace`或`-n`标志来指定应该用于该命令的命名空间。如果需要查询所有名称空间中的对象，可以使用`--all-namespaces`标志。例如，要列出`prod`命名空间中的所有 Pods，请使用以下命令:

```
kubectl get pods -n prod
```

在前面的几章中，您已经多次使用了这个构造。但是，最好知道，如果没有为命令提供名称空间，它将使用在当前 kubeconfig 上下文中设置为默认值的名称空间。换句话说，它不必是默认的名称空间——这完全取决于您的上下文设置。我们已经在[第 6 章](06.html)、*与库本内特集群*交互中深入介绍了上下文—为了完整起见，我们将展示如何更改当前上下文中使用的命名空间。要在当前上下文中永久设置`prod`名称空间，请使用以下命令:

```
kubectl config set-context --current --namespace=prod
```

现在，任何支持指定命名空间的命令都将默认使用`prod`命名空间。

# 删除命名空间

与其他对象类似，建议强制删除命名空间。要删除`prod`命名空间，请执行以下命令:

```
kubectl delete namespace prod
```

请注意，此命令会删除此命名空间内的所有对象，这意味着它是一个破坏性很强的命令，应谨慎使用！

在下一节中，我们将看到如何使用探测器来配置容器的活性和就绪性监控。

# 使用活跃度和就绪性探测器进行健康监测

在 Kubernetes 中，kubelet 使用探测器来确定 Pod 的状态，您可以使用它们来定制如何检查 Pod 是否准备好为您的流量服务，或者容器是否需要重新启动。您可以为 Pod 中运行的每个容器配置三种类型的探测器:

*   **准备状态探测器**:用于确定给定的集装箱是否准备好接受运输。只有当一个吊舱的所有容器都准备好了，它才被认为是准备好了。未就绪的 pod 将从服务端点中删除，直到它们再次就绪。
*   **Liveness** **探头**:用于检测容器是否需要重启。这在容器陷入死锁或容器进程处于活动状态但无法正常运行的其他问题的情况下很有帮助。在这种情况下，重启容器可能会增加 Pods 的可用性。
*   **启动** **探测器**:这是一个额外的探测器，用于确定容器是否已经完全启动——就绪和活性探测器被禁用，直到该探测器成功返回。这对于由于某些初始化而启动时间较长的容器尤其有用。通过这种方式，你可以避免活跃度探测器过早的杀死。

默认情况下，Pod 容器上没有配置探头。但是，只有当 Pod 容器已经启动(在 Docker 的意义上)时，Kubernetes 才会为流量提供服务，并且在容器崩溃时重新启动它们(当然这取决于您的重新启动策略)。

可以使用三种类型的处理程序操作来配置所有类型的探测器:

*   运行命令(`exec`)—如果在容器中运行的给定命令返回非零退出代码，则探测器处于失败状态。
*   执行 HTTP GET 请求(`httpGet`)—只有当容器用大于或等于 200 且小于 400 的 HTTP 代码响应 HTTP GET 请求时，探测器才处于成功状态。
*   打开指定端口(`tcpSocket`)上容器的 TCP 套接字-如果可以建立连接，则探测器处于成功状态。

You should additionally consider using the termination grace period for your Pods to properly manage a containerized application life cycle and make your application gracefully exit when a SIGTERM signal is received ([https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace)). Please note that, for Windows Pods, the termination grace period is not supported as of Kubernetes 1.17.

使用探针时，有几个注意事项和最佳实践，对于任何具有许多相关组件的大型分布式系统都是如此。我们将在解释每种类型的探针时详细介绍——反映示例的投票应用源代码可以在官方 GitHub 资源库中找到，网址为[https://GitHub . com/packt publishing/hand-On-Kubernetes-On-Windows/tree/master/chapter 11/02 _ voting-application-props-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/02_voting-application-probes-src)。首先，让我们来看看最流行的探测器，就绪探测器。

# 就绪探测器

就绪探测器在 Kubernetes 中用于确定 Pod 容器是否已准备好接受从 Kubernetes 服务传入的流量—未准备好的 Pod(只有当所有容器都被认为已准备好时，Pod 才准备好)将从服务端点列表中删除，直到它们再次准备好。换句话说，它是一个信号，用于通知给定的 Pod 可以用于传入服务的请求。

您应该考虑准备就绪调查的一些既定最佳实践:

*   只要集装箱启动后，集装箱可能还没有准备好为交通服务，就使用这个探测器。
*   请确保在就绪探测评估期间检查缓存预热或数据库迁移状态。如果预热还没有开始，您也可以考虑开始预热的实际过程，但是要谨慎使用这种方法——在 Pod 的整个生命周期中，准备就绪探测将不断执行，这意味着您不应该为每个请求执行任何昂贵的操作。或者，您可能希望为此目的使用一个启动探测器，它是在 Kubernetes 1.16 中新引入的。
*   对于公开 HTTP 端点的微服务应用程序，请考虑始终配置`httpGet`就绪探测器。这将确保当容器成功运行但 HTTP 服务器未完全初始化时，覆盖所有情况。
*   在您的应用程序中使用单独的、专用的 HTTP 端点进行就绪性检查是一个好主意，例如，一个常见的约定是使用`/health`。
*   如果在这种类型的探测中检查依赖项(外部数据库和日志记录服务)的状态，请小心共享依赖项，例如投票应用程序中的 SQL Server。在这种情况下，您应该考虑使用探测超时，它大于外部依赖关系允许的最大超时，否则，您可能会出现级联故障和较低的可用性，而不是偶尔增加延迟。

对于使用 **IIS** (简称**互联网信息服务**)托管的 web 应用程序来说，准备情况调查很有意义—IIS 应用程序池需要完全启动，数据库迁移可能尚未应用。例如，我们将为投票应用程序配置一个简单的就绪探测器，如下所示:

*   ASP.NET MVC 应用程序将实现一个服务于`/health`请求的专用控制器。
*   将检查挂起的数据库迁移。请注意，这将间接验证数据库连接状态，这在某些情况下可能是不可取的。因此，我们将使用大于 30 秒的探测超时(默认的 SQL 命令超时)。
*   控制器动作将返回一个简单的 JSON。如果检查失败，HTTP 状态将为 503，如果检查成功，则为 200。

要为投票应用程序添加就绪探测器，请执行以下步骤:

1.  运行状况检查控制器操作的实现可以在`HealthController`类([https://github . com/PacktPublishing/hand-Kubernetes-On-Windows/blob/master/chapter 11/02 _ voting-application-probe-src/controller/health controller . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/02_voting-application-probes-src/Controllers/HealthController.cs)中找到，如下所示:

```
public ActionResult CheckHealth()
{
    this.Response.TrySkipIisCustomErrors = true;

    if (!this.db.Database.CompatibleWithModel(throwIfNoMetadata: true))
    {
        this.Response.StatusCode = (int)HttpStatusCode.ServiceUnavailable;
        return this.Json(new { status = "Database migrations pending" }, JsonRequestBehavior.AllowGet);
    }

    return this.Json(new { status = "Ok" }, JsonRequestBehavior.AllowGet);
}
```

2.  此外，您需要记住在默认路由映射之前，在`RouteConfig`类中修改您的应用程序的路由配置。

```
routes.MapRoute(
    name: "Health",
    url: "health",
    defaults: new { controller = "Health", action = "CheckHealth" });
```

3.  与前一章一样，构建应用程序的 Docker 映像，将其标记为 1.1.0 版本，并将其推送到 Docker Hub。在我们的演示案例中，我们将使用`packtpubkubernetesonwindows/voting-application:1.1.0`图像。
4.  修改部署清单文件`voting-application.yaml`，为`frontend`容器添加以下准备状态探测配置:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.1.0
        ...
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 40
          successThreshold: 1
          failureThreshold: 3
        ...
```

探测器被配置为调用`/health`端点，该端点将执行我们之前实现的控制器动作。探头配置中的重要部分如下:

5.  现在，使用`kubectl apply -f .\voting-application-readiness-probe.yaml`命令应用清单文件。
6.  像往常一样使用`kubectl get pods -n dev`和`kubectl describe`命令检查卷展过程。在 Pod 事件中，您可以验证 Pod 是否有任何就绪故障。
7.  在网络浏览器中，当您导航到应用程序时，您应该不会遇到任何 IIS 应用程序池启动延迟—网络服务器将通过就绪检查进行预热。

现在，让我们看一下另一个确定 Pod 容器活性状态的探测器。

# 活性探针

第二种类型的探测器是活动探测器，它的配置类似于清单中的就绪探测器。活跃度探测器用于确定是否需要重新启动 Pod 容器。当进程尚未退出但无法处理任何操作时，这种类型的探测对于恢复容器中的死锁或其他类型的问题可能很有用。

与就绪性探测类似，有几个关于如何以及何时应该使用 liveness 探测的指南:

*   应谨慎使用活性探针。此探测器的错误配置会导致服务中的级联故障和容器重启循环。作为一个快速的实验，您可以重新部署投票应用程序清单，用活动探测器替换就绪探测器，配置相似，但超时和延迟非常短，您将经历多次随机崩溃和应用程序可用性差！
*   除非有充分的理由，否则不要使用活性探测器。例如，一个很好的原因可能是您的应用程序中存在已知的死锁问题，其根本原因尚不清楚。
*   执行简单快速的检查，确定流程的状态，而不是其依赖关系。换句话说，您不希望在活跃度探测器中检查外部依赖关系的状态，这可能会导致级联故障，原因是容器重启的雪崩和服务盒的小子集过载。
*   如果在容器中运行的进程在遇到不可恢复的错误时能够崩溃或退出，那么您可能根本不需要活性探测器。
*   对`initialDelaySeconds`使用保守设置，以避免任何容器过早重启并陷入重启循环。

如果你不清楚`ServiceMonitor.exe`和`LogMonitor.exe`入口点进程的幕后到底发生了什么，那么由 IIS 托管的 Web 应用程序可能是使用活跃度探测器的一个很好的选择。理论上，每当 IIS 或 IIS 应用程序池出现问题时，他们应该会崩溃容器，但是让我们假设我们需要自己实现这些检查。我们将实现一个活跃度探测器，它将使用`exec`处理程序检查 IIS 应用程序池是否正在运行。为此，请遵循以下步骤:

1.  用`Deployment`修改`voting-application.yaml`清单文件，用于我们的应用。为`frontend`容器添加以下活性探针配置:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
    ...
    containers:
    - name: frontend
    image: packtpubkubernetesonwindows/voting-application:1.1.0
    ...
    livenessProbe:
      exec:
        command:
        - powershell.exe
        - -Command
        - if ((Get-WebAppPoolState DefaultAppPool).Value -ne "Started") { throw "Default IIS App Pool is NOT started" }
        initialDelaySeconds: 45
        periodSeconds: 10
        timeoutSeconds: 10
        successThreshold: 1
        failureThreshold: 3
        ...
```

探测器被配置为执行 PowerShell 命令`if ((Get-WebAppPoolState DefaultAppPool).Value -ne "Started") { throw "Default IIS App Pool is NOT started" }`，该命令检查默认的 IIS 应用程序池是否处于`Started`状态。如果不是，将引发异常，PowerShell 进程将以非零退出代码退出，导致探测器进入失败状态。

2.  现在，使用`kubectl apply -f .\voting-application-readiness-probe.yaml`命令应用清单文件。
3.  再次，使用`kubectl get pods -n dev`和`kubectl describe`命令检查卷展过程。在 Pod 事件中，您可以验证 Pod 是否有任何活动失败。

When using the `exec` handler, you should carefully analyze how the chosen command behaves. The `exec` handler has been reported to cause zombie process bloat in some cases.

最后，让我们快速看一下最后一种类型的探测器，启动探测器。

# 启动探测器

最近在 Kubernetes 1.16 中引入了启动探测器，以支持容器可能需要比就绪探测器中设置的`initialDelaySeconds + failureThreshold * periodSeconds`更多的初始化时间的情况。一般来说，您应该对启动探测使用与就绪探测相同的处理程序配置，但是使用更大的延迟。如果一个容器在`initialDelaySeconds + failureThreshold * periodSeconds`内没有准备好进行准备状态探测，那么该容器将被杀死，并服从 Pod 的重启策略。

我们的投票应用程序不需要专用的启动探测器，但是部署清单文件中的示例定义可能如下所示:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.1.0
        ...
        startupProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 60
          timeoutSeconds: 40
          successThreshold: 1
          failureThreshold: 5
        ...
```

在下一节中，我们将重点关注为 Pods 分配资源限制，以及如何为我们的投票应用程序配置自动缩放。

# 指定资源限制和配置自动缩放

作为容器编排者，Kubernetes 开箱即用，具有两个重要特性，有助于管理集群资源:

*   Pod 容器的资源请求和限制
*   HPA，允许根据 CPU 资源使用情况(稳定支持)、内存资源使用情况(测试版支持)或自定义指标(也是测试版支持)自动扩展您的部署或状态集

让我们首先看一下指定资源请求和限制。

# 资源请求和限制

当您创建一个 Pod 时，可以指定它的容器需要多少计算资源——在上一章中，我们已经执行了一个为投票应用程序分配资源的简短练习。一般来说，计算资源是 CPU 和 RAM 内存—Kubernetes 还能够管理其他资源，例如 Linux 上的大型内存或本地节点上的临时存储。

Kubernetes 资源模型在两类资源之间提供了额外的区别:可压缩和不可压缩。简而言之，可压缩资源可以很容易地被节流，而不会产生严重的后果。这种资源的一个完美例子是中央处理器——如果您需要限制给定容器的中央处理器使用，容器将正常运行，只是速度较慢。另一方面，我们有不可压缩的资源，无法在不产生不良后果的情况下对其进行节流——内存分配就是这种资源的一个例子。

There are two great design proposal documents that describe the Kubernetes resource model ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md)) and resource quality of service ([https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md)). We highly recommend reading them to fully understand the vision of Kubernetes resource management and which features are already implemented.

关于资源分配，您可以为 Pod 容器指定两个值:

*   `requests`:指定系统提供给定资源的保有量。您也可以反过来考虑这个问题——这是 Pod 容器要求系统正常运行的给定资源量。吊舱调度取决于`requests`值(而不是`limits`)。
*   `limits`:指定系统提供给定资源的最大数量。如果与`requests`一起指定，该值必须大于或等于`requests`。根据资源是可压缩的还是不可压缩的，超过限制会有不同的后果——可压缩资源(中央处理器)将被节流，而不可压缩资源(内存)会导致容器死亡。

使用不同的`requests`和`limits`值允许资源过量使用，这有助于有效地处理资源使用的短突发，同时允许平均更好的资源利用。如果根本不指定限制，容器可以根据需要消耗节点上的资源。这可以通过名称空间资源配额(在本章前面介绍)和限制范围来控制，您可以在[https://kubernetes.io/docs/concepts/policy/limit-range/](https://kubernetes.io/docs/concepts/policy/limit-range/)的文档中了解这些对象的更多信息。

我们在[第 4 章](04.html)、*库本内特概念和窗口支持*中介绍了库本内特窗口节点上资源管理支持的细节。重要的一点是，Windows 目前缺乏对内存不足杀手的支持(对内存限制的一些支持可能会在 Kubernetes 中的传入 Hyper-V 容器功能中提供)。这意味着超过为 Windows 容器内存设置的`limits`值不会导致任何节流或容器重启。这里，经验法则是使用`requests`仔细管理内存调度，并监控任何突然的内存分页。

在深入了解配置细节之前，我们需要了解一下在 Kubernetes 中测量 CPU 资源和内存的单位是什么。对于 CPU 资源，基本单位是**Kubernetes CPU**(**KCU**)，其中`1` 相当于例如 Azure 上的 1 个 vCPU、GCP 上的 1 个 Core 或裸机上的 1 个超线程核心。允许小数值:`0.1`也可以指定为`100m`(毫微微处理器)。对于内存，基本单位是字节；当然，您可以指定标准单位前缀，如`M`、`Mi`、`G`或`Gi`。

要演示如何使用资源`limits`和`requests`，请执行以下步骤:

1.  修改`voting-application.yaml`部署清单，使其不指定任何更新`strategy`，并为 CPU 和内存设置资源分配:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  replicas: 5
  ...
  # strategy:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: frontend
        ...        
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 1000m
            memory: 256Mi
```

对于内存，我们遵循当前针对 Windows 节点的建议—我们只指定希望请求多少内存。为了让 CPU 模拟资源耗尽，我们指定了一个大的请求值，该值将消耗 Windows 节点的所有群集 CPU。这样做的原因是，两个带有 Azure 虚拟机类型 Standard_D2_v3 的节点各有两个虚拟桌面，并且运行五个副本，我们总共需要五个虚拟桌面。更新`strategy`需要删除，以避免在部署期间出现任何死锁。

2.  使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
3.  现在，仔细观察部署中新 Pods 的创建。你会注意到有显示`Pending`状态的吊舱:

```
PS C:\src> kubectl get pods -n dev
NAME                                            READY   STATUS      RESTARTS   AGE
voting-application-frontend-54bbbbd655-nzt2n    1/1     Running     0          118s
voting-application-frontend-54bbbbd655-phdhr    0/1     Pending     0          118s
voting-application-frontend-54bbbbd655-qggc2    1/1     Running     0          118s
...
```

4.  这是意料之中的，因为`voting-application-frontend-54bbbbd655-phdhr` Pod 不能被调度到任何节点，因为没有可用的 CPU 资源。要检查实际原因，请描述 Pod 并检查`Events`:

```
PS C:\src> kubectl describe pod -n dev voting-application-frontend-54bbbbd655-phdhr
Events:
 Type     Reason            Age        From                 Message
 ----     ------            ----       ----                 -------
 Warning  FailedScheduling  <unknown>  default-scheduler    0/5 nodes are available: 2 Insufficient cpu, 3 node(s) didn't match node selector.
```

5.  不出所料，由于与节点选择器匹配的所有节点上的 CPU 资源不足，无法调度 Pod。让我们通过降低 Pod 容器的`requests`和`limits` CPU 值来解决这个问题—修改`voting-application.yaml`清单文件，以便将 CPU 的`requests`设置为`250m`，将`limits`设置为`500m`。

6.  使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件，并观察成功的部署。

现在，您已经知道如何为容器分配和管理资源，我们可以演示如何使用 HPA 为您的应用程序使用自动缩放。

# 高功率放大器（high-power amplifier 的缩写）

Kubernetes 的真正威力来自 HPA 实现的自动缩放，HPA 是一个由`HorizontalPodAutoscaler` API 对象支持的专用控制器。从高层次来看，高性能计算的目标是根据当前的 CPU 利用率或其他自定义指标(包括一次多个指标)自动扩展部署或状态集中的副本数量。基于度量值确定副本目标数量的算法详情可在[https://kubernetes . io/docs/tasks/run-application/horizontal-Pod-autoscale/# algorithm-details](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details)找到。高性能计算是高度可配置的，在本书中，我们将介绍一个标准场景，说明我们希望何时根据目标 CPU 使用率自动扩展。

我们的投票应用程序公开了不需要太多 CPU 的功能，这意味着可能很难按需触发自动缩放。为了解决这个问题，我们将添加一个专用的控制器动作，它可以用给定的目标百分比值模拟恒定的 CPU 负载。用于压力模拟的`packtpubkubernetesonwindows/voting-application:1.2.0` Docker 图像的源代码可以在[https://github . com/PacktPublishing/hand-Kubernetes-On-Windows/tree/master/chapter 11/08 _ voting-application-HPA-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/08_voting-application-hpa-src)上找到。如果您想自己自定义应用程序，请在 Visual Studio 2019 中打开您的解决方案，并按照以下步骤操作:

1.  定义`StressCpuWorker`类([https://github . com/PacktPublishing/hand-Kubernetes-On-Windows/blob/master/chapter 11/08 _ voting-application-HPA-src/Services/cpustressworker . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Services/CpuStressWorker.cs)，包含模拟 CPU 压力的主要工作人员代码:

```
private void StartCpuStress()
{
    this.logger.Info($"Environment.ProcessorCount: {Environment.ProcessorCount}");

    for (int i = 0; i < Environment.ProcessorCount; i++)
    {
        var thread = new Thread(
            () =>
                {
                    var watch = new Stopwatch();
                    watch.Start();

                    while (this.isEnabled)
                    {
                        if (watch.ElapsedMilliseconds <= this.targetCpuLoad)
                        {
                            continue;
                        }

                        Thread.Sleep(100 - this.targetCpuLoad);

                        watch.Reset();
                        watch.Start();
                    }
                });

        thread.Start();
    }
}
```

这段代码将启动几个线程，线程的数量将等于环境中当前可用的处理器数量，然后每个逻辑处理器将通过几乎空的`while`循环来承受`this.targetCpuLoad`毫秒的压力。对于剩余的 100 毫秒“段”，线程将处于休眠状态——这意味着，平均而言，我们应该将所有可用的 CPU 加载到`this.targetCpuLoad`百分比。当然，这取决于分配给容器的处理器数量——这个数量可能会因您的`requests`和`limits`值而异；您可以随时查看 Pod 日志，查看有多少逻辑处理器可用于此 Pod。另外，请注意，即使容器有两个逻辑处理器可用，也不意味着容器能够充分利用它们；负载可根据`limits`值进行调节。

2.  在`HomeController`类([https://github . com/PacktPublishing/hand-Kubernetes-On-Windows/blob/master/chapter 11/08 _ voting-application-HPA-src/controller/homecontroller . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/Controllers/HomeController.cs)中，添加一个新的控制器操作，该操作将通过`/Home/StressCpu?value={targetPercent}`路由可用。请注意，我们允许通过 GET 请求(而不是 PUT)来执行此操作，以便在使用网络浏览器时轻松进行交互。此外，将`IStressCpuWorker`注入到构造器中—最终动作实现如下:

```
public ActionResult StressCpu([FromUri] int value)
{
    this.Response.StatusCode = (int)HttpStatusCode.Accepted;
    var host = Dns.GetHostEntry(string.Empty).HostName;

    if (value < 0)
    {
        this.cpuStressWorker.Disable();
        return this.Json(new { host, status = $"Stressing CPU turned off" }, JsonRequestBehavior.AllowGet);
    }

    if (value > 100)
    {
        value = 100;
    }

    this.cpuStressWorker.Enable(value);
    return this.Json(new { host, status = $"Stressing CPU at {value}% level" }, JsonRequestBehavior.AllowGet);
}
```

此实现将启用 CPU 压力如果您提供正值，对于负值，压力将被禁用。

3.  在`NinjectWebCommon`类中配置依赖注入([https://github . com/PacktPublishing/hand-On-Kubernetes-On-Windows/blob/master/chapter 11/08 _ voting-application-HPA-src/App _ Start/ninejectwebcommon . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/08_voting-application-hpa-src/App_Start/NinjectWebCommon.cs))。确保`StressCpuWorker`类被解析为单例:

```
kernel.Bind<ICpuStressWorker>().To<CpuStressWorker>().InSingletonScope();
```

4.  构建带有标签`1.2.0`的 Docker 图像，并将其推送到您的存储库中，就像我们之前所做的那样。

图像准备就绪后，我们可以继续部署新版本的投票应用程序并配置自动缩放。为此，请执行以下步骤:

1.  修改`voting-application.yaml`清单文件，确保您使用了图像的`1.2.0`标签，并且`resources`的指定如下:

```
resources:
  limits:
    cpu: 500m
  requests:
    cpu: 400m
    memory: 256Mi
```

2.  在 PowerShell 窗口中，使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
3.  等待部署完成，并使用以下命令观察 Pods 的 CPU 使用情况:

```
PS C:\src> kubectl top pod -n dev
NAME                                           CPU(cores)   MEMORY(bytes)
mssql-deployment-58bcb8b89d-7f9xz              339m         903Mi
voting-application-frontend-6b6c9557f8-5wwln   117m         150Mi
voting-application-frontend-6b6c9557f8-f787m   221m         148Mi
voting-application-frontend-6b6c9557f8-rjwmj   144m         164Mi
voting-application-frontend-6b6c9557f8-txwl2   120m         191Mi
voting-application-frontend-6b6c9557f8-vw5r9   160m         151Mi
```

当 IIS 应用程序池完全初始化时，每个 Pod 的 CPU 使用率应稳定在`150m`左右。

4.  为 HPA 创建`hpa.yaml`清单文件:

```
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  namespace: dev
  name: voting-application-frontend
spec:
  minReplicas: 1
  maxReplicas: 8
  targetCPUUtilizationPercentage: 60
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: voting-application-frontend
```

该 HPA 将自动将`voting-application-frontend`部署扩展到`1`和`8`副本之间，试图以`60`的 CPU 使用率为目标。请注意，此目标使用率很高，在生产环境中，您应该考虑使用更低、更合适的值。该清单文件与使用`kubectl autoscale deployment/voting-application-frontend -n dev --cpu-percent=60 --min=1 --max=8`命令强制创建的 HPA 大致相同。

5.  使用`kubectl apply -f .\hpa.yaml`命令应用清单文件。

6.  HPA 会延迟冷却，以避免颠簸(即副本数量经常波动)。默认延迟为五分钟。这意味着在您应用部署后，您应该会期待一些延迟，直到 HPA 扩展部署。使用`kubectl describe`命令监控 HPA 的状态:

```
PS C:\src> kubectl describe hpa -n dev voting-application-frontend
...
Metrics:                                               ( current / target )
 resource cpu on pods (as a percentage of request): 37% (150m) / 60%
Events:
 Type     Reason                        Age   From                       Message
 ----     ------                        ----  ----                       -------
...
 Normal   SuccessfulRescale             8m6s  horizontal-Pod-autoscaler  New size: 4; reason: All metrics below target
 Normal   SuccessfulRescale             3m3s  horizontal-Pod-autoscaler  New size: 3; reason: All metrics below targetcpu
```

随着时间的推移，您会注意到，由于没有足够的 CPU 负载，HPA 往往会缩小到单个副本。

7.  让我们使用专用端点来增加 CPU 负载。在网络浏览器中，转到以下网址:`http://<serviceExternalIp>/Home/StressCpu?value=90`。这将使中央处理器的压力达到 90%的目标水平，请记住，根据逻辑处理器在 Pods 中的分配方式，实际使用情况可能会有所不同。
8.  您可以执行多个请求，以确保部署中的更多 Pods 开始对 CPU 施加压力。
9.  过一会儿，观察 HPA 事件发生的情况:

```
 Normal   SuccessfulRescale             7m44s            horizontal-Pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
 Normal   SuccessfulRescale             7m29s               horizontal-Pod-autoscaler  New size: 5; reason: cpu resource utilization (percentage of request) above target
 Normal   SuccessfulRescale             2m25s               horizontal-Pod-autoscaler  New size: 8; reason: cpu resource utilization (percentage of request) above target
```

由于 CPU 资源利用率高于 60%的目标，部署会自动扩大！添加更多 Pods 后，平均利用率将会降低，因为并非所有 Pods 都在执行 CPU 压力测试。

For AKS and an AKS Engine cluster, it is possible to leverage the cluster autoscaler to automatically adjust the number of nodes in your cluster depending on the resource demands. You can read more in the official Azure documentation ([https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler)) and in the guide for configuring the cluster autoscaler on Azure ([https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/azure/README.md)).

祝贺您，您已经成功地为投票应用程序配置了 HPA。我们将要演示的下一个 Kubernetes 特性是使用配置映射和机密来注入配置数据。

# 使用配置映射和机密管理应用程序配置

为在 Kubernetes 上运行的应用程序提供配置，有两种可能的方法，记录在[https://kubernetes.io/docs/tasks/inject-data-application/](https://kubernetes.io/docs/tasks/inject-data-application/)中:

*   向容器命令传递参数
*   为容器定义系统环境变量
*   将配置映射或机密装载为容器卷
*   可选地使用 pods preferences 包装所有内容

本节将重点介绍配置映射和机密的使用，它们在许多方面相似，但用途却大相径庭。

首先，让我们来看看《秘密》。几乎在每个应用程序中，您都必须管理用于访问依赖项的敏感信息，例如密码、OAuth 令牌或证书。由于明显的安全问题和非常有限的灵活性，将这些信息作为硬编码值放在 Docker 映像中是不可能的。同样，不建议直接在 Pod 清单文件中定义密码—清单文件旨在保持在源代码控制中，这绝对不是存储此类敏感信息的地方。为了管理这类信息，Kubernetes 提供了 Secret 对象，从技术上讲，它可以保存任何类型的由键值对组成的数据。或者，可以在`etcd`中加密静态机密，这在生产场景中是推荐的。

我们现在将演示如何使用`kubectl`创建通用(不透明)秘密。您也可以为此目的使用清单文件，但是如何生成这些清单文件取决于您的配置项/光盘管道(您不想将这些清单文件签入源代码管理！).要为 SQL Server 密码创建密码，请执行以下步骤:

1.  打开一个 PowerShell 窗口。
2.  假设您想在`dev`命名空间中创建一个名为`mssql`的秘密，它在`SA_PASSWORD`键下保存`S3cur3P@ssw0rd`，执行以下命令:

```
kubectl create secret generic -n dev mssql --from-literal=SA_PASSWORD="S3cur3P@ssw0rd"
```

3.  现在，秘密可以作为装载在容器中的卷(作为文件或目录)使用，或者用于定义容器的环境变量。在投票应用程序的情况下，更容易使用带有 SQL Server 密码的机密作为环境变量。这是通过部署清单中的以下方式实现的:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.2.0
        env:
        - name: MSSQL_SA_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mssql
              key: SA_PASSWORD
        - name: CONNECTIONSTRING_VotingApplication
          value: "Data Source=mssql-deployment;Initial Catalog=VotingApplication;MultipleActiveResultSets=true;User Id=sa;Password=$(MSSQL_SA_PASSWORD);"
```

这里的关键概念是使用`secretKeyRef`从我们刚刚创建的`mssql`秘密中引用`SA_PASSWORD`密钥的值。该值被注入到`MSSQL_SA_PASSWORD`环境变量中(但是您可以检查在使用`kubectl describe`时不可能看到该值！)，容器中运行的应用程序可以访问它。在我们的例子中，我们使用这个变量来定义另一个名为`CONNECTIONSTRING_VotingApplication`的环境变量。例如，当您需要创建一个必须包含密码的连接字符串时，这是一种常见的模式，但请记住，这可能是一种不如使用卷安全的解决方案。

将机密用作环境变量和装载卷之间有一个显著的区别:如果机密发生变化，通过卷提供的机密数据将被更新。根据您的需求和实施细节，您可能希望选择将机密装载为卷。当然，这需要您的应用程序知道机密文件的可能更改，这意味着它需要主动监控文件系统并刷新任何凭据提供程序、连接字符串或证书，这些通常保存在内存中。将机密视为不可变的配置值是最好的选择(无论是作为卷还是作为环境变量装载时)，并且使您的应用程序更具可预测性，更不复杂。但是，如果您的体系结构有限制，希望尽可能少的 Pod 重启，那么将 Secrets 作为一个卷注入并在您的应用程序中实现自动刷新是建议的解决方案。

From a security perspective, injecting Secrets as environment variables is less secure on Linux as, when having root privileges, you can enumerate all environment variables for a process from `/proc/<pid>/environ`. On Windows nodes, the issue is even more complex: you can still access environment variables for processes but volumes cannot currently use the in-memory filesystem. This means that Secrets are then stored directly on the node's disk storage.

为了存储应用程序的非敏感配置数据，Kubernetes 提供了 ConfigMap 对象。这是您可以用来从运行时配置数据中完全分离 Docker 映像(您的构建工件)的另一个概念。从应用编程接口的角度来看，这个概念类似于机密——您可以存储键值对，并将它们作为容器的环境变量注入，或者使用卷作为文件或目录来装载它们。为了演示这一点，我们将创建一个配置图，用于存储 ASP.NET MVC 应用程序的`Web.config`文件中引用的配置文件`customErrors.config`，并使用卷装载它。

As mentioned in [Chapter 4](04.html), *Kubernetes Concepts and Windows Support*, as of Kubernetes 1.17, there is no support for mounting a volume `subPath` as a file on Windows. This means that it is not possible to easily override the whole `Web.config` file for the ASP.NET MVC using ConfigMap.

请遵循以下步骤:

1.  首先，我们需要对投票应用程序源代码进行一个小的修改。我们将把`<customErrors>`节点从`<system.web>`节点提取到子目录中的一个单独文件中。在`Web.config`文件中，将`<system.web>`节点更改为:

```
  <system.web>
    <compilation debug="true" targetFramework="4.8" />
    <httpRuntime targetFramework="4.8" />
    <customErrors configSource="config\customErrors.config" />
  </system.web>
```

2.  在`config`目录下创建`customErrors.config`文件，内容如下。我们将在接下来的步骤中使用配置映射覆盖它:

```
<customErrors mode="On" />
```

3.  构建一个带有`1.3.0`标签的 Docker 映像，并将其发布到 Docker Hub，就像前面的例子一样。
4.  为配置图定义创建`voting-application-customerrors-config.yaml`清单文件，该文件具有以下形式，并将文件([https://github . com/packt publishing/hand-On-Kubernetes-On-Windows/blob/master/chapter 11/10 _ voting-application-config map-src/config/customerrors . config](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/10_voting-application-configmap-src/config/customErrors.config))作为`data`:

```
kind: ConfigMap 
apiVersion: v1 
metadata: 
  namespace: dev 
  name: voting-application-customerrors-config
  labels: 
    app: voting-application
data: 
  customErrors.config: |
    <customErrors mode="On" />
```

可以强制使用`kubectl`创建配置映射，但是我们想要演示配置映射清单文件的结构。重要的部分是在对更大的配置文件(`|`)使用 YAML 多行字符串时保持适当的缩进。

5.  使用`kubectl apply -f .\voting-application-customerrors-config.yaml`命令应用清单文件。
6.  修改用于部署的`voting-application.yaml`清单文件，将我们的配置图装载为容器中的目录(记住使用新的 Docker 图像标签):

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.3.0
        ...
        volumeMounts:
        - name: customerrors-config-volume
          mountPath: C:\inetpub\wwwroot\config\
        ...
      volumes:
      - name: customerrors-config-volume
        configMap:
          name: voting-application-customerrors-config
```

这里重要的部分是将`voting-application-customerrors-config`配置图引用为一个卷(`customerrors-config-volume`)并将其安装到容器中的`C:\inetpub\wwwroot\config\`。如果`subPath`挂载目前在 Windows 上得到支持，我们可以覆盖单个文件，而不是整个目录。

7.  使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
8.  现在，导航到浏览器中的`http://<serviceExternalIp>/Home/StressCpu`地址。这将触发一个异常——我们没有在 URL 中提供所需的请求参数。您应该会看到一个自定义错误页面，它只是通知`An error occurred while processing your request`。
9.  关闭自定义错误页面，修改配置映射的`voting-application-customerrors-config.yaml`清单文件，使其包含以下节点:

```
  customErrors.config: |
    <customErrors mode="Off" />
```

10.  使用`kubectl apply -f .\voting-application-customerrors-config.yaml`命令应用清单文件。

Depending on whether IIS is able to watch for changes in the `C:\inetpub\wwwroot\config\` directory, the IIS App Pool may not be reloaded in the Pod. In such a case, `exec` into the container and execute the `Restart-WebAppPool DefaultAppPool` command.

11.  再次导航至`http://<serviceExternalIp>/Home/StressCpu`。如果您的 IIS 应用程序池已重新加载，您将看到完整的异常详细信息，而不是自定义错误页面。

通过这种方式，我们演示了如何在 Windows Pods 中使用机密和配置映射。现在，是时候熟悉管理 Windows 节点上的持久数据存储了。

# 管理 Windows 节点上的持久数据存储

在[第 4 章](04.html)、 *Kubernetes 概念和 Windows 支持*中，我们已经介绍了 Kubernetes 中与存储相关的一些概念，例如**persistent volumes**(**PV**)、**persistent volume claims**(**PVC**)和**storagelces**(**SC**)以及它们在 Windows 工作负载中是如何得到支持的。管理容器化应用程序中的状态和存储以及使用状态集是一个广泛而复杂的话题，不在本书的讨论范围内——官方文档提供了一个很好的介绍，可以在[https://kubernetes.io/docs/concepts/storage/](https://kubernetes.io/docs/concepts/storage/)找到。Windows Pods 的 PersistentVolume 支持的关键是，您可以使用一些现有的卷插件，但不是全部。在 Windows 上，支持以下功能:

*   树内卷插件:azureDisk、azureFile、gcePersistentDisk、awsElasticBlockStore(自 1.16 起)和 vsphereVolume(自 1.16 起)
*   灵活卷插件:中小企业和 iSCSI
*   CSI 卷插件(树外插件)

这意味着，对于 Windows 节点，在 AKS 或 AKS Engine 集群的情况下，您仅限于使用 azureDisk 和 azureFile 树内卷插件，从技术上讲，您可以将 FlexVolume SMB 插件与 Azure Files SMB 共享相结合。对于内部部署场景，您必须依赖配置为使用您自己的存储或连接到作为外部云服务公开的中小型企业共享的灵活卷中小型企业或 iSCSI 插件。如果你在虚拟空间上运行，你当然可以利用虚拟空间卷插件。一般来说，处理本地运行的混合 Windows/Linux 集群的持久卷仍然很困难。

For on-premises clusters, using Rook ([https://rook.io/](https://rook.io/)) to orchestrate storage and integrate with Kubernetes is a good solution. Unfortunately, there is no support for Windows yet, even for consuming the volumes.

我们的投票应用程序已经对运行在 Linux Pod 中的 SQL Server 使用了 PersistentVolumes 在本例中，我们已经对`kubernetes.io/azure-disk`置备程序使用了 StorageClass，它在内部使用了 azureDisk 卷插件。这个场景与 Linux Pods 有关——现在，我们将为 Windows Pods 使用 PersistentVolumes。投票应用程序不需要在前端容器中保存数据，但是作为一个纯粹的例子，我们将展示如何为每个 Pod 存储投票日志。

本次变更的源代码可在[https://github . com/packt publishing/hand-On-Kubernetes-On-Windows/tree/master/chapter 11/12 _ voting-application-persistent volume-src](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/tree/master/Chapter11/12_voting-application-persistentvolume-src)获得。我们将不讨论实施细节，但变化很简单:

*   添加一个新的`VoteLogManager`类([https://github . com/PacktPublishing/hand-Kubernetes-On-Windows/blob/master/chapter 11/12 _ voting-application-persistent volume-src/Services/votelogmanager . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Services/VoteLogManager.cs)，管理`C:\data\voting.log`文件—可以在日志中添加新的投票并读取日志内容。该日志文件将使用 Kubernetes PersistentVolume 持久化。
*   对于`SurveyController`类中增加的每一张选票([https://github . com/packt publishing/hand-On-Kubernetes-On-Windows/blob/master/chapter 11/12 _ voting-application-persistent volume-src/controller/survesses controller . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/SurveysController.cs))，通知`VoteLogManager`。
*   在`HomeController`类([https://github . com/packt publishing/hand-On-Kubernetes-On-Windows/blob/master/chapter 11/12 _ voting-application-persistent volume-src/controller/homecontroller . cs](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/12_voting-application-persistentvolume-src/Controllers/HomeController.cs)中，添加一个新的控制器操作，`VotingLog`，该操作将返回投票日志的内容。然后，您可以使用`http://<serviceExternalIp>/Home/VotingLog`访问当前服务副本的投票日志。

要部署应用程序，请执行以下步骤:

1.  为投票应用程序构建一个带有标签`1.4.0`的 Docker 映像，并将其推送到 Docker Hub，就像前面的例子一样。
2.  我们需要将我们的部署转换为状态集。因此，您首先需要从集群中删除部署:

```
kubectl delete deployment -n dev voting-application-frontend
```

3.  创建`StorageClass`清单`sc.yaml`，内容如下。我们将使用`kubernetes.io/azure-disk`置备程序来使用 azure 磁盘卷插件:

```
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: azure-disk
provisioner: kubernetes.io/azure-disk
parameters:
  storageaccounttype: Standard_LRS
  kind: Managed
```

4.  使用`kubectl apply -f sc.yaml`命令应用清单文件。
5.  将部署转换为状态集，并使用 Docker 映像的`1.4.0`版本。完整的清单文件可以在[上找到。与之前的`voting-application.yaml`清单文件相比，我们强调了所需的更改，如下所示:](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/13_persistentvolume/voting-application.yaml)

```
apiVersion: apps/v1
kind: StatefulSet
...
spec:
  replicas: 5
  serviceName: voting-application-frontend  # (1)
  ...
  template:
    ...
    spec:
      ...
      initContainers:  # (2)
      - name: volume-mount-permissions-fix
        image: packtpubkubernetesonwindows/voting-application:1.4.0
        command: ["powershell.exe", "-Command", "iisreset.exe /START; icacls.exe c:\\data /grant '\"IIS AppPool\\DefaultAppPool\":RW'"]
        volumeMounts:
        - mountPath: C:/data
          name: voting-log-volume
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.4.0
        ...
        volumeMounts:  # (3)
        - mountPath: C:/data
          name: voting-log-volume
  volumeClaimTemplates:  # (4)
  - metadata:
      name: voting-log-volume
      labels:
        app: voting-application
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
      storageClassName: azure-disk
```

状态集合要求提供负责该状态集合的服务名称(`1`)。除此之外，我们定义了`volumeClaimTemplates` ( `4`)，它将用于为这个状态集中的每个 Pod 副本创建一个专用的 PersistentVolumeClaim。我们将这个用于安装卷的聚氯乙烯作为容器(`3`)中的`C:/data`目录，其中`voting.log`将被持久化。此外，我们还需要向 IIS 应用程序池用户授予对`C:/data`目录的适当读/写权限，否则，网络应用程序将无法访问我们的持久卷。这是使用在`init`容器(`2`)中执行的`icasls.exe`来实现的。请注意，在分配权限之前，您需要首先启动 IIS ( `iisreset.exe /START`)以正确创建 IIS 应用程序池用户！

6.  使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件。
7.  当状态集准备好之后，在网络浏览器中导航到该应用程序并投票几次。
8.  在网络浏览器中打开`http://<serviceExternalIp>/Home/VotingLog`，根据您到达的 Pod 副本，您将看到不同的结果:

![](assets/a40d5661-8380-427f-88ca-7e156f2419d7.png)

很好，现在我们知道在容器中写入目录的工作正如预期的那样。但是让我们证明这个目录确实是由 PersistentVolume 挂载支持的。为此，请执行以下步骤:

1.  将`statefulset`缩小到`0`副本。这将删除状态集合的所有 Pods:

```
kubectl scale statefulset/voting-application-frontend -n dev --replicas=0
```

2.  等待直到所有吊舱终止，并使用`kubectl get pods -n dev`命令进行观察。
3.  例如，将`statefulset`扩展到`5`副本:

```
kubectl scale statefulset/voting-application-frontend -n dev --replicas=5
```

4.  等待吊舱创建并准备就绪。由于我们的准备就绪探测器，可能需要几分钟。
5.  在网络浏览器中导航至`http://<serviceExternalIp>/Home/VotingLog`。您应该会看到与之前完全相同的投票日志。这表明所有 Pods 都装载了与以前相同的持久卷。

恭喜你！您已经在投票应用程序的窗口窗格中成功装载了 azureDisk PersistentVolumes。接下来，我们将了解如何为您的应用程序配置滚动更新。

# 为部署配置滚动更新

在生产场景中，您肯定需要一种部署策略，为您的应用程序提供零停机更新。作为一个容器编排者，Kubernetes 提供了不同的构建模块，可用于实现蓝绿色部署、加那利部署或滚动部署。Kubernetes Deployment 对象完全支持执行滚动更新部署—在这种类型的部署中，应用程序的新版本是通过逐渐用新副本替换旧副本来推出的，所有这些副本都在同一服务的后面。这意味着，在部署过程中，最终用户将达到应用程序的旧版本或新版本。

To ensure real zero downtime updates of your Deployments in Kubernetes, you need to configure proper probes, especially readiness. In this way, the user will be redirected to a replica only if this replica can properly respond to the request.

让我们看看如何为投票应用程序实现滚动部署。事实上，我们已经在前面的示例中使用了这种方法，现在我们将更详细地解释配置。请遵循以下步骤:

1.  使用`kubectl delete statefulset -n dev voting-application-frontend`命令删除我们在上一节中创建的 StatefulSet。
2.  让我们回到我们用于 HPA 演示的`voting-application.yaml`部署清单文件。您可以在 GitHub 存储库中的[https://GitHub . com/PacktPublishing/hand-On-Kubernetes-On-Windows/blob/master/chapter 11/14 _ rolling update/voting-application . YAML](https://github.com/PacktPublishing/Hands-On-Kubernetes-on-Windows/blob/master/Chapter11/14_rollingupdate/voting-application.yaml)找到该文件。
3.  滚动更新部署的配置方式如下:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  replicas: 5
  minReadySeconds: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  ...
    spec:
      ...
      containers:
      - name: frontend
        image: packtpubkubernetesonwindows/voting-application:1.2.0
        ...
```

为您的部署对象定义滚动更新部署的关键部分是`strategy`。要配置滚动更新，您需要使用带有`RollingUpdate`值的`type`(这也是默认值)。另一种方法是使用重新创建，这将在创建新的 Pods 之前简单地杀死所有 Pods—通常，您不希望在生产中使用这种策略类型，除非它与更复杂的模式(如蓝绿色部署)相结合。对于`RollingUpdate`类型，可以定义`maxUnavailable`，表示在更新过程中有多少 Pods 可以处于非就绪状态。类似地，`maxSurge`定义了在部署过程中，在所需数量的 Pods 上可以创建的最大 Pods 数量。您可以将这些值指定为数字或百分比，默认情况下，它们都设置为 25%。为了更好地理解这些数字在实践中的含义，让我们分析一下我们的例子。在期望的副本数量为`5`的情况下，当您触发“部署”卷展栏时，可能会发生以下事件序列:

4.  让我们看看它在实践中是如何工作的。首先，使用`kubectl apply -f .\voting-application.yaml`命令应用清单文件——这将创建应用程序的初始版本。
5.  现有部署的展开可以通过实时编辑对象或使用`kubectl rollout`命令来强制完成。一般来说，最好使用声明性方法:更改清单文件并再次应用它。在清单文件中将容器图像标签更改为`packtpubkubernetesonwindows/voting-application:1.4.0`，并使用`kubectl apply -f .\voting-application.yaml`命令应用。

6.  之后，使用以下命令快速开始观察`rollout status`:

```
PS C:\src> kubectl rollout status -n dev deployment/voting-application-frontend
Waiting for deployment "voting-application-frontend" rollout to finish: 2 out of 5 new replicas have been updated...
Waiting for deployment "voting-application-frontend" rollout to finish: 3 out of 5 new replicas have been updated...
Waiting for deployment "voting-application-frontend" rollout to finish: 4 out of 5 new replicas have been updated...
Waiting for deployment "voting-application-frontend" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "voting-application-frontend" rollout to finish: 4 of 5 updated replicas are available...
deployment "voting-application-frontend" successfully rolled out
```

7.  在卷展栏期间，您可以使用`kubectl rollout undo -n dev deployment/voting-application-frontend`或`kubectl rollout pause -n dev deployment/voting-application-frontend`等命令来控制“部署”卷展栏。但是，您仍然可以通过修改清单文件并再次应用它来实现同样的目的，这甚至包括暂停。
8.  您可以尝试在部署期间访问该应用程序。我们已经正确配置了就绪探测器，因此您不会遇到来自应用程序的任何意外响应！

StatefulSets also have a customizable strategy for rollouts. Due to state persistence, the strategy is a bit different from Deployments. You can read more in the official documentation, at [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies).

现在，让我们关注 Kubernetes 中的另一个重要话题:**基于角色的访问控制** ( **RBAC** )。

# 基于角色的访问控制

Kubernetes 附带了一个内置的 RBAC 机制，允许您配置细粒度的权限集，并将它们分配给用户、组和服务帐户(主体)。这样，作为集群管理员，您可以控制集群用户(内部和外部)如何与应用编程接口服务器交互，他们可以访问哪些应用编程接口资源，以及他们可以执行哪些操作(动词)。

Authentication in Kubernetes is highly configurable and extensible; you can read more in the official documentation, at [https://kubernetes.io/docs/reference/access-authn-authz/authentication/](https://kubernetes.io/docs/reference/access-authn-authz/authentication/). In AKS Engine clusters, it is possible to easily integrate with **Azure Active Directory** (**AAD**); you can find more details at [https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)[.](https://github.com/Azure/aks-engine/blob/master/docs/topics/aad.md)

使用 RBAC 涉及两组应用编程接口资源:

*   `Role`和`ClusterRole`:它们定义了一组权限。`Role`中的每一条规则都规定了哪些应用编程接口资源允许哪些动词。`Role`和`ClusterRole`唯一的区别是`Role`是命名空间范围的，而`ClusterRole`不是。
*   `RoleBinding`和`ClusterRoleBinding`:它们将用户或一组用户与给定的角色相关联。类似地，`RoleBinding`是命名空间范围的，`ClusterRoleBinding`是集群范围的。`ClusterRoleBinding`配合`ClusterRole`，`RoleBinding`配合`ClusterRole`或`Role`使用。

Kubernetes 使用了一个宽容的 RBAC 模型——没有否认规则；默认情况下，一切都被拒绝，您必须定义允许规则。使用 RBAC 是有据可查的，所有的功能都在官方文档中有介绍，可在[https://kubernetes . io/docs/reference/access-authn-authz/RBAC/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)上获得。对于您的 RBAC 战略，您应该考虑两个关键点:

*   使用最小特权原则。您的应用程序应该只能访问自己的资源(建议您使用专用服务帐户运行每个应用程序，该帐户可以访问该应用程序的机密或配置映射)。根据用户在项目中的角色，他们应该有受限的访问权限(例如，质量保证工程师可能对集群只有只读访问权限)。
*   将`RoleBinding`分配给组，而不是单个用户。这将使您的权限管理更加容易。请注意，这需要与外部身份验证提供程序集成才能发挥最佳功能。

让我们演示如何使用投票应用程序的`Role`和`RoleBinding`将对部署的访问限制在所需的最少一组配置映射和机密。我们将在 ASP.NET MVC 应用程序中这样做，在 SQL Server 中使用类似的方法可能是一个额外的练习。为此，我们将使用投票应用程序 Docker 图像，`packtpubkubernetesonwindows/voting-application:1.3.0`，我们用它来演示配置地图。此部署在运行时需要配置映射和机密。请按照以下步骤配置 RBAC:

1.  为专用服务帐户创建`serviceaccount.yaml`清单文件，命名为`voting-application`:

```
apiVersion: v1
kind: ServiceAccount
metadata:
  name: voting-application
  namespace: dev
```

2.  使用`kubectl apply -f .\serviceaccount.yaml`命令应用清单文件。
3.  为`Role`创建`role.yaml`清单文件，用于读取应用程序的机密和配置映射:

```
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: dev
  name: voting-application-data-reader
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  resourceNames: ["voting-application-customerrors-config"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["secret"]
  resourceNames: ["mssql"]
  verbs: ["get"]
```

4.  使用`kubectl auth reconcile -f .\role.yaml`命令应用`Role`。推荐使用`kubectl auth reconcile`而不是`kubectl apply`。

5.  为`RoleBinding`创建`rolebinding.yaml`清单文件，该文件将我们的服务帐户与前面的角色相关联:

```
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  namespace: dev
  name: voting-application-data-reader
subjects:
- kind: ServiceAccount
  name: voting-application
roleRef:
  kind: Role
  name: voting-application-data-reader
  apiGroup: rbac.authorization.k8s.io
```

6.  使用`kubectl auth reconcile -f .\rolebinding.yaml`命令应用`RoleBinding`。
7.  检查 RBAC 是否允许访问服务帐户的配置映射。您可以使用`kubectl auth can-i get configmap/voting-application-customerrors-config -n dev --as system:serviceaccount:dev:voting-application`命令或使用`kubectl auth can-i --list -n dev --as system:serviceaccount:dev:voting-application`命令可视化所有可访问的应用编程接口资源。
8.  修改`voting-application.yaml`清单文件，以便部署使用`voting-application`服务帐户:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev
  name: voting-application-frontend
  ...
spec:
  ...
  template:
    ...
    spec:
      serviceAccountName: voting-application
      ...
```

9.  使用`kubectl apply -f .\voting-application.yaml`命令应用部署清单文件。

您可以为集群中的用户执行类似的操作，例如，通过定义允许对所有应用编程接口资源进行只读访问的角色。

恭喜你！您已经为投票申请成功设置了 RBAC。

# 摘要

在本章中，我们展示了 Kubernetes 的几个常用的高级特性。首先，您了解了 Kubernetes 中名称空间的用途以及如何管理它们。然后，我们介绍了就绪性、活性和启动探测器，它们用于监控 Pod 容器的生命周期，并且我们为您提供了一组使用探测器时的推荐做法以及如何避免常见陷阱。下一步是学习如何指定 Pod 资源请求和限制，以及如何使用 HPA 将其与自动缩放相结合。为了将配置数据(包括敏感密码)注入我们的应用程序，我们使用了配置映射和机密。除此之外，我们还演示了如何在运行于 Windows 节点上的状态集中使用 PersistentVolumes(由 azureDisk Volume 插件支持)。最后，您学习了如何处理部署对象的滚动更新，以及 RBAC 在 Kubernetes 的目的是什么。

下一章将重点介绍使用 Kubernetes 的开发工作流，以及在创建 Kubernetes 应用程序时如何与其他开发人员合作。

# 问题

1.  什么时候应该考虑使用 Kubernetes 命名空间？
2.  就绪和活跃探测器之间有什么区别？
3.  使用配置不当的活性探针有什么风险？
4.  Pod 容器的资源`requests`和`limits`值有什么区别？
5.  HPA 冷却延迟的目的是什么？
6.  配置映射和机密有什么区别？
7.  StatefulSet 规范中的`volumeClaimTemplates`是什么？
8.  在部署中使用滚动更新时，为什么要确保就绪探测器的正确配置？
9.  在 Kubernetes 中使用 RBAC 时，最重要的经验法则是什么？

你可以在本书的 *评估*中找到这些问题的答案。

# 进一步阅读

*   有关 Kubernetes 功能和如何管理应用程序的更多信息，请参考以下 Packt 书籍:
    *   *Jonathan Baier，Gigi Sayfan 等人的《完整的 Kubernetes 指南》*(https://www . packtpub . com/virtual-and-cloud/Complete-Kubernetes-Guide)。
    *   *Kubernetes 入门-第三版*作者:杰西·怀特 Jonathan Baier([https://www . packtpub . com/虚拟化与云/入门-Kubernetes-第三版](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition))。
    *   *开发人员的 Kubernetes*作者:Joseph Heck([https://www . packtpub . com/virtual-and-cloud/Kubernetes-Developers](https://www.packtpub.com/virtualization-and-cloud/kubernetes-developers))。