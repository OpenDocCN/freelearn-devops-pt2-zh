- en: Log Monitoring and Serverless Automated Defense (Elastic Stack in AWS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Log monitoring is the perfect place to think about security automation. For
    monitoring to be effective, a few things need to happen. We should be able to
    move logs from different devices to a central location. We should be able to make
    sense of what a regular log entry is and what could possibly be an attack. We
    should be able to store the logs, and also operate on them for things such as
    aggregation, normalization, and eventually, analysis.
  prefs: []
  type: TYPE_NORMAL
- en: But, before diving into setting up the stack and building centralized logging
    and monitoring using Elastic Stack, we need to understand a little bit about why
    we need to use and automate the setup for defending against near real-time attacks.
    It's difficult to be a jack-of-all-trades. Traditional logging systems find it
    difficult to log for all applications, systems, and devices. The variety of time
    formats, log output formats, and so on, makes the task pretty complicated.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest roadblock is finding a way to be able to centralize logs. This gets
    in the way of being able to process log entries in real time, or near real time
    effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the problematic points are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Access is often difficult
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High expertise in mined data is required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs can be difficult to find
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log data is immense in size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Elastic Stack for log monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Beats on the server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up and configuring alerts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up an AWS Lambda endpoint to do automated defense
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Elastic Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Elastic Stack is a group of open source products from the Elastic company.
    It takes data from any type of source and in any format and searches, analyzes,
    and visualizes that data in real time. It consists of four major components, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logstash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kibana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/07737655-ba15-4f81-8526-9cf1d3c9aa88.png)'
  prefs: []
  type: TYPE_IMG
- en: Elastic Stack architecture overview (image taken from https://www.elastic.co/blog/beats-1-0-0)
  prefs: []
  type: TYPE_NORMAL
- en: It helps users/admins to collect, analyze, and visualize data in (near) real
    time. Each module fits based on your use case and environment.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elasticsearch is a distributed, RESTful search and analytics engine capable
    of solving a growing number of use cases. As the heart of the Elastic Stack, it
    centrally stores your data so you can discover the expected and uncover the unexpected
  prefs: []
  type: TYPE_NORMAL
- en: 'Main plus points of Elastic Stack:'
  prefs: []
  type: TYPE_NORMAL
- en: Distributed and highly available search engine, written in Java, and uses Groovy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built on top of Lucene
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-tenant, with multi types and a set of APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document-oriented, providing (near) real-time search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logstash
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logstash is an open source, server-side data processing pipeline that ingests
    data from a multitude of sources, simultaneously transforms it, and then sends
    it to your favorite *stash.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to highlight Logstash is:'
  prefs: []
  type: TYPE_NORMAL
- en: A tool for managing events and logs written in Ruby
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralized data processing of all types of logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consists of the following three main components:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input**: Passing logs to process them into machine-understandable format'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filter**: A set of conditions to perform a specific action on an event'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: The decision maker for processed events/logs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kibana lets you visualize your Elasticsearch data and navigate the Elastic Stack,
    so you can do anything from learning why you're getting paged at 2:00 a.m. to
    understanding the impact rain might have on your quarterly numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kibana''s list of features:'
  prefs: []
  type: TYPE_NORMAL
- en: Powerful frontend dashboard is written in JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Browser-based analytics and search dashboard for Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A flexible analytics and visualization platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides data in the form of charts, graphs, counts, maps, and so on, in real
    time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beats is the platform for single-purpose data shippers. They install as lightweight
    agents and send data from hundreds or thousands of machines to Logstash or Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Beats are:'
  prefs: []
  type: TYPE_NORMAL
- en: Lightweight shippers for Elasticsearch and Logstash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capture all sorts of operational data, like logs or network packet data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They can send logs to either Elasticsearch or Logstash
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The different types of Beats are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Libbeat**: The Go framework for creating new Beats'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Packetbeat**: Taps into your wire data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filebeat**: Lightweight log forwarder to Logstash and Elasticsearch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Winlogbeat**: Sends windows event logs, and many other Beats, by community'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why should we use Elastic Stack for security monitoring and alerting?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Elastic Stack solves most of the problems that we have discussed before,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Ability to store large amounts of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to understand and read a variety of log formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to ship the log information from a variety of devices in near real time
    to one central location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A visualization dashboard for log analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites for setting up Elastic Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start with the prerequisites. Here, we are using `debconf` to add values
    for interactive inputs. Then we are installing Java, nginx, and other required
    packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Setting up the Elastic Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The stack is a combination of:'
  prefs: []
  type: TYPE_NORMAL
- en: The Elasticsearch service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Logstash service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kibana service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Beats service on all the devices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This Elastic Stack can be set up in different ways. In this chapter, we are
    going to set up Elasticsearch, Logstash, and Kibana on a single machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the main log collection machine:'
  prefs: []
  type: TYPE_NORMAL
- en: It requires a minimum of 4 GB RAM, as we are using a single machine to serve
    three services (Elasticsearch, Logstash, and Kibana)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It requires a minimum of 20 GB disk space, and, based on your log size, you
    can add the disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logstash integrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logstash has a very large amount of integration support for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input**: An input plugin enables a specific source of events to be read by
    Logstash. The input plugin has file, lumberjack, s3, Beats, stdin, and many more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filter**: A filter plugin performs intermediary processing on an event. Filters
    are often applied conditionally, depending on the characteristics of the event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: An output plugin sends event data to a particular destination.
    Outputs are the final stage in the event pipeline. The output plugin has Elasticsearch,
    email, stdout, s3, file, HTTP, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kibana has different kinds of plugins and integrations by default, as well as
    those from the community, which can be found at [https://www.elastic.co/guide/en/kibana/current/known-plugins.html](https://www.elastic.co/guide/en/kibana/current/known-plugins.html).
  prefs: []
  type: TYPE_NORMAL
- en: ElastAlert
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ElastAlert is a Python tool which also bundles with the different types of integrations
    to support with alerting and notifications. Some of them include Command, Email,
    JIRA, OpsGenie, AWS SNS, HipChat, Slack, Telegram, and so on. It also provides
    a modular approach to creating our own integrations.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Install Elasticsearch from the repository with `gpg key` and add it to the
    startup programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Configure the Elasticsearch cluster with the required settings. Also, set up
    the JVM options for the Elasticsearch cluster. Also, create a backup directory
    for Elasticsearch cluster backups and snapshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The notify part will trigger the `restart elasticsearch` handler and the handler
    file will look as follows. We can use handlers anywhere in tasks once we create
    them in the handlers directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Installing Logstash
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Install Logstash from the repository with `gpg key` and add it to the startup
    programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Configure the Logstash service with input, output, and filter settings. This
    enables receiving logs, processing logs, and sending logs to the Elasticsearch
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Logstash configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To receive logs from different systems, we use the Beats service from Elastic.
    The following configuration is to receive logs from different servers to the Logstash
    server. Logstash runs on port `5044` and we can use SSL certificates to ensure
    logs are transferred via an encrypted channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following configuration is to parse the system SSH service logs (`auth.log`)
    using `grok` filters. It also applies filters like `geoip`, while providing additional
    information like country, location, longitude, latitude, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following configuration is to parse web server logs (`nginx`, `apache2`).
    We will also apply filters for `geoip` and `useragent`. The `useragent` filter
    allows us to get information about the agent, OS type, version information, and
    so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following configuration will send the log output into the Elasticsearch
    cluster with daily index formats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Installing Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following playbook will install Kibana. By default we are not making any
    changes in Kibana, as it works out of the box with Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By default Kibana doesn't have any authentication, X-Pack is the commercial
    plug-in by Elastic for RBAC (role-based access control) with security. Also, some
    open source options include [https://readonlyrest.com/](https://readonlyrest.com/)
    and Search Guard ([https://floragunn.com](https://floragunn.com)) to interact
    with Elasticsearch. Using TLS/SSL and custom authentication and aauthorization
    is highly recommended. Some of the open source options includes Oauth2 Proxy ([https://github.com/bitly/oauth2_proxy](https://github.com/bitly/oauth2_proxy))
    and Auth0, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up nginx reverse proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following configuration is to enable basic authentication for Kibana using
    `nginx` reverse proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Setting up and configuring the nginx service looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Installing Beats to send logs to Elastic Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we discussed, Beats are different types. In the following playbook, we are
    going to install Filebeat to send SSH and web server logs to the Elastic Stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can configure the Filebeat to send both SSH and web server logs to Elastic
    Stack, to process and index in near real-time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: ElastAlert for alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we need to install the prerequisites for setting up ElastAlert. Then
    we will add the configuration files to perform alerting based on the rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We are also creating a simple startup script so that ElastAlert will be used
    as a system service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Configuring the Let's Encrypt service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use a command-line tool offered by Let's Encrypt to get free SSL/TLS
    certificates in an open, automated manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tool is capable of reading and understanding an nginx virtual host file
    and generating the relevant certificates completely automatically, without any
    kind of manual intervention:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ElastAlert rule configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Assuming that you already have Elastic Stack installed and logging SSH logs,
    use the following ElastAlert rule to trigger SSH attack IP blacklisting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example rule, most of the parameters are configurable, based
    on use case.
  prefs: []
  type: TYPE_NORMAL
- en: For more references, visit [https://elastalert.readthedocs.io/en/latest/running_elastalert.html](https://elastalert.readthedocs.io/en/latest/running_elastalert.html).
  prefs: []
  type: TYPE_NORMAL
- en: Kibana dashboards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can import existing dashboard files (JSON format) into Kibana to view different
    patterns by uploading the JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e6a3bd97-e0b8-489c-8923-7cb7604497e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Index creation in Kibana dashboard
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9600d4f-2e98-4357-81ca-44952ffbbbe7.png)'
  prefs: []
  type: TYPE_IMG
- en: Importing existing dashboards and visualizations into Kibana dashboard
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ff55bec-6f91-41a5-8cec-700f4de02ab9.png)'
  prefs: []
  type: TYPE_IMG
- en: Attack dashboards from SSH and web server logs
  prefs: []
  type: TYPE_NORMAL
- en: Automated defense?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we can get a notification for an attack, we can set up and do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Call an AWS Lambda function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send the attacker's IP address information to this AWS Lambda function endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the code deployed in the Lambda function to call the VPC network access
    list API and block the attacker's IP address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure that we don't fill up the ACLs with attacker IPs, we can combine this
    approach with AWS DynamoDB to store this information for a short duration and
    remove it from the block list.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3bc96a8d-e7d8-4319-bda8-232f46135565.png)'
  prefs: []
  type: TYPE_IMG
- en: AWS services used in setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As soon as an attack is detected, the alerter sends the IP to the blacklist
    lambda endpoint via an HTTPS request. The IP is blocked using the network ACL
    and the record of it is maintained in DynamoDB. If the IP is currently blocked
    already, then the expiry time for the rule will be extended in the DynamoDB.
  prefs: []
  type: TYPE_NORMAL
- en: An expiry handler function is periodically triggered, which removes expired
    rules from DynamoDB and ACL accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DynamoDB is the central database where rules are mapped to their respective
    ACL IDs. Rules for IP addresses are added and removed from the `blacklist_ip`
    table by appropriate lambda functions.
  prefs: []
  type: TYPE_NORMAL
- en: Blacklist lambda function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Blacklist function is the only exposed endpoint from the setup. Any IP that
    needs to be blacklisted needs to be supplied to this function via an HTTPS request.
  prefs: []
  type: TYPE_NORMAL
- en: HandleExpiry lambda function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HandleExpiry function is triggered every minute and removes expired rules
    from the ACL and DynamoDB based on the `expirymin` field.
  prefs: []
  type: TYPE_NORMAL
- en: Cloudwatch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloudwatch is used to trigger the HandleExpiry lambda function periodically.
    By default, the function is triggered every minute.
  prefs: []
  type: TYPE_NORMAL
- en: VPC Network ACL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The VPC Network ACL is where the ACL rules are added and deleted from. The ACL
    ID must be configured during the time of setup.
  prefs: []
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The setup involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain IAM credentials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a table in DynamoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure the lambda function based on requirement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy code to AWS Lambda
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure Cloudwatch to periodic invocation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire setup is automated, except for obtaining the IAM credentials and
    configuring the function based on requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following parameters are configurable before deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '`region`: AWS region to deploy in. This needs to be the same as the region
    where the VPC network resides.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`accessToken`: The accessToken that will be used to authenticate the requests
    to the blacklist endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aclLimit`: The maximum number of rules an ACL can handle. The maximum limit
    in AWS is 20 by default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ruleStartId`: The starting ID for rules in the ACL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aclID`: The ACL ID of the network where the rules will be applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tableName`: The unique table name in DynamoDB, created for each VPC to be
    defended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ruleValidity`: The duration for which a rule is valid, after which the IP
    will be unblocked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Configure the following in the `config.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure to modify at least the `aclId`, `accessToken`, and `region` based
    on your setup. To modify the lambda deployment configuration use the `serverless.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: For example, the rate at which the expiry function is triggered and the endpoint
    URL for the blacklist function can be modified using the YML file. But the defaults
    are already optimal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The playbook looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The current setup for AWS Lambda is to block the IP address against network
    ACL. This can be reused with other API endpoints, like a firewall dynamic block
    list and other security devices.
  prefs: []
  type: TYPE_NORMAL
- en: As per the AWS documentation, the VPC network ACL rule limit is set to 20: [http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-nacls](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-nacls)
  prefs: []
  type: TYPE_NORMAL
- en: Usage - block an IP address
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The blacklist endpoint is responsible for blocking an IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Request
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The URL looks like the following: `https://lambda_url/blacklistipaccessToken=ACCESS_TOKEN&ip=IP_ADDRESS`
  prefs: []
  type: TYPE_NORMAL
- en: 'The query parameters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`IP_ADDRESS`: This is the IP address to be blocked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ACCESS_TOKEN`: The `accessToken` to authenticate the request'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Response
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Responses are standard HTTP status codes, which are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Status code** | **Body** | **Explanation** |'
  prefs: []
  type: TYPE_TB
- en: '| `200` | Blocked | The IP has been added to the blacklist |'
  prefs: []
  type: TYPE_TB
- en: '| `200` | Expiryextended | The blacklist rule validity has been extended |'
  prefs: []
  type: TYPE_TB
- en: '| `400` | Bad Request | Required fields are missing |'
  prefs: []
  type: TYPE_TB
- en: '| `401` | Unauthorized | The accessToken is invalid or missing |'
  prefs: []
  type: TYPE_TB
- en: '| `500` | Rulelimitreached | The ACL rule limit has been reached |'
  prefs: []
  type: TYPE_TB
- en: Automated defense lambda in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the ElastAlert detects an SSH brute force attack, it will trigger a request
    to lambda endpoint by providing the attacker's IP address. Then our automated
    defense platform will trigger a network ACL blocklist rule. This can be configurable
    to say for how much time it should be blocked.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf231e4a-6b2a-44db-8f58-c18ca8739187.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That is a lot of information to take in. Also, we have made many assumptions
    about the scenario. But if this spurs you into thinking about combining the various
    logs of your devices and servers into one central location and enabling automated
    alerting and defenses, we have done our job well.
  prefs: []
  type: TYPE_NORMAL
- en: As this chapter demonstrates, security automation is a bit like plumbing. As
    long as we can understand how a bunch of disparate systems can be made to communicate
    together, we can add them to our playbooks. In many cases, Ansible will already
    have a module in place for us to use and get going.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have whet your appetite for logging and attack detection, in the
    next chapter, let's dive into what it takes to set up an automated web security
    testing setup. We will pick the incredibly powerful and versatile OWASP ZAP scanner
    and intercepting proxy and use it to scan and test websites and APIs.
  prefs: []
  type: TYPE_NORMAL
