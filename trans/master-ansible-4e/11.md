# 十一、通过滚动部署最大限度地减少停机时间

Ansible 非常适合在实时服务环境中升级或部署应用的任务。当然，应用部署和升级可以通过各种不同的策略来实现。最佳方法取决于应用本身、应用运行的基础架构的功能，以及与应用用户达成的任何承诺的服务级别协议(T2 服务级别协议)。无论采用哪种方法，应用部署或升级都必须是可控的、可预测的和可重复的，以确保用户在后台进行自动化部署时能够体验到稳定的服务。任何人最不想看到的是自动化工具的意外行为导致的停机；自动化工具应该是可信的，而不是额外的风险因素。

尽管有无数的选择，但有些部署策略比其他策略更常见，在本章中，我们将介绍几个更常见的策略。这样，我们将展示在这些策略中有用的 Ansible 特性。我们还将讨论两种部署策略中常见的一些其他部署注意事项。为此，我们将在滚动 Ansible 部署的背景下深入研究以下主题的细节:

*   就地升级
*   扩张和收缩
*   快速下降
*   最大限度减少中断
*   序列化单个任务

# 技术要求

按照本章中给出的示例，您将需要一台运行 **Ansible 4.3** 或更新版本的 Linux 机器。几乎任何风格的 Linux 都可以——对于那些对细节感兴趣的人来说，本章中给出的所有代码都在 **Ubuntu Server 20.04 长期支持(LTS)** 上进行了测试，除非另有说明，并且在 Ansible 4.3 上进行了测试。本章附带的示例代码可从 GitHub 下载，网址为[https://GitHub . com/PacktPublishing/Mastering-Ansible-第四版/tree/main/Chapter11](https://github.com/PacktPublishing/Mastering-Ansible-Fourth-Edition/tree/main/Chapter11) 。

查看以下视频，查看正在运行的代码:[https://bit.ly/3lZ6Y9W](https://bit.ly/3lZ6Y9W)T2

# 就地升级

我们将介绍的第一种部署类型是就地升级。这种部署方式在已经存在的基础设施上运行，以便升级现有的应用。这种模式是一种传统模式，在创建新的基础设施需要花费大量时间和金钱时使用。

在这种类型的升级过程中，最大限度地减少停机时间的一般设计模式是在负载平衡器后面跨多个主机部署应用。负载平衡器将充当应用用户和运行应用的服务器之间的网关。对应用的请求将到达负载平衡器，并且根据配置，负载平衡器将决定将请求定向到哪个后端服务器。

要对使用此模式部署的应用执行滚动就地升级，每个服务器(或服务器的一小部分)将在负载平衡器处被禁用、升级，然后重新启用以接受新的请求。将对池中的其余服务器重复此过程，直到所有服务器都升级完毕。由于只有一部分可用的应用服务器脱机进行升级，应用作为一个整体仍可用于请求。当然，这假设应用可以在混合版本同时运行的情况下运行良好。

让我们构建一个剧本来升级一个虚构的应用。我们虚构的应用将在服务器`foo-app01`到`foo-app08`上运行，这些服务器存在于`foo-app`组中。这些服务器将有一个简单的网站，通过`nginx`网络服务器提供服务，内容来自`foo-app` Git 存储库，由`foo-app.repo`变量定义。运行`haproxy`软件的负载均衡服务器`foo-lb`将位于这些应用服务器的前面。

为了在我们的`foo-app`服务器的子集上运行，我们需要采用`serial`模式。该模式改变了 Ansible 执行播放的方式。默认情况下，Ansible 将按照任务列出的顺序在每台主机上执行播放任务。Ansible 在进行下一个任务之前，会在每台主机上执行该剧的每个任务。如果我们使用默认方法，我们的第一个任务将从负载平衡器中删除每台服务器，这将导致我们的应用完全中断。相反，`serial`模式允许我们操作一个子集，以便应用作为一个整体保持可用，即使一些成员离线。在我们的示例中，我们将使用`2`的连续计数来保持大多数应用成员在线:

```
--- 
- name: Upgrade foo-app in place 
  hosts: foo-app 
  serial: 2 
```

重要说明

Ansible 2.2 引入了串行批处理的概念:一个数字列表，可以增加每次通过游戏串行寻址的主机数量。这使得被寻址的主机的大小随着置信度的增加而增加。在向`serial`关键字提供一批编号的情况下，最后提供的编号将是任何剩余批次的大小，直到清单中的所有主机都已完成。

现在，我们可以开始创建我们的任务。第一个任务是从负载平衡器中禁用主机。负载平衡器运行在`foo-lb`主机上；然而，我们在`foo-app`主机上运行。因此，我们需要使用`delegate_to`任务操作符来委派任务。该操作符重定向 Ansible 将连接到的位置，以便执行任务，但它保留了原始主机的所有变量上下文。我们将使用`community.general.haproxy`模块禁用`foo-app`后端池中的当前主机。下面的代码片段演示了该代码:

```
  tasks: 
  - name: disable member in balancer 
    community.general.haproxy: 
      backend: foo-app 
      host: "{{ inventory_hostname }}" 
      state: disabled 
    delegate_to: foo-lb 
```

主机禁用后，我们现在可以更新`foo-app`内容。我们将使用`ansible.builtin.git`模块更新所需版本的内容路径，将定义为`foo-version`。如果内容更新导致更改，我们将为该任务添加一个`notify`处理程序来重新加载`nginx`服务器。这种重启每次都可以完成，但我们也将此作为`notify`的示例用法。您可以查看以下代码片段:

```
  - name: pull stable foo-app 
    ansible.builtin.git: 
      repo: "{{ foo-app.repo }}" 
      dest: /srv/foo-app/ 
      version: "{{ foo-version }}" 
    notify: 
      - reload nginx 
```

我们的下一步是在负载平衡器中重新启用主机；然而，如果我们接下来执行这个任务，我们会将旧版本放回原位，因为我们的通知处理程序还没有运行。因此，我们需要通过`meta: flush_handlers`调用提前触发我们的处理程序，您在 [*第 10 章*](10.html#_idTextAnchor183)*扩展 Ansible* 中了解到了这一点。您可以在这里再次看到这一点:

```
  - meta: flush_handlers 
```

现在，我们可以在负载平衡器中重新启用主机。我们可以立即启用它，并依靠负载平衡器等到主机运行正常后再向它发送请求。但是，因为我们运行的可用主机数量减少，所以我们需要确保所有剩余的主机都是健康的。我们可以利用`ansible.builtin.wait_for`任务来等待`nginx`服务再次服务连接。`ansible.builtin.wait_for`模块将等待端口或文件路径上的条件。在下面的例子中，我们将等待端口`80`和端口应该在的条件。如果它已启动(默认)，这意味着它正在接受连接:

```
  - name: ensure healthy service 
    ansible.builtin.wait_for: 
      port: 80 
```

最后，我们可以在`haproxy`内重新启用该成员。我们再次将任务委托给`foo-lb`，如下面的代码片段所示:

```
  - name: enable member in balancer 
    community.general.haproxy: 
      backend: foo-app 
      host: "{{ inventory_hostname }}" 
      state: enabled 
    delegate_to: foo-lb 
```

当然，我们仍然需要定义我们的`reload nginx`处理程序。我们可以通过运行以下代码来做到这一点:

```
  handlers: 
  - name: reload nginx 
    ansible.builtin.service: 
      name: nginx 
      state: restarted 
```

该行动手册运行后，现在将对我们的应用执行滚动就地升级。当然，就地运行升级并不总是可取的——这总是有可能影响服务，尤其是当服务承受意外负载时。下一节将探讨防止这种情况的另一种策略，即扩张和收缩。

# 扩张和收缩

原地升级战略的另一种选择是扩展和收缩 T2 战略。由于云计算或虚拟化池等按需基础架构的自助服务性质，这种策略最近变得流行起来。从大量可用资源中按需创建新服务器的能力意味着应用的每次部署都可以在全新的系统上进行。这种策略避免了一系列问题，例如在长时间运行的系统上积累 cruft，例如:

*   不再由 Ansible 管理的配置文件被留下了
*   后台消耗资源的失控进程
*   在不更新 Ansible 行动手册的情况下，由人工对服务器进行的更改

每次重新启动也消除了初始部署和升级之间的差异。可以使用相同的代码路径，从而降低升级应用时出现意外的风险。如果新版本的性能不如预期，这种类型的安装也可以使回滚变得非常容易。除此之外，由于创建了新系统来替换旧系统，应用在升级过程中不需要进入降级状态。

让我们用扩展和收缩战略重新审视我们之前的升级行动手册。我们的模式将是创建新的服务器，部署我们的应用，验证我们的应用，向负载平衡器添加新的服务器，并从负载平衡器中删除旧的服务器。让我们从创建新服务器开始。在这个例子中，我们将利用 OpenStack 计算云来启动新的实例:

```
--- 
- name: Create new foo servers 
  hosts: localhost 

  tasks: 
  - name: launch instances
    openstack.cloud.os_server:
      name: foo-appv{{ version }}-{{ item }}
      image: foo-appv{{ version }}
      flavor: 4
      key_name: ansible-prod
      security_groups: foo-app
      auto_floating_ip: false
      state: present
      auth:
        auth_url: https://me.openstack.blueboxgrid.com:5001/v2.0
        username: jlk
        password: FAKEPASSW0RD
        project_name: mastery
    register: launch
    loop: "{{ range(1, 8 + 1, 1)|list }}"
```

在这个任务中，我们使用 Ansible 2.5 中引入的带有`range`语法的新`loop`循环遍历`8`的计数。对于循环的每次迭代，`item`变量将被一个数字代替。这允许我们根据应用的版本和循环的数量创建八个新的服务器实例。我们还假设我们有一个预构建的映像，这样我们就不需要在实例上做任何进一步的配置。为了在未来的游戏中使用这些服务器，我们需要将它们的详细信息添加到清单中。为了实现这一点，我们在`launch`变量中注册运行结果，我们将使用它来创建运行时清单条目。下面的代码片段演示了该代码:

```
  - name: add hosts 
    ansible.builtin.add_host: 
      name: "{{ item.openstack.name }}" 
      ansible_ssh_host: "{{ item.openstack.private_v4 }}" 
      groups: new-foo-app 
    loop: launch.results 
```

此任务将创建与我们的服务器实例同名的新库存项目。为了帮助 Ansible 知道如何连接，我们将把`ansible_ssh_host`设置为我们的云供应商分配给实例的**互联网协议** ( **IP** )地址(这是假设运行 Ansible 的主机可以到达该地址)。最后，我们将主机添加到`new-foo-app`组。由于我们的`launch`变量来自一个带有循环的任务，我们需要通过访问`results`键来迭代该循环的结果。这允许我们循环每个启动操作来访问特定于该任务的数据。

接下来，我们将在服务器上运行，以确保新服务可以使用。我们将再次使用`ansible.builtin.wait_for`，就像我们之前做的那样，作为在我们的`new-foo-app`组上运行的新剧的一部分。下面的代码片段演示了该代码:

```
- name: Ensure new app 
  hosts: new-foo-app 
  tasks: 
    - name: ensure healthy service 
      ansible.builtin.wait_for: 
        port: 80 
```

一旦它们都准备好了，我们就可以重新配置负载平衡器来使用我们的新服务器。为了简单起见，我们将假设`haproxy`配置的模板期望`new-foo-app`组中的主机，最终结果将是一个知道所有新主机而忘记旧主机的配置。这意味着我们可以简单地在负载平衡器系统本身上调用一个`ansible.builtin.template`任务，而不是试图操纵平衡器的运行状态。下面的代码片段演示了该代码:

```
- name: Configure load balancer 
  hosts: foo-lb 
  tasks:
  - name: haproxy config
    ansible.builtin.template:
      dest: /etc/haproxy/haproxy.cfg
      src: templates/etc/haproxy/haproxy.cfg
  - name: reload haproxy
    ansible.builtin.service:
      name: haproxy
      state: reloaded
```

一旦新的配置文件到位，我们就可以重新加载`haproxy`服务了。这将解析新的配置文件，并为新的传入连接启动新的侦听过程。现有的连接将最终关闭，旧的进程将终止。所有新连接将被路由到运行我们新应用版本的新服务器。

本行动手册可以扩展到使旧版本的服务器退役，或者当决定不再需要回滚到旧版本功能时，该操作可能会在不同的时间发生。

扩展和收缩策略可能涉及更多的任务，甚至是创建黄金映像集的单独行动手册，但是每个版本的新基础架构的好处远远超过额外的任务或创建后删除的额外复杂性。

# 快速失败

当执行应用的升级时，可能需要在出现任何错误迹象时完全停止部署。具有混合版本的部分升级系统可能根本不起作用，因此继续使用部分基础架构，而将故障系统留在后面可能会导致大问题。幸运的是，Ansible 提供了一种机制来决定何时到达致命错误场景。

默认情况下，当 Ansible 正在运行播放手册并遇到错误时，它将从播放主机列表中删除故障主机，并继续执行任务或播放。当所有请求的播放主机都失败或所有播放都已完成时，Ansible 将停止执行。要改变这种行为，可以使用几个播放控制。这些控件是`any_errors_fatal`、`max_fail_percentage`和`force_handlers`，接下来将讨论这些控件。

## 任何 _ 错误 _ 致命选项

该设置指示 Ansible 认为整个操作是致命的，如果任何主机遇到错误，立即停止执行。为了演示这一点，我们将编辑我们的`mastery-hosts`清单，定义一个将扩展到 10 个新主机的模式，如下面的代码片段所示:

```
[failtest] 
failer[01:10] 
```

然后，我们将在这个组上创建一个将`any_errors_fatal`设置为`true`的游戏。我们还将关闭事实收集，因为这些主机并不存在。下面的代码片段演示了该代码:

```
--- 
- name: any errors fatal 
  hosts: failtest 
  gather_facts: false 
  any_errors_fatal: true 
```

我们希望一个任务对其中一个主机会失败，但对其他主机不会。然后，我们还需要第二个任务，只是为了演示它将如何不运行。下面是我们需要执行的代码:

```
  tasks: 
  - name: fail last host
    ansible.builtin.fail:
      msg: "I am last"
    when: inventory_hostname == play_hosts[-1]
  - name: never run
    ansible.builtin.debug:
      msg: "I should never be run"
    when: inventory_hostname == play_hosts[-1]
```

我们现在使用以下命令执行剧本:

```
ansible-playbook -i mastery-hosts failtest.yaml
```

当我们这样做的时候，我们会看到一个主机失败，但是第一个任务之后整个游戏就会停止，并且`ansible.builtin.debug`任务永远不会尝试，如下图截图所示:

![Figure 11.1 – Failing an entire playbook early when just one host in the inventory fails ](Images/B17462_11_01.jpg)

图 11.1–当清单中只有一台主机出现故障时，整个行动手册提前失效

我们可以看到，只有一台主机出现故障；然而，Ansible 报道了`NO MORE HOSTS LEFT`(暗示所有主持人都失败了)，并在进入下一部剧之前中止了的剧本。

## 最大失败百分比选项

这个设置允许游戏开发者定义一个百分比的主机，在整个操作中止之前可以失败。在每个任务结束时，Ansible 将执行计算，以确定该剧所针对的达到失败状态的主机数量，如果该数量大于允许的数量，Ansible 将中止该剧。这类似于`any_errors_fatal`；事实上，`any_errors_fatal`只是在内部表达了`0`的一个`max_fail_percentage`参数，任何失败都被认为是致命的。让我们从上一节编辑我们的剧本，删除`any_errors_fatal`，用设置为`20`的`max_fail_percentage`参数替换它，如下所示:

```
--- 
- name: any errors fatal 
  hosts: failtest 
  gather_facts: false 
  max_fail_percentage: 20 
```

通过进行这一更改，并使用与之前相同的命令运行我们的剧本，我们的剧本应该可以完成这两项任务而不会中止，如下图所示:

![Figure 11.2 – Demonstrating our previous failure-test playbook proceeding with fewer than 20 percent failed hosts ](Images/B17462_11_02.jpg)

图 11.2–展示了我们之前的故障测试行动手册，其中故障主机不到 20%

现在，如果我们改变第一个任务的条件，使我们故意在超过`20`%的主机上失败，我们将看到行动手册提前中止:

```
  - name: fail last host
    ansible.builtin.fail:
      msg: "I am last"
    when: inventory_hostname in play_hosts[0:3]
```

我们故意设置三个主机失败，这会给我们一个大于`20`百分比的失败率。`max_fail_percentage`设置是允许的最大值，因此我们的`20`设置将允许十台主机中的两台出现故障。由于三台主机出现故障，在允许执行第二个任务之前，我们将看到一个致命错误，如下图所示:

![Figure 11.3 – Demonstrating the max_fail_percentage operation failing a play when the percentage is exceeded ](Images/B17462_11_03.jpg)

图 11.3–演示当超过百分比时，最大失败百分比操作失败

有了这些参数组合，我们可以轻松地在一组主机上设置和控制**故障快速**条件，如果我们的目标是在Ansible部署期间保持环境的完整性，这是非常有价值的。

## 强制处理程序

通常情况下，当 Ansible 对一台主机失败时，它会停止在该主机上执行任何操作。这意味着任何挂起的处理程序都不会运行。这可能是不可取的，并且有一个播放控件会强制 Ansible 为失败的主机处理挂起的处理程序。该播放控制为`force_handlers`，必须设置为`true`布尔值。

为了演示这个功能，让我们稍微修改一下前面的例子。我们将移除`max_fail_percentage`参数，并添加新的第一个任务。我们需要创建一个任务，该任务将通过更改成功返回。这在使用`changed_when`任务控制的`ansible.builtin.debug`模块中是可能的，因为否则该模块将永远不会记录更改。我们也将把我们的`ansible.builtin.fail`任务条件恢复到原来的任务。下面的代码片段演示了该代码:

```
--- 
- name: any errors fatal 
  hosts: failtest 
  gather_facts: false 
  tasks:
  - name: run first
    ansible.builtin.debug:
      msg: "I am a change"
    changed_when: true
    when: inventory_hostname == play_hosts[-1]
    notify: critical handler
  - name: change a host
    ansible.builtin.fail:
      msg: "I am last"
    when: inventory_hostname == play_hosts[-1] 
```

我们的第三个任务保持不变，但是我们将定义我们的关键处理程序，如下所示:

```
  - name: never run
    ansible.builtin.debug:
      msg: "I should never be run"
    when: inventory_hostname == play_hosts[-1]
  handlers:
    - name: critical handler
      ansible.builtin.debug:
        msg: "I really need to run"
```

让我们运行这个新的游戏来显示没有被执行的处理程序的默认行为。为了减少输出，我们将使用以下命令将执行限制在一个主机上:

```
ansible-playbook -i mastery-hosts failtest.yaml --limit failer01:failer01
```

请注意，虽然处理程序在播放输出中被引用，但它实际上并没有运行，这一点可以从缺少任何调试消息中得到证明，下面的截图清楚地显示了这一点:

![Figure 11.4 – Demonstrating how handlers are not run even when notified if a play fails ](Images/B17462_11_04.jpg)

图 11.4–演示了即使在播放失败的情况下，处理程序也不会运行

现在，我们添加的`force_handlers`玩法控制并将其设置为`true`，如下:

```
---
- name: any errors fatal
  hosts: failtest
  gather_facts: false
  force_handlers: true
```

这一次，当我们运行 playbook(使用与之前相同的命令)时，我们应该看到即使对于失败的主机也运行了处理程序，如下面的截图所示:

![Figure 11.5 – Demonstrating that handlers can be forced to run, even for failed hosts in a failed play ](Images/B17462_11_05.jpg)

图 11.5–演示了可以强制运行处理程序，即使是失败游戏中的失败主机

重要说明

使用`ansible-playbook`上的`--force-handlers`命令行参数，强制处理程序也可以作为的运行时决策。也可以全局设置，作为`ansible.cfg`中的参数。

强制处理程序运行对于重复的剧本运行非常有用。第一次运行可能会导致一些更改，但是如果在刷新处理程序之前遇到致命错误，这些处理程序调用将会丢失。重复运行不会导致相同的更改，因此处理程序在没有手动交互的情况下永远不会运行。强制处理程序可以确保这些处理程序调用不会丢失，因此无论任务结果如何，处理程序总是会运行。当然，任何升级策略的整体目标都是尽可能降低对任何给定服务的影响——你能想象你最喜欢的零售网站会因为有人升级软件而关闭吗？这在这个时代是不可想象的！在下一节中，我们将探索使用 Ansible 来最小化潜在破坏性操作的方法。

# 最大限度地减少中断

在部署期间，通常有一些任务可以被认为是破坏性的。这些任务可能包括重新启动服务、执行数据库迁移等。破坏性任务应该聚集在一起，以最小化对应用的总体影响，而破坏性任务应该只执行一次。接下来的两个小节将探讨如何使用 Ansible 实现这两个目标。

## 延迟中断

为新的配置或代码版本重新启动服务是非常常见的需求。孤立地看，只要应用的代码和配置发生变化，单个服务就可以重新启动，而无需考虑整个分布式系统的运行状况。通常，分布式系统的每个部分都有各自的角色，每个角色基本上都是在目标主机上独立运行的。第一次部署应用时，没有整个系统现有的正常运行时间需要担心，所以服务可以随意重启。但是，在升级过程中，可能需要延迟所有服务的重新启动，直到每个服务都准备好，以最大限度地减少中断。

强烈鼓励重用角色代码，而不是设计一个完全独立的升级代码路径。为了适应协调的重新启动，特定服务的角色代码需要在服务重新启动时得到保护。一种常见的模式是将条件语句放在检查变量值的破坏性任务上。执行升级时，可以在运行时定义变量来触发这种替代行为。一旦完成了所有角色，该变量还可以在主行动手册的末尾触发服务的协调重启，以便将中断集中起来，并将总停机时间降至最低。

让我们创建一个虚构的应用升级，它涉及两个角色和模拟的服务重启。我们将这些角色称为`microA`和`microB`。下面的代码片段演示了该代码:

```
roles/microA 
├── handlers 
│   └── main.yaml 
└── tasks 
    └── main.yaml 
roles/microB 
├── handlers 
│   └── main.yaml 
└── tasks 
    └── main.yaml 
```

对于这两个角色，我们将有一个简单的调试任务来模拟包的安装。我们将通知一个处理程序来模拟服务的重启，为了确保处理程序会触发，我们将强制任务始终注册为已更改。以下代码片段显示了`roles/microA/tasks/main.yaml`的内容:

```
--- 
- name: install microA package 
  ansible.builtin.debug: 
    msg: "This is installing A" 
  changed_when: true 
  notify: restart microA 
```

`roles/microB/tasks/main.yaml`的内容如下所示:

```
---
- name: install microB package
  ansible.builtin.debug:
    msg: "This is installing B"
  changed_when: true
  notify: restart microB
```

这些角色的处理程序也将是调试动作，我们将向处理程序任务附加一个条件语句，以便只有在升级变量评估为`false`布尔值时才重新启动。我们还将使用默认过滤器给这个变量一个默认值`false`。`roles/microA/handlers/main.yaml`的内容如下所示:

```
--- 
- name: restart microA 
  ansible.builtin.debug: 
    msg: "microA is restarting" 
  when: not upgrade | default(false) | bool 
```

`roles/microB/handlers/main.yaml`的内容如下图所示:

```
---
- name: restart microB
  ansible.builtin.debug:
    msg: "microB is restarting"
  when: not upgrade | default(false) | bool
```

对于我们的顶级剧本，我们将创建四个剧本(请记住，一个剧本可以由一个或多个剧本组成)。前两部剧将应用每个微角色，后两部剧将重新开始。只有在执行升级时，才会执行最后两个播放；所以，他们会利用`upgrade`变量作为条件。我们来看看下面的代码片段(叫做`micro.yaml`):

```
---
- name: apply microA
  hosts: localhost
  gather_facts: false
  roles:
  - role: microA
- name: apply microB
  hosts: localhost
  gather_facts: false
  roles:
  - role: microB
- name: restart microA
  hosts: localhost
  gather_facts: false
  tasks:
  - name: restart microA for upgrade
    ansible.builtin.debug:
      msg: "microA is restarting"
    when: upgrade | default(false) | bool
- name: restart microB
  hosts: localhost
  gather_facts: false
  tasks:
  - name: restart microB for upgrade
    ansible.builtin.debug:
      msg: "microB is restarting"
    when: upgrade | default(false) | bool
```

我们使用以下命令在不定义`upgrade`变量的情况下执行本行动手册:

```
ansible-playbook -i mastery-hosts micro.yaml
```

当我们这样做时，我们将看到每个角色的执行，以及其中的处理程序。最后两部剧将跳过任务，如下图所示:

![Figure 11.6 – Demonstrating a role-based playbook for installing a microservice architecture ](Images/B17462_11_06.jpg)

图 11.6–演示安装微服务架构的基于角色的行动手册

现在，让我们再次执行剧本；这一次，我们将在运行时将`upgrade`变量定义为`true`，使用`-e`标志如下:

```
ansible-playbook -i mastery-hosts micro.yaml -e upgrade=true
```

这一次的结果应该是这样的:

![Figure 11.7 – Demonstrating the same playbook, but in an upgrade scenario  with all restarts batched at the end ](Images/B17462_11_07.jpg)

图 11.7–演示了相同的剧本，但在升级场景中，所有重启都是在最后分批进行的

这一次，我们可以看到我们的处理程序被跳过了，但是最后两个剧本有任务要执行。在现实场景中，更多的事情发生在`microA`和`microB`角色(以及其他主机上潜在的其他微服务角色)中，差异可能是几分钟甚至更长。将重启集中在最后可以显著缩短的中断时间。

## 只运行一次破坏性任务

破坏性任务有多种口味。它们可能是极难回滚的单向任务、无法轻松重新运行的一次性任务，或者是如果并行执行会导致灾难性失败的竞争条件任务。出于这些原因以及更多原因，这些任务必须只从一台主机上执行一次。Ansible 提供了一种通过`run_once`任务控制来实现这一点的机制。

`run_once`任务控制将确保任务仅从单个主机执行一次，而不管一次游戏中碰巧有多少台主机。虽然还有其他方法可以实现这个目标，比如使用条件语句让任务只在一部剧的第一个主机上执行，`run_once`控件是表达这个愿望最简单直接的方式。此外，从由`run_once`控制的任务中注册的任何可变数据将对该剧的所有主持人可用，而不仅仅是由 Ansible 选择来执行该动作的主持人。这可以简化变量数据的后续检索。

让我们创建一个示例剧本来演示这一功能。我们将重用在前面的示例中创建的`failtest`主机，以便拥有一个主机池，我们将使用主机模式选择其中的两个。我们将创建一个设置为`run_once`的`ansible.builtin.debug`任务并注册结果，然后我们将在一个不同的主机上访问不同任务的结果。代码如下:

```
--- 
- name: run once test 
  hosts: failtest[0:1] 
  gather_facts: false 

  tasks: 
  - name: do a thing
    ansible.builtin.debug:
      msg: "I am groot"
    register: groot
    run_once: true
  - name: what is groot
    ansible.builtin.debug:
      var: groot
    when: inventory_hostname == play_hosts[-1]
```

我们用以下命令运行这个游戏:

```
ansible-playbook -i mastery-hosts runonce.yaml
```

当我们这样做时，我们将特别注意下面截图中显示的每个任务操作的主机名:

![Figure 11.8 – Demonstrating the use of the run_once task parameter, and the availability of variable data from that task on other hosts in the play ](Images/B17462_11_08.jpg)

图 11.8–演示了 run_once 任务参数的使用，以及该任务的可变数据在游戏中其他主机上的可用性

我们可以看到在`failer01`主机上执行`do a thing`任务，而`what is groot`任务检查`do a thing`任务的数据，在`failer02`主机上运行。当然，虽然您可以使用我们在此讨论的技术来降低生产服务中断的风险，但我们还可以做更多的事情，例如限制任务的运行次数或运行主机的数量。我们将在本章的下一节探讨这个主题。

# 序列化单个任务

某些运行一个服务的多个副本的应用可能无法很好地应对所有这些服务同时重启的情况。通常，当升级这种类型的应用时，会使用`serial`游戏。然而，如果应用的规模足够大，序列化整个剧本可能会非常低效。可以使用不同的方法，即只序列化敏感任务(通常是重启服务的处理程序)。

为了序列化特定的处理程序任务，我们可以使用一个内置变量`play_hosts`。这个变量包含一个主机列表，作为游戏的一部分，该列表应该用于给定的任务。它与发生故障或无法访问的主机保持同步。使用这个变量，我们可以构造一个循环来迭代每个可能运行处理程序任务的主机。我们将在`when`条件和`delegate_to`指令中使用`item`值，而不是在模块参数中使用`item`值。以这种方式，在剧本中得到通知的处理程序任务可以委托给上述循环中的主机，而不是原始主机。然而，如果我们仅仅使用这个作为`loop`指令的列表，我们将结束为每个触发处理程序的主机执行任务。这显然是不需要的，所以我们可以使用任务指令`run_once`来改变行为。`run_once`指令指示 Ansible 只为一台主机执行任务，而不是为它通常瞄准的每台主机。将`run_once`和我们的`play_hosts`循环结合在一起，创建了一个 Ansible 只运行一次循环的场景。最后，我们希望在每个循环之间等待一小段时间，以便重新启动的服务在我们重新启动下一个之前可以正常工作。我们可以使用名为`pause`的`loop_control`参数(在 Ansible 版本中引入)在循环的每次迭代之间插入一个暂停。

为了演示这种序列化是如何工作的，我们将使用我们的`failtest`组中的几个主机编写一个剧本，用一个任务创建一个变更并注册输出，这样我们就可以在我们通知的处理程序任务中检查这个输出，这个任务被称为`restart groot`。然后，我们在剧本的底部创建一个序列化的处理程序任务本身。代码如下所示:

```
--- 
- name: parallel and serial 
  hosts: failtest[0:3] 
  gather_facts: false 

  tasks: 
  - name: do a thing
    ansible.builtin.debug:
      msg: "I am groot"
    changed_when: inventory_hostname in play_hosts[0:2]
    register: groot
    notify: restart groot
  handlers:
  - name: restart groot
    debug:
      msg: "I am groot?"
    loop: "{{ play_hosts }}"
    delegate_to: "{{ item }}"
    run_once: true
    when: hostvars[item]['groot']['changed'] | bool
    loop_control:
      pause: 2
```

在执行本行动手册时，我们可以看到处理程序通知(由于使用以下命令的双重赘述):

```
ansible-playbook -i mastery-hosts forserial.yaml -vv
```

在处理程序任务中，我们可以看到循环、条件和委托，如下图所示:

![Figure 11.9 – A playbook with a serialized handler routing for the restart of services ](Images/B17462_11_09.jpg)

图 11.9–服务重启的序列化处理程序流程图

如果您自己尝试过这段代码，您会注意到每次处理程序运行之间的延迟，就像我们在任务的`loop_control`部分中指定的那样。使用这些技术，您可以放心地向您的环境推出更新和升级，同时将中断降至最低。希望本章已经为您提供了在您的环境中自信地执行此类操作的工具和技术。

# 总结

部署和升级策略是一个品味问题。每种策略都有不同的优点和缺点。Ansible 没有声明哪个更好的意见，因此它非常适合执行部署和升级，而不管策略如何。Ansible 提供了方便各种风格的功能和设计模式。了解每种策略的本质以及 Ansible 如何针对该策略进行调整，将使您能够决定和设计每个应用的部署。任务控件和内置变量提供了在仔细处理特定任务的同时高效升级大规模应用的方法。

在本章中，您学习了如何使用 Ansible 执行就地升级以及一些不同的方法，包括扩展和收缩环境等技术。您学习了快速失败，以确保剧本在早期出错时不会造成大范围的损害，以及如何最大限度地减少破坏性和破坏性行为。最后，您学习了序列化单个任务，通过以最小的受控方式停止节点服务，最大限度地减少对运行服务的中断。这确保了服务保持运行，而维护工作(如升级)在幕后进行。

在下一章中，我们将详细介绍如何使用 Ansible 与云基础设施供应商和容器系统合作，以创建要管理的基础设施。

# 问题

1.  What is a valid strategy for minimizing disruption when in-place upgrades are performed?

    a)使用`serial`模式更改 Ansible 一次在多少台主机上执行升级。

    b)使用`limit`参数改变 Ansible 一次在多少台主机上执行升级。

    c)拥有大量小型库存，每个库存中只有几台主机。

    d)取消 Ansible 对主机的访问权限。

2.  What is a key benefit of expanding and contracting as an upgrade strategy?

    a)降低云操作成本。

    b)它非常符合开发操作文化。

    c)所有主机都是为每个应用部署或升级而新构建的，减少了库和配置过时的可能性。

    d)它为您的升级方法提供了灵活性。

3.  Why would you want to fail fast?

    a)以便您尽快了解您的行动手册错误。

    b)这样你就可以最大限度地减少失败游戏造成的伤害或干扰。

    c)以便您可以调试代码。

    d)以便您可以灵活部署。

4.  Which Ansible play option would you use to ensure that your play stops executing early in the event of errors on any single host?

    a) `ansible.builtin.fail`

    b) `any_errors_fatal`

    c) `when: failed`

    d) `max_fail_percentage: 50`

5.  Which Ansible play option would you use to ensure that your play stops executing early in the event of errors on more than 30 percent of the hosts in your inventory?

    a) `any_errors_fatal`

    b) `max_fail_percentage: 30%`

    c) `max_fail_percentage: 30`

    d) `max_fail: 30%`

6.  Which play-level option can you specify to ensure that your handlers are run even if your play fails?

    a) `handlers_on_fail`

    b) `handlers_on_failure`

    c) `always_handlers`

    d) `force_handlers`

7.  Why might you want to delay the running of handlers to the end of your play?

    a)它可以节省整个剧的执行时间。

    b)它使操作更加可预测。

    c)它降低了停机的风险。

    d)它可能有助于增加您成功升级的机会。

8.  Which task-level parameter can you use to ensure that a task does not get executed more than once, even when you have multiple hosts in your inventory?

    a) `task_once`

    b) `run_once`

    c) `limit: 1`

    d) `run: once`

9.  Which `loop_control` parameter can insert a delay between iterations of a loop in Ansible?

    a) `pause`

    b) `sleep`

    c) `delay`

    d) `wait_for`

10.  Which task conditional could you use to ensure you only run a task on the first four hosts in an inventory?

    a) `when: inventory_hostname in play_hosts[0:3]`

    b) `when: inventory_hostname in play_hosts[1:4]`

    c) `when: inventory_hostname[0:3]`

    d) `when: play_hosts[0:3]`