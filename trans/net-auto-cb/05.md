# 借助 F5 LTM 和 Ansible 实现应用交付自动化

在本章中，我们将概述如何将作为**负载平衡器** ( **LBs** )或**本地流量管理器** ( **LTM** )设备运行的 F5 大 IP 平台自动化。我们将探索如何使用 Ansible 与 F5 LTM 节点进行交互，以及如何搭载这些设备，并使用各种 Ansible 模块加速这些设备托管的应用部署。我们将根据下面的网络图示例进行说明。该图显示了连接到**直流** ( **DC** )开关的单个 F5 LTM 节点:

![](assets/27890347-0c13-4b72-946d-5d198bf422b7.png)

本章涵盖的主要配方如下:

*   建立一个可靠的网络清单
*   连接和验证大知识产权设备
*   在大知识产权设备上配置通用系统选项
*   在大 IP 设备上配置接口和中继
*   在大 IP 设备上配置**虚拟局域网** ( **虚拟局域网**)和**自互联网协议** ( **自 IP**)
*   在大 IP 设备上配置静态路由
*   在大知识产权设备上部署节点
*   在大 IP 设备上配置负载平衡池
*   在大知识产权设备上配置虚拟服务器
*   从大知识产权节点检索运营数据

# 技术要求

本章食谱中使用的所有代码都可以在以下 GitHub 存储库中找到:[https://GitHub . com/PacktPublishing/Network-Automation-cook book/tree/master/ch5 _ F5](https://github.com/PacktPublishing/Network-Automation-Cookbook/tree/master/ch5_f5)。

以下是本章所基于的软件版本:

*   运行 CentOS 7 的可移植机器
*   Ansible 2.9
*   F5 大 IP 设备运行大 IP 13.1.1，构建 0.0.4 最终版

查看以下视频，了解《行动守则》:
[https://bit.ly/2RE5tOL](https://bit.ly/2RE5tOL)

# 建立一个可靠的网络清单

在本食谱中，我们将概述如何构建和组织我们的 Ansible 库存，以描述我们的 F5 BIG-IP 节点示例。建立 Ansible 清单是告诉 Ansible 如何连接到被管理设备的强制性步骤。

# 准备好

我们将创建一个新文件夹，其中将存放我们将在本章中创建的所有文件。新文件夹名为`ch5_f5`。

# 怎么做...

1.  在新文件夹`ch5_f5`中，我们创建了一个`hosts`文件，内容如下:

```
$ cat hosts
[ltm]
ltm01 Ansible_host=172.20.1.34
```

2.  创建一个`Ansible.cfg`文件，如下代码所示:

```
$ cat Ansible.cfg
[defaults]
inventory=hosts
retry_files_enabled=False
gathering=explicit
host_key_checking=False
```

# 它是如何工作的...

由于我们的网络拓扑中只有一个 LTM 节点，这简化了我们的 Ansible 清单文件。在我们的`hosts`文件中，我们创建了一个单独的组(称为`ltm`)，并在其中指定了一个单独的节点，称为`ltm01`。我们使用`Ansible_host`参数为节点指定管理 IP 地址。

BIG-IP 设备上的管理端口必须配置此 IP 地址，并且 Ansible 控制机器和 BIG-IP 节点之间的 IP 连接通过此管理端口建立。

最后，我们创建`Ansible.cfg`文件，并将其配置为指向我们的`hosts`文件，以用作 Ansible 库存文件。我们禁用设置模块，这在对网络节点运行 Ansible 时是不需要的。

# 连接和验证大知识产权设备

在本食谱中，我们将概述如何通过 BIG-IP 设备公开的**表示状态转移** ( **REST** ) API 从 Ansible 连接到 BIG-IP 节点，以便从 Ansible 开始管理设备。我们将使用用户名和密码向拓扑中的大 IP 节点进行身份验证。

# 准备好

为了遵循该配方，应根据之前的配方构建一个可翻译的库存文件。必须在 Ansible 控制机器和网络中的所有设备之间建立 IP 可达性。

# 怎么做...

1.  在`ch5_f5`文件夹内，创建一个`group_vars`文件夹。
2.  使用以下连接参数设置创建新的`group_vars/all.yml`文件:

```
conn_parameters:
 user: admin
 password: admin
 server: "{{ Ansible_host }}"
 server_port: 443
 validate_certs: no
admin_passwd: NewP@sswd
users:
 - name: Ansible
 passwd: Ansible123
 role: all:admin
 state: present
```

3.  创建一个名为`pb_f5_onboard.yml`的新剧本，任务如下创建新的系统用户:

```
- name: Onboarding a New LTM
 hosts: ltm01
 connection: local
 tasks:
 - name: "P1T1: Create new Users"
 bigip_user:
 username_credential: "{{ item.name }}"
 password_credential: "{{ item.passwd }}"
 partition_access: "{{ item.role }}"
 state: "{{ item.state | default('present')}}"
 provider: "{{ conn_parameters }}"
 loop: "{{ users }}"
```

4.  使用以下任务更新`pb_f5_onboard.yml`行动手册，以更新管理员用户帐户:

```
 - name: "P1T1: Update admin Password"
 bigip_user:
 username_credential: admin
 password_credential: "{{ admin_passwd }}"
 state: present
 provider: "{{ conn_parameters }}"
```

# 它是如何工作的...

Ansible 在 F5 LTM 节点上使用 REST 应用编程接口来管理大 IP 节点。Ansible 建立到大 IP 节点的 HTTPS 连接，并将其用作在大 IP 节点上调用 REST API 的传输机制。为了建立与大 IP 系统的 HTTPS 连接，我们需要提供一些参数，以便 Ansible 启动并建立与大 IP 节点的连接。这些参数包括以下内容:

*   使用大知识产权休息应用编程接口进行身份验证的用户名/密码
*   IP 地址和端口，通过它们我们可以到达大 IP 节点上的 REST API 端点
*   我们是否验证通过 HTTPS 会话协商的大 IP 节点的证书

我们将所有这些参数包含在一个名为`conn_parameters`的字典中，该字典包含在`group_vars/all.yml`文件中，以便应用于任何大 IP 节点。

默认情况下，新的 LTM 设备带有**图形用户界面** ( **图形用户界面**)和 REST 应用编程接口访问的`admin/admin`默认用户名和密码。我们将这些凭证用作`conn_parameters`字典中的用户和密码变量，并将`Ansible_host`变量指定为可以通过端口`443`建立 REST 应用编程接口的 IP 地址。最后，我们禁用证书验证，因为 BIG-IP 节点上的证书是自签名的。

我们创建了一个名为`users`的新变量，它保存了我们想要在 LTM 上配置的所有新用户，以及他们的角色/权限。在这种情况下，我们希望在 LTM 节点的所有分区上为 Ansible 用户提供管理权限。

我们为加入新的 LTM 节点创建了新的行动手册。在第一个任务中，我们使用`bigip_user`模块创建新用户，并使用`provider`属性提供建立 HTTPS 连接的参数。我们循环遍历我们的`users`变量中的所有用户来供应他们。

第二个任务还使用`bigip_user`模块来更新 LTM 上的默认`admin`配置文件，并将该默认密码更改为在`admin_passwd`变量中指定的新密码。

在剧本层面，我们将连接设置为`local`。这是因为我们要从 Ansible 控制机建立 HTTPS 连接，我们要防止 Ansible 使用 **Secure Shell** ( **SSH** )连接到 LTM 节点。

以下屏幕截图显示了在大 IP 节点上创建的新 Ansible 用户:

![](assets/e027eff4-2fc6-421a-8c26-9ce4f291d62f.png)

以下屏幕截图显示了使用行动手册创建的 Ansible 用户的详细信息:

![](assets/42db9ea5-67fc-498c-a7ca-f76a2b83a20d.png)

We are using a plaintext password for simplicity; however, a plaintext password should never be used. Ansible Vault should be used to secure the password.

# 还有更多...

添加新的 Ansible 用户后，我们用自己创建的新用户更新`conn_parameters`词典。我们可以开始管理该用户的 LTM 节点，如下所示:

```
$ cat group_vars/all.yml
conn_parameters:
 user: Ansible
 password: Ansible123
 server: "{{ Ansible_host }}"
 server_port: 443
 validate_certs: no
< -- Output Omitted for brevity --> 
```

# 在大知识产权设备上配置通用系统选项

在本食谱中，我们将概述如何在大知识产权节点上配置一些基本的系统选项，如主机名、**域名系统** ( **域名系统**)和**网络时间协议** ( **NTP** )。我们将了解如何使用各种可用的 Ansible 模块设置所有这些系统级参数。

# 准备好

为了遵循这个配方，假设已经建立了一个 Ansible 库存。使用正确的用户凭据，Ansible 和 BIG-IP 节点之间的 IP 连接已经建立。

# 怎么做...

1.  用以下系统级参数更新`group_vars/all.yml`文件:

```
$ cat group_vars/all.yml
< -- Output Omitted for brevity -->
domain: lab.net
nms_servers:
 - 172.20.1.250
```

2.  创建一个名为`tasks`的新文件夹，并创建一个包含以下内容的`f5_system.yml`文件:

```
$ cat tasks/f5_system.yml
---
- name: "Setup BIG-IP Hostname"
 bigip_hostname:
 hostname: "{{ inventory_hostname }}.{{ domain }}"
 provider: "{{ conn_parameters }}"
- name: "Setup BIG-IP DNS Servers"
 bigip_device_dns:
 ip_version: '4'
 name_servers: "{{ nms_servers }}"
 provider: "{{ conn_parameters }}"
- name: "Setup BIG-IP NTP Servers"
 bigip_device_ntp:
 ntp_servers: "{{ nms_servers }}"
 provider: "{{ conn_parameters }}"
```

3.  在`pb_f5_onboard.yml`文件中，添加以下突出显示的任务:

```
$ cat pb_f5_onboard.yml
< -- Output Omitted for brevity -->
- name: "P1T3: Configure System Parameters"
 import_tasks: "tasks/f5_system.yml"
 tags: system
```

# 它是如何工作的...

为了在 BIG-IP 节点上配置各种系统参数，我们为每个任务使用一个单独的模块。我们将所有这些任务分组到一个名为`tasks`文件夹下的`f5_system.yml`文件中，在这个文件中，我们使用三个独立的任务/模块，如下所示:

*   `bigip_hostname`设置主机名
*   `bigip_device_dns`设置大 IP 节点将使用的 DNS 服务器
*   `bigip_device_ntp`在大 IP 节点上设置 NTP 服务器

所有这些模块都以`conn_parameters`字典来正确设置如何与 BIG-IP 节点的 REST API 进行通信。在我们的示例拓扑中，我们使用单个服务器作为 DNS 和 NTP。我们使用`group_vars/all.yml`文件中的`nms_servers`变量来描述它，以应用于我们的 Ansible 清单中的所有节点。

为了配置主机名，我们需要为设备提供一个**完全合格的域名** ( **FQDN** )。因此，我们在`group_vars/all.yml`文件下再次配置我们的域，并将其与设备名称结合使用来设置其主机名。

运行本行动手册后，我们可以看到该配置已应用于 BIG-IP 节点。以下屏幕截图显示主机名已正确设置:

![](assets/a93c4e9f-0d35-49f2-af99-2e69cdd359dd.png)

NTP 配置部署正确，如下图所示:

![](assets/23fdad58-75d6-4d81-b37b-0751bb0068ee.png)

域名系统配置正确，如下图所示:

![](assets/1f9537f9-1277-4ef7-b402-6987b1abdf07.png)

# 在大 IP 设备上配置接口和中继

在本食谱中，我们将概述如何在大 IP 设备上设置中继。通过将多个接口组合成一个逻辑接口，BIG-IP 节点上的中继端口用于为设备提供更多冗余。它与传统网络供应商中的端口通道非常相似。

# 准备好

为了遵循这个配方，假设已经建立了一个 Ansible 库存。使用正确的用户凭据，Ansible 和 BIG-IP 节点之间的 IP 连接已经建立。

# 怎么做...

1.  创建一个`host_vars`文件夹，创建一个`ltm01.yml`文件，内容如下:

```
$ cat host_vars/ltm01.yml
----
phy_interfaces:
 - 1.1
 - 1.2
trunks:
 - name: po1
 members: "{{ phy_interfaces }}"
```

2.  在`tasks`文件夹下，添加一个名为`f5_interfaces.yml`的新文件，内容如下:

```
$ cat tasks/f5_interfaces.yml
---
- name: Create a Port channel on BIG-IP
 bigip_trunk:
 name: "{{ item.name}}"
 interfaces: "{{ item.members }}"
 link_selection_policy: maximum-bandwidth
 frame_distribution_hash: destination-mac
 lacp_enabled: no
 provider: "{{ conn_parameters }}"
 state: present
 loop: "{{ trunks }}"
```

3.  用以下新任务更新`pb_f5_onboard.yml`行动手册:

```
$ cat pb_f5_onboard.yml
< -- Output omitted for brevity -->
- name: "P1T4: Configure Interfaces"
 import_tasks: "tasks/f5_interfaces.yml"
 tags: intfs
```

# 它是如何工作的...

我们在名为`ltm01.yml`的文件中的`host_vars`文件夹下定义 LTM 设备的主机特定数据。在这个文件中，我们在`phy_interfaces`变量下定义了 LTM 节点上的物理接口。为了定义设备上可用的中继，我们定义了另一个名为`trunks`的变量。在`trunks`变量中，为了限制数据重复，我们引用了`phy_interfaces`变量。

在`f5_interfaces.yml`任务文件中，我们使用`bigip_trunk`模块添加了一个新任务，以在 BIG-IP 节点上提供所需的中继。我们循环使用`trunks`数据结构来提供所有需要的中继端口。在本任务中，我们提供了调整中继属性的不同参数(例如禁用**链路聚合控制协议** ( **LACP** ))并设置了在中继端口之间分发帧的正确方法。

运行行动手册后，我们可以看到所需的中继接口已配置完毕，如下图所示:

![](assets/70a5696e-b909-4f39-9818-07a08c18d74d.png)

# 请参见...

有关`bigip_trunk` Ansible 模块的更多信息，以及如何在 BIG-IP 节点上部署中继端口的不同选项，请参考以下网址: [https://docs。Ansible.com/Ansible/latest/modules/bigip_trunk_module.html](https://docs.ansible.com/ansible/latest/modules/bigip_trunk_module.html)。

# 在大 IP 设备上配置虚拟局域网和自 IP

在本食谱中，我们将概述如何在大 IP 节点上配置虚拟局域网。大 IP 节点上的虚拟局域网是大 IP LTM 节点托管的不同应用流量分离的基础。它们是指定外部(面向互联网)和内部(面向服务器)域的基础。我们还将概述如何在我们提供的 VLAN 接口上分配一个 IP 地址。

# 准备好

为了遵循这个配方，假设已经建立了一个 Ansible 库存。使用正确的用户凭据，Ansible 和 BIG-IP 节点之间的 IP 连接已经建立。由于此设置中的所有虚拟局域网都将部署在中继端口上，因此我们需要按照前面的方法，已经配置了中继端口。

# 怎么做...

1.  用以下 VLAN 数据更新`host_vars`文件夹下的`host_vars/ltm01.yml`文件:

```
$ cat host_vars/ltm01.yml
< -- Output Omitted for brevity -->
vlans:
 - vlan: 100
 description: Extrnal VLAN (Internet)
 ip: 10.1.100.254/24
 tagged_intf: po1
 - vlan: 10
 description: Server VLAN10 (Internal)
 ip: 10.1.10.254/24
 tagged_intf: po1
```

2.  用配置虚拟局域网的任务更新`tasks`文件夹下的`f5_interfaces.yml`文件，如下所示:

```
$ cat tasks/f5_interfaces.yml
< -- Output Omitted for brevity -->
- name: Create VLANs on BIG-IP
 bigip_vlan:
 tagged_interfaces: "{{ item.tagged_intf }}"
 name: "VL{{item.vlan}}"
 description: "{{ item.description }}"
 tag: "{{item.vlan}}"
 provider: "{{ conn_parameters }}"
 state: present
 loop: "{{ vlans }}"
```

3.  更新`tasks`文件夹下的`f5_interfaces.yml`文件，任务是在各自的虚拟局域网上设置 IP 地址，如下所示:

```
$ cat tasks/f5_interfaces.yml
< -- Output Omitted for brevity -->
- name: Provision IP addresses on BIG-IP
 bigip_selfip:
 address: "{{ item.ip | ipv4('address') }}"
 name: "VL{{ item.vlan }}_IP"
 netmask: "{{ item.ip | ipv4('netmask') }}"
 vlan: "VL{{ item.vlan }}"
 provider: "{{ conn_parameters }}"
 state: present
 loop: "{{ vlans }}"
```

# 它是如何工作的...

我们在`host_vars/ltm01.yml`中添加`vlans`数据结构来声明我们需要在 LTM 节点上提供的所有虚拟局域网，以及与这个 VLAN 相关联的 IP 地址。

我们使用任务更新`f5_interfaces.yml`文件，使用`bigip_vlan`模块在 BIG-IP 节点上配置虚拟局域网，并且我们循环使用`vlans`数据结构来提取所有需要的参数来设置需要的虚拟局域网。接下来，我们使用`bigip_selfip` Ansible 模块添加另一个任务，在虚拟局域网上部署 IP 地址。

再次运行剧本后，我们可以看到大 IP 节点上的 VLANs 和自 IP，如下图所示:

![](assets/fe846472-f643-46dc-8c0a-34c03e1bb338.png)

正确的 IP 地址在 VLAN 接口上配置正确，如下图所示:

![](assets/e02acc83-96e3-449d-b708-9ff502f6b703.png)

# 请参见...

有关如何在大 IP 节点上部署虚拟局域网和自 IP 的更多选项，请参考以下网址:

`bigip-vlan`
[https://docs . ansi ble . com/ansi ble/latest/modules/bigip _ VLAN _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_vlan_module.html)

`bigip-selfip`
[https://docs。ansi ble . com/ansi ble/latest/modules/bigip _ self IP _ module . html # bigip-self IP-module](https://docs.ansible.com/ansible/latest/modules/bigip_selfip_module.html#bigip-selfip-module)

# 在大 IP 设备上配置静态路由

在大 IP 设备上部署虚拟局域网和 IP 地址后，我们需要在大 IP 节点上配置路由，以便到达外部目的地。我们在拓扑中使用静态路由，以便在 LTM 节点上提供所需的路由。在本食谱中，我们将概述如何在大 IP 设备上配置静态路由。

# 准备好

按照这个方法，假设已经建立了 Ansible 清单，并且 Ansible 和 BIG-IP 节点之间的 IP 连接已经建立，并且具有正确的用户凭证。此外，我们需要按照前面的方法，在大 IP 节点中部署虚拟局域网和 IP 地址。

# 怎么做...

1.  用以下路由数据更新`host_vars/ltm01.yml`文件:

```
$ cat host_vars/ltm01.yml
< -- Output Omitted for brevity -->
routes:
 - dst: 0.0.0.0/0
 gw: 10.1.100.1
 name: default_route
```

2.  用以下任务更新`pb_f5_onboard.yml`文件:

```
$ cat pb_f5_onboard.yml
< -- Output Omitted for brevity -->
- name: "P1T5: Setup External Routing"
 bigip_static_route:
 destination: "{{ item.dst.split('/')[0] }}"
 netmask: "{{item.dst | ipv4('prefix')}}"
 gateway_address: "{{ item.gw }}"
 name: "{{ item.name }}"
 provider: "{{ conn_parameters }}"
 loop: "{{ routes }}"
 tags: routing
```

# 它是如何工作的...

我们在`host_vars/ltm01.yml`文件下添加`routes`数据结构，以声明需要在 LTM 节点上提供的所有静态路由。

我们更新`pb_f5_onboard.yml`行动手册，任务是使用`bigip_static_route`模块提供静态路由，我们循环使用`routes`数据结构来提供设备上所有需要的路由。

再次运行剧本后，我们可以看到正确的静态路由，如下图所示:

![](assets/6e89a8c6-85b8-4d73-949c-e8fe27fc2cba.png)

# 在大知识产权设备上部署节点

使用 BIG-IP LTM 部署应用需要在多台服务器之间实现应用流量的负载平衡。这要求我们定义托管应用的服务器/实例。在大 IP 中，这些实例被称为节点，它们用唯一的 IP 地址标识每台服务器。在这个食谱中，我们将开始在 BIG-IP 设备上部署一个新的应用(web 服务器)，并且我们将使用 Ansible 提供承载该服务的节点。

# 准备好

BIG-IP 的基本设置应该已经按照前面的方法完成，并且必须部署到达这些节点(物理服务器)的正确虚拟局域网。

# 怎么做...

1.  创建一个名为`web_app.yml`的新 YAML 文件，内容如下:

```
---
vip: 10.1.100.100
vip_port: 443
endpoint: dev.internet.net
pool_name: dev_web_app
pool_members:
 - ip: 10.1.10.10
 name: "dev01.internal.net"
 port: 443
 - ip: 10.1.10.11
 name: "dev01\. internal.net"
 port: 443
```

2.  创建名为`pb_f5_deploy_app.yml`的新 Ansible 行动手册，内容如下:

```
---
- name: Deploying a New App on BIG-IP
 hosts: ltm01
 connection: local
 vars_file: web_app.yml
 tasks:
 - name: "Create Nodes on BIG-IP"
 bigip_node:
 address: "{{ item.ip }}"
 name: "{{ item.name }}"
 provider: "{{ conn_parameters }}"
 state: present
 loop: "{{ pool_members }}"
```

# 它是如何工作的...

我们在一个名为`web_app.yaml`的 YAML 文件中定义了新网络应用的所有参数，该应用应该托管在 BIG-IP LTM 设备上。在这个文件中，我们包含一个`pool_members`参数来概述将容纳应用的网络服务器。我们使用此参数在大 IP LTM 上创建节点。

我们为应用部署创建了一个新的剧本，叫做`pb_f5_deploy_app.yml`。我们包含`web_app.yml`文件，以便访问为此应用定义的所有参数。我们使用`bigip_node`模块创建一个新任务，在大 IP 设备上配置一个新节点，并循环使用从`web_app.yml`文件中导出的`pool_members`参数，在大 IP 设备上配置所有需要的节点。为了连接到 BIG-IP 节点，我们使用在`group_vars/all.yml`文件中定义的带有`conn_parameters`参数的相同的先前提供者属性来建立与 BIG-IP 的连接。

运行本行动手册，我们创建了所有必需的节点，如下图所示:

![](assets/3e0103c7-336a-4e03-92e5-caf6650a098a.png)

# 在大 IP 设备上配置负载平衡池

在 BIG-IP 上创建一个节点后，我们需要为正在部署的应用创建一个负载平衡池，并将我们创建的节点中的池成员分配到该池中。在本食谱中，我们将概述如何在大 IP 节点上调配负载平衡池，以及如何向负载平衡池分配成员。

# 准备好

此方案假设所有以前的方案都已实施，并且根据以前的方案，BIG-IP 上的节点已经配置完毕。

# 怎么做...

1.  使用以下任务更新`pb_f5_deploy_app.yml`行动手册以创建新池:

```
- name: Create New LB Pool
 bigip_pool:
 name: "POOL_{{ website }}_{{ vip_port }}"
 lb_method: round-robin
 state: present
 provider: "{{ conn_parameters }}"
```

2.  使用以下任务更新`pb_f5_deploy_app.yml`行动手册，将池成员分配给新创建的池:

```
- name: Add Members to the Pool
 bigip_pool_member:
 pool: "POOL_{{ website }}_{{ vip_port }}"
 host: "{{ item.ip }}"
 name: "{{ item.name }}"
 port: "{{ item.port }}"
 description: "Web Server for {{ website }}"
 provider: "{{ conn_parameters }}"
 loop: "{{ pool_members }}"
```

# 它是如何工作的...

在这个配方中，我们使用`bigip_pool`模块在 BIG-IP 系统上创建了一个负载平衡池，并且我们指定了应该在这个池中使用的负载平衡技术。在这个例子中，我们使用的是`round-robin`技术。我们使用从`web_app.yml`文件(主要是网站和`vip_port`提取的不同参数创建池名。

接下来，我们使用`bigip_pool_member`模块将池成员分配给这个新创建的池，并遍历在`web_app.yml`文件中定义的所有`pool_members`。

我们可以看到，所有这些过程都为定义池名称以及将所需的池成员分配给正确的池成员创建了一致的方法。所有的信息都是从一个单一的定义文件中获取的，该文件描述并概述了应该如何部署服务。

运行这两个任务，我们将看到使用正确的池成员正确创建了池，如下图所示:

![](assets/f819655c-1d20-4c4d-a3cf-3ae7b81da67f.png)

以下屏幕截图显示了当前成员:

![](assets/dd97973c-1947-4845-8522-000e93f7e12a.png)

# 请参见...

在本食谱中，我们概述了 Ansible 模块在 BIG-IP 节点上调配负载平衡池的基本用途。但是，这些模块有更多的选项可用，例如为每个成员指定负载平衡比率，以及为整个池附加监视器。有关更多选项，请参考以下网址:

*   `bigip_pool` : [https://docs。Ansible.com/Ansible/latest/modules/bigip_pool_module.htmlb](https://docs.ansible.com/ansible/latest/modules/bigip_pool_module.html)
*   `bigip_pool_member` : [https://docs。ansi ble . com/ansi ble/最新/模块/bigip _ pool _ member _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_pool_member_module.html#bigip-pool-member-module)

# 在大知识产权设备上配置虚拟服务器

在 BIG-IP LTM 上部署应用进行负载平衡的最后一部分是在 BIG-IP LTM 节点上配置虚拟服务器，并在 BIG-IP 节点上为此虚拟服务器创建一个**虚拟 IP** ( **VIP** )。在本食谱中，我们概述了如何使用 Ansible 部署虚拟服务器。

# 准备好

此方案假设所有以前的方案都已完成，并且已经配置了负载平衡池和池成员。

# 怎么做...

1.  使用以下任务更新`pb_f5_deploy_app.yml`行动手册:

```
- name: Create Virtual Server
 bigip_virtual_server:
 name: "{{ website }}_{{ vip_port }}_VS"
 destination: "{{ vip }}"
 port: "{{ vip_port}}"
 pool: "POOL_{{ website }}_{{ vip_port }}"
 description: "VIP for {{ website }}"
 profiles:
 - http
 - name: clientssl
 context: client-side
 - name: serverssl
 context: server-side
 state: present
 provider: "{{ conn_parameters }}"
```

# 它是如何工作的...

我们使用`bigip_virtual_server`模块，通过指定`web_app.yml`文件中定义的参数，在 BIG-IP 设备上配置所需的虚拟服务器。我们还定义和提供需要应用于新创建的虚拟服务器的配置文件。这些配置文件是 HTTP 和 SSL 配置文件。默认情况下，这些概要文件已经在 BIG-IP 节点上创建，在我们需要创建自定义概要文件的情况下，我们需要在一个单独的任务中使用适当的 Ansible 模块来创建这些概要文件。

运行最后一个任务，我们可以看到创建了虚拟服务器，如下图所示:

![](assets/3f6ccbc6-1552-4b76-b73d-4748a42fc8bb.png)

在最后一个任务中，我们在 LTM 节点上创建了一个功能服务 VIP，以便开始处理新网站的 HTTP 请求，并在负载平衡组中的所有实例之间负载平衡流量。

# 请参见...

在本食谱中，我们讨论了 Ansible 模块在 BIG-IP 节点上配置虚拟服务器的基本用法。但是，为了调整需要部署的虚拟服务器的配置，有更多的选项可用。

有更多的 Ansible 模块可以让您创建可用于连接到虚拟服务器的配置文件，以下是这些模块的一些链接:

*   `bigip_virtual_server` : [https://docs。ansi ble . com/ansi ble/最新/模块/bigip _ virtual _ server _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_virtual_server_module.html#bigip-virtual-server-module)
*   `bigip_profile_http` : [https://docs。ansi ble . com/ansi ble/latest/modules/bigip _ profile _ http _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_profile_http_module.html#bigip-profile-http-module)
*   `bigip_profile_client_ssl` : [https://docs。ansi ble . com/ansi ble/latest/modules/bigip _ profile _ client _ SSL _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_profile_client_ssl_module.html#bigip-profile-client-ssl-module)
*   `bigip_profile_server_ssl` : [https://docs。ansi ble . com/ansi ble/最新/模块/bigip _ profile _ server _ SSL _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_profile_server_ssl_module.html#bigip-profile-server-ssl-module)

# 从大知识产权节点检索运营数据

在本食谱中，我们概述了如何根据大 IP 节点的网络状态(如接口和虚拟局域网)检索大 IP 设备上不同组件的操作数据，以及与负责应用交付的组件(如虚拟服务器和池)相关的数据。

# 准备好

按照这个方法，假设已经建立了 Ansible 清单，并且 Ansible 和 BIG-IP 节点之间的 IP 连接已经建立，并且具有正确的用户凭证。

# 怎么做...

1.  创建新的 Ansible 行动手册`pb_f5_validate.yml`，内容如下:

```
---
- name: Validating BIG-IP Health
 hosts: ltm01
 connection: local
 tasks:
 - name: Collect Device Facts from BIG-IP
 bigip_device_facts:
 gather_subset:
 - interfaces
 provider: "{{ conn_parameters }}"
 register: bigip_facts
```

2.  使用新任务更新行动手册，以过滤界面事实，如下所示:

```
 - name: Set Device Links
 set_fact:
 net_intfs: "{{ net_intfs | default([]) +
 bigip_facts.interfaces | selectattr('name','equalto',item|string) | list }}"
 loop: "{{ phy_interfaces }}"
```

3.  用新任务更新`pb_f5_validate.yml`行动手册以验证界面状态，如下所示:

```
 - name: Validate All Interface are operational
 assert:
 that:
 - item.enabled == 'yes'
 fail_msg: " Interface {{ item.name }} is Down"
 loop: "{{net_intfs}}"
```

# 它是如何工作的...

BIG-IP 节点上支持的 REST API 使用不同的方法从设备中检索操作数据，并且它以 JSON 格式输出所有这些数据。以下片段概述了使用`bigip_device_facts`模块从大 IP 节点收集的接口状态:

```
"bigip_facts": {
< -- Output Omitted for brevity -->
 "interfaces": [
 {
 "active_media_type": "10000T-FD",
 "bundle": "not-supported",
 "bundle_speed": "not-supported",
 "enabled": "yes",
 "flow_control": "tx-rx",
 "full_path": "1.1",
 "if_index": 48,
 "lldp_admin": "txonly",
 "mac_address": "00:50:00:00:01:01",
 "media_sfp": "auto",
 "mtu": 1500,
 "name": "1.1",
 < -- Output Omitted for brevity -->
 }
```

我们使用`bigip_device_facts`从 BIG-IP 节点检索操作事实，并使用`gather_subset`仅限制从节点检索的数据。我们包含`interfaces`选项只是为了获取接口数据。我们将所有检索到的输出保存到`bigip_facts`变量中。

我们为这个设备创造了一个新的事实，叫做`net_intfs`。这个新事实的唯一用途是将从上一个任务中检索到的接口事实过滤到我们在`phy_interfaces`参数(在`host_vars`文件夹下定义)中为设备定义的接口中。这个新参数将只包括我们在设计中声明的接口的接口事实。

我们使用`assert`模块来验证我们为应用定义的所有接口都已启用，并且可以从检索到的数据进行操作，我们循环使用`net_intfs`变量(这是一个列表)来循环所有接口，并确认它们已启用。

# 还有更多...

如果我们需要获取我们已经在 LTM 节点上部署的应用的操作数据，我们将创建一个新的行动手册来验证应用部署，如下面的代码所示，使用`bigip_device_facts`模块。我们将检索的数据仅限于虚拟服务器。我们使用`assert`语句来验证数据，就像我们在之前的剧本中所做的那样。以下代码显示了应用部署验证的行动手册内容。

1.  我们创建了一个新的剧本`pb_f5_app_validate.yml`，其任务是收集`virtual-servers`事实:

```
---
- name: Validating BIG-IP App Health
 hosts: ltm01
 connection: local
 vars_files: web_app.yml
 tasks:
 - name: Collect Virtual-Servers Facts from BIG-IP
 bigip_device_facts:
 gather_subset:
 - virtual-servers
 provider: "{{ conn_parameters }}"
 register: bigip_app_facts
```

2.  我们使用以下任务更新行动手册，以过滤`virtual-servers`事实:

```
    - name: Create Virtual Server Name Fact
 set_fact:
 vs_name: "{{ website }}_{{ vip_port }}_VS" - name: Create App Virtual Servers
 set_fact:
 app_vs: "{{ app_vs | default([]) +
 bigip_app_facts.virtual_servers | selectattr('name','equalto',vs_name) | list }}"
```

3.  我们使用以下任务更新行动手册，以验证我们应用的虚拟服务器状态:

```
    - name: Validate Virtual Address Status
 assert:
 that:
 - item.enabled == 'yes'
 - item.destination_address == vip
 - item.destination_port == vip_port
 fail_msg: " {{ item.name }} is No Setup Correctly"
 loop: "{{app_vs}}"
```

这些验证行动手册可以扩展到验证虚拟服务器上的多个参数。此外，我们还可以验证其他组件，如 LTM 负载平衡池，以便为部署的应用构建更全面的验证。

# 请参见...

有关 Ansible `bigip_device_facts`模块的更多信息以及我们可以从 BIG-IP 节点检索的所有信息，请访问以下网站: [https://docs。ansi ble . com/ansi ble/latest/modules/bigip _ device _ facts _ module . html](https://docs.ansible.com/ansible/latest/modules/bigip_device_facts_module.html#bigip-device-facts-module)。