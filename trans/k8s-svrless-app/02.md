# 《忽必烈的概论》

正如上一章末尾提到的，在这一章中，我们将研究 Kubernetes。我们将讨论:

*   库本内特斯简史——它来自哪里？
*   它是如何运作的？
*   Kubernetes 有哪些用例，谁在使用它？
*   为什么要在服务器上无服务器运行？

# 库本内特斯简史

在讨论 Kubernetes 来自哪里之前，我们应该先快速讨论一下 Kubernetes 是什么。发音为 **koo-ber-net** **-eez** ，有时也被称为 **K8s** 。 **Kubernetes** 是一艘船的舵手或引航员的希腊语名字，当你考虑 Kubernetes 的设计意图时，这个名字很贴切。你可以在[https://kubernetes.io/](https://kubernetes.io/)找到这个项目的网站，描述为:

"An open-source system for automating deployment, scaling, and management of containerized applications."

该项目源于谷歌内部的一个名为**博格**的项目。早在 Docker 引起轰动之前，谷歌就已经是容器技术的长期用户。

# 对照组

谷歌自己的集装箱之旅始于 2006 年，当时他们的两名工程师启动了**控制组** ( **控制组**)**T5 项目。这是 Linux 内核的特性，它可以为一组进程隔离内存、中央处理器、网络和磁盘输入/输出等资源。cgroups 最初于 2007 年发布，2008 年初，该功能被合并到 Linux 内核主线版本 2.6.24 中。**

You can find the release notes for version 2.6.24 of the Linux kernel at [https://kernelnewbies.org/Linux_2_6_24](https://kernelnewbies.org/Linux_2_6_24). You can find information about the introduction of cgroups at *point 10* in the *Important things* list where it discusses the framework that allows cgroups to hook into the kernel.

# lmgtfy

几年后的 2013 年 10 月，谷歌发布了自己容器系统的开源版本 **lmctfy** ，其实就是**让我为你包容**的简称。这个工具实际上是他们在自己的服务器上使用的，使他们能够运行 Linux 应用容器，它是作为 LXC 的一个替代物而设计的。

lmctfy、LXC 和 Docker 都占据了相同的空间。为此，谷歌实际上在 2015 年停止了 lmctfy 上的所有开发。该项目的 GitHub 页面发布公告称，谷歌一直在与 Docker 合作，他们正在将 lmctfy 的核心概念移植到 libcontainer。

# 博格

这就是博格项目的切入点。谷歌经常使用容器，当我说很多的时候，我指的是*很多*。2014 年 5 月，来自谷歌的乔·贝达在 Gluecon 做了一个题为“T2”的演讲。演示文稿中有几个要点，例如:

"Everything at Google runs in a container."

被谈论最多的是:

"We start over 2 billion containers per week."

这个数字约为每秒 3000 个，在谈话中，有人提到这个数字不包括任何长时间运行的容器。

虽然乔详细介绍了当时谷歌是如何使用容器的，但他没有直接提到博格项目；相反，它被简单地称为集群调度器。

演示的最后一部分是标题为*宣告式优先于命令式*的幻灯片，它介绍了以下概念:

*   **命令**:在那个服务器上启动这个容器
*   **声明性**:以< = 2 个任务为目标，随时运行该容器的 100 个副本

这个概念解释了谷歌如何能够每周推出这 20 亿个容器，而不必真正管理超过 20 亿个容器。

直到谷歌在 2015 年发表了一篇名为*谷歌与博格*的大规模集群管理的论文，我们才真正了解到乔·贝达前一年提到的集群调度器的实践和设计决策。

这篇文章讨论了谷歌的内部工具博格是如何管理成千上万个工作岗位的，这些工作岗位构成了谷歌在由成千上万台机器组成的集群中几乎所有的应用。

然后它继续揭示面向客户的服务，如谷歌邮件、谷歌文档和谷歌搜索，都是由博格管理的集群以及他们自己的内部工具提供的。它详细说明了用户可以用来声明其所需状态的作业规范语言，使用户可以轻松地部署他们的应用，而不必担心在谷歌基础设施的高可用性配置中部署他们的应用所需的所有步骤。

我建议通读这篇论文，因为它很好地概述了谷歌如何处理自己的容器服务。

另外，如果你想知道，博格是根据《星际迷航:下一代》电视节目中的外星种族命名的。

# 项目七

2014 年，乔·贝达、布兰登·伯恩斯和克雷格·麦克卢基与布莱安·葛兰特和蒂姆·霍金一起参加了第七项目。

这个项目以《星际迷航》中的角色“T2”命名，旨在制作一个更友好的博格版本。到第一次提交时，该项目有了一个外部名称，Kubernetes。

You can see the first commit at [https://github.com/kubernetes/kubernetes/commit/2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56 ](https://github.com/kubernetes/kubernetes/commit/2c4b3a562ce34cddc3f8218a2c4d11c7310e6d56)and the first really stable release, which came four months later, can be found at [https://github.com/kubernetes/kubernetes/releases/tag/v0.4](https://github.com/kubernetes/kubernetes/releases/tag/v0.4).

最初，Kubernetes 的目标是利用谷歌从博格那里学到的一切，运行其大型容器集群，并将其开源，作为吸引客户使用谷歌自己的公共云平台的一种方式——这就是为什么您可能仍然可以在[https://github.com/GoogleCloudPlatform/kubernetes/](https://github.com/GoogleCloudPlatform/kubernetes/)找到该项目的原始 GitHub 页面的参考。

然而，到 2015 年 7 月 1.0 发布时，谷歌已经看到它很快变得远远不止于此，他们加入了 Linux 基金会、推特、英特尔、Docker 和 VMware(仅举几例)组成了云原生计算基金会。作为这一新伙伴关系的一部分，谷歌捐赠了 Kubernetes 项目作为新集团的基础。

此后，其他项目也加入了 Kubernetes，例如:

*   普罗米修斯([https://prometheus.io/](https://prometheus.io/))最初由 SoundCloud 开发，是一个时间序列数据库，可以用来存储指标
*   fluentd([https://www.fluentd.org/](https://www.fluentd.org/))是一个数据收集器，允许您从许多不同的来源获取数据，对其进行过滤或规范化，然后将其路由到存储引擎，如 Elasticsearch、MongoDB 或 Hadoop(仅举几例)
*   containerd([http://containerd.io/](http://containerd.io/))是一个开源的容器运行时，最初由 Docker 开发来实现开放容器倡议标准
*   CoreDNS([https://coredns.io/](https://coredns.io/))是一个完全基于插件构建的 DNS 服务，这意味着您可以创建传统上配置起来极其复杂的 DNS 服务

除此之外，新成员如 AWS、微软、红帽和甲骨文都向基金会的项目提供支持和资源。

# 库本内特斯概述

现在我们已经了解了 Kubernetes 是如何形成的，我们应该了解构成典型 Kubernetes 集群的所有不同组件。

Kubernetes 本身就是用 Go 写的。虽然项目的 GitHub 页面显示项目目前是 84.9% Go，剩下的，5.8% HTML，4.7% Python，3.3% Shell(剩下的是配置/规范文件等等)，都是文档和助手脚本。

Go is a programming language developed and open sourced by Google who describes it as *A fast, statically typed, compiled language that feels like a dynamically typed, interpreted language.* For more information, see [https://golang.org/](https://golang.org/).

# 成分

Kubernetes 有两个主要的服务器角色:主机和节点；这些角色中的每一个都由几个组件组成。

主服务器是集群的大脑，它们决定在集群中的什么位置部署吊舱(下一节将详细介绍)，并不仅对集群，而且对吊舱本身的运行状况采取行动和查看。

主服务器的核心组件是:

*   `kube-apiserver`:这是你的 Kubernetes 控制面板的前端；无论您使用什么来管理集群，它都将直接与这个 API 服务进行对话。
*   `etcd` : `etcd`是一个分布式键值存储，Kubernetes 使用它来存储集群的状态。
*   `kube-controller-manager`:这个服务做后台工作，维护你的集群。它寻找加入和离开集群的节点，确保运行正确数量的吊舱，以及它们是健康的等等。
*   `cloud-controller-manager`:这项服务对于 Kubernetes 来说是全新的。它与`kube-controller-manager`一起工作，其目的是与云提供商(如 AWS、谷歌云和微软 Azure)的应用编程接口进行交互。它执行的任务的一个例子是，如果要从集群中删除一个节点，它将检查您的云服务应用编程接口，以查看该节点是否仍然存在。如果是这样，那就有问题了；如果不是，那么很可能该节点已经因为缩放事件而被移除。
*   `kube-scheduler`:这将根据一系列规则、利用率和可用性来选择吊舱应该在哪里发射。

接下来是节点。一旦部署，主节点就与安装在节点上的组件进行交互，以实现集群内的更改；这是你的吊舱运行的地方。

组成节点的组件包括:

*   `kubelet`:这是节点上运行的主要组件。它负责接受来自主服务器的指令并向主服务器报告。
*   `kube-proxy`:该服务帮助集群通信。它充当节点上所有网络流量的基本代理，并能够配置 TCP/UDP 转发或充当多个后端的 TCP/UDP 循环负载平衡器。
*   `docker`或`rkt`:这些是节点上实际的容器引擎。`kubelet`服务与这些交互来启动和管理运行在每个集群节点上的容器。在接下来的章节中，我们将研究运行两者的启动节点。
*   `supervisord`:该流程管理器和监控器维护节点上其他服务的可用性，如`kubelet`、`docker`、`rkt`。
*   `fluentd`:该服务有助于集群级日志记录。

您可能已经注意到，这些服务中唯一提到的容器是`docker`和`rkt`。Kubernetes 实际上并不直接与您的容器交互；相反，它与一个吊舱通信。

# 吊舱和服务

如前所述，Kubernetes 不部署容器；相反，它发射吊舱。在其最简单的形式中，一个吊舱实际上可以是一个单独的容器；但是，通常一个 pod 由几个容器、存储和网络组成。

The following is meant to be illustrative and not a practical example; we will be working through a practical example in the next chapter.

将 pod 视为一个完整的应用；例如，如果您正在运行一个简单的 web 应用，它可能会运行一个 NGINX 容器，这个容器的 pod 定义文件看起来如下所示:

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 8080
```

如您所见，我们提供了一些关于 pod 的简单元数据，在本例中，它只是名称，因此我们可以识别它。然后我们定义了一个单独的容器，它运行 Docker 集线器的最新 NGINX 映像，端口`8080`被暴露。

就目前的情况来看，这个吊舱毫无用处，因为我们将只显示一个欢迎来到 nginx！佩奇。接下来，我们需要添加一个卷来存储我们的网站数据。为此，我们的 pod 定义文件如下所示:

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    volumeMounts:
    - mountPath: /srv/www
      name: web-data
      readOnly: true
    ports:
    - containerPort: 8080
 volumes:
 - name: web-data
 emptyDir: {} 
```

如您所见，我们现在正在创建一个名为`web-data`的卷，并将其以只读方式装载在`/srv/www`上，这是我们 NGINX 容器上的默认 web 根目录。这仍然有点毫无意义，因为我们的卷是空的，这意味着我们所有的访问者都会看到一个 404 页。

让我们添加第二个容器，它将从亚马逊 S3 桶同步我们网站的 HTML:

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    volumeMounts:
    - mountPath: /srv/www
      name: web-data
      readOnly: true
    ports:
    - containerPort: 8080
  - name: sync
    image: ocasta/sync-s3:latest
    volumeMounts:
    - mountPath: /data
      name: web-data
      readOnly: false
    env:
    - ACCESS_KEY: "awskey"
      SECRET_KEY: "aws_secret"
      S3_PATH: "s3://my-awesome-website/"
      SYNC_FROM_S3: "true"
  volumes:
  - name: web-data
    emptyDir: {}
```

现在我们有两个容器:NGINX 容器和运行`s3 sync`命令([https://github.com/ocastastudios/docker-sync-s3/](https://github.com/ocastastudios/docker-sync-s3/))的容器。这将把我们所有的网站数据从名为`my-awesome-website`的亚马逊 S3 桶复制到与 NGINX 容器共享的卷中。这意味着我们现在有了一个网站；请注意，这一次，当我们想要写入卷时，我们没有以只读方式装载它。

到目前为止，一切都很好，你可能在想自己；我们有一个豆荚服务于我们的网站，这是从亚马逊 S3 桶部署的，这是真的。然而，我们还没有完全完成。我们有一个正在运行的 pod，但是我们需要将该 pod 暴露给网络，以便能够在浏览器中访问它。

为此，我们需要启动一项服务。对于我们的示例，服务文件看起来类似于:

```
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
```

如您所见，服务定义看起来类似于 pod。我们正在使用元数据部分设置名称。然后我们选择我们的 NGINX 吊舱，并将端口`80`映射到端口`8080`，这就是我们的吊舱正在监听的。

如前所述，我们将在下一章启动第一个 Kubernetes 集群时更详细地了解这一点，但现在，这应该会让您很好地了解 Kubernetes 是如何结合在一起的。

# 工作量

在前一节中，我们看了 pods 和服务。虽然这些可以手动启动，但您也可以使用控制器来管理您的吊舱。这些控制器允许执行不同类型的工作负载。我们将快速了解不同类型的控制器，并讨论何时使用它们。

# replication set-复制集

副本集可用于启动和维护同一个 pod 的多个副本。例如，使用我们在上一节中讨论的 NGINX 容器，我们可以创建一个复制集，启动同一个容器的三个副本。然后，流量可以在三个吊舱之间进行负载平衡。

我们的三个单元可以分布在多台主机上，这意味着，如果一台主机因为任何原因想要消失，使我们的一个单元停止服务，它将在一个健康的节点上自动被替换。您也可以使用复制集来自动和手动添加和删除豆荚。

# 部署

你可能认为你能用复制集做的一件事是滚动升级和回滚。不幸的是，复制集只能复制同一个版本的 pod 幸运的是，这是部署的切入点。

部署控制器旨在更新复制集或 pod。让我们以 NGINX 为例。从下面的定义可以看出，我们有`3`个副本都运行 NGINX 版本`1.9.14`:

```
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.9.14
        ports:
        - containerPort: 80
```

`kubectl` is the command-line client for Kubernetes; we will be looking at this in more detail in our next chapter.

我们可以使用以下命令进行部署:

```
$ kubectl create -f nginx-deployment.yaml
```

现在假设我们想要更新所使用的 NGINX 映像的版本。我们只需要运行以下命令:

```
$ kubectl set image deployment/nginx-deployment nginx=nginx:1.13.5 deployment "nginx-deployment" image updated
```

这将依次更新每个吊舱，直到所有吊舱都运行新版本的 NGINX。

# 状态集

该控制器是 Kubernetes 公司的新产品，旨在取代 PetSets。正如你可能已经猜到的名字，作为部署的一部分，吊舱保持它们的状态。它们被设计成具有:

*   在 pod 的整个生命周期中保持一致的唯一网络标识符
*   持久存储
*   按照您定义的顺序执行优雅的部署和扩展
*   用户定义和控制的自动滚动更新

所以当名字有变化的时候，你应该把状态套当成宠物，把复制套当成牛。

# 忽必烈使用箱子

正如我们在本章中已经提到的，Kubernetes 几乎可以在任何地方运行，从您的本地机器(我们将在下一章中介绍)，从您的虚拟机基础架构的内部硬件，到 AWS、Microsoft Azure 或 Google Cloud 中的数百个公共云实例。事实上，您甚至可以用 Kubernetes 集群跨越多个环境。

这意味着，无论您在哪里运行应用，您都可以获得一致的体验，而且还可以利用底层平台的功能，如负载平衡、持久存储和自动扩展，而不必真正设计应用来意识到它正在运行，例如 AWS 或微软 Azure。

阅读成功案例时，你会注意到一个常见的线索，那就是人们在谈论不要被某个特定的供应商所束缚。由于 Kubernetes 是开源的，它们不会被任何许可成本所束缚。如果他们有问题或者想要添加功能，他们能够直接进入源代码并进行修改；他们还可以通过拉取请求将所做的任何更改贡献给项目。

此外，正如已经讨论过的，使用 Kubernetes 允许他们不受任何特定平台供应商或架构的限制。这是因为有理由假设 Kubernetes 在其他平台上安装时会以完全相同的方式运行。正因为如此，突然之间，您可以相对轻松地在提供商之间移动您的应用。

另一个常见的用例是运营团队使用 Kubernetes 作为**基础设施即服务** ( **IaaS** )平台。这允许他们通过应用编程接口、网络和 CLi 向开发人员提供他们可以使用的资源，这意味着他们可以轻松地连接到自己的工作流中。它还为本地开发提供了一致的环境，从试运行或**用户验收测试** ( **UAT** )一直到最终在生产中运行他们的应用。

这就是为什么使用 Kubernetes 来执行无服务器工作负载是一个好主意的部分原因。您没有被任何一个提供商锁定，例如 AWS 或微软 Azure。事实上，你应该把 Kubernetes 想象成一个云平台，就像我们在[第 1 章](00.html#section_9)、*无服务器景观*中看到的那样；它有一个基于网络的控制台、一个应用编程接口和一个命令行客户端。

# 参考

有几个关于 Kubernetes 的案例研究，用户在使用 Kubernetes 的过程中会详细了解这些案例:

*   **眨眼**:[https://kubernetes.io/case-studies/wink/](https://kubernetes.io/case-studies/wink/)
*   **缓冲区**:[https://kubernetes.io/case-studies/buffer/](https://kubernetes.io/case-studies/buffer/)
*   **祖先**:[https://kubernetes.io/case-studies/ancestry/](https://kubernetes.io/case-studies/ancestry/)
*   **维基媒体基金会**:[https://kubrines . io/case-studies/wiki media/](https://kubernetes.io/case-studies/wikimedia/)

以下还有讲座、采访和演讲:

*   **新时报**:[https://www.youtube.com/watch?v=P5qfyv_zGcU](https://www.youtube.com/watch?v=P5qfyv_zGcU)
*   **mon zo**:[https://www . YouTube . com/watch？v = yoy 7 dgxyk](https://www.youtube.com/watch?v=YkOY7DgXKyw)
*   **高盛**:[https://blogs . wsj . com/CIO/2016/02/24/Goldman s-software-emerge-from-small-containers/](https://blogs.wsj.com/cio/2016/02/24/big-changes-in-goldmans-software-emerge-from-small-containers/)

最后，您可以在[https://www.cncf.io/](https://www.cncf.io/)阅读更多关于云原生计算基金会的信息。

# 摘要

在这一章中，我们讲了很多关于 Kubernetes 的来源，我们还介绍了它的一些用例。我们还研究了一些基本功能。

在下一章中，我们将通过在本地安装 Minikube 来实际操作 Kubernetes。一旦我们有了本地 Kubernetes 安装，我们将准备进入[第 4 章](04.html)，*介绍无库功能*，在这里我们将开始在 Kubernetes 上部署我们的第一个无服务器功能。